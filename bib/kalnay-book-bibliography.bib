
@article{compo_twentieth_2011,
	title = {The {Twentieth} {Century} {Reanalysis} {Project}},
	volume = {137},
	issn = {0035-9009},
	url = {https://doi.org/10.1002/qj.776},
	doi = {10.1002/qj.776},
	abstract = {Abstract The Twentieth Century Reanalysis (20CR) project is an international effort to produce a comprehensive global atmospheric circulation dataset spanning the twentieth century, assimilating only surface pressure reports and using observed monthly sea-surface temperature and sea-ice distributions as boundary conditions. It is chiefly motivated by a need to provide an observational dataset with quantified uncertainties for validations of climate model simulations of the twentieth century on all time-scales, with emphasis on the statistics of daily weather. It uses an Ensemble Kalman Filter data assimilation method with background ?first guess? fields supplied by an ensemble of forecasts from a global numerical weather prediction model. This directly yields a global analysis every 6 hours as the most likely state of the atmosphere, and also an uncertainty estimate of that analysis. The 20CR dataset provides the first estimates of global tropospheric variability, and of the dataset's time-varying quality, from 1871 to the present at 6-hourly temporal and 2° spatial resolutions. Intercomparisons with independent radiosonde data indicate that the reanalyses are generally of high quality. The quality in the extratropical Northern Hemisphere throughout the century is similar to that of current three-day operational NWP forecasts. Intercomparisons over the second half-century of these surface-based reanalyses with other reanalyses that also make use of upper-air and satellite data are equally encouraging. It is anticipated that the 20CR dataset will be a valuable resource to the climate research community for both model validations and diagnostic studies. Some surprising results are already evident. For instance, the long-term trends of indices representing the North Atlantic Oscillation, the tropical Pacific Walker Circulation, and the Pacific?North American pattern are weak or non-existent over the full period of record. The long-term trends of zonally averaged precipitation minus evaporation also differ in character from those in climate model simulations of the twentieth century. Copyright ? 2011 Royal Meteorological Society and Crown Copyright.},
	number = {654},
	urldate = {2020-07-09},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Compo, G. P. and Whitaker, J. S. and Sardeshmukh, P. D. and Matsui, N. and Allan, R. J. and Yin, X. and Gleason, B. E. and Vose, R. S. and Rutledge, G. and Bessemoulin, P. and Brönnimann, S. and Brunet, M. and Crouthamel, R. I. and Grant, A. N. and Groisman, P. Y. and Jones, P. D. and Kruk, M. C. and Kruger, A. C. and Marshall, G. J. and Maugeri, M. and Mok, H. Y. and Nordli, Ø. and Ross, T. F. and Trigo, R. M. and Wang, X. L. and Woodruff, S. D. and Worley, S. J.},
	month = jan,
	year = {2011},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {data assimilation, Ensemble Kalman Filter, sea-level pressure, state estimation, surface pressure},
	pages = {1--28},
	annote = {doi: 10.1002/qj.776}
}

@article{nerger_unification_2012,
	title = {A {Unification} of {Ensemble} {Square} {Root} {Kalman} {Filters}},
	volume = {140},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/MWR-D-11-00102.1},
	doi = {10.1175/MWR-D-11-00102.1},
	abstract = {In recent years, several ensemble-based Kalman filter algorithms have been developed that have been classified as ensemble square root Kalman filters. Parallel to this development, the singular “evolutive” interpolated Kalman (SEIK) filter has been introduced and applied in several studies. Some publications note that the SEIK filter is an ensemble Kalman filter or even an ensemble square root Kalman filter. This study examines the relation of the SEIK filter to ensemble square root filters in detail. It shows that the SEIK filter is indeed an ensemble square root Kalman filter. Furthermore, a variant of the SEIK filter, the error subspace transform Kalman filter (ESTKF), is presented that results in identical ensemble transformations to those of the ensemble transform Kalman filter (ETKF), while having a slightly lower computational cost. Numerical experiments are conducted to compare the performance of three filters (SEIK, ETKF, and ESTKF) using deterministic and random ensemble transformations. The results show better performance for the ETKF and ESTKF methods over the SEIK filter as long as this filter is not applied with a symmetric square root. The findings unify the separate developments that have been performed for the SEIK filter and the other ensemble square root Kalman filters.},
	number = {7},
	urldate = {2020-07-10},
	journal = {Monthly Weather Review},
	author = {Nerger, Lars and Janjić, Tijana and Schröter, Jens and Hiller, Wolfgang},
	month = jul,
	year = {2012},
	pages = {2335--2345}
}

@article{pham_stochastic_2001,
	title = {Stochastic {Methods} for {Sequential} {Data} {Assimilation} in {Strongly} {Nonlinear} {Systems}},
	volume = {129},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/1520-0493(2001)129<1194:SMFSDA>2.0.CO;2},
	doi = {10.1175/1520-0493(2001)129<1194:SMFSDA>2.0.CO;2},
	abstract = {This paper considers several filtering methods of stochastic nature, based on Monte Carlo drawing, for the sequential data assimilation in nonlinear models. They include some known methods such as the particle filter and the ensemble Kalman filter and some others introduced by the author: the second-order ensemble Kalman filter and the singular extended interpolated filter. The aim is to study their behavior in the simple nonlinear chaotic Lorenz system, in the hope of getting some insight into more complex models. It is seen that these filters perform satisfactory, but the new filters introduced have the advantage of being less costly. This is achieved through the concept of second-order-exact drawing and the selective error correction, parallel to the tangent space of the attractor of the system (which is of low dimension). Also introduced is the use of a forgetting factor, which could enhance significantly the filter stability in this nonlinear context.},
	number = {5},
	urldate = {2020-07-10},
	journal = {Monthly Weather Review},
	author = {Pham, Dinh Tuan},
	month = may,
	year = {2001},
	pages = {1194--1207}
}

@article{keppenne_data_2000,
	title = {Data {Assimilation} into a {Primitive}-{Equation} {Model} with a {Parallel} {Ensemble} {Kalman} {Filter}},
	volume = {128},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/1520-0493(2000)128<1971:DAIAPE>2.0.CO;2},
	doi = {10.1175/1520-0493(2000)128<1971:DAIAPE>2.0.CO;2},
	abstract = {Data assimilation experiments are performed using an ensemble Kalman filter (EnKF) implemented for a two-layer spectral shallow water model at triangular truncation T100 representing an abstract planet covered by a strongly stratified fluid. Advantage is taken of the inherent parallelism in the EnKF by running each ensemble member on a different processor of a parallel computer. The Kalman filter update step is parallelized by letting each processor handle the observations from a limited region.The algorithm is applied to the assimilation of synthetic altimetry data in the context of an imperfect model and known representation-error statistics. The effect of finite ensemble size on the residual errors is investigated and the error estimates obtained with the EnKF are compared to the actual errors.},
	number = {6},
	urldate = {2020-07-10},
	journal = {Monthly Weather Review},
	author = {Keppenne, Christian L.},
	month = jun,
	year = {2000},
	pages = {1971--1981}
}

@article{hamill_distance-dependent_2001,
	title = {Distance-{Dependent} {Filtering} of {Background} {Error} {Covariance} {Estimates} in an {Ensemble} {Kalman} {Filter}},
	volume = {129},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/1520-0493(2001)129<2776:DDFOBE>2.0.CO;2},
	doi = {10.1175/1520-0493(2001)129<2776:DDFOBE>2.0.CO;2},
	abstract = {The usefulness of a distance-dependent reduction of background error covariance estimates in an ensemble Kalman filter is demonstrated. Covariances are reduced by performing an elementwise multiplication of the background error covariance matrix with a correlation function with local support. This reduces noisiness and results in an improved background error covariance estimate, which generates a reduced-error ensemble of model initial conditions.The benefits of applying the correlation function can be understood in part from examining the characteristics of simple 2 × 2 covariance matrices generated from random sample vectors with known variances and covariance. These show that noisiness in covariance estimates tends to overwhelm the signal when the ensemble size is small and/or the true covariance between the sample elements is small. Since the true covariance of forecast errors is generally related to the distance between grid points, covariance estimates generally have a higher ratio of noise to signal with increasing distance between grid points. This property is also demonstrated using a two-layer hemispheric primitive equation model and comparing covariance estimates generated by small and large ensembles. Covariances from the large ensemble are assumed to be accurate and are used a reference for measuring errors from covariances estimated from a small ensemble.The benefits of including distance-dependent reduction of covariance estimates are demonstrated with an ensemble Kalman filter data assimilation scheme. The optimal correlation length scale of the filter function depends on ensemble size; larger correlation lengths are preferable for larger ensembles.The effects of inflating background error covariance estimates are examined as a way of stabilizing the filter. It was found that more inflation was necessary for smaller ensembles than for larger ensembles.},
	number = {11},
	urldate = {2020-07-10},
	journal = {Monthly Weather Review},
	author = {Hamill, Thomas M. and Whitaker, Jeffrey S. and Snyder, Chris},
	month = nov,
	year = {2001},
	pages = {2776--2790}
}

@article{gaspari_construction_1999,
	title = {Construction of correlation functions in two and three dimensions},
	volume = {125},
	issn = {0035-9009},
	url = {https://doi.org/10.1002/qj.49712555417},
	doi = {10.1002/qj.49712555417},
	abstract = {Abstract This article focuses on the construction, directly in physical space, of simply parametrized covariance functions for data-assimilation applications. A self-contained, rigorous mathematical summary of relevant topics from correlation theory is provided as a foundation for this construction. Covariance and correlation functions are defined, and common notions of homogeneity and isotropy are clarified. Classical results are stated, and proven where instructive. Included are smoothness properties relevant to multivariate statistical-analysis algorithms where wind/wind and wind/mass correlation models are obtained by differentiating the correlation model of a mass variable. the Convolution Theorem is introduced as the primary tool used to construct classes of covariance and cross-covariance functions on three-dimensional Euclidean space R3. Among these are classes of compactly supported functions that restrict to covariance and cross-covariance functions on the unit sphere S2, and that vanish identically on subsets of positive measure on S2. It is shown that these covariance and cross-covariance functions on S2, referred to as being space-limited, cannot be obtained using truncated spectral expansions. Compactly supported and space-limited covariance functions determine sparse covariance matrices when evaluated on a grid, thereby easing computational burdens in atmospheric data-analysis algorithms. Convolution integrals leading to practical examples of compactly supported covariance and cross-covariance functions on R3 are reduced and evaluated. More specifically, suppose that gi and gj are radially symmetric functions defined on R3 such that gi(x) = 0 for {\textbar}x{\textbar} {\textgreater} di and gj(x) = 0 for {\textbar}xv {\textgreater} dj, O {\textless} di,dj ?, where {\textbar}. {\textbar} denotes Euclidean distance in R3. the parameters di and dj are ?cut-off? distances. Closed-form expressions are determined for classes of convolution cross-covariance functions Cij(x,y) := (gi * gj)(x-y), i ? j, and convolution covariance functions Cii(x,y) := (gi * gi)(x-y), vanishing for {\textbar}x - y{\textbar} {\textgreater} di + dj and {\textbar}x - y{\textbar} {\textgreater} 2di, respectively, Additional covariance functions on R3 are constructed using convolutions over the real numbers R, rather than R3. Families of compactly supported approximants to standard second- and third-order autoregressive functions are constructed as illustrative examples. Compactly supported covariance functions of the form C(x,y) := Co({\textbar}x - y{\textbar}), x,y ? R3, where the functions Co(r) for r ? R are 5th-order piecewise rational functions, are also constructed. These functions are used to develop space-limited product covariance functions B(x, y) C(x, y), x, y ? S2, approximating given covariance functions B(x, y) supported on all of S2 ? S2.},
	number = {554},
	urldate = {2020-07-09},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Gaspari, Gregory and Cohn, Stephen E.},
	month = jan,
	year = {1999},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {Compactly supported, Convolution, Correlation functions, Data assimilation, Space-limited},
	pages = {723--757},
	annote = {doi: 10.1002/qj.49712555417}
}

@article{mitchell_ensemble_2002,
	title = {Ensemble {Size}, {Balance}, and {Model}-{Error} {Representation} in an {Ensemble} {Kalman} {Filter}*},
	volume = {130},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/1520-0493(2002)130<2791:ESBAME>2.0.CO;2},
	doi = {10.1175/1520-0493(2002)130<2791:ESBAME>2.0.CO;2},
	abstract = {The ensemble Kalman filter (EnKF) has been proposed for operational atmospheric data assimilation. Some outstanding issues relate to the required ensemble size, the impact of localization methods on balance, and the representation of model error.To investigate these issues, a sequential EnKF has been used to assimilate simulated radiosonde, satellite thickness, and aircraft reports into a dry, global, primitive-equation model. The model uses the simple forcing and dissipation proposed by Held and Suarez. It has 21 levels in the vertical, includes topography, and uses a 144 × 72 horizontal grid. In total, about 80 000 observations are assimilated per day.It is found that the use of severe localization in the EnKF causes substantial imbalance in the analyses. As the distance of imposed zero correlation increases to about 3000 km, the amount of imbalance becomes acceptably small.A series of 14-day data assimilation cycles are performed with different configurations of the EnKF. Included is an experiment in which the model is assumed to be perfect and experiments in which model error is simulated by the addition of an ensemble of approximately balanced model perturbations with a specified statistical structure. The results indicate that the EnKF, with 64 ensemble members, performs well in the present context.The growth rate of small perturbations in the model is examined and found to be slow compared with the corresponding growth rate in an operational forecast model. This is partly due to a lack of horizontal resolution and partly due to a lack of realistic parameterizations. The growth rates in both models are found to be smaller than the growth rate of differences between forecasts with the operational model and verifying analyses. It is concluded that model-error simulation would be important, if either of these models were to be used with the EnKF for the assimilation of real observations.},
	number = {11},
	urldate = {2020-07-10},
	journal = {Monthly Weather Review},
	author = {Mitchell, Herschel L. and Houtekamer, P. L. and Pellerin, Gérard},
	month = nov,
	year = {2002},
	pages = {2791--2808}
}

@article{houtekamer_sequential_2001,
	title = {A {Sequential} {Ensemble} {Kalman} {Filter} for {Atmospheric} {Data} {Assimilation}},
	volume = {129},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/1520-0493(2001)129<0123:ASEKFF>2.0.CO;2},
	doi = {10.1175/1520-0493(2001)129<0123:ASEKFF>2.0.CO;2},
	abstract = {An ensemble Kalman filter may be considered for the 4D assimilation of atmospheric data. In this paper, an efficient implementation of the analysis step of the filter is proposed. It employs a Schur (elementwise) product of the covariances of the background error calculated from the ensemble and a correlation function having local support to filter the small (and noisy) background-error covariances associated with remote observations. To solve the Kalman filter equations, the observations are organized into batches that are assimilated sequentially. For each batch, a Cholesky decomposition method is used to solve the system of linear equations. The ensemble of background fields is updated at each step of the sequential algorithm and, as more and more batches of observations are assimilated, evolves to eventually become the ensemble of analysis fields.A prototype sequential filter has been developed. Experiments are performed with a simulated observational network consisting of 542 radiosonde and 615 satellite-thickness profiles. Experimental results indicate that the quality of the analysis is almost independent of the number of batches (except when the ensemble is very small). This supports the use of a sequential algorithm.A parallel version of the algorithm is described and used to assimilate over 100 000 observations into a pair of 50-member ensembles. Its operation count is proportional to the number of observations, the number of analysis grid points, and the number of ensemble members. In view of the flexibility of the sequential filter and its encouraging performance on a NEC SX-4 computer, an application with a primitive equations model can now be envisioned.},
	number = {1},
	urldate = {2020-07-10},
	journal = {Monthly Weather Review},
	author = {Houtekamer, P. L. and Mitchell, Herschel L.},
	month = jan,
	year = {2001},
	pages = {123--137}
}

@article{yoshida_correlation-cutoff_2018,
	title = {Correlation-{Cutoff} {Method} for {Covariance} {Localization} in {Strongly} {Coupled} {Data} {Assimilation}},
	volume = {146},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/MWR-D-17-0365.1},
	doi = {10.1175/MWR-D-17-0365.1},
	abstract = {Strongly coupled data assimilation (SCDA), where observations of one component of a coupled model are allowed to directly impact the analysis of other components, sometimes fails to improve the analysis accuracy with an ensemble Kalman filter (EnKF) as compared with weakly coupled data assimilation (WCDA). It is well known that an observation’s area of influence should be localized in EnKFs since the assimilation of distant observations often degrades the analysis because of spurious correlations. This study derives a method to estimate the reduction of the analysis error variance by using estimates of the cross covariances between the background errors of the state variables in an idealized situation. It is shown that the reduction of analysis error variance is proportional to the squared background error correlation between the analyzed and observed variables. From this, the authors propose an offline method to systematically select which observations should be assimilated into which model state variable by cutting off the assimilation of observations when the squared background error correlation between the observed and analyzed variables is small. The proposed method is tested with the local ensemble transform Kalman filter (LETKF) and a nine-variable coupled model, in which three Lorenz models with different time scales are coupled with each other. The covariance localization with the correlation-cutoff method achieves an analysis more accurate than either the full SCDA or the WCDA methods, especially with smaller ensemble sizes.},
	number = {9},
	urldate = {2020-07-10},
	journal = {Monthly Weather Review},
	author = {Yoshida, Takuma and Kalnay, Eugenia},
	month = aug,
	year = {2018},
	pages = {2881--2889}
}

@phdthesis{yoshida_covariance_2019,
	type = {{PhD} {Thesis}},
	title = {Covariance {Localization} in {Strongly} {Coupled} {Data} {Assimilation}},
	author = {Yoshida, Takuma},
	year = {2019}
}

@article{tremolet_accounting_2006,
	title = {Accounting for an imperfect model in {4D}-{Var}},
	volume = {132},
	number = {621},
	journal = {Quarterly Journal of the Royal Meteorological Society: A journal of the atmospheric sciences, applied meteorology and physical oceanography},
	author = {Trémolet, Yannick},
	year = {2006},
	pages = {2483--2504},
	annote = {Publisher: Wiley Online Library}
}

@phdthesis{chen_applications_2018,
	type = {{PhD} {Thesis}},
	title = {Applications of ensemble forecast sensitivity to observations for improving numerical weather prediction},
	author = {Chen, Tse-Chun},
	year = {2018}
}

@article{lorenc_forecast_2014,
	title = {Forecast sensitivity to observations in the {Met} {Office} {Global} numerical weather prediction system},
	volume = {140},
	issn = {0035-9009},
	url = {https://doi.org/10.1002/qj.2122},
	doi = {10.1002/qj.2122},
	abstract = {Abstract An adjoint-based method for calculating the impacts of observations in the Met Office's global four-dimensional variational assimilation (4D-Var) system is documented. Our approach is novel, as we seek from the outset a linearized approximation to partition the finite impact from a batch of observations, but our method and results are very similar to those of other systems. The large beneficial impacts measured for satellite radiances and radiosonde soundings in our system are interesting results. We also identify areas for potential improvement, such as the assimilation of Northern Hemisphere stratospheric satellite radio occultation (GPSRO) observations, polar atmospheric motion vectors and tropical cyclone (TC) bogus observations synthesized automatically from tropical cyclone warning centre advisory messages. We use a toy model to explain why only just over 50\% of observations improve the forecast. Growing modes, observational errors and errors in the verifying forecast contribute approximately equally and we suggest that our necessarily imperfect knowledge of background-error statistics also contributes.},
	number = {678},
	urldate = {2020-07-07},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Lorenc, Andrew C. and Marriott, Richard T.},
	month = jan,
	year = {2014},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {forecast sensitivity to observations (FSO), observation impact, observation sensitivity},
	pages = {209--224},
	annote = {doi: 10.1002/qj.2122}
}

@article{buehner_new_2018,
	title = {A {New} {Approach} for {Estimating} the {Observation} {Impact} in {Ensemble}–{Variational} {Data} {Assimilation}},
	volume = {146},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/MWR-D-17-0252.1},
	doi = {10.1175/MWR-D-17-0252.1},
	abstract = {Two types of approaches are commonly used for estimating the impact of arbitrary subsets of observations on short-range forecast error. The first was developed for variational data assimilation systems and requires the adjoint of the forecast model. Comparable approaches were developed for use with the ensemble Kalman filter and rely on ensembles of forecasts. In this study, a new approach for computing observation impact is proposed for ensemble–variational data assimilation (EnVar). Like standard adjoint approaches, the adjoint of the data assimilation procedure is implemented through the iterative minimization of a modified cost function. However, like ensemble approaches, the adjoint of the forecast step is obtained by using an ensemble of forecasts. Numerical experiments were performed to compare the new approach with the standard adjoint approach in the context of operational deterministic NWP. Generally similar results are obtained with both approaches, especially when the new approach uses covariance localization that is horizontally advected between analysis and forecast times. However, large differences in estimated impacts are obtained for some surface observations. Vertical propagation of the observation impact is noticeably restricted with the new approach because of vertical covariance localization. The new approach is used to evaluate changes in observation impact as a result of the use of interchannel observation error correlations for radiance observations. The estimated observation impact in similarly configured global and regional prediction systems is also compared. Overall, the new approach should provide useful estimates of observation impact for data assimilation systems based on EnVar when an adjoint model is not available.},
	number = {2},
	urldate = {2020-07-07},
	journal = {Monthly Weather Review},
	author = {Buehner, Mark and Du, Ping and Bédard, Joël},
	month = jan,
	year = {2018},
	pages = {447--465}
}

@article{gelaro_thorpex_2010,
	title = {The {THORPEX} {Observation} {Impact} {Intercomparison} {Experiment}},
	volume = {138},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/2010MWR3393.1},
	doi = {10.1175/2010MWR3393.1},
	abstract = {An experiment is being conducted to directly compare the impact of all assimilated observations on short-range forecast errors in different forecast systems using an adjoint-based technique. The technique allows detailed comparison of observation impacts in terms of data type, location, satellite sounding channel, or other relevant attributes. This paper describes results for a “baseline” set of observations assimilated by three forecast systems for the month of January 2007. Despite differences in the assimilation algorithms and forecast models, the impacts of the major observation types are similar in each forecast system in a global sense. However, regional details and other aspects of the results can differ substantially. Large forecast error reductions are provided by satellite radiances, geostationary satellite winds, radiosondes, and commercial aircraft. Other observation types provide smaller impacts individually, but their combined impact is significant. Only a small majority of the total number of observations assimilated actually improves the forecast, and most of the improvement comes from a large number of observations that have relatively small individual impacts. Accounting for this behavior may be especially important when considering strategies for deploying adaptive (or “targeted”) components of the observing system.},
	number = {11},
	urldate = {2020-07-07},
	journal = {Monthly Weather Review},
	author = {Gelaro, Ronald and Langland, Rolf H. and Pellerin, Simon and Todling, Ricardo},
	month = nov,
	year = {2010},
	pages = {4009--4025}
}

@article{ancell_comparing_2007,
	title = {Comparing {Adjoint}- and {Ensemble}-{Sensitivity} {Analysis} with {Applications} to {Observation} {Targeting}},
	volume = {135},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/2007MWR1904.1},
	doi = {10.1175/2007MWR1904.1},
	abstract = {The sensitivity of numerical weather forecasts to small changes in initial conditions is estimated using ensemble samples of analysis and forecast errors. Ensemble sensitivity is defined here by linear regression of analysis errors onto a given forecast metric. It is shown that ensemble sensitivity is proportional to the projection of the analysis-error covariance onto the adjoint-sensitivity field. Furthermore, the ensemble-sensitivity approach proposed here involves a small calculation that is easy to implement. Ensemble- and adjoint-based sensitivity fields are compared for a representative wintertime flow pattern near the west coast of North America for a 90-member ensemble of independent initial conditions derived from an ensemble Kalman filter. The forecast metric is taken for simplicity to be the 24-h forecast of sea level pressure at a single point in western Washington State. Results show that adjoint and ensemble sensitivities are very different in terms of location, scale, and magnitude. Adjoint-sensitivity fields reveal mesoscale lower-tropospheric structures that tilt strongly upshear, whereas ensemble-sensitivity fields emphasize synoptic-scale features that tilt modestly throughout the troposphere and are associated with significant weather features at the initial time. Optimal locations for targeting can easily be determined from ensemble sensitivity, and results indicate that the primary targeting locations are located away from regions of greatest adjoint and ensemble sensitivity. It is shown that this method of targeting is similar to previous ensemble-based methods that estimate forecast-error variance reduction, but easily allows for the application of statistical confidence measures to deal with sampling error.},
	number = {12},
	urldate = {2020-07-07},
	journal = {Monthly Weather Review},
	author = {Ancell, Brian and Hakim, Gregory J.},
	month = dec,
	year = {2007},
	pages = {4117--4134}
}

@article{sommer_observation_2014,
	title = {Observation impact in a convective-scale localized ensemble transform {Kalman} filter},
	volume = {140},
	issn = {0035-9009},
	url = {https://doi.org/10.1002/qj.2343},
	doi = {10.1002/qj.2343},
	abstract = {The aim of the present study is the accuracy and sensitivity assessment of a recently developed approximation method for observation impact, i.e. the contribution of observations to forecast-error reduction. The considered method uses an analysis and forecast ensemble for the approximation and does not require the adjoint model. The method is implemented for the first time in a convective-scale limited-area modelling system and its accuracy is assessed through comparison with results from a number of data denial experiments. It has been found that the difference from data denial is not significant and it is possible to assess the impact of subgroups of observations and detect disadvantageous or improperly used observations.},
	number = {685},
	urldate = {2020-07-07},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Sommer, Matthias and Weissmann, Martin},
	month = oct,
	year = {2014},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {data assimilation, forecast sensitivity to observations, FSO},
	pages = {2672--2679},
	annote = {doi: 10.1002/qj.2343}
}

@article{torn_ensemble-based_2008,
	title = {Ensemble-{Based} {Sensitivity} {Analysis}},
	volume = {136},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/2007MWR2132.1},
	doi = {10.1175/2007MWR2132.1},
	abstract = {The sensitivity of forecasts to observations is evaluated using an ensemble approach with data drawn from a pseudo-operational ensemble Kalman filter. For Gaussian statistics and a forecast metric defined as a scalar function of the forecast variables, the effect of observations on the forecast metric is quantified by changes in the metric mean and variance. For a single observation, expressions for these changes involve a product of scalar quantities, which can be rapidly evaluated for large numbers of observations. This technique is applied to determining climatological forecast sensitivity and predicting the impact of observations on sea level pressure and precipitation forecast metrics. The climatological 24-h forecast sensitivity of the average pressure over western Washington State shows a region of maximum sensitivity to the west of the region, which tilts gently westward with height. The accuracy of ensemble sensitivity predictions is tested by withholding a single buoy pressure observation from this region and comparing this perturbed forecast with the control case where the buoy is assimilated. For 30 cases, there is excellent agreement between these forecast differences and the ensemble predictions, as measured by the forecast metric. This agreement decreases for increasing numbers of observations. Nevertheless, by using statistical confidence tests to address sampling error, the impact of thousands of observations on forecast-metric variance is shown to be well estimated by a subset of the O(100) most significant observations.},
	number = {2},
	urldate = {2020-07-07},
	journal = {Monthly Weather Review},
	author = {Torn, Ryan D. and Hakim, Gregory J.},
	month = feb,
	year = {2008},
	pages = {663--677}
}

@article{cardinali_monitoring_2009,
	title = {Monitoring the observation impact on the short-range forecast},
	volume = {135},
	issn = {0035-9009},
	url = {https://doi.org/10.1002/qj.366},
	doi = {10.1002/qj.366},
	abstract = {Abstract This paper describes the use of forecast sensitivity to observations as a diagnostic tool to monitor the observation impact on the 24-hour forecast range. In particular, the forecast error is provided by the control experiments (using all observations available) of two sets of observing system experiments performed at ECMWF, a month in summer 2006 and a month in winter 2007, respectively. In such a way, the observation data impact obtained with the forecast sensitivity is compared with the observing system experiment's data impact; differences and similarities are highlighted. Globally, the assimilated observations decrease the forecast error; locally, some poor performances are detected that are related either to the data quality or to the suboptimality of the data assimilation system. It is also found that the synoptic situation can affect the measurements or can produce areas of large field variability that the assimilation system cannot model correctly. Copyright ? 2009 Royal Meteorological Society},
	number = {638},
	urldate = {2020-07-07},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Cardinali, Carla},
	month = jan,
	year = {2009},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {data assimilation, adjoint system, observations impact},
	pages = {239--250},
	annote = {doi: 10.1002/qj.366}
}

@article{kalnay_simpler_2012,
	title = {A simpler formulation of forecast sensitivity to observations: application to ensemble {Kalman} filters},
	volume = {64},
	issn = {null},
	url = {https://doi.org/10.3402/tellusa.v64i0.18462},
	doi = {10.3402/tellusa.v64i0.18462},
	abstract = {ABSTRACTWe introduce a new formulation of the ensemble forecast sensitivity developed by Liu and Kalnay with a small correction from Li et al. The new formulation, like the original one, is tested on the simple Lorenz 40-variable model. We find that, except for short-range forecasts, the use of localization in the analysis, necessary in ensemble Kalman filter (EnKF) when the number of ensemble members is much smaller than the model's degrees of freedom, has a negative impact on the accuracy of the sensitivity. This is because the impact of an observation during the analysis (i.e. the analysis increment associated with the observation) is transported by the flow during the integration, and this is ignored when the ensemble sensitivity uses a fixed localization. To address this problem, we introduce two approaches that could be adapted to evolve the localization during the estimation of forecast sensitivity to the observations. The first one estimates the non-linear evolution of the initial localization but is computationally expensive. The second one moves the localization with a constant estimation of the group velocity. Both methods succeed in improving the ensemble estimations for longer forecasts.Overall, the adjoint and ensemble forecast impact estimations give similarly accurate results for short-range forecasts, except that the new formulation gives an estimation of the fraction of observations that improve the forecast closer to that obtained by data denial (Observing System Experiments). For longer-range forecasts, they both deteriorate for different reasons. The adjoint sensitivity becomes noisy due to the forecast non-linearities not captured in the linear tangent model and the adjoint. The ensemble sensitivity becomes less accurate due to the use of a fixed localization, a problem that could be ameliorated with an evolving adaptive localization. Advantages of the new formulation include it being simpler than the original formulation and computationally more efficient and that it can be applied to other EnKF methods in addition to the local ensemble transform Kalman filter.},
	number = {1},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Kalnay, Eugenia and Ota, Yoichiro and Miyoshi, Takemasa and Liu, Junjie},
	month = dec,
	year = {2012},
	note = {Publisher: Taylor \& Francis},
	pages = {18462},
	annote = {doi: 10.3402/tellusa.v64i0.18462}
}

@article{kotsuki_can_2017,
	title = {Can {We} {Optimize} the {Assimilation} {Order} in the {Serial} {Ensemble} {Kalman} {Filter}? {A} {Study} with the {Lorenz}-96 {Model}},
	volume = {145},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/MWR-D-17-0094.1},
	doi = {10.1175/MWR-D-17-0094.1},
	abstract = {With the serial treatment of observations in the ensemble Kalman filter (EnKF), the assimilation order of observations is usually assumed to have no significant impact on analysis accuracy. However, Nerger derived that analyses with different assimilation orders are different if covariance localization is applied in the observation space. This study explores whether the assimilation order can be optimized to systematically improve the filter estimates. A mathematical demonstration of a simple two-dimensional case indicates that different assimilation orders can cause different analyses, although the differences are two orders of magnitude smaller than the analysis increments if two identical observation error variances are the same size as the two identical state error variances. Numerical experiments using the Lorenz-96 40-variable model show that the small difference due to different assimilation orders could eventually result in a significant difference in analysis accuracy. Several ordering rules are tested, and the results show that an ordering rule that gives a better forecast relative to future observations improves the analysis accuracy. In addition, the analysis is improved significantly by ordering observations from worse to better impacts using the ensemble forecast sensitivity to observations (EFSO), which estimates how much each observation reduces or increases the forecast error. With the EFSO ordering rule, the change in error during the serial assimilation process is similar to that obtained by the experimentally found best sampled assimilation order. The ordering has more impact when the ensemble size is smaller relative to the degrees of freedom of the dynamical system.},
	number = {12},
	urldate = {2020-07-07},
	journal = {Monthly Weather Review},
	author = {Kotsuki, Shunji and Greybush, Steven J. and Miyoshi, Takemasa},
	month = dec,
	year = {2017},
	pages = {4977--4995}
}

@phdthesis{chen_proactive_2017,
	type = {{PhD} {Thesis}},
	title = {Proactive {Quality} {Control} to {Improve} {NWP}, {Reanalysis}, and {Observations}},
	school = {Department of Atmospheric and Oceanic Science, University of Maryland …},
	author = {Chen, Tse-Chun},
	year = {2017}
}

@article{lien_effective_2013,
	title = {Effective assimilation of global precipitation: simulation experiments},
	volume = {65},
	issn = {null},
	url = {https://doi.org/10.3402/tellusa.v65i0.19915},
	doi = {10.3402/tellusa.v65i0.19915},
	abstract = {Past attempts to assimilate precipitation by nudging or variational methods have succeeded in forcing the model precipitation to be close to the observed values. However, the model forecasts tend to lose their additional skill after a few forecast hours. In this study, a local ensemble transform Kalman filter (LETKF) is used to effectively assimilate precipitation by allowing ensemble members with better precipitation to receive higher weights in the analysis. In addition, two other changes in the precipitation assimilation process are found to alleviate the problems related to the non-Gaussianity of the precipitation variable: (a) transform the precipitation variable into a Gaussian distribution based on its climatological distribution (an approach that could also be used in the assimilation of other non-Gaussian observations) and (b) only assimilate precipitation at the location where at least some ensemble members have precipitation. Unlike many current approaches, both positive and zero rain observations are assimilated effectively.Observing system simulation experiments (OSSEs) are conducted using the Simplified Parametrisations, primitivE-Equation DYnamics (SPEEDY) model, a simplified but realistic general circulation model. When uniformly and globally distributed observations of precipitation are assimilated in addition to rawinsonde observations, both the analyses and the medium-range forecasts of all model variables, including precipitation, are significantly improved as compared to only assimilating rawinsonde observations. The effect of precipitation assimilation on the analyses is retained on the medium-range forecasts and is larger in the Southern Hemisphere (SH) than that in the Northern Hemisphere (NH) because the NH analyses are already made more accurate by the denser rawinsonde stations. These improvements are much reduced when only the moisture field is modified by the precipitation observations. Both the Gaussian transformation and the new observation selection criterion are shown to be beneficial to the precipitation assimilation especially in the case of larger observation errors. Assigning smaller horizontal localisation length scales for precipitation observations further improves the LETKF analysis.},
	number = {1},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Lien, Guo-Yuan and Kalnay, Eugenia and Miyoshi, Takemasa},
	month = dec,
	year = {2013},
	note = {Publisher: Taylor \& Francis},
	pages = {19915},
	annote = {doi: 10.3402/tellusa.v65i0.19915}
}

@article{lien_statistical_2016,
	title = {Statistical {Properties} of {Global} {Precipitation} in the {NCEP} {GFS} {Model} and {TMPA} {Observations} for {Data} {Assimilation}},
	volume = {144},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/MWR-D-15-0150.1},
	doi = {10.1175/MWR-D-15-0150.1},
	abstract = {Assimilation of satellite precipitation data into numerical models presents several difficulties, with two of the most important being the non-Gaussian error distributions associated with precipitation, and large model and observation errors. As a result, improving the model forecast beyond a few hours by assimilating precipitation has been found to be difficult. To identify the challenges and propose practical solutions to assimilation of precipitation, statistics are calculated for global precipitation in a low-resolution NCEP Global Forecast System (GFS) model and the TRMM Multisatellite Precipitation Analysis (TMPA). The samples are constructed using the same model with the same forecast period, observation variables, and resolution as in the follow-on GFS/TMPA precipitation assimilation experiments presented in the companion paper.The statistical results indicate that the T62 and T126 GFS models generally have positive bias in precipitation compared to the TMPA observations, and that the simulation of the marine stratocumulus precipitation is not realistic in the T62 GFS model. It is necessary to apply to precipitation either the commonly used logarithm transformation or the newly proposed Gaussian transformation to obtain a better relationship between the model and observational precipitation. When the Gaussian transformations are separately applied to the model and observational precipitation, they serve as a bias correction that corrects the amplitude-dependent biases. In addition, using a spatially and/or temporally averaged precipitation variable, such as the 6-h accumulated precipitation, should be advantageous for precipitation assimilation.},
	number = {2},
	urldate = {2020-07-07},
	journal = {Monthly Weather Review},
	author = {Lien, Guo-Yuan and Kalnay, Eugenia and Miyoshi, Takemasa and Huffman, George J.},
	month = feb,
	year = {2016},
	pages = {663--679}
}

@article{lien_assimilation_2016,
	title = {Assimilation of {TRMM} {Multisatellite} {Precipitation} {Analysis} with a {Low}-{Resolution} {NCEP} {Global} {Forecast} {System}},
	volume = {144},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/MWR-D-15-0149.1},
	doi = {10.1175/MWR-D-15-0149.1},
	abstract = {Current methods of assimilation of precipitation into numerical weather prediction models are able to make the model precipitation become similar to the observed precipitation during the assimilation, but the model forecasts tend to return to their original solution after a few hours. To facilitate the precipitation assimilation, a logarithm transformation has been used in several past studies. Lien et al. proposed instead to assimilate precipitation using the local ensemble transform Kalman filter (LETKF) with a Gaussian transformation technique and succeeded in improving the model forecasts in perfect-model observing system simulation experiments (OSSEs).In this study, the method of Lien et al. is tested within a more realistic configuration: the TRMM Multisatellite Precipitation Analysis (TMPA) data are assimilated into a low-resolution version of the NCEP Global Forecast System (GFS). With guidance from a statistical study comparing the GFS model background precipitation and the TMPA data, some modifications of the assimilation methods proposed in Lien et al. are made, including 1) applying separate Gaussian transformations to model and to observational precipitation based on their own cumulative distribution functions; 2) adopting a quality control criterion based on the correlation between the long-term model and observed precipitation data at the observation location; and 3) proposing a new method to define the transformation of zero precipitation that takes into account the zero precipitation probability in the background ensemble rather than the climatology. With these modifications, the assimilation of the TMPA precipitation data improves both the analysis and 5-day model forecasts when compared with a control experiment assimilating only rawinsonde data.},
	number = {2},
	urldate = {2020-07-07},
	journal = {Monthly Weather Review},
	author = {Lien, Guo-Yuan and Miyoshi, Takemasa and Kalnay, Eugenia},
	month = feb,
	year = {2016},
	pages = {643--661}
}

@article{sommer_ensemble-based_2016,
	title = {Ensemble-based approximation of observation impact using an observation-based verification metric},
	volume = {68},
	issn = {null},
	url = {https://doi.org/10.3402/tellusa.v68.27885},
	doi = {10.3402/tellusa.v68.27885},
	abstract = {Knowledge on the contribution of observations to forecast accuracy is crucial for the refinement of observing and data assimilation systems. Several recent publications highlighted the benefits of efficiently approximating this observation impact using adjoint methods or ensembles. This study proposes a modification of an existing method for computing observation impact in an ensemble-based data assimilation and forecasting system and applies the method to a pre-operational, convective-scale regional modelling environment. Instead of the analysis, the modified approach uses observation-based verification metrics to mitigate the effect of correlation between the forecast and its verification norm. Furthermore, a peculiar property in the distribution of individual observation impact values is used to define a reliability indicator for the accuracy of the impact approximation. Applying this method to a 3-day test period shows that a well-defined observation impact value can be approximated for most observation types and the reliability indicator successfully depicts where results are not significant.},
	number = {1},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Sommer, Matthias and Weissmann, Martin},
	month = dec,
	year = {2016},
	note = {Publisher: Taylor \& Francis},
	pages = {27885},
	annote = {doi: 10.3402/tellusa.v68.27885}
}

@article{ota_ensemble-based_2013,
	title = {Ensemble-based observation impact estimates using the {NCEP} {GFS}},
	volume = {65},
	issn = {null},
	url = {https://doi.org/10.3402/tellusa.v65i0.20038},
	doi = {10.3402/tellusa.v65i0.20038},
	abstract = {The impacts of the assimilated observations on the 24-hour forecasts are estimated with the ensemble-based method proposed by Kalnay et al. using an ensemble Kalman filter (EnKF). This method estimates the relative impact of observations in data assimilation similar to the adjoint-based method proposed by Langland and Baker but without using the adjoint model. It is implemented on the National Centers for Environmental Prediction Global Forecasting System EnKF that has been used as part of operational global data assimilation system at NCEP since May 2012. The result quantifies the overall positive impacts of the assimilated observations and the relative importance of the satellite radiance observations compared to other types of observations, especially for the moisture fields. A simple moving localisation based on the average wind, although not optimal, seems to work well. The method is also used to identify the cause of local forecast failure cases in the 24-hour forecasts. Data-denial experiments of the observations identified as producing a negative impact are performed, and forecast errors are reduced as estimated, thus validating the impact estimation.},
	number = {1},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Ota, Yoichiro and Derber, John C. and Kalnay, Eugenia and Miyoshi, Takemasa},
	month = dec,
	year = {2013},
	note = {Publisher: Taylor \& Francis},
	pages = {20038},
	annote = {doi: 10.3402/tellusa.v65i0.20038}
}

@article{lien_accelerating_2018,
	title = {Accelerating assimilation development for new observing systems using {EFSO}},
	volume = {25},
	url = {https://npg.copernicus.org/articles/25/129/2018/},
	doi = {10.5194/npg-25-129-2018},
	number = {1},
	journal = {Nonlinear Processes in Geophysics},
	author = {Lien, G.-Y. and Hotta, D. and Kalnay, E. and Miyoshi, T. and Chen, T.-C.},
	year = {2018},
	pages = {129--143}
}

@article{hotta_proactive_2017,
	title = {Proactive {QC}: {A} {Fully} {Flow}-{Dependent} {Quality} {Control} {Scheme} {Based} on {EFSO}},
	volume = {145},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/MWR-D-16-0290.1},
	doi = {10.1175/MWR-D-16-0290.1},
	abstract = {Despite dramatic improvements over the last decades, operational NWP forecasts still occasionally suffer from abrupt drops in their forecast skill. Such forecast skill “dropouts” may occur even in a perfect NWP system because of the stochastic nature of NWP but can also result from flaws in the NWP system. Recent studies have shown that dropouts occur due not to a model’s deficiencies but to misspecified initial conditions, suggesting that they could be mitigated by improving the quality control (QC) system so that the observation-minus-background (O-B) innovations that would degrade a forecast can be detected and rejected. The ensemble forecast sensitivity to observations (EFSO) technique enables for the quantification of how much each observation has improved or degraded the forecast. A recent study has shown that 24-h EFSO can detect detrimental O-B innovations that caused regional forecast skill dropouts and that the forecast can be improved by not assimilating them. Inspired by that success, a new QC method is proposed, termed proactive QC (PQC), that detects detrimental innovations 6 h after the analysis using EFSO and then repeats the analysis and forecast without using them. PQC is implemented and tested on a lower-resolution version of NCEP’s operational global NWP system. It is shown that EFSO is insensitive to the choice of verification and lead time (24 or 6 h) and that PQC likely improves the analysis, as attested to by forecast improvements of up to 5 days and beyond. Strategies for reducing the computational costs and further optimizing the observation rejection criteria are also discussed.},
	number = {8},
	urldate = {2020-07-07},
	journal = {Monthly Weather Review},
	author = {Hotta, Daisuke and Chen, Tse-Chun and Kalnay, Eugenia and Ota, Yoichiro and Miyoshi, Takemasa},
	month = jul,
	year = {2017},
	pages = {3331--3354}
}

@article{hotta_efsr_2017,
	title = {{EFSR}: {Ensemble} {Forecast} {Sensitivity} to {Observation} {Error} {Covariance}},
	volume = {145},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/MWR-D-17-0122.1},
	doi = {10.1175/MWR-D-17-0122.1},
	abstract = {Data assimilation (DA) methods require an estimate of observation error covariance  as an external parameter that typically is tuned in a subjective manner. To facilitate objective and systematic tuning of  within the context of ensemble Kalman filtering, this paper introduces a method for estimating how forecast errors would be changed by increasing or decreasing each element of , without a need for the adjoint of the model and the DA system, by combining the adjoint-based -sensitivity diagnostics presented by Daescu previously with the technique employed by Kalnay et al. to derive ensemble forecast sensitivity to observations (EFSO). The proposed method, termed EFSR, is shown to be able to detect and adaptively correct misspecified  through a series of toy-model experiments using the Lorenz ’96 model. It is then applied to a quasi-operational global DA system of the National Centers for Environmental Prediction to provide guidance on how to tune the . A sensitivity experiment in which the prescribed observation error variances for four selected observation types were scaled by 0.9 or 1.1 following the EFSR guidance, however, resulted in forecast improvement that is not statistically significant. This can be explained by the smallness of the perturbation given to the . An iterative online approach to improve on this limitation is proposed. Nevertheless, the sensitivity experiment did show that the EFSO impacts from each observation type were increased by the EFSR-guided tuning of .},
	number = {12},
	urldate = {2020-07-07},
	journal = {Monthly Weather Review},
	author = {Hotta, Daisuke and Kalnay, Eugenia and Ota, Yoichiro and Miyoshi, Takemasa},
	month = dec,
	year = {2017},
	pages = {5015--5031}
}

@article{chen_proactive_2018,
	title = {Proactive {Quality} {Control}: {Observing} {System} {Simulation} {Experiments} with the {Lorenz} ’96 {Model}},
	volume = {147},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/MWR-D-18-0138.1},
	doi = {10.1175/MWR-D-18-0138.1},
	abstract = {Proactive quality control (PQC) is a fully flow-dependent QC for observations based on the ensemble forecast sensitivity to observations technique (EFSO). It aims at reducing the forecast skill dropout events suffered in operational numerical weather prediction by rejecting observations identified as detrimental by EFSO. Past studies show that individual dropout cases from the Global Forecast System (GFS) were significantly improved by noncycling PQC. In this paper, we perform for the first time cycling PQC experiments in a controlled environment with the Lorenz model to provide a systematic testing of the new method and possibly shed light on the optimal configuration of operational implementation. We compare several configurations and PQC update methods. It is found that PQC improvement is insensitive to the suboptimal configurations in DA, including ensemble size, observing network size, model error, and the length of DA window, but the improvements increase with the flaws in observations. More importantly, we show that PQC improves the analysis and forecast even in the absence of flawed observations. The study reveals that reusing the exact same Kalman gain matrix for PQC update not only provides the best result but requires the lowest computational cost among all the tested methods.},
	number = {1},
	urldate = {2020-07-07},
	journal = {Monthly Weather Review},
	author = {Chen, Tse-Chun and Kalnay, Eugenia},
	month = dec,
	year = {2018},
	pages = {53--67}
}

@article{thepaut_four-dimensional_1991,
	title = {Four-dimensional variational data assimilation using the adjoint of a multilevel primitive-equation model},
	volume = {117},
	issn = {0035-9009},
	url = {https://doi.org/10.1002/qj.49711750206},
	doi = {10.1002/qj.49711750206},
	abstract = {Abstract The aim of the paper is to demonstrate the numerical feasibility of 4-D variational assimilation using a multilevel primitive-equation model. The experiments consist in minimizing the distance between the model solution and the observations. The gradient of the cost function thus defined is computed by integrating the adjoint of the model. Here, assimilations are performed using model-generated observations. In a preliminary set of experiments, assimilations were performed assuming that observations consisting of a full-model-state vector are available only at the end of the assimilation period. The numerical convergence of the method is proved and the results are meteorologically realistic. The use of the Machenhauer nonlinear normal mode initialization scheme and its adjoint turned out to have hastened the convergence and to have controlled to some extent the amount of gravity waves appearing in the solution. We identify a loss of conditioning of the minimization problem with an increase in the length of the assimilation period. The presence of horizontal diffusion in the model has the effect of degrading the convergence. The second set of experiments evaluates the impact of observations distributed over the whole assimilation period. Through different senarios of sets of observations, we demonstrate the efficiency of the 4-D variational approach in extracting the information contained in the dynamics of the model, together with the information contained in the observations. In particular, observing only the small scales of the flow leads to a good reconstruction of both small scales and large scales. Observations of the mass-field evolution lead to a good reconstruction of the vorticity field in mid latitudes but less so in the tropics. Increased resolution in the model in the experiments was found to have a negative impact on the speed of convergence of the minimization algorithm.},
	number = {502},
	urldate = {2020-07-07},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Thépaut, Jean-Noéul and Courtier, Philippe},
	month = oct,
	year = {1991},
	note = {Publisher: John Wiley \& Sons, Ltd},
	pages = {1225--1254},
	annote = {doi: 10.1002/qj.49711750206}
}

@article{corazza_use_2003,
	title = {Use of the breeding technique to estimate the structure of the analysis "errors of the day"},
	volume = {10},
	url = {https://npg.copernicus.org/articles/10/233/2003/},
	doi = {10.5194/npg-10-233-2003},
	number = {3},
	journal = {Nonlinear Processes in Geophysics},
	author = {Corazza, M. and Kalnay, E. and Patil, D. J. and Yang, S.-C. and Morss, R. and Cai, M. and Szunyogh, I. and Hunt, B. R. and Yorke, J. A.},
	year = {2003},
	pages = {233--243}
}

@article{cohn_behavior_1990,
	title = {The {Behavior} of {Forecast} {Error} {Covariances} for a {Kalman} {Filter} in {Two} {Dimensions}},
	volume = {119},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/1520-0493(1991)119<1757:TBOFEC>2.0.CO;2},
	doi = {10.1175/1520-0493(1991)119<1757:TBOFEC>2.0.CO;2},
	abstract = {A Kalman filter algorithm is implemented for a linearized shallow-water model over the continental United States. It is used to assimilate simulated data from the existing radiosonde network, from the demonstration network of 31 Doppler wind profilers in the central United States, and from hypothetical radiometers located at five of the profiler sites. We provide some theoretical justification of Phillips' hypothesis, and we use the hypothesis, with some modification, to formulate the model error covariance matrix required by the Kalman filter.Our results show that assimilating the profiler wind data leads to a large reduction of forecast/analysis error in heights as well as in winds, over the profiler region and also downstream, when compared with the results of assimilating the radiosonde data alone. The forecast error covariance matrices that the Kalman filter calculates to obtain this error reduction, however, differ considerably from those prescribed by the optimal interpolation schemes that are employed for data assimilation at operational centers. Height-height forecast error correlation functions spread out broadly over the profiler region. Height-wind correlation functions for a base point near the boundary of the profiler region are not antisymmetric with respect to the line of zero correlation, nor does the zero-line pass through the base point.We explain why these effects on forecast error correlations are to be expected for wind profilers, which provide abundant wind information but no height information. Our explanation is supported by further experiments in which height observations assimilated from radiometers at just a few profiler sites reduce these effects.},
	number = {8},
	urldate = {2020-07-08},
	journal = {Monthly Weather Review},
	author = {Cohn, Stephen E. and Parrish, David F.},
	month = aug,
	year = {1990},
	pages = {1757--1785}
}

@article{barker_three-dimensional_2004,
	title = {A {Three}-{Dimensional} {Variational} {Data} {Assimilation} {System} for {MM5}: {Implementation} and {Initial} {Results}},
	volume = {132},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/1520-0493(2004)132<0897:ATVDAS>2.0.CO;2},
	doi = {10.1175/1520-0493(2004)132<0897:ATVDAS>2.0.CO;2},
	abstract = {A limited-area three-dimensional variational data assimilation (3DVAR) system applicable to both synoptic and mesoscale numerical weather prediction is described. The system is designed for use in time-critical real- time applications and is freely available to the data assimilation community for general research.The unique features of this implementation of 3DVAR include (a) an analysis space represented by recursive filters and truncated eigenmodes of the background error covariance matrix, (b) the inclusion of a cyclostrophic term in 3DVAR's explicit mass–wind balance equation, and (c) the use of the software architecture of the Weather Research and Forecast (WRF) model to permit efficient performance on distributed-memory platforms.The 3DVAR system is applied to a multiresolution, nested-domain forecast system. Resolution and seasonal- dependent background error statistics are presented. A typhoon bogusing case study is performed to illustrate the 3DVAR response to a single surface pressure observation and its subsequent impact on numerical forecasts of the fifth-generation Pennsylvania State University–National Center for Atmospheric Research Mesoscale Model (MM5). Results are also presented from an initial real-time MM5-based application of 3DVAR.},
	number = {4},
	urldate = {2020-07-08},
	journal = {Monthly Weather Review},
	author = {Barker, D. M. and Huang, W. and Guo, Y-R. and Bourgeois, A. J. and Xiao, Q. N.},
	month = apr,
	year = {2004},
	pages = {897--914}
}

@book{edwards_likelihood_1984,
	title = {Likelihood},
	publisher = {CUP Archive},
	author = {Edwards, Anthony William Fairbank},
	year = {1984}
}

@phdthesis{miyoshi_ensemble_2005,
	address = {College Park, MD, USA},
	type = {{PhD} {Thesis}},
	title = {Ensemble {Kalman} filter experiments with a primitive-equation global model},
	language = {EN-US},
	school = {University of Maryland},
	author = {Miyoshi, Takemasa},
	year = {2005}
}

@article{caya_comparison_2005,
	title = {A {Comparison} between the {4DVAR} and the {Ensemble} {Kalman} {Filter} {Techniques} for {Radar} {Data} {Assimilation}},
	volume = {133},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/MWR3021.1},
	doi = {10.1175/MWR3021.1},
	abstract = {A four-dimensional variational data assimilation (4DVAR) algorithm is compared to an ensemble Kalman filter (EnKF) for the assimilation of radar data at the convective scale. Using a cloud-resolving model, simulated, imperfect radar observations of a supercell storm are assimilated under the assumption of a perfect forecast model. Overall, both assimilation schemes perform well and are able to recover the supercell with comparable accuracy, given radial-velocity and reflectivity observations where rain was present. 4DVAR produces generally better analyses than the EnKF given observations limited to a period of 10 min (or three volume scans), particularly for the wind components. In contrast, the EnKF typically produces better analyses than 4DVAR after several assimilation cycles, especially for model variables not functionally related to the observations. The advantages of the EnKF in later cycles arise at least in part from the fact that the 4DVAR scheme implemented here does not use a forecast from a previous cycle as background or evolve its error covariance. Possible reasons for the initial advantage of 4DVAR are deficiencies in the initial ensemble used by the EnKF, the temporal smoothness constraint used in 4DVAR, and nonlinearities in the evolution of forecast errors over the assimilation window.},
	number = {11},
	urldate = {2020-07-06},
	journal = {Monthly Weather Review},
	author = {Caya, A. and Sun, J. and Snyder, C.},
	month = nov,
	year = {2005},
	pages = {3081--3094}
}

@article{miyoshi_estimating_2013,
	title = {Estimating and including observation-error correlations in data assimilation},
	volume = {21},
	issn = {1741-5977},
	url = {https://doi.org/10.1080/17415977.2012.712527},
	doi = {10.1080/17415977.2012.712527},
	abstract = {Usually in data assimilation with geophysical systems, the observation-error covariance matrix R is assumed to be diagonal for simplicity and computational efficiency, although there are studies indicating that several types of satellite observations contain significantly correlated errors. This study brings to light the impact of the off-diagonal terms of R in data assimilation. The adaptive estimation method of Li et al., which allows online estimation of the observation-error variance using innovation statistics, is extended to include off-diagonal terms of R. The extended method performs well with the 40-variable Lorenz model in estimating non-diagonal observation-error covariances. Interestingly, the analysis accuracy is improved when the observation errors are correlated, but only if the observation-error correlations are explicitly considered in data assimilation. Further theoretical considerations relate the impact of observing systems (characterized by both R and an observation operator H) on analysis accuracy. This analysis points out the importance of distinguishing between observation-error correlations (i.e. non-diagonal R) and correlated observations (i.e. non-orthogonal H). In general, observations with a non-diagonal R carry more information, whereas observations with a non-orthogonal H carry less information, but it turns out that the combination of R and H is essential: more information is available from positively (negatively) correlated observations with negatively (positively) correlated errors, resulting in a more accurate analysis.},
	number = {3},
	journal = {Inverse Problems in Science and Engineering},
	author = {Miyoshi, Takemasa and Kalnay, Eugenia and Li, Hong},
	month = apr,
	year = {2013},
	note = {Publisher: Taylor \& Francis},
	pages = {387--398},
	annote = {doi: 10.1080/17415977.2012.712527}
}

@article{zhu_observation_2008,
	title = {Observation {Sensitivity} {Calculations} {Using} the {Adjoint} of the {Gridpoint} {Statistical} {Interpolation} ({GSI}) {Analysis} {System}},
	volume = {136},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/MWR3525.1},
	doi = {10.1175/MWR3525.1},
	abstract = {The adjoint of a data assimilation system provides an efficient way of estimating sensitivities of analysis or forecast measures with respect to observations. The NASA Global Modeling and Assimilation Office (GMAO) has developed an exact adjoint of the Gridpoint Statistical Interpolation (GSI) analysis scheme developed at the National Centers for Environmental Prediction (NCEP). The development approach is unique in that the adjoint is derived from a line-by-line tangent linear version of the GSI. Availability of the tangent linear scheme provides an explicit means of assessing not only the fidelity of the adjoint, but also the effects of nonlinear processes in the GSI itself. In this paper, the development of the tangent linear and adjoint versions of the GSI are discussed and observation sensitivity results for a near-operational version of the system are shown. Results indicate that the GSI adjoint provides accurate assessments of the sensitivities with respect to observations of wind, temperature, satellite radiances, and, to a lesser extent, moisture. Sensitivities with respect to ozone observations are quite linear for the ozone fields themselves, but highly nonlinear for other variables. The sensitivity information provided by the adjoint is used to estimate the contribution, or impact, of various observing systems on locally defined response functions based on the analyzed increments of temperature and zonal wind. It is shown, for example, that satellite radiances have the largest impact of all observing systems on the temperature increments over the eastern North Pacific, while conventional observations from rawinsondes and aircraft dominate the impact on the zonal wind increments over the continental United States. The observation impact calculations also provide an additional means of validating the observation sensitivities produced by the GSI adjoint.},
	number = {1},
	urldate = {2020-07-06},
	journal = {Monthly Weather Review},
	author = {Zhu, Yanqiu and Gelaro, Ronald},
	month = jan,
	year = {2008},
	pages = {335--351}
}

@article{langland_estimation_2004,
	title = {Estimation of observation impact using the {NRL} atmospheric variational data assimilation adjoint system},
	volume = {56},
	issn = {null},
	url = {https://doi.org/10.3402/tellusa.v56i3.14413},
	doi = {10.3402/tellusa.v56i3.14413},
	abstract = {An adjoint-based procedure for assessing the impact of observations on the short-range forecast error in numerical weather prediction is described. The method is computationally inexpensive and allows observation impact to be partitioned for any set or subset of observations, by instrument type, observed variable, geographic region, vertical level or other category. The cost function is the difference between measures of 24-h and 30-h global forecast error in the Navy Operational Global Atmospheric Prediction System (NOGAPS) during June and December 2002. Observations are assimilated at 00UTC in the Naval Research Laboratory (NRL) Atmospheric Variational Data Assimilation System (NAVDAS). The largest error reductions in the Northern Hemisphere are produced by rawinsondes, satellite wind data, and aircraft observations. In the Southern Hemisphere, the largest error reductions are produced by Advanced TIROS Operational Vertical Sounder (ATOVS) temperature retrievals, satellite wind data and rawinsondes. Approximately 60\% (40\%) of global observation impact is attributed to observations below (above) 500 hPa. A significant correlation is found between observation impact and cloud cover at the observation location. Currently, without consideration of moisture observations and moist processes in the forecast model adjoint, the observation impact procedure accounts for about 75\% of the actual reduction in 24-h forecast error.},
	number = {3},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Langland, Rolf H. and Baker, Nancy L.},
	month = jan,
	year = {2004},
	note = {Publisher: Taylor \& Francis},
	pages = {189--201},
	annote = {doi: 10.3402/tellusa.v56i3.14413}
}

@inproceedings{gordon_novel_1993,
	title = {Novel approach to nonlinear/non-{Gaussian} {Bayesian} state estimation},
	volume = {140},
	booktitle = {{IEE} proceedings {F} (radar and signal processing)},
	publisher = {IET},
	author = {Gordon, Neil J and Salmond, David J and Smith, Adrian FM},
	year = {1993},
	note = {Issue: 2},
	pages = {107--113}
}

@article{bonavita_estimating_2011,
	title = {Estimating background-error variances with the {ECMWF} {Ensemble} of {Data} {Assimilations} system: some effects of ensemble size and day-to-day variability},
	volume = {137},
	number = {655},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Bonavita, Massimo and Raynaud, Laure and Isaksen, Lars},
	year = {2011},
	note = {Publisher: Wiley Online Library},
	pages = {423--434}
}

@article{hamrud_enkf_2015,
	title = {{EnKF} and {Hybrid} {Gain} {Ensemble} {Data} {Assimilation}. {Part} {I}: {EnKF} {Implementation}},
	volume = {143},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/MWR-D-14-00333.1},
	doi = {10.1175/MWR-D-14-00333.1},
	abstract = {The desire to do detailed comparisons between variational and more scalable ensemble-based data assimilation systems in a semioperational environment has led to the development of a state-of-the-art EnKF system at ECMWF. A broad description of the ECMWF EnKF is given in this paper, focusing on highlighting differences compared to standard EnKF practice. In particular, a discussion of the novel algorithm used to control imbalances between the mass and wind fields in the EnKF analysis is given. The scalability and computational properties of the EnKF are reviewed and the implementation choices adopted at ECMWF described. The sensitivity of the ECMWF EnKF to ensemble size, horizontal resolution, and representation of model errors is also discussed. A comparison with 4DVar will be found in Part II of this two-part study.},
	number = {12},
	urldate = {2020-07-06},
	journal = {Monthly Weather Review},
	author = {Hamrud, Mats and Bonavita, Massimo and Isaksen, Lars},
	month = nov,
	year = {2015},
	pages = {4847--4864}
}

@article{bonavita_enkf_2015,
	title = {{EnKF} and {Hybrid} {Gain} {Ensemble} {Data} {Assimilation}. {Part} {II}: {EnKF} and {Hybrid} {Gain} {Results}},
	volume = {143},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/MWR-D-15-0071.1},
	doi = {10.1175/MWR-D-15-0071.1},
	abstract = {The desire to do detailed comparisons between variational and more scalable ensemble-based data assimilation systems in a semioperational environment has led to the development of a state-of-the-art EnKF system at ECMWF, which has been described in Part I of this two-part study. In this part the performance of the EnKF system is evaluated compared to a 4DVar of similar resolution. It is found that there is not a major difference between the forecast skill of the two systems. However, similarly to the operational hybrid 4DVar–EDA, a hybrid EnKF–variational system [which we refer to as the hybrid gain ensemble data assimilation (HG-EnDA)] is capable of significantly outperforming both component systems. The HG-EnDA has been implemented with relatively little effort following Penny’s recent study. Results of numerical experimentation comparing the HG-EnDA with the hybrid 4DVar–EDA used operationally at ECMWF are presented, together with diagnostic results, which help characterize the behavior of the proposed ensemble data assimilation system. A discussion of these results in the context of hybrid data assimilation in global NWP is also provided.},
	number = {12},
	urldate = {2020-07-06},
	journal = {Monthly Weather Review},
	author = {Bonavita, Massimo and Hamrud, Mats and Isaksen, Lars},
	month = nov,
	year = {2015},
	pages = {4865--4882}
}

@article{schraff_kilometre-scale_2016,
	title = {Kilometre-scale ensemble data assimilation for the {COSMO} model ({KENDA})},
	volume = {142},
	issn = {0035-9009},
	url = {https://doi.org/10.1002/qj.2748},
	doi = {10.1002/qj.2748},
	abstract = {An ensemble Kalman filter for convective-scale data assimilation (KENDA) has been developed for the COnsortium for Small-scale MOdelling (COSMO) model. The KENDA system comprises a local ensemble transform Kalman filter (LETKF) and a deterministic analysis based on the Kalman gain for the analysis ensemble mean. The KENDA software suite includes tools for adaptive localization, multiplicative covariance inflation, relaxation to prior perturbations and adaptive observation errors. In the version introduced here, conventional data (radiosonde, aircraft, wind profiler, surface station data) are assimilated. Latent heat nudging of radar precipitation has also been added to the KENDA system to be applied to the deterministic analysis only or additionally to all ensemble members. The performance of different system components is investigated in a quasi-operational setting using a basic cycling environment (BACY) for a period of six days with 24 h forecasts. For this period and an additional 28 day period, deterministic KENDA forecasts are compared with forecasts based on the observation nudging data assimilation scheme, which is currently operational at the German Weather Service (Deutscher Wetterdienst, DWD). For our experiments, lateral boundary conditions for the regional model are given by a global ensemble Kalman filter for the ICOsahedral Nonhydrostatic (ICON) model. The performance of the KENDA system proves overall to be superior to the forecast quality of the operational nudging scheme, in particular with regard to precipitation. Latent heat nudging improves precipitation forecasts in both systems and has slightly more benefit in combination with the LETKF than with observation nudging.},
	number = {696},
	urldate = {2020-07-06},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Schraff, C. and Reich, H. and Rhodin, A. and Schomburg, A. and Stephan, K. and Periáñez, A. and Potthast, R.},
	month = apr,
	year = {2016},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {data assimilation, convective-scale, COSMO, ensemble Kalman filter, KENDA, latent heat nudging, LETKF},
	pages = {1453--1472},
	annote = {doi: 10.1002/qj.2748}
}

@article{kleist_introduction_2009,
	title = {Introduction of the {GSI} into the {NCEP} {Global} {Data} {Assimilation} {System}},
	volume = {24},
	issn = {0882-8156},
	url = {https://doi.org/10.1175/2009WAF2222201.1},
	doi = {10.1175/2009WAF2222201.1},
	abstract = {At the National Centers for Environmental Prediction (NCEP), a new three-dimensional variational data assimilation (3DVAR) analysis system was implemented into the operational Global Data Assimilation System (GDAS) on 1 May 2007. The new analysis system, the Gridpoint Statistical Interpolation (GSI), replaced the Spectral Statistical Interpolation (SSI) 3DVAR system, which had been operational since 1991. The GSI was developed at the Environmental Modeling Center at NCEP as part of an effort to create a more unified, robust, and efficient analysis scheme. The key aspect of the GSI is that it formulates the analysis in model grid space, which allows for more flexibility in the application of the background error covariances and makes it straightforward for a single analysis system to be used across a broad range of applications, including both global and regional modeling systems and domains.Due to the constraints of working with an operational system, the final GDAS package included many changes other than just a simple replacing of the SSI with the new GSI. The new GDAS package contained an upgrade to the Global Forecast System model, including a new vertical coordinate, as well as new features in the GSI that were never developed for the SSI. Some of these new features included changes to the observation selection, quality control, minimization algorithm, dynamic balance constraint, and assimilation of new observation types. The evaluation of the new system relative to the SSI-based system was performed for nearly an entire year of analyses and forecasts. The objective and subjective evaluations showed that the new package exhibited superior forecast performance relative to the old SSI-based system. The new system has been shown to improve forecast skill in the tropics and substantially reduce the short-term forecast error in the extratropics. This implementation has laid the groundwork for future scientific advancements in data assimilation at NCEP.},
	number = {6},
	urldate = {2020-07-06},
	journal = {Weather and Forecasting},
	author = {Kleist, Daryl T. and Parrish, David F. and Derber, John C. and Treadon, Russ and Wu, Wan-Shu and Lord, Stephen},
	month = dec,
	year = {2009},
	pages = {1691--1705}
}

@article{molteni_atmospheric_2003,
	title = {Atmospheric simulations using a {GCM} with simplified physical parametrizations. {I}: model climatology and variability in multi-decadal experiments},
	volume = {20},
	issn = {1432-0894},
	url = {https://doi.org/10.1007/s00382-002-0268-2},
	doi = {10.1007/s00382-002-0268-2},
	abstract = {This work describes the formulation and climatology of an atmospheric general circulation model (GCM) of intermediate complexity, based on a spectral primitive-equation dynamical core and a set of simplified physical parametrization schemes. The parametrization package has been specially designed to work in models with just a few vertical levels, and is based on the same physical principles adopted in the schemes of state-of-the art GCMs. The parametrized processes include large-scale condensation, convection, clouds, short-wave and long-wave radiation, surface fluxes and vertical diffusion. In the current configuration, the model (nicknamed SPEEDY, from Simplified Parametrizations, primitivE-Equation DYnamics") has five vertical levels and a spectral truncation at total wave number 30 (T30L5). The top vertical level (crudely) represents the stratosphere, the bottom one the planetary boundary layer. Computationally, SPEEDY requires (at least) one order of magnitude less CPU time than a state-of-the-art GCM at the same horizontal resolution, and is therefore suitable for studies of inter-decadal or inter-centennial variability. Statistics of the model mean state and variability are computed from an ensemble of 41-year simulations forced by observed sea-surface temperatures in the period 1952–1992. The model mean state is closer to the observed climatology during the (boreal) winter than during summer. In winter (i.e. December to February, DJF), the model underestimates the amplitude of the Northern Hemisphere stationary wave pattern, particularly in the European-Atlantic sector. Some aspects of the systematic error of SPEEDY are in fact typical of many GCMs, although the error amplitude is stronger than in state-of-the-art models. On the other hand, the global distribution of precipitation in DJF is quite realistic, and compares well with that of more complex GCMs. In summer (June to August), a strong negative bias in the mid-tropospheric temperature generates a Northern Hemisphere circulation with some springtime characteristics. In particular, the position of the Tropical Convergence Zone in the Indian Ocean remains too far south, leading to a deficient simulation of the monsoon circulation over South Asia. The simulated variability during the northern winter is reasonably realistic as far as the spatial distribution is concerned, although some underestimation in the intensity can be found, particularly in the low-frequency range and in the Atlantic sector. The atmospheric response to ENSO events is also weaker than observed, although the spatial patterns of the rainfall and geopotential response in the Pacific sector are in phase with their observed counterparts. In the Atlantic/Eurasian region, the spatial patterns associated with the interdecadal trends in the simulated and observed large-scale circulation show a clear positive correlation, consistent with the hypothesis of a positive ocean–atmosphere feedback on decadal time scales.},
	number = {2},
	journal = {Climate Dynamics},
	author = {Molteni, F.},
	month = jan,
	year = {2003},
	pages = {175--191}
}

@article{purser_numerical_2003,
	title = {Numerical aspects of the application of recursive filters to variational statistical analysis. {Part} {II}: {Spatially} inhomogeneous and anisotropic general covariances},
	volume = {131},
	number = {8},
	journal = {Monthly Weather Review},
	author = {Purser, R James and Wu, Wan-Shu and Parrish, David F and Roberts, Nigel M},
	year = {2003},
	pages = {1536--1548}
}

@article{purser_numerical_2003-1,
	title = {Numerical aspects of the application of recursive filters to variational statistical analysis. {Part} {I}: {Spatially} homogeneous and isotropic {Gaussian} covariances},
	volume = {131},
	number = {8},
	journal = {Monthly Weather Review},
	author = {Purser, R James and Wu, Wan-Shu and Parrish, David F and Roberts, Nigel M},
	year = {2003},
	pages = {1524--1535}
}

@article{wu_three-dimensional_2002,
	title = {Three-dimensional variational analysis with spatially inhomogeneous covariances},
	volume = {130},
	number = {12},
	journal = {Monthly Weather Review},
	author = {Wu, Wan-Shu and Purser, R James and Parrish, David F},
	year = {2002},
	pages = {2905--2916}
}

@article{kotsuki_assimilating_2017,
	title = {Assimilating the global satellite mapping of precipitation data with the {Nonhydrostatic} {Icosahedral} {Atmospheric} {Model} ({NICAM})},
	volume = {122},
	issn = {2169-897X},
	url = {https://doi.org/10.1002/2016JD025355},
	doi = {10.1002/2016JD025355},
	abstract = {Abstract This study aims to propose two new approaches to improve precipitation forecasts from numerical weather prediction (NWP) models through effective data assimilation of satellite-derived precipitation. The assimilation of precipitation data is known to be very difficult mainly because of highly non-Gaussian statistics of precipitation variables. Following Lien et al., this study addresses the non-Gaussianity issue by applying the Gaussian transformation (GT) based on the empirical cumulative distribution function (CDF) of precipitation. We propose a method that constructs the CDF with only recent 1?month samples, without using a long period of samples needed previously. We also propose a method to use the inverse GT, with which we can obtain realistic precipitation fields from biased NWP model outputs. We assimilate the Japan Aerospace eXploration Agency's Global Satellite Mapping of Precipitation (GSMaP) data into the Nonhydrostatic Icosahedral Atmospheric Model (NICAM) at 112?km horizontal resolution. Assimilating the GSMaP data results in improved weather forecasts compared to the control experiment assimilating only rawinsonde data. We find that horizontal observation thinning is necessary, probably due to the horizontal observation-error correlations in the GSMaP data. We also obtained precipitation fields similar to GSMaP from the NICAM precipitation forecasts by using the inverse GT, leading to an improved precipitation forecast.},
	number = {2},
	urldate = {2020-07-06},
	journal = {Journal of Geophysical Research: Atmospheres},
	author = {Kotsuki, Shunji and Miyoshi, Takemasa and Terasaki, Koji and Lien, Guo-Yuan and Kalnay, Eugenia},
	month = jan,
	year = {2017},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {data assimilation, ensemble Kalman filter, Gaussian transformation, GSMaP, NICAM, numerical weather prediction},
	pages = {631--650},
	annote = {doi: 10.1002/2016JD025355}
}

@book{lahoz_data_2010,
	title = {Data assimilation},
	publisher = {Springer},
	author = {Lahoz, Boris Khattatov William and Menard, Richard},
	year = {2010}
}

@article{law_data_2015,
	title = {Data assimilation},
	journal = {Cham, Switzerland: Springer},
	author = {Law, Kody and Stuart, Andrew and Zygalakis, Kostas},
	year = {2015},
	note = {Publisher: Springer}
}

@book{lewis_dynamic_2006,
	title = {Dynamic data assimilation: a least squares approach},
	volume = {13},
	publisher = {Cambridge University Press},
	author = {Lewis, John M and Lakshmivarahan, Sivaramakrishnan and Dhall, Sudarshan},
	year = {2006}
}

@book{evensen_data_2009,
	title = {Data assimilation: the ensemble {Kalman} filter},
	publisher = {Springer Science \& Business Media},
	author = {Evensen, Geir},
	year = {2009}
}

@book{park_data_2013,
	title = {Data assimilation for atmospheric, oceanic and hydrologic applications},
	volume = {2},
	publisher = {Springer Science \& Business Media},
	author = {Park, Seon Ki and Xu, Liang},
	year = {2013}
}

@article{wang_theoretical_2007,
	title = {On the {Theoretical} {Equivalence} of {Differently} {Proposed} {Ensemble}–{3DVAR} {Hybrid} {Analysis} {Schemes}},
	volume = {135},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/MWR3282.1},
	doi = {10.1175/MWR3282.1},
	abstract = {Hybrid ensemble–three-dimensional variational analysis schemes incorporate flow-dependent, ensemble-estimated background-error covariances into the three-dimensional variational data assimilation (3DVAR) framework. Typically the 3DVAR background-error covariance estimate is assumed to be stationary, nearly homogeneous, and isotropic. A hybrid scheme can be achieved by 1) directly replacing the background-error covariance term in the cost function by a linear combination of the original background-error covariance with the ensemble covariance or 2) through augmenting the state vector with another set of control variables preconditioned upon the square root of the ensemble covariance. These differently proposed hybrid schemes are proven to be equivalent. The latter framework may be a simpler way to incorporate ensemble information into operational 3DVAR schemes, where the preconditioning is performed with respect to the background term.},
	number = {1},
	urldate = {2020-07-06},
	journal = {Monthly Weather Review},
	author = {Wang, Xuguang and Snyder, Chris and Hamill, Thomas M.},
	month = jan,
	year = {2007},
	pages = {222--227}
}

@article{clayton_operational_2013,
	title = {Operational implementation of a hybrid ensemble/{4D}-{Var} global data assimilation system at the {Met} {Office}},
	volume = {139},
	issn = {0035-9009},
	url = {https://doi.org/10.1002/qj.2054},
	doi = {10.1002/qj.2054},
	abstract = {Abstract We describe the development and testing of the hybrid ensemble/4D-Var global data assimilation system that was implemented operationally at the Met Office in July 2011, giving an average reduction of RMS errors of just under 1\%. The scheme uses the extended control variable technique to implement a hybrid background error covariance that combines the standard climatological covariance with a covariance derived from the 23-member operational ensemble MOGREPS-G. Unique features of the Met Office scheme include application of a horizontal ?anti-aliasing? filter to the ensemble error modes, a vertical localization scheme based uniquely on a modification of the climatological stream function covariance, and inflation of the climatological covariance to maintain the analysis fit to observations. Findings during development include a significantly greater impact of the scheme in 3D-Var than 4D-Var, a clear positive impact from the combination of the anti-aliasing filter and vertical localization, and a relatively small sensitivity to full coupling of the ensemble and 4D-Var systems. Supplementary experiments suggest that the ability of the ensemble to capture coherent ?Errors of the Day? is key to the improvements in forecast skill. A particular problem encountered during development was significantly poorer tropical verification scores when measured against own analyses. In contrast, verification against independent (ECMWF) analyses gave scores that were much more consistent with those against observations.},
	number = {675},
	urldate = {2020-07-06},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Clayton, A. M. and Lorenc, A. C. and Barker, D. M.},
	month = jul,
	year = {2013},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {background error covariance, covariance localization, MOGREPS},
	pages = {1445--1461},
	annote = {doi: 10.1002/qj.2054}
}

@article{buehner_intercomparison_2010,
	title = {Intercomparison of {Variational} {Data} {Assimilation} and the {Ensemble} {Kalman} {Filter} for {Global} {Deterministic} {NWP}. {Part} {I}: {Description} and {Single}-{Observation} {Experiments}},
	volume = {138},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/2009MWR3157.1},
	doi = {10.1175/2009MWR3157.1},
	abstract = {An intercomparison of the Environment Canada variational and ensemble Kalman filter (EnKF) data assimilation systems is presented in the context of global deterministic NWP. In an EnKF experiment having the same spatial resolution as the inner loop in the four-dimensional variational data assimilation system (4D-Var), the mean of each analysis ensemble is used to initialize the higher-resolution deterministic forecasts. Five different variational data assimilation experiments are also conducted. These include both 4D-Var and 3D-Var (with first guess at appropriate time) experiments using either (i) prescribed background-error covariances similar to those used operationally, which are static in time and include horizontally homogeneous and isotropic correlations; or (ii) flow-dependent covariances computed from the EnKF background ensembles with spatial covariance localization applied. The fifth variational data assimilation experiment is a new approach called the Ensemble-4D-Var (En-4D-Var). This approach uses 4D flow-dependent background-error covariances estimated from EnKF ensembles to produce a 4D analysis without the need for tangent-linear or adjoint versions of the forecast model. In this first part of a two-part paper, results from a series of idealized assimilation experiments are presented. In these experiments, only a single observation or vertical profile of observations is assimilated to explore the impact of various fundamental differences among the EnKF and the various variational data assimilation approaches considered. In particular, differences in the application of covariance localization in the EnKF and variational approaches are shown to have a significant impact on the assimilation of satellite radiance observations. The results also demonstrate that 4D-Var and the EnKF can both produce similar 4D background-error covariances within a 6-h assimilation window. In the second part, results from medium-range deterministic forecasts for the study period of February 2007 are presented for the EnKF and the five variational data assimilation approaches considered.},
	number = {5},
	urldate = {2020-07-06},
	journal = {Monthly Weather Review},
	author = {Buehner, Mark and Houtekamer, P. L. and Charette, Cecilien and Mitchell, Herschel L. and He, Bin},
	month = may,
	year = {2010},
	pages = {1550--1566}
}

@article{buehner_intercomparison_2010-1,
	title = {Intercomparison of {Variational} {Data} {Assimilation} and the {Ensemble} {Kalman} {Filter} for {Global} {Deterministic} {NWP}. {Part} {II}: {One}-{Month} {Experiments} with {Real} {Observations}},
	volume = {138},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/2009MWR3158.1},
	doi = {10.1175/2009MWR3158.1},
	abstract = {An intercomparison of the Environment Canada variational and ensemble Kalman filter (EnKF) data assimilation systems is presented in the context of producing global deterministic numerical weather forecasts. Five different variational data assimilation approaches are considered including four-dimensional variational data assimilation (4D-Var) and three-dimensional variational data assimilation (3D-Var) with first guess at the appropriate time (3D-FGAT). Also included among these is a new approach, called Ensemble-4D-Var (En-4D-Var), that uses 4D ensemble background-error covariances from the EnKF. A description of the experimental configurations and results from single-observation experiments are presented in the first part of this two-part paper. The present paper focuses on results from medium-range deterministic forecasts initialized with analyses from the EnKF and the five variational data assimilation approaches for the period of February 2007. All experiments assimilate exactly the same full set of meteorological observations and use the same configuration of the forecast model to produce global deterministic medium-range forecasts.The quality of forecasts in the short (medium) range obtained by using the EnKF ensemble mean analysis is slightly degraded (improved) in the extratropics relative to using the 4D-Var analysis with background-error covariances similar to those used operationally. The use of the EnKF flow-dependent error covariances in the variational system (4D-Var or 3D-FGAT) leads to large (modest) forecast improvements in the southern extratropics (tropics) as compared with using covariances similar to the operational system (a gain of up to 9 h at day 5). The En-4D-Var approach leads to (i) either improved or similar forecast quality when compared with the 4D-Var experiment similar to the currently operational system, (ii) slightly worse forecast quality when compared with the 4D-Var experiment with EnKF error covariances, and (iii) generally similar forecast quality when compared with the EnKF experiment.},
	number = {5},
	urldate = {2020-07-06},
	journal = {Monthly Weather Review},
	author = {Buehner, Mark and Houtekamer, P. L. and Charette, Cecilien and Mitchell, Herschel L. and He, Bin},
	month = may,
	year = {2010},
	pages = {1567--1586}
}

@article{chen_proactive_2020,
	title = {Proactive {Quality} {Control}: {Observing} {System} {Experiments} using the {NCEP} {Global} {Forecast} {System}},
	shorttitle = {Proactive {Quality} {Control}},
	url = {https://journals.ametsoc.org/mwr/article/doi/10.1175/MWR-D-20-0001.1/348489/Proactive-Quality-Control-Observing-System},
	doi = {10.1175/MWR-D-20-0001.1},
	language = {en},
	urldate = {2020-07-04},
	journal = {Monthly Weather Review},
	author = {Chen, Tse-Chun and Kalnay, Eugenia},
	month = jun,
	year = {2020}
}

@article{poterjoy_localized_2016,
	title = {A {Localized} {Particle} {Filter} for {High}-{Dimensional} {Nonlinear} {Systems}},
	volume = {144},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/mwr/article/144/1/59/72639/A-Localized-Particle-Filter-for-High-Dimensional},
	doi = {10.1175/MWR-D-15-0163.1},
	language = {en},
	number = {1},
	urldate = {2020-07-04},
	journal = {Monthly Weather Review},
	author = {Poterjoy, Jonathan},
	month = jan,
	year = {2016},
	note = {Publisher: American Meteorological Society},
	pages = {59--76}
}

@article{van_leeuwen_particle_2019,
	title = {Particle filters for high-dimensional geoscience applications: {A} review},
	volume = {145},
	copyright = {© 2019 The Authors. Quarterly Journal of the Royal Meteorological Society published by John Wiley \& Sons Ltd on behalf of the Royal Meteorological Society.},
	issn = {1477-870X},
	shorttitle = {Particle filters for high-dimensional geoscience applications},
	url = {https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/qj.3551},
	doi = {10.1002/qj.3551},
	abstract = {Particle filters contain the promise of fully nonlinear data assimilation. They have been applied in numerous science areas, including the geosciences, but their application to high-dimensional geoscience systems has been limited due to their inefficiency in high-dimensional systems in standard settings. However, huge progress has been made, and this limitation is disappearing fast due to recent developments in proposal densities, the use of ideas from (optimal) transportation, the use of localization and intelligent adaptive resampling strategies. Furthermore, powerful hybrids between particle filters and ensemble Kalman filters and variational methods have been developed. We present a state-of-the-art discussion of present efforts of developing particle filters for high-dimensional nonlinear geoscience state-estimation problems, with an emphasis on atmospheric and oceanic applications, including many new ideas, derivations and unifications, highlighting hidden connections, including pseudo-code, and generating a valuable tool and guide for the community. Initial experiments show that particle filters can be competitive with present-day methods for numerical weather prediction, suggesting that they will become mainstream soon.},
	language = {en},
	number = {723},
	urldate = {2020-03-30},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {van Leeuwen, Peter Jan and Künsch, Hans R. and Nerger, Lars and Potthast, Roland and Reich, Sebastian},
	year = {2019},
	note = {\_eprint: https://rmets.onlinelibrary.wiley.com/doi/pdf/10.1002/qj.3551},
	keywords = {hybrids, localization, nonlinear data assimilation, particle filters, proposal densities},
	pages = {2335--2365}
}

@article{penny_local_2016,
	title = {A local particle filter for high-dimensional geophysical systems},
	volume = {23},
	issn = {1023-5809},
	url = {https://www.nonlin-processes-geophys.net/23/391/2016/npg-23-391-2016-discussion.html},
	doi = {https://doi.org/10.5194/npg-23-391-2016},
	abstract = {{\textless}p{\textgreater}{\textless}strong{\textgreater}Abstract.{\textless}/strong{\textgreater} A local particle filter (LPF) is introduced that outperforms traditional ensemble Kalman filters in highly nonlinear/non-Gaussian scenarios, both in accuracy and computational cost. The standard sampling importance resampling (SIR) particle filter is augmented with an observation-space localization approach, for which an independent analysis is computed locally at each grid point. The deterministic resampling approach of Kitagawa is adapted for application locally and combined with interpolation of the analysis weights to smooth the transition between neighboring points. Gaussian noise is applied with magnitude equal to the local analysis spread to prevent particle degeneracy while maintaining the estimate of the growing dynamical instabilities. The approach is validated against the local ensemble transform Kalman filter (LETKF) using the 40-variable Lorenz-96 (L96) model. The results show that (1) the accuracy of LPF surpasses LETKF as the forecast length increases (thus increasing the degree of nonlinearity), (2) the cost of LPF is significantly lower than LETKF as the ensemble size increases, and (3) LPF prevents filter divergence experienced by LETKF in cases with non-Gaussian observation error distributions.{\textless}/p{\textgreater}},
	language = {English},
	number = {6},
	urldate = {2020-03-30},
	journal = {Nonlinear Processes in Geophysics},
	author = {Penny, Stephen G. and Miyoshi, Takemasa},
	month = nov,
	year = {2016},
	note = {Publisher: Copernicus GmbH},
	pages = {391--405}
}

@incollection{wheeler_tropical_2003,
	address = {Oxford},
	title = {{TROPICAL} {METEOROLOGY} {\textbar} {Equatorial} {Waves}},
	isbn = {978-0-12-227090-1},
	url = {http://www.sciencedirect.com/science/article/pii/B0122270908004140},
	urldate = {2018-07-09},
	booktitle = {Encyclopedia of {Atmospheric} {Sciences}},
	publisher = {Academic Press},
	author = {Wheeler, M. C.},
	editor = {Holton, James R.},
	month = jan,
	year = {2003},
	doi = {10.1016/B0-12-227090-8/00414-0},
	pages = {2313--2325}
}

@book{richardson_weather_1922,
	title = {Weather prediction by numerical process},
	url = {http://archive.org/details/weatherpredictio00richrich},
	language = {eng},
	urldate = {2018-07-19},
	publisher = {Cambridge, The University press},
	author = {Richardson, Lewis Fry},
	collaborator = {{University of California Libraries}},
	year = {1922},
	keywords = {Mathematics / Applied, Mathematics / Mathematical Analysis, Mathematics / Numerical Analysis, Science / Earth Sciences / Meteorology \& Climatology, Weather forecasting}
}

@article{phillips_carl-gustaf_1998,
	title = {Carl-{Gustaf} {Rossby}: {His} {Times}, {Personality}, and {Actions}},
	volume = {79},
	issn = {0003-0007},
	shorttitle = {Carl-{Gustaf} {Rossby}},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/1520-0477(1998)079%3C1097:CGRHTP%3E2.0.CO%3B2},
	doi = {10.1175/1520-0477(1998)079<1097:CGRHTP>2.0.CO;2},
	abstract = {The many activities of Carl-Gustaf Rossby are described, beginning with his early adventures at sea, and presented in the context of the meteorological world of his time. His scientific ideas and papers are not discussed except for an important aspect of his typical approach to analysis of atmospheric and oceanic motion. His success in fostering interaction between different people and institutions is emphasized.},
	number = {6},
	urldate = {2018-06-22},
	journal = {Bulletin of the American Meteorological Society},
	author = {Phillips, Norman A.},
	month = jun,
	year = {1998},
	pages = {1097--1112}
}

@article{putman_finite-volume_2007,
	title = {Finite-volume transport on various cubed-sphere grids},
	volume = {227},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999107003105},
	doi = {10.1016/j.jcp.2007.07.022},
	abstract = {The performance of a multidimensional finite-volume transport scheme is evaluated on the cubed-sphere geometry. Advection tests with prescribed winds are used to evaluate a variety of cubed-sphere projections and grid modifications including the gnomonic and conformal mappings, as well as two numerically generated grids by an elliptic solver and spring dynamics. We explore the impact of grid non-orthogonality on advection tests over the corner singularities of the cubed-sphere grids, using some variations of the transport scheme, including the piecewise parabolic method with alternative monotonicity constraints. The advection tests revealed comparable or better accuracy to those of the original latitudinal–longitudinal grid implementation. It is found that slight deviations from orthogonality on the modified cubed-sphere (quasi-orthogonal) grids do not negatively impact the accuracy. In fact, the more uniform version of the quasi-orthogonal cubed-sphere grids provided better overall accuracy than the most orthogonal (and therefore, much less uniform) conformal grid. It is also shown that a simple non-orthogonal extension to the transport equation enables the use of the highly non-orthogonal and computationally more efficient gnomonic grid with acceptable accuracy.},
	number = {1},
	urldate = {2018-07-16},
	journal = {Journal of Computational Physics},
	author = {Putman, William M. and Lin, Shian-Jiann},
	month = nov,
	year = {2007},
	keywords = {Advection, Cubed-sphere, Finite-volume, Monotonicity, Transport schemes},
	pages = {55--78}
}

@incollection{lorenz_charney---_1990,
	address = {Boston, MA},
	title = {Charney--- {A} {Remarkable} {Colleague}},
	isbn = {978-1-944970-35-2},
	url = {http://link.springer.com/10.1007/978-1-944970-35-2},
	language = {en},
	urldate = {2019-08-27},
	booktitle = {The {Atmosphere} — {A} {Challenge}: {The} {Science} of {Jule} {Gregory} {Charney}},
	publisher = {American Meteorological Society},
	author = {Lorenz, Edward N.},
	editor = {Lindzen, Richard S. and Lorenz, Edward N. and Platzman, George W.},
	year = {1990},
	doi = {10.1007/978-1-944970-35-2},
	pages = {89--91}
}

@incollection{thompson_charney_1990,
	address = {Boston, MA},
	title = {Charney and the {Revival} of {Numerical} {Weather} {Prediction}},
	isbn = {978-1-944970-35-2},
	url = {http://link.springer.com/10.1007/978-1-944970-35-2},
	language = {en},
	urldate = {2019-08-27},
	booktitle = {The {Atmosphere} — {A} {Challenge}: {The} {Science} of {Jule} {Gregory} {Charney}},
	publisher = {American Meteorological Society},
	author = {Thompson, Philip Duncan},
	editor = {Lindzen, Richard S. and Lorenz, Edward N. and Platzman, George W.},
	year = {1990},
	doi = {10.1007/978-1-944970-35-2},
	pages = {93--199}
}

@article{bjerknes_problem_1904,
	title = {Das {Problem} der {Wettervorhersage}, betrachtet vom {Standpunkte} der {Mechanik} und der {Physik}.},
	volume = {21},
	language = {German},
	journal = {Meteorologische Zeitschrift},
	author = {Bjerknes, V.},
	year = {1904},
	pages = {1--7}
}

@article{wiin--nielsen_birth_1991,
	title = {The birth of numerical weather prediction},
	volume = {43},
	issn = {1600-0870},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1034/j.1600-0870.1991.t01-2-00006.x},
	doi = {10.1034/j.1600-0870.1991.t01-2-00006.x},
	abstract = {The paper describes the major events leading gradually to operational, numerical, short-range predictions for the large-scale atmospheric flow. The theoretical foundation starting with Rossby's studies of the linearized, barotropic equation and ending a decade and a half later with the general formulation of the quasi-geostrophic, baroclinic model by Charney and Phillips is described. The problems connected with the very long waves and the inconsistences of the geostrophic approximation which were major obstacles in the first experimental forecasts are discussed. The resulting changes to divergent barotropic and baroclinic models and to the use of the balance equation are described. After the discussion of the theoretical foundation, the paper describes the major developments leading to the Meteorology Project at the Institute for Advanced Studied under the leadership of John von Neumann and Jule Charney followed by the establishment of the Joint Numerical Weather Prediction Unit in Suitland, Maryland. The interconnected developments in Europe, taking place more-or-less at the same time, are described by concentrating on the activities in Stockholm where the barotropic model was used in many experiments leading also to operational forecasts. The further developments resulting in the use of the primitive equations and the formulation of medium-range forecasting models are not included in the paper.},
	language = {en},
	number = {4},
	urldate = {2018-06-22},
	journal = {Tellus A},
	author = {Wiin--Nielsen, A.},
	month = aug,
	year = {1991},
	pages = {36--52}
}

@book{lindzen_atmosphere_1990,
	address = {Boston, MA},
	title = {The {Atmosphere} — {A} {Challenge}: {The} {Science} of {Jule} {Gregory} {Charney}},
	isbn = {978-1-944970-35-2},
	shorttitle = {The {Atmosphere} — {A} {Challenge}},
	url = {http://link.springer.com/10.1007/978-1-944970-35-2},
	language = {en},
	urldate = {2019-08-27},
	publisher = {American Meteorological Society},
	editor = {Lindzen, Richard S. and Lorenz, Edward N. and Platzman, George W.},
	year = {1990},
	doi = {10.1007/978-1-944970-35-2}
}

@article{teweles_verification_1954,
	title = {Verification of {Prognostic} {Charts}},
	volume = {35},
	issn = {0003-0007},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/1520-0477-35.10.455},
	doi = {10.1175/1520-0477-35.10.455},
	abstract = {Desirable characteristics of a system for scoring prognostic charts are discussed. A successful system now in use at the WBAN Analysis Center is described in detail. The preliminary score produced is a function of the pressure difference between pairs of stations over the area of the chart. A secondary score, the deviation from a running mean of daily scores adjusted by handicaps assigned to the individual forecasters, is a measure of forecasting skill relatively independent of many spurious effects. The slowly varying handicap is a useful means of ranking the ability of the forecasters.},
	number = {10},
	urldate = {2019-08-27},
	journal = {Bulletin of the American Meteorological Society},
	author = {Teweles, Sidney and Wobus, Hermann B.},
	month = dec,
	year = {1954},
	pages = {455--463}
}

@article{lorenz_experiment_1977,
	title = {An {Experiment} in {Nonlinear} {Statistical} {Weather} {Forecasting}},
	volume = {105},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/doi/10.1175/1520-0493%281977%29105%3C0590%3AAEINSW%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1977)105<0590:AEINSW>2.0.CO;2},
	abstract = {We inquire whether an empirical weather forecasting scheme can profitably incorporate a possible nonlinear relationship between observed predictands and predictors. We analyze a set of twice–daily hemispheric 500 mb height fields into truncated series of spherical harmonies. From each act of spherical-harmonic coefficients, we predict the coefficients 24 h in advance by integrating the barotropic vorticity equation in spherical-harmonic form. We then establish linear regression equations for predicting the same coefficients, using as predictors the coefficients which represent the observed height fields, and, in some instances, the numerically predicted height fields. We find that the empirical schemes which incorporate nonlinearity by using the numerically predicted fields perform considerably better than those which do not.},
	number = {5},
	urldate = {2018-07-19},
	journal = {Monthly Weather Review},
	author = {Lorenz, Edward N.},
	month = may,
	year = {1977},
	pages = {590--602}
}

@article{anderson_ensemble_2001,
	title = {An ensemble adjustment {Kalman} filter for data assimilation},
	volume = {129},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(2001)129%3C2884:AEAKFF%3E2.0.CO%3B2},
	number = {12},
	urldate = {2013-09-13},
	journal = {Monthly weather review},
	author = {Anderson, Jeffrey L.},
	year = {2001},
	pages = {2884--2903}
}

@article{lonnberg_statistical_1986,
	title = {The statistical structure of short-range forecast errors as determined from radiosonde data {Part} {II}: {The} covariance of height and wind errors},
	volume = {38},
	issn = {null},
	shorttitle = {The statistical structure of short-range forecast errors as determined from radiosonde data {Part} {II}},
	url = {http://dx.doi.org/10.3402/tellusa.v38i2.11708},
	doi = {10.3402/tellusa.v38i2.11708},
	abstract = {Part I of this study analysed the statistical structure of the mid-latitude errors of the short-range wind forecasts used in the global data assimilation system at ECMWF, by comparing the forecasts with verifying radiosonde data over North America. After an analysis of the corresponding statistics for the errors of the height forecasts, this paper studies the covariance of the height and wind forecast errors.The methods of Part I, based on the kinematics of homogeneous turbulence, are used to provide a spectral description of the height autocovariance function and of the cross-covariances of height with stream function and velocity potential. Particular attention is paid to the question of the degree of geostrophy of the non-divergent forecast errors. As a by-product, the calculations provide estimates of the vertical covariance matrices for prediction error and radiosonde observational error in the height field, where the term observational error includes both instrumental error and errors of representativeness.The forecast errors for height are comparable in magnitude with the observation errors, and there are good grounds for increasing the resolution of the analysis system, both in the horizontal and the vertical. The height errors have a substantial large-scale component whose vertical structure has a very broad scale; the geostrophic wind errors are dominated by synoptic scales. There is a high directional correlation (0.89) between the geostrophic wind and the stream function wind. The magnitudes of the geostrophic and non-divergent wind errors agree to within 15\% in the troposphere. In the stratosphere, the geostrophic wind errors are somewhat smaller than the non-divergent wind errors, indicating a possible aliasing from the large scales to synoptic scales in our calculations there. The correlation of height and velocity potential is such as to imply convergence in lows in the troposphere, but divergence in lows in the stratosphere.The methods developed here and in Part I offer a powerful set of diagnostic tools with which to improve both analysis and short-range forecast performance.},
	number = {2},
	urldate = {2017-11-01},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {LÖnnberg, P. and Hollingsworth, A.},
	month = jan,
	year = {1986},
	pages = {137--161}
}

@article{eliassen_numerical_1968,
	title = {A numerical integration experiment with a model atmosphere based on isentropic surfaces},
	volume = {5},
	journal = {Meteorologiske Annaler},
	author = {Eliassen, Arnt and Raustein, Elmer},
	year = {1968},
	pages = {45--63}
}

@article{ritchie_eliminating_1986,
	title = {Eliminating the {Interpolation} {Associated} with the {Semi}-{Lagrangian} {Scheme}},
	volume = {114},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1986)114%3C0135:ETIAWT%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1986)114<0135:ETIAWT>2.0.CO;2},
	abstract = {There are several reasons why it is desirable to eliminate the interpolation associated with the conventional semi-Larangian scheme. Interpolation leads to smoothing and is also the most costly operation associated with the technique. Furthermore, its elimination produces a scheme that is more readily adaptable to a spectral model. In the conventional semi-Lagrangian method, in order to predict a field value at grid point (Xi, Yj) it is necessary to calculate the trajectory over one time step for the fluid element that arrives at (Xi, Yj). One then moves along this trajectory in order to extract the field value at an upstream location that generally lies between the grid points, and hence requires the use of interpolation formulae. This trajectory can be represented as a vector. In the new scheme, the trajectory vector is considered to be the sum of two other vectors—a first vector joining (Xi, Yj) to the grid point (Xu, Yu) nearest the upstream location, and a second vector joining (Xu, Yu) to the upstream location. The advection along the first vector is done via a Lagrangian technique that displaces the field from one grid point to another and, therefore, does not require interpolation. The advection along the second vector is accounted for by an Eulerian approach with the advecting winds modified in such a way that the Courant number is always less than one, thus retaining the attractive stability properties of the interpolating semi-Lagrangian method. Here the noninterpolating scheme is applied to a model of the shallow water equations and its performance is assessed by comparing the results with those produced by one model which uses the interpolating semi-Lagrangian technique, and another model which uses a fourth-order Eulerian approach. Five-day integrations indicate that the scheme is stable, accurate, and appears to have efficiency advantages.},
	number = {1},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Ritchie, Harold},
	month = jan,
	year = {1986},
	pages = {135--146}
}

@article{ringler_modeling_2000,
	title = {Modeling the {Atmospheric} {General} {Circulation} {Using} a {Spherical} {Geodesic} {Grid}: {A} {New} {Class} of {Dynamical} {Cores}},
	volume = {128},
	issn = {0027-0644},
	shorttitle = {Modeling the {Atmospheric} {General} {Circulation} {Using} a {Spherical} {Geodesic} {Grid}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(2000)128%3C2471:MTAGCU%3E2.0.CO;2},
	doi = {10.1175/1520-0493(2000)128<2471:MTAGCU>2.0.CO;2},
	abstract = {This paper documents the development and testing of a new type of atmospheric dynamical core. The model solves the vorticity and divergence equations in place of the momentum equation. The model is discretized in the horizontal using a geodesic grid that is nearly uniform over the entire globe. The geodesic grid is formed by recursively bisecting the triangular faces of a regular icosahedron and projecting those new vertices onto the surface of the sphere. All of the analytic horizontal operators are reduced to line integrals, which are numerically evaluated with second-order accuracy. In the vertical direction the model can use a variety of coordinate systems, including a generalized sigma coordinate that is attached to the top of the boundary layer. Terms related to gravity wave propagation are isolated and an efficient semi-implicit time-stepping scheme is implemented. Since this model combines many of the positive attributes of both spectral models and conventional finite-difference models into a single dynamical core, it represents a distinctively new approach to modeling the atmosphere’s general circulation. The model is tested using the idealized forcing proposed by Held and Suarez. Results are presented for simulations using 2562 polygons (approximately 4.5° × 4.5°) and using 10 242 polygons (approximately 2.25° × 2.25°). The results are compared to those obtained with spectral model simulations truncated at T30 and T63. In terms of first and second moments of state variables such as the zonal wind, meridional wind, and temperature, the geodesic grid model results using 2562 polygons are comparable to those of a spectral model truncated at slightly less than T30, while a simulation with 10 242 polygons is comparable to a spectral model simulation truncated at slightly less than T63. In order to further demonstrate the viability of this modeling approach, preliminary results obtained from a full-physics general circulation model that uses this dynamical core are presented. The dominant features of the DJF climate are captured in the full-physics simulation. In terms of computational efficiency, the geodesic grid model is somewhat slower than the spectral model used for comparison. Model timings completed on an SGI Origin 2000 indicate that the geodesic grid model with 10 242 polygons is 20\% slower than the spectral model truncated at T63. The geodesic grid model is more competitive at higher resolution than at lower resolution, so further optimization and future trends toward higher resolution should benefit the geodesic grid model.},
	number = {7},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Ringler, Todd D. and Heikes, Ross P. and Randall, David A.},
	month = jul,
	year = {2000},
	pages = {2471--2490}
}

@article{longuet-higgins_eigenfunctions_1968,
	title = {The eigenfunctions of {Laplace}'s tidal equations over a sphere},
	volume = {262},
	number = {1132},
	journal = {Philosophical Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences},
	author = {Longuet-Higgins, Michael Selwyn},
	year = {1968},
	pages = {511--607}
}

@techreport{eliassen_upper_1954,
	title = {Upper air network requirements for numerical weather prediction},
	number = {29},
	institution = {World Meteorological Organization},
	author = {Eliassen, A. and Sawyer, J. S. and {Smagorinsky, J.}},
	year = {1954},
	pages = {16}
}

@article{lindzen_oscillations_1968,
	title = {Oscillations in atmospheres with tops},
	volume = {96},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1968)096%3C0133:OIAWT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1968)096<0133:OIAWT>2.0.CO;2},
	abstract = {Free and forced oscillations are compared for infinite and bounded atmospheres. Both continuous and two layer bounded atmospheres are considered. It is found that bounded atmospheres reproduce the free oscillations of the infinite atmosphere with accuracy that depends on top height—they, however, also introduce spurious free oscillations. In studying forced oscillations, the spurious oscillations of bounded atmospheres appear as spurious resonances. In general, bounded atmospheres do not properly respond to oscillations that propagate vertically.},
	number = {3},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Lindzen, R. S. and Batten, E. S. and Kim, J.-W.},
	month = mar,
	year = {1968},
	pages = {133--140}
}

@article{lindzen_supersaturation_1988,
	title = {Supersaturation of {Vertically} {Propagating} {Internal} {Gravity} {Waves}},
	volume = {45},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1988)045%3C0705:SOVPIG%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1988)045<0705:SOVPIG>2.0.CO;2},
	abstract = {The usual assumption that vertically propagating internal gravity waves will cease growing with height once their amplitudes are such as to permit convective instability anywhere within the wave is reexamined. Two factors lead to amplitude limitation: (i) wave clipping associated with convective mixing, and (ii) energetic constraints associated with the rate at which the wave can supply energy to the convection. It is found that these two factors limit supersaturation to about 50\% for waves with short horizontal wavelengths and high relative phase speeds. Usually the degree of supersaturation will be much less. These factors also lead to a gradual, rather than sudden, cessation of wave growth with height.},
	number = {4},
	urldate = {2017-11-01},
	journal = {Journal of the Atmospheric Sciences},
	author = {Lindzen, Richard S.},
	month = feb,
	year = {1988},
	pages = {705--711}
}

@book{richtmyer_difference_1967,
	title = {Difference methods for initial value problems: {New} {York}, {Interscience} {Publ}},
	shorttitle = {Difference methods for initial value problems},
	publisher = {Inc},
	author = {Richtmyer, R. W. and Morton, K. W.},
	year = {1967}
}

@article{cressman_operational_1959,
	title = {An operational objective analysis system},
	volume = {87},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281959%29087%3C0367%3AAOOAS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1959)087<0367:AOOAS>2.0.CO;2},
	abstract = {The system of objective weather map analysis used at the Joint Numerical Weather Prediction Unit is described. It is an integral part of the automatic data processing system, and is designed to operate with a minimum of manual supervision. The analysis method, based mainly on the method of Bergthórssen and Dööos, is essentially a method of applying corrections to a first guess field. The corrections are determined from a comparison of the data with the interpolated value of the guess field at the observation point. For the analysis of the heights of a pressure surface the reported wind is taken into account in determining the lateral gradient of the correction to be applied. A series of scans of the field is made, each scan consisting of application of corrections on a smaller lateral scale than during the previous scan. The analysis system is very flexible, and has been used to analyze many different types of variables. An example of horizontal divergence computed from a direct wind analysis is shown.},
	number = {10},
	journal = {Monthly Weather Review},
	author = {Cressman, George P.},
	month = oct,
	year = {1959},
	pages = {367--374}
}

@article{lin_finite-volume_1997,
	title = {A finite-volume integration method for computing pressure gradient force in general vertical coordinates},
	volume = {123},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49712354214/abstract},
	doi = {10.1002/qj.49712354214},
	abstract = {A finite-volume integration method is proposed for computing the pressure gradient force in general vertical coordinates. It is based on fundamental physical principles in the discrete physical space, rather than on the common approach of transforming analytically the pressure gradient terms in differential form from the vertical physical (i.e., height or pressure) coordinate to one following the bottom topography. The finite-volume discretization is compact, involving only the four vertices of the finite volume. The accuracy of the method is evaluated statically in a two-dimensional environment and dynamically in three-dimensional dynamical cores for general circulation models. The errors generated by the proposed method are demonstrated to be very low in these tests.},
	language = {en},
	number = {542},
	urldate = {2017-11-01},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Lin, Shian-Jiann},
	month = jul,
	year = {1997},
	keywords = {Finite-volume discretization, Numerical techniques, Orography},
	pages = {1749--1762}
}

@article{cullen_forecasting_1979,
	title = {Forecasting and general circulation results from finite element models},
	volume = {105},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49710544506/abstract},
	doi = {10.1002/qj.49710544506},
	abstract = {A 5-level global model is described in which finite element methods are used to describe the variations of fields in the horizontal. Three versions of the model are used: two use velocity components as dependent variables but differ in horizontal resolution; the third uses stream function and velocity potential. The results show that the finite element models are competitive with existing finite difference models but proper comparison is difficult because of the large effect of certain special features of the models, for instance the treatment of the poles. The change in dependent variable has a much greater impact on the results than a change in resolution with no change in formulation.},
	language = {en},
	number = {445},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Cullen, M. J. P. and Hall, C. D.},
	month = jul,
	year = {1979},
	pages = {571--592}
}

@book{edwards_likelihood_1972,
	title = {Likelihood},
	publisher = {Cambridge University Press},
	author = {Edwards, A. W. F.},
	year = {1972}
}

@article{courtier_strategy_1994,
	title = {A strategy for operational implementation of {4D}-{Var}, using an incremental approach},
	volume = {120},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49712051912/abstract},
	doi = {10.1002/qj.49712051912},
	abstract = {An order of magnitude reduction in the cost of four-dimensional variational assimilation (4D-Var) is required before operational implementation is possible. Preconditioning is considered and, although it offers a significant reduction in cost, it seems that it is unlikely to provide a reduction as large as an order of magnitude. An approximation to 4D-Var, namely the incremental approach, is then considered and is shown to produce the same result at the end of the assimilation window as an extended Kalman filter in which no approximations are made in the assimilating model but in which instead a simplified evolution of the forecast error is introduced. This approach provides the flexibility for a cost—benefit trade-off of 4D-Var to be made.},
	language = {en},
	number = {519},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Courtier, P. and Thépaut, J.-N. and Hollingsworth, A.},
	month = jul,
	year = {1994},
	pages = {1367--1387}
}

@article{reynolds_iv._1895,
	title = {{IV}. {On} the dynamical theory of incompressible viscous fluids and the determination of the criterion},
	volume = {186},
	copyright = {Scanned images copyright © 2017, Royal Society},
	issn = {0264-3820, 2053-9231},
	url = {http://rsta.royalsocietypublishing.org/content/186/123},
	doi = {10.1098/rsta.1895.0004},
	abstract = {Extract
1. The equations of motion of viscous fluid (obtained by grafting on certain terms to the abstract equations of the Eulerian form so as to adapt these equations to the case of fluids subject to stresses depending in some hypothetical manner on the rates of distortion, which equations Navier seems to have first introduced in 1822, and which were much studied by Cauchy and Poisson) were finally shown by St. Venant and Sir Gabriel Stokes, in 1845, to involve no other assumption than that the stresses, other than that of pressure uniform in all directions, are linear functions of the rates of distortion, with a co-efficient depending on the physical state of the fluid. By obtaining a singular solution of these equations as applied to the case of pendulums in steady periodic motion, Sir G. Stokes was able to compare the theoretical results with the numerous experiments that had been recorded, with the result that the theoretical calculations agreed so closely with the experimental determinations as seemingly to prove the truth of the assumption involved. This was also the result of comparing the flow of water through uniform tubes with the flow calculated from a singular solution of the equations so long as the tubes were small and the velocities slow. On the other hand, these results, both theoretical and practical, were directly at variance with common experience as to the resistance encountered by larger bodies moving with higher velocities through water, or by water moving with greater velocities through larger tubes. This discrepancy Sir G. Stokes considered as probably resulting from eddies which rendered the actual motion other than that to which the singular solution referred and not as disproving the assumption.},
	language = {en},
	urldate = {2017-11-01},
	journal = {Phil. Trans. R. Soc. Lond. A},
	author = {Reynolds, Osborne and A, M. and D, Ll and S, F. R.},
	month = jan,
	year = {1895},
	pages = {123--164}
}

@article{courtier_important_1993,
	title = {Important literature on the use of adjoint, variational methods and the {Kalman} filter in meteorology},
	volume = {45},
	issn = {null},
	url = {http://dx.doi.org/10.3402/tellusa.v45i5.14898},
	doi = {10.3402/tellusa.v45i5.14898},
	abstract = {The use of adjoint equations is proving to be invaluable in many areas of meteorological research. Unlike a forecast model which describes the evolution of meteorological fields forward in time, the adjoint equations describe the evolution of sensitivity (to initial, boundary and parametric conditions) backward in time. Essentially, by utilizing this sensitivity information, many types of problems can be solved more efficiently than in the past, including variational data assimilation, parameter fitting, optimal instability and sensitivity analysis in general. For this reason, the adjoints of various models and their applications have been appearing more and more frequently in meteorological research. This paper is a bibliography in chronological order of published works in meteorology dealing with adjoints which have appeared prior to this issue of Tellus. Also included are meteorological works regarding variational methods (even without adjoints) and Kalman filtering in data assimilation, plus some references outside meteorology. These additional works are included here because the main thrust for adjoint application within meteorology is currently concentrated in the development of next-generation data assimilation systems.},
	number = {5},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Courtier, Philippe and Derber, John and Errico, Ron and Louis, Jean-Francois and Vukićević, Tomislava},
	month = jan,
	year = {1993},
	pages = {342--357}
}

@article{hodur_naval_1997,
	title = {The {Naval} {Research} {Laboratory}’s {Coupled} {Ocean}/{Atmosphere} {Mesoscale} {Prediction} {System} ({COAMPS})},
	volume = {125},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1997)125%3C1414:TNRLSC%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1997)125<1414:TNRLSC>2.0.CO;2},
	abstract = {The three-dimensional Coupled Ocean/Atmosphere Mesoscale Prediction System (COAMPS) has been developed by the Naval Research Laboratory. COAMPS consists of an atmospheric data assimilation system comprising data quality control, analysis, initialization, and nonhydrostatic forecast model components, as well as a hydrostatic ocean model. The models can be integrated simultaneously so that the surface fluxes of heat, momentum, and moisture are exchanged across the air–water interface every time step. Optionally, either the atmospheric or ocean model can be used as a stand-alone system. The atmospheric component of COAMPS was used for operational support for the America3 team in the 1995 America’s Cup races. Results of these forecasts indicated the necessity of data assimilation to reduce model spinup in the first 6 h of the forecast. Accurate forecasts of the low-level wind in the coastal race area was accomplished by utilizing triply nested grids to attain the necessary high resolution to resolve the local wind patterns and the underlying surface terrain field. Two idealized simulations of a tropical cyclone were performed with COAMPS. In the first simulation, only the atmospheric model was used, assuming a fixed sea surface temperature (SST). A realistic structure developed with spiral bands of convection present outside the inner eyewall. These spiral bands occasionally contracted inward resulting in rapid fluctuations in the intensity of the tropical cyclone. In the second simulation, the ocean model was run simultaneously with the atmospheric model. The SST cooled over 8°C over a small area within the radius of maximum winds, resulting in a much weaker system. However, there appeared to be little effect on the overall strength of the system, as measured by the tangential velocities outside the radius of maximum winds.},
	number = {7},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Hodur, Richard M.},
	month = jul,
	year = {1997},
	pages = {1414--1430}
}

@incollection{hinkelmann_numerisches_1959,
	title = {Ein numerisches {Experiment} mit den primitive {Gleichungen}},
	booktitle = {The {Atmosphere} and the {Sea} in {Motion}},
	publisher = {Rockfeller Institute Press},
	author = {Hinkelmann, Karl},
	year = {1959},
	pages = {486--500}
}

@article{reynolds_decaying_1998,
	title = {Decaying {Singular} {Vectors} and {Their} {Impact} on {Analysis} and {Forecast} {Correction}},
	volume = {55},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1998)055%3C3005:DSVATI%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1998)055<3005:DSVATI>2.0.CO;2},
	abstract = {The full set of kinetic energy singular values and singular vectors for the forward tangent propagator of a quasigeostrophic potential vorticity model is examined. In contrast to the fastest growing singular vectors, the fastest decaying vectors exhibit a downward and downscale transfer of energy and an eastward tilt with height. The near-neutral singular vectors resemble small-scale noise with no localized structure or coherence between levels. Post-time forecast and analysis correction techniques are examined as a function of the number of singular vectors included in the representation of the inverse of the forward tangent propagator. It is found that for the case when the forecast error is known exactly, the best corrections are obtained when using the full inverse, which includes all of the singular vectors. It is also found that the erroneous projection of the analysis uncertainty onto the fastest decaying singular vectors has a significant detrimental effect on the estimation of analysis error. Therefore, for the more realistic case where the forecast error is known imperfectly, use of the full inverse will result in an inaccurate estimate of analysis errors, and the best corrections are obtained when using an inverse composed only of the growing singular vectors. Running the tangent equations with a negative time step is a very good approximation to using the full inverse of the forward tangent propagator.},
	number = {19},
	urldate = {2017-11-01},
	journal = {Journal of the Atmospheric Sciences},
	author = {Reynolds, C. A. and Palmer, T. N.},
	month = oct,
	year = {1998},
	pages = {3005--3023}
}

@article{courtier_variational_1990,
	title = {Variational assimilation of meteorological observations with the direct and adjoint shallow-water equations},
	volume = {42},
	issn = {1600-0870},
	url = {http://onlinelibrary.wiley.com/doi/10.1034/j.1600-0870.1990.t01-4-00004.x/abstract},
	doi = {10.1034/j.1600-0870.1990.t01-4-00004.x},
	abstract = {Experiments of variational assimilation, similar to those already performed by the authors on a vorticity equation model are performed on a shallow-water equation model. The variational algorithm requires the computation of the gradient of the distance function to be minimized with respect to the model state at the beginning of the assimilation period. As in the previous experiments, this gradient is computed by using the adjoint equations of the model. Northern Hemisphere observations of wind and geopotential, distributed at the 500 mb level over a 24-h time period, are assimilated with a spectral model truncated at degree 21. The results confirm the results previously obtained, namely that the variational process reconstructs to a satisfactory degree of accuracy the meteorological structures of the flow. In addition: (i) Gravity wave noise can be efficiently eliminated by adding an appropriate penalty term to the distance function, and by introducing in the variational process a nonlinear normal mode initialization algorithm. The latter has the effect of improving the numerical conditioning of the variational process. (ii) The quality of forecasts produced from the results of variational assimilation is similar to the quality of shallow-water equation forecasts produced from the results of operational assimilations, which use many more data and more realistic models. Assimilations performed with a model truncated at degree 42 produce similar results. They also show that the numerical efficiency of the variational process, as measured by the number of descent steps necessary to reach convergence, is almost insensitive to the dimension of the model phase space. Finally, study of the variations of the distance function suggests that, as in the case of the vorticity equation, the tangent linear approximation to the model equations is valid in the conditions of data assimilation.},
	language = {en},
	number = {5},
	journal = {Tellus A},
	author = {Courtier, Philippe and Talagrand, Olivier},
	month = oct,
	year = {1990},
	pages = {531--549}
}

@book{barry_atmosphere_2009,
	title = {Atmosphere,, {Weather} and {Climate}, {Chapter} 10 in {Climate} {System} {Modeling}},
	isbn = {978-1-135-26749-0},
	abstract = {This book presents a comprehensive introduction to weather processes and climatic conditions around the world, their observed variability and changes, and projected future trends. Extensively revised and updated, this ninth edition retains its tried and tested structure while incorporating recent advances in the field. From clear explanations of the basic physical and chemical principles of the atmosphere, to descriptions of regional climates and their changes, the book presents a comprehensive coverage of global meteorology and climatology. In this new edition the latest scientific ideas are again expressed in a clear, non-mathematical matter.  New features include:    extended and updated treatment of atmospheric models   final chapter on climate variability and change has been completely rewritten to take account of the IPCC 2007 scientific assessment.   new four-colour text design featuring over 30 colour plates   over 360 diagrams have been redrawn in full colour to improve clarity and aid understanding.   Atmosphere, Weather and Climate continues to be an indispensable source for all those studying the earth’s atmosphere and world climate, whether from environmental and earth sciences, geography, ecology, agriculture, hydrology, or related disciplinary perspectives. Its pedagogic value is enhanced by several features: learning points at the opening of each chapter and discussion topics at their ending, boxes on topical subjects and on twentieth century advances in the field.},
	language = {en},
	publisher = {Routledge},
	author = {Barry, Roger G. and Chorley, Richard J.},
	month = oct,
	year = {2009},
	note = {Google-Books-ID: NxaPAgAAQBAJ},
	keywords = {Science / Earth Sciences / Geography, Science / Environmental Science, Social Science / Human Geography, Technology \& Engineering / Environmental / General}
}

@article{baumhefner_evaluation_1982,
	title = {Evaluation of lateral boundary errors in a limited-domain model},
	volume = {34},
	issn = {2153-3490},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.2153-3490.1982.tb01831.x/abstract},
	doi = {10.1111/j.2153-3490.1982.tb01831.x},
	abstract = {Computational errors that arise from the imposition of artificial lateral boundaries in numerical forecast models are evaluated, using the Perkey–Kreitzberg method of variable tendency averaging near the boundary in the NCAR second generation Limited Area Model. Boundary error is diagnosed for two sets of initial conditions by using an unbounded forecast as background truth. Several components of boundary error are identified and evaluated. These include the accuracy of the boundary specification, the formulation of the blending, the increased boundary diffusion, and the physical location of the boundary. The formulation is tested by comparing boundary errors generated by the Williamson–Browning method for the same initial conditions. Finally, the boundary errors are compared to the total forecast error to evaluate its significance. Results indicate the Perkey–Kreitzberg method is stable for a wide variety of resolutions and situations. Significant errors propagate inward from the boundaries at speeds of 20–30° longitude per day. Inaccuracies in the data specified at the boundary can account for a major part of these errors, while increased diffusion near the boundary plays a lesser role in error generation. The two formulations produce similar error structures, but with less generation of spurious transients in the Williamson–Browning method. However this method proved to be unstable at high horizontal resolutions. In general, the boundary error is much less than the total forecast error.},
	language = {en},
	number = {5},
	urldate = {2017-11-01},
	journal = {Tellus},
	author = {Baumhefner, David P. and Perkey, Donald J.},
	month = oct,
	year = {1982},
	pages = {409--428}
}

@techreport{ebisuzaki_ensemble_1991,
	address = {Geneva, Switzerland},
	title = {Ensemble experiments with a new lagged average forecasting scheme},
	number = {15},
	institution = {World Meteorological Organization},
	author = {Ebisuzaki, W. and Kalnay, E.},
	year = {1991},
	pages = {308}
}

@article{reynolds_random_1994,
	title = {Random {Error} {Growth} in {NMC}'s {Global} {Forecasts}},
	volume = {122},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1994)122%3C1281%3AREGING%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1994)122<1281:REGING>2.0.CO;2},
	abstract = {The three-dimensional structure of random error growth in the National Meteorological Center's Medium-Range Forecast Model is investigated in an effort to identify the sources of error growth. The random error growth is partitioned into two types: external error growth, which is due to model deficiencies, and internal error growth, which is the self-growth of errors in the initial conditions. Forecasts from winter 1987, summer 1990, and winter 1992 are compared to assess seasonal variations in regional error growth as well as forecast model improvement. The following is found: 					  In the tropics, large external error growth at the 200-mb level is closely associated with deep convection. There is evidence of significant model improvements in the tropics at the 850-mb level between 1987 and 1992.   The spatial structure of the external error growth in the midlatitudes suggests that the representation of orography in the model, especially over Antarctica and the Rockies, is a significant source of errors.   Internal error growth in the midlatitudes is greater over the Atlantic and European regions than over the Pacific region and appears to be associated with blocking phenomena, especially over the North Atlantic and Europe. The Northern Hemisphere exhibits a seasonal cycle in the magnitude of error growth, but the Southern Hemisphere does not.    The results for the external and internal error growth rates were obtained using a parameterization of the correlation between forecasts and the verifying analyses. The parameterization is based on the assumption that linear random error growth is caused primarily by model deficiencies, and the validity of this assumption is examined. The results suggest that, in the tropics, significant increases in forecast skill may be obtainable through both model and analysis improvement. In the midlatitudes, however, there is less potential for increases in forecast skill through model improvement, and decreasing the analysis error becomes more important. The parameterization yields results that are physically meaningful and in agreement with previous predictability studies, and that provide quantitative estimates of the spatial and temporal distribution of the sources of forecast errors.},
	number = {6},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Reynolds, Carolyn A. and Webster, Peter J. and Kalnay, Eugenia},
	month = jun,
	year = {1994},
	pages = {1281--1305}
}

@article{ray_single-_1980,
	title = {Single- and {Multiple}-{Doppler} {Radar} {Observations} of {Tornadic} {Storms}},
	volume = {108},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1980)108%3C1607:SAMDRO%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1980)108<1607:SAMDRO>2.0.CO;2},
	abstract = {The use of one, two, three or more Doppler radars has become increasingly common in research programs. The advantage in increasing the number of radars is in the increased area covered and the accuracy with which wind estimates may be obtained. Although multiple-radar systems can yield special quantitative insight, a great deal of information can still be determined in real time from a single radar. It should be noted that the interpretation of radial velocity estimates from a single radar are not always unambiguous. Color displays of single-Doppler radial velocity patterns aid in the real-time interpretation of the associated reflectivity fields and can reveal important features not evident in the reflectivity structures alone. Such a capability is of particular interest in the identification and study of severe storms. A display utilizing a 5 cm Doppler radar is used to illustrate the patterns seen from several tornadic storms that occurred in central Oklahoma on 20 May 1977. Interpretation of some complicated or ambiguous features is aided by including data from additional radars. Further explanations on such structure are given from an analysis based on a new dual-Doppler analysis technique for one of 16 tornadic storms that occurred on 20 May 1977. Several alternative analysis schemes for two to four Doppler radars are also demonstrated and compared. These illustrate the major differences found in error propagation, use of information, and in difference quantities, such as divergence. It is shown that an analysis that specifies boundary values for w is not strongly dependent on the number of radars.},
	number = {10},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Ray, Peter S. and Ziegler, Conrad L. and Bumgarner, William and Serafin, Robert J.},
	month = oct,
	year = {1980},
	pages = {1607--1625}
}

@incollection{lilly_mesoscale_1983,
	series = {{NATO} {ASI} {Series}},
	title = {Mesoscale {Variability} of the {Atmosphere}},
	isbn = {978-90-481-8390-6 978-94-017-2241-4},
	url = {https://link.springer.com/chapter/10.1007/978-94-017-2241-4_2},
	abstract = {Statistical measures of atmospheric variability are reviewed as they apply to the mesoscales. Horizontal spectra of kinetic energy are found to conform approximately to a −5/3 power law from a few to about 1000 km wavelengths, while the vertical spectra follow a slope of about −2.5. As measured by structure functions, humidity variables have unusually high variability in the mesoscale. Two competitive explanations for mesoscale spectra are discussed, one based on two-dimensional turbulence concepts and the other on the theory of internal gravity waves.},
	language = {en},
	urldate = {2017-11-01},
	booktitle = {Mesoscale {Meteorology} — {Theories}, {Observations} and {Models}},
	publisher = {Springer, Dordrecht},
	author = {Lilly, D. K.},
	year = {1983},
	doi = {10.1007/978-94-017-2241-4_2},
	pages = {13--24}
}

@article{rasch_computational_1990,
	title = {Computational aspects of moisture transport in global models of the atmosphere},
	volume = {116},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49711649504/abstract},
	doi = {10.1002/qj.49711649504},
	abstract = {Computational aspects of methods used to simulate the transport of water vapour in a global atmospheric general circulation model are examined. A set of properties useful in characterizing numerical methods for modelling atmospheric transport are identified. Spectral and semi-Lagrangian methods, which are very different in terms of these desired properties are compared. The extent to which the schemes do not satisfy certain properties of the continuous equations provides a measure of one component of the error of the solution. For the spectral scheme, negative specific humidities q indicate such an error component. Conventional semi-Lagrangian schemes are also susceptible to generating negative values. In addition, they are not inherently conservative. Shape-preserving semi-Lagrangian methods do not generate negative values, but still are non-conservative. the degree to which the advection process does not conserve mass provides a measure of another error associated with the numerical solution. the negative error is shown to be large for the spectral transport scheme, measured either locally or globally. Measured globally, the semi-Lagrangian transport schemes' conservation errors are equally large. Locally, the correction of this error can be made very much smaller, relative to physical processes in the model. The study highlights the computational problems which still exist within the better numerical methods used to simulate the transport of water vapour, and demonstrates the care with which one must apply computational constraints to the solution. the spectral and semi-Lagrangian transport schemes produce very different climatologies in model simulations. A comparison of these climatologies will appear elsewhere.},
	language = {en},
	number = {495},
	urldate = {2017-11-01},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Rasch, Philip J. and Williamson, David L.},
	month = jul,
	year = {1990},
	pages = {1071--1090}
}

@article{courtier_ecmwf_1998,
	title = {The {ECMWF} implementation of three-dimensional variational assimilation ({3D}-{Var}). {I}: {Formulation}},
	volume = {124},
	issn = {1477-870X},
	shorttitle = {The {ECMWF} implementation of three-dimensional variational assimilation ({3D}-{Var}). {I}},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49712455002/abstract},
	doi = {10.1002/qj.49712455002},
	abstract = {In the first of this set of three papers, the formulation of the European Centre for Medium-Range Weather Forecasts (ECMWF) implementation of 3D-Var is described. In the second, the specification of the structure function is presented, and the last is devoted to the results of the extensive numerical experimentation programme which was conducted. The 3D-Var formulation uses a spherical-harmonic expansion, much as the ECMWF optimal interpolation (OI) scheme used an expansion of Bessel functions. This formulation is introduced using a convolution algebra over the sphere expressed directly in spectral space. It is shown that all features of the OI statistical model can be implemented within 3D-Var. Furthermore, a non-separable statistical model is described. In the present formulation, geostrophy is accounted for through a Hough-modes separation of the gravity and Rossby components of the analysis increments. As in OI, the tropical analysis remains essentially non-divergent and with a weak mass-wind coupling. The observations used, as well as their specified statistics of errors, are presented, together with some implementation details. In the light of the results, 3D-Var was implemented operationally at the end of January 1996.},
	language = {en},
	number = {550},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Courtier, P. and Andersson, E. and Heckley, W. and Vasiljevic, D. and Hamrud, M. and Hollingsworth, A. and Rabier, F. and Fisher, M. and Pailleux, J.},
	month = jul,
	year = {1998},
	keywords = {Data assimilation, Numerical weather prediction, Objective analysis},
	pages = {1783--1807}
}

@article{lilly_aircraft_1982,
	title = {Aircraft measurements of wave momentum flux over the {Colorado} {Rocky} {Mountains}},
	volume = {108},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49710845709/abstract},
	doi = {10.1002/qj.49710845709},
	abstract = {Results are presented from a programme designed to measure the momentum flux associated with standing gravity waves over the central Rocky Mountains of North America. The purpose was to determine momentum losses from the westerlies as they cross a mountainous section of the northern hemisphere where wave drag is believed to be substantial. The data from one to three instrumented aircraft, operating on 20 flight days, mostly during January to March of 1973, are in reasonably good conformity with linear wave theory and also correlate well with surface measurements of downslope winds. Downward westerly momentum flux averaged 0.5 - 1.0 dynes cm−2 (0.05 - 0.1 Pa). The mean westerly flow on the flight days was near the climatological mean for the period of the project, although the mean flow over this period as a whole was much weaker than the climatological mean.},
	language = {en},
	number = {457},
	urldate = {2017-11-01},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Lilly, Douglas K. and Nicholls, J. M. and Kennedy, Patrick J. and Klemp, Joseph B. and Chervin, Robert M.},
	month = jul,
	year = {1982},
	pages = {625--642}
}

@article{rasch_toward_1986,
	title = {Toward atmospheres without tops: {Absorbing} upper boundary conditions for numerical models},
	volume = {112},
	issn = {1477-870X},
	shorttitle = {Toward atmospheres without tops},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49711247415/abstract},
	doi = {10.1002/qj.49711247415},
	abstract = {The appropriate upper boundary condition (UBC) formulation for the dynamical equations used in atmospheric physics is discussed in terms of both theoretical and computational aspects. The previous work on the UBC formulation is reviewed in the context of a linear mid-latitude primitive equation (PE) model. A new technique for constructing the UBC is introduced. The technique depends upon the existence of analytic solutions to simplifications to the equations of motion. These analytic solutions are used to construct the exact radiation UBCs (often used in tidal theory and studies of the upper atmosphere) which are non-local in time and space. Approximate UBCs, which are local in time, are formed through rational approximations to the exact radiation UBCs. The technique is demonstrated to be effective for both Rossby and gravity modes. The UBC is tested for computational problems initially in the linear PE model, and subsequently in a forced, damped nonlinear quasi-geostrophic model.},
	language = {en},
	number = {474},
	urldate = {2017-11-01},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Rasch, Philip J.},
	month = oct,
	year = {1986},
	pages = {1195--1218}
}

@article{courtier_variational_1997,
	title = {Variational {Methods}},
	volume = {75},
	shorttitle = {Variational {Methods} ({gtSpecial} {IssueltData} {Assimilation} in {Meteology} and {Oceanography}},
	doi = {10.2151/jmsj1965.75.1B_211},
	abstract = {Variational methods are introduced as particular algorithms to solve linear estimation problems in the presence of a dynamics i.e. data assimilation. They are compared from the algebraic and algorithmic viewpoint to optimal interpolation and the Kalman filter.},
	number = {1B},
	journal = {Journal of the Meteorological Society of Japan},
	author = {Courtier, Philippe},
	year = {1997},
	pages = {211--218}
}

@article{battisti_interannual_1988,
	title = {Interannual {Variability} in a {Tropical} {Atmosphere}–{Ocean} {Model}: {Influence} of the {Basic} {State}, {Ocean} {Geometry} and {Nonlinearity}},
	volume = {46},
	issn = {0022-4928},
	shorttitle = {Interannual {Variability} in a {Tropical} {Atmosphere}–{Ocean} {Model}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1989)046%3C1687:IVIATA%3E2.0.CO;2},
	doi = {10.1175/1520-0469(1989)046<1687:IVIATA>2.0.CO;2},
	abstract = {The behavior of a tropical coupled atmosphere/ocean model is analyzed for a range of different background states and ocean geometries. The model is essentially that of Cane and Zebiak for the tropical Pacific, except only temporally constant background states are considered here. For realistic background states and ocean geometry, the model solutions feature oscillations of period of 3–5 yr. By comparing the full model solution with a linearized version of the model, it is shown that the basic mechanism of the oscillation is contained within linear theory. A simple linear analog model is derived that describes the nature of the interannual variability in the coupled tropical atmosphere–ocean system. The analog model highlights the properties that produce coupled atmosphere–ocean instability in the eastern ocean basin, and the equatorial wave dynamics in the western ocean basin that are responsible for a delayed, negative feedback into this instability growth. The growth rate of the local instability c together with the magnitude b and lag  of the wave-induced processes determine the nature of the interannual variability displayed in the coupled model. Specifically, these processes determine the growth rate of the coupled system and, when the solutions are oscillatory, the period of the oscillation. The terms b, c, and  are set by the background state of the atmosphere and ocean, and the geometry of the ocean basin. The simple analog model is used to design and interpret a set of experiments using the full linear and nonlinear numerical models of the coupled atmosphere ocean system in the Pacific. In these experiments, we examine the effects of the assumed basic state and ocean geometry on the interannual variability of the coupled system. The simple model is shown to be a remarkably good proxy of the full linear and nonlinear numerical models. The limiting nonlinearity in the full numerical model is shown to be the dependence of the temperature of the upward water on the thermocline depth. However, we find the essential processes that describe the local instability growth rate and period of the interannual oscillations in the coupled system are linear. Nonlinearities primarily act as a bound on the amplitude of the final state oscillations, and decrease the period of the firm state oscillations by about 10 percent from that obtained in the small amplitude regime of the full coupled model and the linear analog model. The nonlinear analog model for the full numerical model is derived, and compared with that proposed by Suarez and Schopf. The numerical and analog models help to explain why organized, large amplitude, interannual variability is prominent in the tropical Pacific basin, and not in Atlantic and Indian basins.},
	number = {12},
	urldate = {2017-11-01},
	journal = {Journal of the Atmospheric Sciences},
	author = {Battisti, David S. and Hirst, Anthony C.},
	month = jun,
	year = {1988},
	pages = {1687--1712}
}

@book{randall_general_2000,
	title = {General {Circulation} {Model} {Development}: {Past}, {Present}, and {Future}},
	volume = {70},
	isbn = {978-0-08-050723-1},
	shorttitle = {General {Circulation} {Model} {Development}},
	abstract = {General Circulation Models (GCMs) are rapidly assuming widespread use as powerful tools for predicting global events on time scales of months to decades, such as the onset of EL Nino, monsoons, soil moisture saturation indices, global warming estimates, and even snowfall predictions. While GCMs have been praised for helping to foretell the current El Nino and its impact on droughts in Indonesia, its full power is only now being recognized by international scientists and governments who seek to link GCMs to help them estimate fish harvests, risk of floods, landslides, and even forest fires.Scientists in oceanography, hydrology, meteorology, and climatology and civil, ocean, and geological engineers perceive a need for a reference on GCM design. In this compilation of information by an internationally recognized group of experts, Professor Randall brings together the knowledge base of the forerunners in theoretical and applied frontiers of GCM development. General Circulation Model Development focuses on the past, present, and future design of numerical methods for general circulation modeling, as well as the physical parameterizations required for their proper implementation. Additional chapters on climate simulation and other applications provide illustrative examples of state-of-the-art GCM design.Key Features* Foreword by Norman Phillips* Authoritative overviews of current issues and ideas on global circulation modeling by leading experts* Retrospective and forward-looking chapters by Akio Arakawa of UCLA* Historical perspectives on the early years of general circulation modeling* Indispensable reference for researchers and graduate students},
	language = {en},
	publisher = {Academic Press},
	author = {Randall, David A.},
	month = jul,
	year = {2000},
	note = {Google-Books-ID: vnYeHl6AvgkC},
	keywords = {Science / Earth Sciences / Meteorology \& Climatology}
}

@article{lilly_comments_1980,
	title = {Comments on “{The} {Evolution} and {Stability} of {Finite}-{Amplitude} {Mountain} {Waves}. {Part} {II}: {Surface} {Wave} {Drag} and {Severe} {Downslope} {Windstorms}”},
	volume = {37},
	shorttitle = {Comments on “{The} {Evolution} and {Stability} of {Finite}-{Amplitude} {Mountain} {Waves}. {Part} {II}},
	number = {9},
	journal = {Journal of the Atmospheric Sciences},
	author = {Lilly, D. K. and Klemp, J. B.},
	year = {1980},
	pages = {2119--2121}
}

@article{courtier_global_1988,
	title = {A global numerical weather prediction model with variable resolution: {Application} to the shallow-water equations},
	volume = {114},
	issn = {1477-870X},
	shorttitle = {A global numerical weather prediction model with variable resolution},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49711448309/abstract},
	doi = {10.1002/qj.49711448309},
	abstract = {We follow the approach suggested by F. Schmidt to implement a spectral global shallow-water model with variable resolution. A conformal mapping is built between the earth and a computational sphere and the equations are discretized on the latter using the standard spectral technique associated with a collocation (Gaussian) grid. We prove that the only non-trivial conformal mapping which exists between the two spheres is based on the transformation introduced by Schmidt, but the pole of the collocation grid has no longer to coincide with the pole of dilatation. We implement the technique in an explicit model, where only minor modifications to a uniform resolution model are needed. The semi-implicit scheme and the nonlinear normal mode initialization are proved to work satisfactorily. 24-hour forecasts show that the method is successful in dealing with the shallow-water equations and allow us to discuss the potential of the approach.},
	language = {en},
	number = {483},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Courtier, Philippe and Geleyn, Jean-Francois},
	month = jul,
	year = {1988},
	pages = {1321--1346}
}

@article{lilly_effects_1979,
	title = {The effects of terrain shape on nonlinear hydrostatic mountain waves},
	volume = {95},
	issn = {1469-7645, 0022-1120},
	url = {https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/the-effects-of-terrain-shape-on-nonlinear-hydrostatic-mountain-waves/937982627E53EC23366555DA3BEDCE6A},
	doi = {10.1017/S0022112079001452},
	abstract = {Solutions to Long's equation for a stably stratified incompressible fluid traversing a mountain range are obtained for various terrain shapes and amplitudes when the horizontal scale is large compared to the vertical wavelength. Nonlinear lower and upper (radiative) boundary conditions are utilized and found to have a strong influence on the wave structure at large amplitudes. The results for symmetric and asymmetric mountain profiles reveal that the wave amplitude and wave drag are significantly enhanced for mountains with gentle windward and steep leeward slopes. These results confirm and explain those obtained by Raymond (1972) using a different solution method. Several results obtained by Smith (1977) from perturbation analysis are also confirmed and extended to large amplitudes. The methods are also applied to investigate the nonlinear nature of the singularity predicted by linear theory for flow over a step.},
	number = {2},
	urldate = {2017-11-01},
	journal = {Journal of Fluid Mechanics},
	author = {Lilly, D. K. and Klemp, J. B.},
	month = nov,
	year = {1979},
	pages = {241--261}
}

@article{bates_global_1995,
	title = {A global shallow-water numerical model based on the semi-lagrangian advection of potential vorticity},
	volume = {121},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49712152810/abstract},
	doi = {10.1002/qj.49712152810},
	abstract = {A global shallow-water primitive equation model based on the semi-Lagrangian advection of potential vorticity is presented. A modification of the basic advection scheme needed to stabilize Rossby waves is introduced. the divergence and continuity equations are the remaining governing equations. A two-time-level semi-Lagrangian semi-implicit numerical scheme that avoids forward extrapolation of non-linear terms is used. This leads to a set of non-linear implicit equations to be solved at each time-step. the wind field is expressed in terms of a streamfunction and velocity potential, and a spatial discretization based on second-order finite differences on an unstaggered grid is used. the implicit equations are solved simultaneously using a non-linear multigrid method. The model is integrated for periods of up to 50 days at various resolutions, using a variety of initial conditions including real data. Comparisons with an existing semi-Lagrangian finite-difference shallow-water model and an Eulerian spectral shallow-water model are carried out. the new model is found to integrate stably and efficiently, and to require no noise suppressors other than the inherent diffusivity associated with the interpolations. the model gives results that are, in general, very close to those of the comparison models, but a case of highly non-linear flow (where the true solution is unknown) is presented in which it gives results that stand notably apart.},
	language = {en},
	number = {528},
	urldate = {2017-11-01},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Bates, J. R. and Li, Y. and Brandt, A. and McCormick, S. F. and Ruge, J.},
	month = oct,
	year = {1995},
	keywords = {Numerical methods, Potential vorticity, Semi-Lagrangian models},
	pages = {1981--2005}
}

@article{lilly_observations_1973,
	title = {Observations of a {Stationary} {Mountain} {Wave} and its {Associated} {Momentum} {Flux} and {Energy} {Dissipation}},
	volume = {30},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1973)030%3C1135:OOASMW%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1973)030<1135:OOASMW>2.0.CO;2},
	abstract = {Analysis is presented of data obtained from instrumented aircraft flying in a mountain wave of moderate amplitude west of Denver, Colo., on 17 February 1970. Emphasis is placed on determination of the downward flux of westerly momentum generated by the wave, for which accurate measurements of vertical velocities on scales of order 50 km are essential. Three different methods are applied and compared: direct aircraft measurement, using vanes and an inertial platform; evaluation from the steady-state equation for conservation of potential temperature; and integration of the steady-state continuity equation. Each method produces errors, but by combining the results of the three methods a profile is obtained which agrees. fairly well with a steady-state theoretical prediction. An important side result is the discovery that gust-probe equipment is apparently not necessary for the direct aircraft measurement of wave momentum flux, but an inertial platform or similarly stable attitude reference level is essential. A region of severe turbulence at 100 mb is found to he associated with the source of most of the downward wave momentum flux. Measurements of the loss of total energy along isentropes are found to he consistent with kinetic energy losses estimated from momentum flux divergence and with energy dissipation estimated from inertial-range aircraft measurements of the turbulent energy spectrum.},
	number = {6},
	urldate = {2017-11-01},
	journal = {Journal of the Atmospheric Sciences},
	author = {Lilly, D. K. and Kennedy, P. J.},
	month = sep,
	year = {1973},
	pages = {1135--1152}
}

@article{courtier_variational_1987,
	title = {Variational {Assimilation} of {Meteorological} {Observations} {With} the {Adjoint} {Vorticity} {Equation}. {II}: {Numerical} {Results}},
	volume = {113},
	issn = {1477-870X},
	shorttitle = {Variational {Assimilation} of {Meteorological} {Observations} {With} the {Adjoint} {Vorticity} {Equation}. {Ii}},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49711347813/abstract},
	doi = {10.1002/qj.49711347813},
	abstract = {The adjoint variational approach to data assimilation described in the first part of this paper is used, with the same vorticity equation model, to assimilate northern hemisphere radiosonde observations of wind and geopotential distributed over a 24-hour period. Except over the eastern Pacific Ocean, where no observations are available, the variational assimilation reconstructs all structures of the flow resolvable by the model to an accuracy of about 30 m for geopotential heights and 8 m s−1 for wind vectors. A particular structure, the Aleutian depression, is reconstructed even though it was not covered by the available observations. The assimilation produces unrealistic small-scale noise which can be reduced by adding an appropriate smoothing term to the distance function minimized in the variational process. Detailed study of the minimization strongly suggests that the distance function varies quadratically with respect to the model's initial conditions. This implies that the tangent linear equation of the model suffices to describe the 24-hour evolution of the forecast error.},
	language = {en},
	number = {478},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Courtier, Philippe and Talagrand, Olivier},
	month = oct,
	year = {1987},
	pages = {1329--1347}
}

@article{avolio_preliminary_2011,
	title = {Preliminary {Meteorological} {Results} of a {Four}-{Dimensional} {Data} {Assimilation} {Technique} in {Southern} {Italy}},
	volume = {01},
	copyright = {http://creativecommons.org/licenses/by/4.0/},
	url = {http://www.scirp.org/journal/PaperInformation.aspx?PaperID=6196&#abstract},
	doi = {10.4236/acs.2011.13015},
	abstract = {A four-dimensional data assimilation (FDDA) scheme based on a Newtonian relaxation (or “nudging”) was tested using observational asynoptic data collected at a coastal site in the Central Mediterranean peninsula of Calabria, southern Italy. The study is referred to an experimental campaign carried out in summer 2008. For this period a wind profiler, a sodar and two surface meteorological stations were considered. The collected measurements were used for the FDDA scheme, and the technique was incorporated into a tailored version of the Regional Atmospheric Modeling System (RAMS). All instruments are installed and operated routinely at the experimental field of the CRATI-ISAC/CNR located at 600 m from the Tyrrhenian coastline. Several simulations were performed, and the results show that the assimilation of wind and/or temperature data, both throughout the simulation time (continuous FDDA) and for a 12 h time window (forecasting configuration), produces improvements of the model performance. Considering a whole single day, improvements are sub-stantial in the case of continuous FDDA while they are smaller in the case of forecasting configuration. En-hancements, during the first six hours of each run, are generally higher. The resulting meteorological fields are finalised as input into air quality and agro-meteorological models, for short-term predictions of renew-able energy production forecast, and for atmospheric model initialization.},
	language = {en},
	number = {03},
	urldate = {2017-11-01},
	journal = {Atmospheric and Climate Sciences},
	author = {Avolio, Elenio and Federico, S. and Sempreviva, A. M. and Calidonna, C. R. and Leo, L. De and Bellecci, C.},
	month = jul,
	year = {2011},
	pages = {134}
}

@article{rancic_global_1996,
	title = {A global shallow-water model using an expanded spherical cube: {Gnomonic} versus conformal coordinates},
	volume = {122},
	issn = {1477-870X},
	shorttitle = {A global shallow-water model using an expanded spherical cube},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49712253209/abstract},
	doi = {10.1002/qj.49712253209},
	abstract = {A model using shallow-water equations with an Arakawa-type scheme for momentum terms is tested on a quasi-uniform geometry on the sphere, derived by a spherical expansion of the inscribed cube based on the gnomonic projection. Thereby, a quasi-homogeneous distribution of grid points is achieved, and a global finite-difference model is designed which does not require Fourier filtering or suffer from the burden of redundant computational points at high latitudes. Difficulties resulting from the directional discontinuity of the coordinate lines crossing the edges of the expanded cube are almost completely eliminated by using the Arakawa B-grid, so that only scalar points are placed along the edges. An alternative approach is developed based on numerical orthogonalization of the grid whereby, inter alia, the directional discontinuity at the edges is avoided at the cost of some accumulation of points in the vicinity of the vertices of the cube. In the customary Rossby–Haurwitz wave-4 tests, both approaches are shown to converge to a visually indistinguishable solution as the resolution is increased. However, with the orthogonalized, conformal grid, convergence towards the asymptotic solution was substantially faster.},
	language = {en},
	number = {532},
	urldate = {2017-11-01},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Rančić, M. and Purser, R. J. and Mesinger, F.},
	month = apr,
	year = {1996},
	keywords = {Numerical weather prediction, Finite differences, Quasi-uniform grids, Shallow-water equations},
	pages = {959--982}
}

@book{durran_numerical_1999,
	title = {Numerical {Methods} for {Wave} {Equations} in {Geophysical} {Fluid} {Dynamics}},
	isbn = {978-1-4757-3081-4},
	abstract = {Mathematics is playing an ever more important role in the physical and biological sciences, provoking a blurring of boundaries between scientific disciplines and a resurgence of interest in the modem as weIlas the classical techniques of applied mathematics. This renewal of interest, both in research and teaching, has led to the establishment of the series: Texts in AppliedMathematics (TAM). The development of new courses is a natural consequence of a high level of excitement on the research frontier as newer techniques, such as numerical and symbolic computer systems, dynamical systems, and chaos, mix with and rein force the traditional methods of applied mathematics. Thus, the purpose of this textbook series is to meet the current and future needs of these advances and en courage the teaching of new courses. TAM will publish textbooks suitable for use in advanced undergraduate and beginning graduate courses, and will complement the AppliedMathematical Sei ences (AMS) series, which will focus on advanced textbooks and research level monographs. Preface This book is designed to serve as a textbook for graduate students or advanced undergraduates studying numerical methods for the solution of partial differen tial equations goveming wave-like flows. Although the majority of the schemes presented in this text were introduced ineither the applied-rnathematics or atmos pheric-science literature, the focus is not on the nuts-and-bolts details of various atmospheric models but on fundamental numerical methods that have applications in a wide range of scientific and engineering disciplines.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Durran, Dale R.},
	year = {1999},
	note = {Google-Books-ID: JioBCAAAQBAJ},
	keywords = {Mathematics / Numerical Analysis, Mathematics / Algebra / General, Mathematics / Number Systems, Science / Physics / Geophysics}
}

@article{bates_multiply-upstream_1982,
	title = {Multiply-{Upstream}, {Semi}-{Lagrangian} {Advective} {Schemes}: {Analysis} and {Application} to a {Multi}-{Level} {Primitive} {Equation} {Model}},
	volume = {110},
	issn = {0027-0644},
	shorttitle = {Multiply-{Upstream}, {Semi}-{Lagrangian} {Advective} {Schemes}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281982%29110%3C1831%3AMUSLAS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1982)110<1831:MUSLAS>2.0.CO;2},
	abstract = {The stability properties of some simple semi-Lagrangian advective schemes, based on a multiply-upstream interpolation, are examined. In these schemes, the interpolation points are chosen to surround the departure points of the fluid particles at the beginning of a time step. It is shown that the schemes, though explicit, are unconditionally stable for a constant wind field. Application of the schemes to a multi-level split explicit model shows that they enable full advantage to be taken of the splitting method by allowing a long time step for advection. It is shown that they can thus lead to a considerable saving of computer time compared to Eulerian schemes, while giving comparable accuracy.},
	number = {12},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Bates, J. R. and McDonald, A.},
	month = dec,
	year = {1982},
	pages = {1831--1842}
}

@incollection{hibler_iii_sea_1992,
	title = {Sea ice models},
	booktitle = {Climate {System} {Modeling}},
	publisher = {Cambridge University Press},
	author = {Hibler III, William D. and Flato, Gregory M.},
	year = {1992},
	pages = {788}
}

@article{barkmeijer_singular_1998,
	title = {Singular vectors and estimates of the analysis-error covariance metric},
	volume = {124},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49712454916/abstract},
	doi = {10.1002/qj.49712454916},
	abstract = {An important ingredient of ensemble forecasting is the computation of initial perturbations. Various techniques exist to generate initial perturbations. All these aim to produce an ensemble that, at initial time, reflects the uncertainty in the initial condition. In this paper a method for computing singular vectors consistent with current estimates of the analysis-error statistics is proposed and studied. The singular-vector computation is constrained at initial time by the Hessian of the three-dimensional variational assimilation (3D-Var) cost function in a way which is consistent with the operational analysis procedure. The Hessian is affected by the approximations made in the implementation of 3D-Var; however, it provides a more objective representation of the analysis-error covariances than other metrics previously used to constrain singular vectors. Experiments are performed with a T21L5 Primitive-Equation model. To compute the singular vectors we solve a generalized eigenvalue problem using a recently developed algorithm. It is shown that use of the Hessian of the cost function can significantly influence such properties of singular vectors as horizontal location, vertical structure and growth rate. The impact of using statistics of observational errors is clearly visible in that the amplitude of the singular vectors reduces in data-rich areas. Finally, the use of an approximation to the Hessian is discussed.},
	language = {en},
	number = {549},
	urldate = {2017-11-01},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Barkmeijer, Jan and Bouttier, François and Van Gijzen, Martin},
	month = jul,
	year = {1998},
	keywords = {Cost function, Ensemble forecasting, Forecast skill, Hessian singular vectors},
	pages = {1695--1713}
}

@article{lilly_computational_1965,
	title = {On the computational stability of numerical solutions of time-dependent non-linear geophysical fluid dynamics problems},
	volume = {93},
	number = {1},
	journal = {Mon. Wea. Rev},
	author = {Lilly, Douglas K.},
	year = {1965},
	pages = {11--26}
}

@article{henderson-sellers_project_1993,
	title = {The {Project} for {Intercomparison} of {Land}-surface {Parameterization} {Schemes}},
	volume = {74},
	issn = {0003-0007},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0477(1993)074%3C1335:TPFIOL%3E2.0.CO%3B2},
	doi = {10.1175/1520-0477(1993)074<1335:TPFIOL>2.0.CO;2},
	abstract = {The Project for Intercomparison of Land-surface Parameterization Schemes (PILPS) is described and the first stage science plan outlined. PILPS is a project designed to improve the parameterization of the continental surface, especially the hydrological, energy, momentum, and carbon exchanges with the atmosphere. The PILPS Science Plan incorporates enhanced documentation, comparison, and validation of continental surface parameterization schemes by community participation. Potential participants include code developers, code users, and those who can provide datasets for validation and who have expertise of value in this exercise. PILPS is an important activity because existing intercomparisons, although piecemeal, demonstrate that there are significant differences in the formulation of individual processes in the available land surface schemes. These differences are comparable to other recognized differences among current global climate models such as cloud and convection parameterizations. It is also clear that too few sensitivity studies have been undertaken with the result that there is not yet enough information to indicate which simplifications or omissions are important for the near-surface continental climate, hydrology, and biogeochemistry. PILPS emphasizes sensitivity studies with and intercomparisons of existing land surface codes and the development of areally extensive datasets for their testing and validation.},
	number = {7},
	urldate = {2017-11-01},
	journal = {Bulletin of the American Meteorological Society},
	author = {Henderson-Sellers, A. and Yang, Z-L. and Dickinson, R. E.},
	month = jul,
	year = {1993},
	pages = {1335--1349}
}

@article{held_proposal_1994,
	title = {A {Proposal} for the {Intercomparison} of the {Dynamical} {Cores} of {Atmospheric} {General} {Circulation} {Models}},
	volume = {75},
	issn = {0003-0007},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0477(1994)075%3C1825:APFTIO%3E2.0.CO;2},
	doi = {10.1175/1520-0477(1994)075<1825:APFTIO>2.0.CO;2},
	abstract = {A benchmark calculation is proposed for evaluating the dynamical cores of atmospheric general circulation models independently of the physical parameterizations. The test focuses on the long-term statistical properties of a fully developed general circulation; thus, it is particularly appropriate for intercomparing the dynamics used in climate models. To illustrate the use of this benchmark, two very different atmospheric dynamical cores—one spectral, one finite difference—are compared. It is found that the long-term statistics produced by the two models are very similar. Selected results from these calculations are presented to initiate the intercomparison.},
	number = {10},
	urldate = {2017-11-01},
	journal = {Bulletin of the American Meteorological Society},
	author = {Held, Isaac M. and Suarez, Max J.},
	month = oct,
	year = {1994},
	pages = {1825--1830}
}

@article{li_proposed_2000,
	title = {A proposed adiabatic formulation of 3-dimensional global atmospheric models based on potential vorticity},
	volume = {52},
	issn = {null},
	url = {http://dx.doi.org/10.3402/tellusa.v52i2.12256},
	doi = {10.3402/tellusa.v52i2.12256},
	abstract = {A 2-time-level finite difference atmospheric general circulation model based on the semi-Lagrangian advection of pseudo potential vorticity (which becomes potential vorticity in thatpart of the domain where the hybrid vertical coordinate becomes isentropic) has been formulated.At low levels, the hybrid vertical coordinate is terrain following. The problem of isentropicpotential vorticity possibly becoming ill-defined in the regions of planetary boundary layer isthus circumvented. The divergence equation is a companion to the (pseudo) potential vorticityequation and the model is thus called a PV-D model. Many features of a previously developedshallow water PV-D model are carried over: a modification of the PV equation needed to givecomputational stability of long Rossby waves; a semi-Lagrangian semi-implicit treatment ofboth the linear and the nonlinear terms; the use of an unstaggered grid in the horizontal; theuse of a nonlinear multigrid technique to solve the nonlinear implicit equations. A linearnumerical stability analysis of the model’s gravity–inertia waves indicates that the potentialtemperature needs to be separated into horizontal mean and perturbation parts. This allowsan implicit treatment of the vertical advection associated with the mean in the thermodynamicequation. Numerical experiments with developing baroclinic waves have been carried out andgive realistic results.},
	number = {2},
	urldate = {2017-11-01},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Li, Yong and Ruge, J. and Bates, R. and Brandt, A.},
	month = jan,
	year = {2000},
	pages = {129--139}
}

@article{heikes_numerical_1995,
	title = {Numerical {Integration} of the {Shallow}-{Water} {Equations} on a {Twisted} {Icosahedral} {Grid}. {Part} {I}: {Basic} {Design} and {Results} of {Tests}},
	volume = {123},
	issn = {0027-0644},
	shorttitle = {Numerical {Integration} of the {Shallow}-{Water} {Equations} on a {Twisted} {Icosahedral} {Grid}. {Part} {I}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1995)123%3C1862:NIOTSW%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1995)123<1862:NIOTSW>2.0.CO;2},
	abstract = {The streamfunction-velocity potential form of shallow-water equations, implemented on a spherical geodesic grid, offers an attractive solution to many of the problems associated with fluid-flow simulations in a spherical geometry. Here construction of a new type of spherical geodesic grid is outlined, and discretization of the equations is explained. The model is subjected to the NCAR suite of seven test cases for shallow-water models.},
	number = {6},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Heikes, Ross and Randall, David A.},
	month = jun,
	year = {1995},
	pages = {1862--1880}
}

@article{lewis_use_1985,
	title = {The use of adjoint equations to solve a variational adjustment problem with advective constraints},
	volume = {37},
	issn = {null},
	url = {http://dx.doi.org/10.3402/tellusa.v37i4.11675},
	doi = {10.3402/tellusa.v37i4.11675},
	abstract = {A methodology is developed to guarantee time continuity in a sequence of analyses. Coupling is accomplished by requiring the least squares minimization of adjustment to the analyses subject to dynamic constraints. In this paper, the analyses are assumed to be governed by advective constraints such as those used in vorticity conservation models; however, the method can easily be applied to other constraints. The results correspond to the application of a strong constraint as introduced by Sasaki, but the procedure used to accomplish the minimization is an alternative to the traditional methods for solution of the Euler-Lagrange equation. The method allows easier inclusion of more time levels in the analysis sequence as well as accommodation of more complicated constraints.The method is tested using both simulated and real data. The simulated data studies use a one-dimensional advection equation with progressively more complicated dynamics: constant advection velocity, spatially varying advection velocity, and nonlinear advection. The real data case study uses an advection of quasi-geostrophic potential vorticity constraint to examine the height adjustment process for three time periods on 6 March 1982. Separate studies are made for analyses derived from VAS and RAOB data. The results of this study indicate the method has excellent potential to reduce the random component of the analysis errors.},
	number = {4},
	urldate = {2017-11-01},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Lewis, John M. and Derber, John C.},
	month = jan,
	year = {1985},
	pages = {309--322}
}

@article{hartmann_singular_1995,
	title = {Singular {Vectors}: {The} {Effect} of {Spatial} {Scale} on {Linear} {Growth} of {Disturbances}},
	volume = {52},
	issn = {0022-4928},
	shorttitle = {Singular {Vectors}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1995)052%3C3885%3ASVTEOS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1995)052<3885:SVTEOS>2.0.CO;2},
	abstract = {The scale dependence of rapidly growing perturbations is investigated by studying the dominant singular vectors of T21 and T42 versions of the ECMWF model, which show the most linear energy growth in a 3-day period. A spectral filter is applied to the optimization process to determine which spatial scales are most effective in promoting energy growth. When the initial perturbation is confined to the top half of the total spherical harmonic wavenumber spectrum (high wavenumber end), the growth rates and final structures of the disturbances are changed very little from the case in which all wavenumbers are included. These results indicate that synoptic waves that become fully developed in a period of three days can arise from initial perturbations that are entirely contained at subsynoptic scales. Rapid growth is associated with initial perturbations that consist of smaller spatial scales concentrated near the effective steering level. The linear evolution of these initial perturbations in a highly complex basic flow leads to disturbances of synoptic scale that extend through most of the depth of the troposphere. Growth rates are approximately doubled when the model resolution is increased from T21 to T42, which is consistent with greater growth being associated with smaller spatial scales. When the initial perturbation is confined to the lower half of the total wavenumber spectrum, which describes the larger horizontal scales, the growth rates are significantly reduced and the initial and final structures are very different from the case in which all wavenumbers are included. These low wavenumber perturbations tend to be more barotropic in structure and in growth characteristics. As expected from their linear growth rates, when the low-wavenumber perturbations are inserted in the T63 forecast model, they grow more slowly and result in less forecast dispersion than the high wavenumber perturbations.},
	number = {22},
	urldate = {2017-11-01},
	journal = {Journal of the Atmospheric Sciences},
	author = {Hartmann, D. L. and Buizza, R. and Palmer, T. N.},
	month = nov,
	year = {1995},
	pages = {3885--3894}
}

@article{lewis_incorporation_1978,
	title = {Incorporation of time continuity into subsynoptic analysis by using dynamical constraints},
	volume = {30},
	issn = {2153-3490},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.2153-3490.1978.tb00867.x/abstract},
	doi = {10.1111/j.2153-3490.1978.tb00867.x},
	abstract = {The analyses of surface wind and pressure at 2 observation times are coupled by using the forecast equations of horizontal momentum as dynamical constraints. A Cressman objective analysis procedure is used to interpolate the observations to a uniform grid. The interpolated data at these times are adjusted in a least squares sense subject to the 2 equations of constraint. Although the basic algorithm is designed to adjust data at 2 time levels, more time levels can be incorporated by using the algorithm in a sequential manner. The primary advantages of this scheme over a conventional analysis are: (1) the wind and pressure field are coupled, (2) observations at earlier and later times are incorporated into a given analysis, (3) the analyses have time continuity and, (4) data void regions can be analyzed if data are available at adjoining time levels. Since the adjustments are made in accord with the forecast equations, the methodology can be used for initialization of prediction models or updating these models by inserting new data in a consistent fashion. The scheme is tested on the well-documented squall line case of June 8, 1966, which occurred in the National Severe Storms Laboratory (NSSL) network in central Oklahoma. The data set consists of the hourly surface observations from the Aviation Network (Service A teletype records). A 3-hr period prior to squall line development is examined in order to see the influence of the larger scale circulation upon the generation and organization of mid-latitude squall lines. The principal results of the study were: (1) the observed wind components must be adjusted by 1–2 m s−1 (root-mean-square value) in order to satisfy the governing constraints, (2) the gradual build-up of the convergence zone associated with the squall line is better depicted by the adjusted pattern and, (3) the correlation between surface convergence and radar echo is more reasonable when adjusted winds are used.},
	language = {en},
	number = {6},
	urldate = {2017-11-01},
	journal = {Tellus},
	author = {Lewis, John M. and Bloom, Stephen C.},
	month = dec,
	year = {1978},
	pages = {496--516}
}

@article{barkmeuer_3d-var_1999,
	title = {{3D}-{Var} {Hessian} singular vectors and their potential use in the {ECMWF} ensemble prediction system},
	volume = {125},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49712555818/abstract},
	doi = {10.1002/qj.49712555818},
	abstract = {Singular vectors are computed which are consistent with 3D-Var (three-dimensional variational) estimates of analysis error statistics. This is achieved by defining the norm at initial time in terms of the full Hessian of the 3D-Var cost function. At final time the total energy norm is used. the properties of these Hessian singular vectors (HSVs) differ considerably from total energy singular vectors (TESVs) in such aspects as energy spectrum and growth rate. Despite these differences, the leading 25 TESVs and HSVs explain nearly the same part of the 2-day forecast error. Two experimental ensemble configurations are studied. One configuration uses perturbations based on HSVs in the computation of initial perturbation, the other uses TESVs and 2-day linearly evolved singular vectors (ESVs) of two days before. the latter approach provides a way to include more stable and large-scale structures in the perturbations. Ten pairs of ensembles are compared to the operational European Centre for Medium-Range Weather Forecasts Ensemble Prediction System. the ensembles using ESVs perform slightly better. the ensembles based on HSVs show a slightly worse performance and are lacking some spread in the medium range. Possible directions to improve the computation of HSVs are discussed.},
	language = {en},
	number = {558},
	urldate = {2017-11-01},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Barkmeuer, J. and Buizza, R. and Palmer, T. N.},
	month = jul,
	year = {1999},
	keywords = {Numerical weather prediction, Ensemble forecasting, Hessian singular vectors, Medium-range forecasting},
	pages = {2333--2351}
}

@article{hane_retrieval_1981,
	title = {Retrieval of {Thermodynamic} {Variables} within {Deep} {Convective} {Clouds}: {Experiments} in {Three} {Dimensions}},
	volume = {109},
	issn = {0027-0644},
	shorttitle = {Retrieval of {Thermodynamic} {Variables} within {Deep} {Convective} {Clouds}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1981)109%3C0564%3AROTVWD%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1981)109<0564:ROTVWD>2.0.CO;2},
	abstract = {A three-dimensional thermodynamic retrieval method has been developed and tested for application to deep convective clouds. To test the accuracy of the method and for sensitivity studies, output from a three-dimensional numerical cloud model has been utilized in place of observations. Input to the method are wind component and liquid water fields and basic output variables within the same volume are the deviation of potential temperature and perturbed pressure from their respective horizontal averages. The derivation of the retrieval equations from the momentum equations and the programming of these equations is shown to be correct by comparison of the retrieved fields with output from the numerical model. Other cases test the sensitivity of the retrieved result to inadequacies potentially present in observed (Doppler radar) wind and water fields. Tests are carried out examining the problem of time resolution in the observed data, possible inadequacies in observation and parameterization of turbulence, and accuracy in the measurement of liquid water fields. In other experiments velocity perturbations are added to the input velocity fields to simulate very crudely the errors which might be present on various scales in observed fields, and the sensitivity of the retrieved fields to these errors is assessed. Filtering the result is shown to be effective if the predominant scale within which input errors occur is known.},
	number = {3},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Hane, Carl E. and Wilhelmson, Robert B. and Gal-Chen, Tzvi},
	month = mar,
	year = {1981},
	pages = {564--576}
}

@article{hamill_hybrid_2000,
	title = {A {Hybrid} {Ensemble} {Kalman} {Filter}–{3D} {Variational} {Analysis} {Scheme}},
	volume = {128},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(2000)128%3C2905:AHEKFV%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(2000)128<2905:AHEKFV>2.0.CO;2},
	abstract = {A hybrid ensemble Kalman filter–three-dimensional variational (3DVAR) analysis scheme is demonstrated using a quasigeostrophic model under perfect-model assumptions. Four networks with differing observational densities are tested, including one network with a data void. The hybrid scheme operates by computing a set of parallel data assimilation cycles, with each member of the set receiving unique perturbed observations. The perturbed observations are generated by adding random noise consistent with observation error statistics to the control set of observations. Background error statistics for the data assimilation are estimated from a linear combination of time-invariant 3DVAR covariances and flow-dependent covariances developed from the ensemble of short-range forecasts. The hybrid scheme allows the user to weight the relative contributions of the 3DVAR and ensemble-based background covariances. The analysis scheme was cycled for 90 days, with new observations assimilated every 12 h. Generally, it was found that the analysis performs best when background error covariances are estimated almost fully from the ensemble, especially when the ensemble size was large. When small-sized ensembles are used, some lessened weighting of ensemble-based covariances is desirable. The relative improvement over 3DVAR analyses was dependent upon the observational data density and norm; generally, there is less improvement for data-rich networks than for data-poor networks, with the largest improvement for the network with the data void. As expected, errors depend on the size of the ensemble, with errors decreasing as more ensemble members are added. The sets of initial conditions generated from the hybrid are generally well calibrated and provide an improved set of initial conditions for ensemble forecasts.},
	number = {8},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Hamill, Thomas M. and Snyder, Chris},
	month = aug,
	year = {2000},
	pages = {2905--2919}
}

@article{hamill_comparison_2000,
	title = {A {Comparison} of {Probabilistic} {Forecasts} from {Bred}, {Singular}-{Vector}, and {Perturbed} {Observation} {Ensembles}},
	volume = {128},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/full/10.1175/1520-0493(2000)128%3C1835:ACOPFF%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(2000)128<1835:ACOPFF>2.0.CO;2},
	abstract = {The statistical properties of analysis and forecast errors from commonly used ensemble perturbation methodologies are explored. A quasigeostrophic channel model is used, coupled with a 3D-variational data assimilation scheme. A perfect model is assumed. Three perturbation methodologies are considered. The breeding and singular-vector (SV) methods approximate the strategies currently used at operational centers in the United States and Europe, respectively. The perturbed observation (PO) methodology approximates a random sample from the analysis probability density function (pdf) and is similar to the method performed at the Canadian Meteorological Centre. Initial conditions for the PO ensemble are analyses from independent, parallel data assimilation cycles. Each assimilation cycle utilizes observations perturbed by random noise whose statistics are consistent with observational error covariances. Each member’s assimilation/forecast cycle is also started from a distinct initial condition. Relative to breeding and SV, the PO method here produced analyses and forecasts with desirable statistical characteristics. These include consistent rank histogram uniformity for all variables at all lead times, high spread/skill correlations, and calibrated, reduced-error probabilistic forecasts. It achieved these improvements primarily because 1) the ensemble mean of the PO initial conditions was more accurate than the mean of the bred or singular-vector ensembles, which were centered on a less-skilful control initial condition—much of the improvement was lost when PO initial conditions were recentered on the control analysis; and 2) by construction, the perturbed observation ensemble initial conditions permitted realistic variations in spread from day to day, while bred and singular-vector perturbations did not. These results suggest that in the absence of model error, an ensemble of initial conditions performs better when the initialization method is designed to produce random samples from the analysis pdf. The perturbed observation method did this much more satisfactorily than either the breeding or singular-vector methods. The ability of the perturbed observation ensemble to sample randomly from the analysis pdf also suggests that such an ensemble can provide useful information on forecast covariances and hence improve future data assimilation techniques.},
	number = {6},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Hamill, Thomas M. and Snyder, Chris and Morss, Rebecca E.},
	month = jun,
	year = {2000},
	pages = {1835--1851}
}

@article{hamill_ensemble_2000,
	title = {Ensemble forecasting in the short to medium range: {Report} from a workshop},
	volume = {81},
	shorttitle = {Ensemble forecasting in the short to medium range},
	number = {11},
	journal = {Bulletin of the American Meteorological Society},
	author = {Hamill, Thomas M. and Mullen, Steven L. and Snyder, Chris and Baumhefner, David P. and Toth, Zoltan},
	year = {2000},
	pages = {2653--2664}
}

@book{courant_methods_1962,
	address = {New York},
	title = {Methods of {Mathematical} {Physics}: {Partial} {Differential} {Equations}},
	volume = {II},
	abstract = {Since the first volume of this work came out in Germany in 1937, this book, together with its first volume, has remained standard in the field. Courant and Hilbert's treatment restores the historically deep connections between physical intuition and mathematical development, providing the reader with a unified approach to mathematical physics. The present volume represents Richard Courant's final revision of 1961.},
	language = {en},
	publisher = {Interscience Publishers, Inc.},
	author = {Courant, Richard and Hilbert, David},
	year = {1962},
	keywords = {Differential equations, Partial, Mathematical physics, mathematics, Physics, Science / Mathematical Physics, Science / Physics}
}

@article{hamill_evaluation_1998,
	title = {Evaluation of {Eta}–{RSM} {Ensemble} {Probabilistic} {Precipitation} {Forecasts}},
	volume = {126},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1998)126%3C0711:EOEREP%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1998)126<0711:EOEREP>2.0.CO;2},
	abstract = {The accuracy of short-range probabilistic forecasts of quantitative precipitation (PQPF) from the experimental Eta–Regional Spectral Model ensemble is compared with the accuracy of forecasts from the Nested Grid Model’s model output statistics (MOS) over a set of 13 case days from September 1995 through January 1996. Ensembles adjusted to compensate for deficiencies noted in prior forecasts were found to be more skillful than MOS for all precipitation categories except the basic probability of measurable precipitation. Gamma distributions fit to the corrected ensemble probability distributions provided an additional small improvement. Interestingly, despite the favorable comparison with MOS forecasts, this ensemble configuration showed no ability to “forecast the forecast skill” of precipitation—that is, the ensemble was not able to forecast the variable specificity of the ensemble probability distribution from day-to-day and location-to-location. Probability forecasts from gamma distributions developed as a function of the ensemble mean alone were as skillful at PQPF as forecasts from distributions whose specificity varied with the spread of the ensemble. Since forecasters desire information on forecast uncertainty from the ensemble, these results suggest that future ensemble configurations should be checked carefully for their presumed ability to forecast uncertainty.},
	number = {3},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Hamill, Thomas M. and Colucci, Stephen J.},
	month = mar,
	year = {1998},
	pages = {711--724}
}

@article{hamill_verification_1997,
	title = {Verification of {Eta}–{RSM} {Short}-{Range} {Ensemble} {Forecasts}},
	volume = {125},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/full/10.1175/1520-0493(1997)125%3C1312:VOERSR%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1997)125<1312:VOERSR>2.0.CO;2},
	abstract = {Motivated by the success of ensemble forecasting at the medium range, the performance of a prototype short-range ensemble forecast system is examined. The ensemble dataset consists of 15 case days from September 1995 through January 1996. There are 15 members of the ensemble, 10 from an 80-km version of the eta model and five from the regional spectral model. Initial conditions include various in-house analyses available at the National Centers for Environmental Prediction as well as bred initial conditions interpolated from the medium-range forecast ensemble. Forecasts from the 29-km mesoeta model were archived as well for comparison. The performance of the ensemble is first evaluated by the criterion of “uniformity of verification rank.” Assuming a perfect forecast model, equally plausible initial conditions, and the verification is a plausible member of the ensemble, these imply the verification when pooled with the 15 ensemble forecasts and sorted is equally likely to occur in each of the 16 ranks. Hence, over many independent samples, a histogram of the rank distribution should be nearly uniform. Using data from the ensemble forecasts, rank distributions were populated and found to be nonuniform. This was determined to be largely a result of model and initial condition deficiencies and not problems with the verification data. The uniformity of rank distributions varied with atmospheric baroclinicity for midtropospheric forecast variables but not for precipitation forecasts. Examination of the error characteristics of individual ensemble members showed that the assumption of identical errors for each member is not met with this particular ensemble configuration, primarily because of the use of both bred and nonbred initial conditions in this test. Further, there were both differences in the accuracy of eta and regional spectral model bred member forecasts. The performance of various summary forecasts from the ensemble such as its mean showed that the ensemble can generate forecasts that have similar or lower error than forecasts from the 29-km mesoeta, which was approximately equivalent in computational expense. Also, by combining the ensemble forecasts with rank information from other cases, reliable ensemble precipitation forecasts could be created, indicating the potential for useful probabilistic forecasts of quantitative precipitation from the ensemble.},
	number = {6},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Hamill, Thomas M. and Colucci, Stephen J.},
	month = jun,
	year = {1997},
	pages = {1312--1327}
}

@book{courant_methods_1953,
	address = {New York},
	title = {Methods of {Mathematical} {Physics}},
	volume = {I},
	abstract = {Since the first volume of this work came out in Germany in 1924, this book, together with its second volume, has remained standard in the field. Courant and Hilbert's treatment restores the historically deep connections between physical intuition and mathematical development, providing the reader with a unified approach to mathematical physics. The present volume represents Richard Courant's second and final revision of 1953.},
	language = {en},
	publisher = {Interscience Publishers, Inc.},
	author = {Courant, Richard and Hilbert, David},
	year = {1953},
	keywords = {Science / Physics / Mathematical \& Computational}
}

@book{haltiner_numerical_1980,
	title = {Numerical prediction and dynamic meteorology},
	publisher = {John Wiley and Sons},
	author = {Haltiner, George J. and Williams, Roger T.},
	year = {1980}
}

@article{leslie_three-dimensional_1995,
	title = {Three-{Dimensional} {Mass}-{Conserving} {Semi}-{Lagrangian} {Scheme} {Employing} {Forward} {Trajectories}},
	volume = {123},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1995)123%3C2551:TDMCSL%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1995)123<2551:TDMCSL>2.0.CO;2},
	abstract = {Through the use of the dimensional splitting “cascade” method of grid-to-grid interpolation, it is shown that consistently high-order-accurate semi-Lagrangian integration of a three-dimensional hydrostatic primitive equations model can be carried out using forward (downstream) trajectories instead of the backward (upstream) trajectory computations that are more commonly employed in semi-Lagrangian models. Apart from the efficiency resulting directly from the adoption of the cascade method, improved computational performance is achieved partly by the selective implicit treatment of only the deepest vertical gravity modes and partly by obviating the need to iterate the estimation of each trajectory's location. Perhaps the main distinction of our present semi-Lagrangian method is its inherent exact conservation of mass and passive tracers. This is achieved by adopting a simple variant of the cascade interpolation that incorporates mass (and tracer) conservation directly and at only a very modest additional cost. The conserving cascade, which is described in detail, is a generic algorithm that can be applied at arbitrary order of accuracy. Tests of the new mass-conserving scheme in a regional forecast model show small but consistent improvements in accuracy at 48 h. It is suggested that the benefits to extended global forecasting and simulation should be much greater.},
	number = {8},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Leslie, Lance M. and Purser, R. James},
	month = aug,
	year = {1995},
	pages = {2551--2566}
}

@article{barnston_long-lead_1994,
	title = {Long-{Lead} {Seasonal} {Forecasts}—{Where} {Do} {We} {Stand}?},
	volume = {75},
	issn = {0003-0007},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0477%281994%29075%3C2097%3ALLSFDW%3E2.0.CO%3B2},
	doi = {10.1175/1520-0477(1994)075<2097:LLSFDW>2.0.CO;2},
	abstract = {The National Weather Service intends to begin routinely issuing long-lead forecasts of 3-month mean U.S. temperature and precipitation by the beginning of 1995. The ability to produce useful forecasts for certain seasons and regions at projection times of upto 1 yr is attributed to advances in data observing and processing, computer capability, and physical understanding-particularly, for tropical ocean-atmosphere phenomena. Because much of the skill of the forecasts comes from anomalies of tropical SST related to ENSO, we highlight here long-lead forecasts of the tropical Pacific SST itself, which have higher skill than the U.S forecasts that are made largely on their basis. The performance of five ENSO prediction systems is examined: Two are dynamical [the Cane-Zebiak simple coupled model of Lamont-Doherty Earth Observatory and the nonsimpie coupled model of the National Centers for Environmental Prediction (NCEP)]; one is a hybrid coupled model (the Scripps Institution for Oceanography-Max Planck Institute for Meteorology system with a full ocean general circulation model and a statistical atmosphere); and two are statistical (canonical correlation analysis and constructed analogs, used at the Climate Prediction Center of NCEP). With increasing physical understanding, dynamically based forecasts have the potential to become more skillful than purely statistical ones. Currently, however, the two approaches deliver roughly equally skillful forecasts, and the simplest model performs about as well as the more comprehensive models. At a lead time of 6 months (defined here as the time between the end of the latest observed period and the beginning of the predictand period), the SST forecasts have an overall correlation skill in the 0.60s for 1982-93, which easily outperforms persistence and is regarded as useful. Skill for extra- tropical surface climate is this high only in limited regions for certain seasons. Both types of forecasts are not much better than local higher-order autoregressive controls. However, continual progress is being made in understanding relations among global oceanic and atmospheric climate-scale anomaly fields. 1t is important that more real-time forecasts be made before we rush to judgement. Performance in the real-time setting is the ultimate test of the utility of a long-lead forecast. The National Weather Service's plan to implement new operational long-lead seasonal forecast products demonstrates its effectiveness in identifying and transferring “cutting edge” technologies from theory to applications. This could not have been accomplished without close ties with, and the active cooperation of, the academic and research communities.},
	number = {11},
	urldate = {2017-11-01},
	journal = {Bulletin of the American Meteorological Society},
	author = {Barnston, Anthony G. and van den Dool, Huug M. and Rodenhuis, David R. and Ropelewski, Chester R. and Kousky, Vernon E. and O'Lenic, Edward A. and Livezey, Robert E. and Zebiak, Stephen E. and Cane, Mark A. and Barnett, Tim P. and Graham, Nicholas E. and Ji, Ming and Leetmaa, Ants},
	month = nov,
	year = {1994},
	pages = {2097--2114}
}

@article{ji_ocean_1995,
	title = {An {Ocean} {Analysis} {System} for {Seasonal} to {Interannual} {Climate} {Studies}},
	volume = {123},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1995)123%3C0460:AOASFS%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1995)123<0460:AOASFS>2.0.CO;2},
	abstract = {A dynamical model-based ocean analysis system has been implemented at the National Meteorological Center (NMC). This is used to provide retrospective and routine weekly analyses for the Pacific and Atlantic Oceans. Retrospective analyses have been performed for the period mid-1982 to mid-1993. The analyses are used for diagnostics of past climatic variability, real-time climate monitoring, and as initial conditions for coupled multiseason forecasts. The assimilation system is based on optimal interpolation objective analysis solved using an equivalent variational formulation. Analysis errors are estimated by comparisons to independent datasets such as temperature data from moorings and sea level information from tide gauges. In the near equatorial zone rms errors in thermocline depth are of order of 6–15 m. Comparisons of sea level estimates from the reanalyses with the records from tide gauges indicate that the rms sea level errors for monthly analysis are of the order of 0.04–0.09 m. For the weekly analyses, which potentially have more accurate forcing fields, the rms sea level errors am about 0.02–0.06 m. The analysis system can be used to infer the net heat flux at the air–sea interface on mean annual and interannual timescales. Examination of the dominant components to the oceanic heat budget shows that advection, storage changes, and the net surface heat flux can all be of the same order of magnitude; however, frequently the net surface heat flux is much smaller than the other components. The annual variations in the components are as large or larger than the interannual variability. In the equatorial region interannual changes are of the order of 50–100 W m−2 and act as a negative feedback to the anomalous SSTs. In the subtropics the interannual variability is only in the order of 5–10 W m−2. Principal component analysis of the monthly analyzed ocean fields revealed an interannual sea level and SST empirical orthogonal function that has an intradecadal timescale. This mode is characterized by meridional adjustments of the thermal field. It is probably forced by the changes in the curl of the stress caused by changes in the intensity and location of the trade winds associated with the ENSO.},
	number = {2},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Ji, Ming and Leetmaa, Ants and Derber, John},
	month = feb,
	year = {1995},
	pages = {460--481}
}

@article{leith_nonlinear_1980,
	title = {Nonlinear {Normal} {Mode} {Initialization} and {Quasi}-{Geostrophic} {Theory}},
	volume = {37},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1980)037%3C0958:NNMIAQ%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1980)037<0958:NNMIAQ>2.0.CO;2},
	abstract = {The first iteration of the recently developed nonlinear normal mode initialization procedure for primitive equation models leads to quasi-rotational dynamical and diagnostic equations agreeing with those of quasi-geostrephic theory in a simple Boussinesq f plane model. The proper initialization of a quasi-rotational model, however. requires a nonlinear modification of the geostrophic state traditionally used. Various generalizations are discussed briefly.},
	number = {5},
	urldate = {2017-11-01},
	journal = {Journal of the Atmospheric Sciences},
	author = {Leith, C. E.},
	month = may,
	year = {1980},
	pages = {958--968}
}

@article{barnes_oklahoma_1978,
	title = {Oklahoma {Thunderstorms} on 29–30 {April} 1970. {Part} {I}: {Morphology} of a {Tornadic} {Storm}},
	volume = {106},
	issn = {0027-0644},
	shorttitle = {Oklahoma {Thunderstorms} on 29–30 {April} 1970. {Part} {I}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281978%29106%3C0673%3AOTOAPI%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1978)106<0673:OTOAPI>2.0.CO;2},
	abstract = {Data collected at the National Severe Storms Laboratory reveal the mesogamma-scale (2.5–25 km) features of two severe thunderstorms that struck Oklahoma City within 1 h of each other. This paper discusses the surface, upper air and radar data obtained during the passage of the first tornadic storm (F). Companion papers deal with the second storm (G) which exhibited twin tornado cyclones (Parts II and III), and another discusses the environmental conditions which led to the demise of an earlier hailstorm (Part IV). At the surface, the tornadic supercell storms were characterized by mesocyclonic sinks beneath the main updrafts with convergence values greater than 2 × 10−3 s−1 and vorticity about half as large. Lowest pressures preceded the mesocyclones by several kilometers and are believed to be dissociated from the wind centers because of the storms' rapid translational speeds (25–32 m s−1). Highest pressures were found near the rainy cores but not coincident. Middle-tropospheric air descended on the southwest (rear) flanks and produced accelerators in the cold air behind the gust fronts. Changes in characteristics of tornadoes associated with three tornado cyclones seem closely related to an evolving interaction between each updraft's mesocyclone and the downdraft-induced vorticity maxima. Just ahead of Storm F, rawinsoundings indicated both dry adiabatic descent near the surface and ascent aloft. Boundary layer divergence associated with the former was caused by differential acceleration of surface layer air as the intense 1.5 hPa mesolow rapidly approached. Dry-adiabatic ascent aloft is believed to be driven by the quasi-steady updraft and is a feature similar to that found in several numerical simulation models. One balloon penetrated Storm F's anvil from 7.5 to 9.9 km some 35–40 km downwind of the main updraft and experienced 71 m s−1 winds in a 4 m s−1 “residual” updraft. A Richardson number of about 0.3 indicates such convective perturbations may feed from mean flow energy as opposed to residual buoyancy alone.},
	number = {5},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Barnes, Stanley L.},
	month = may,
	year = {1978},
	pages = {673--684}
}

@book{hageman_applied_1981,
	title = {Applied {Iterative} {Methods}},
	publisher = {Wiley},
	author = {Hageman, L. A. and Young, David M.},
	year = {1981}
}

@book{hackbusch_multi-grid_1985,
	title = {Multi-grid methods and applications},
	publisher = {Springer-Verlag, Berlin},
	author = {Hackbusch, Wolfgang},
	year = {1985}
}

@article{barnes_technique_1964,
	title = {A {Technique} for {Maximizing} {Details} in {Numerical} {Weather} {Map} {Analysis}},
	volume = {3},
	issn = {0021-8952},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0450%281964%29003%3C0396%3AATFMDI%3E2.0.CO%3B2},
	doi = {10.1175/1520-0450(1964)003<0396:ATFMDI>2.0.CO;2},
	abstract = {This paper summarizes the development of a convergent weighted-averaging interpolation scheme which can be used to obtain any desired amount of detail in the analysis of a set of randomly spaced data. The scheme is based on the supposition that the two-dimensional distribution of an atmospheric variable can be represented by the summation of an infinite number of independent waves, i.e., a Fourier integral representation. The practical limitations of the scheme are that the data distribution be reasonably uniform and that the data be accurate. However, the effect of inaccuracies can be controlled by stopping the convergence scheme before the data errors are greatly amplified. The scheme has been tested in the analysis of 500-mb height data over the United States producing a result with details comparable to those obtainable by careful manual analysis. A test analysis of sea level pressure based on the data obtained at only the upper air network stations produced results with essentially the same features as the analysis produced at the National Meteorological Center. Further tests based on a regional sampling of stations reporting airways data demonstrate the applicability of the scheme to mesoscale wavelengths.},
	number = {4},
	urldate = {2017-11-01},
	journal = {Journal of Applied Meteorology},
	author = {Barnes, Stanley L.},
	month = aug,
	year = {1964},
	pages = {396--409}
}

@article{barker_relationship_1991,
	title = {The {Relationship} between {Spread} and {Forecast} {Error} in {Extended}-range {Forecasts}},
	volume = {4},
	issn = {0894-8755},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0442%281991%29004%3C0733%3ATRBSAF%3E2.0.CO%3B2},
	doi = {10.1175/1520-0442(1991)004<0733:TRBSAF>2.0.CO;2},
	abstract = {The relationship between ensemble forecast spread and ensemble forecast error is examined for a large number of extended range forecasts with a fairly simple, yet realistic model. A “perfect model” approach is used so that systematic modeling errors do not overwhelm errors that grow from initial analysis error. Mean square errors and spreads of the forecasts are computed and discussed for this model. The correlation between spread and forecast error tends toward zero at long forecast times, and an explanation of this tendency is presented. Time averaging has little impact on improving the correlation between spread and forecast error. The correlation between spread and forecast error is sensitive to the region being considered, but it is not significantly different for regional domains versus hemispheric domains.},
	number = {7},
	urldate = {2017-11-01},
	journal = {Journal of Climate},
	author = {Barker, Timothy W.},
	month = jul,
	year = {1991},
	pages = {733--742}
}

@article{gustafsson_fourth-order_1995,
	title = {Fourth-{Order} {Difference} {Methods} for {Hyperbolic} {IBVPs}},
	volume = {117},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999185710686},
	doi = {10.1006/jcph.1995.1068},
	abstract = {In this paper we consider fourth-order difference approximations of initial-boundary value problems for hyperbolic partial differential equations. We use the method of lines approach with both explicit and compact implicit difference operators in space. The explicit operator satisfies an energy estimate leading to strict stability. For the implicit operator we develop boundary conditions and give a complete proof of strong stability using the Laplace transform technique. We also present numerical experiments for the linear advection equation and Burgers' equation with discontinuities in the solution or in its derivative. The first equation is used for modeling contact discontinuities in fluid dynamics; the second one is used for modeling shocks and rarefaction waves. The time discretization is done with a third-order Runge-Kutta TVD method. For solutions with discontinuities in the solution itself we add a filter based on second-order viscosity. In case of the non-linear Burgers' equation we use a flux splitting technique that results in an energy estimate for certain difference approximations, in which case also an entropy condition is fulfilled. In particular we shall demonstrate that the unsplit conservative form produces a non-physical shock instead of the physically correct rarefaction wave. In the numerical experiments we compare our fourth-order methods with a standard second-order one and with a third-order TVD method. The results show that the fourth-order methods are the only ones that give good results for all the considered test problems.},
	number = {2},
	urldate = {2017-11-01},
	journal = {Journal of Computational Physics},
	author = {Gustafsson, Bertil and Olsson, Pelle},
	month = mar,
	year = {1995},
	pages = {300--317}
}

@article{ballish_incremental_1992,
	title = {Incremental {Nonlinear} {Normal}-{Mode} {Initialization}},
	volume = {120},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281992%29120%3C1723%3AINNMI%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1992)120<1723:INNMI>2.0.CO;2},
	abstract = {An incremental nonlinear normal-mode initialization procedure developed within the National Meteorological Center (NMC) global analysis and forecast system is described. Unlike conventional nonlinear normal-mode initialization, the incremental nonlinear initialization does not zero-out gravity-mode tendencies but still removes imbalances introduced by the analysis as effectively as the conventional initialization. Incremental initialization can be set up as a relatively simple modification of the conventional (Machenauer) initialization. The tests performed with the NMC global analysis-forecast system indicate that the problems pointed out for other initialization methods (i.e., undesirable changes to the forecast model guess, especially the tidal modes, sensitivity to the way diabatic tendencies are calculated, and lack of nonlinearity) are all greatly reduced by the nonlinear initialization of analysis increments. Based on these results, the new initialization was implemented into the NMC operational suite on 13 December 1989.},
	number = {8},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Ballish, Bradley and Cao, Xianhe and Kalnay, Eugenia and Kanamitsu, Masao},
	month = aug,
	year = {1992},
	pages = {1723--1734}
}

@inproceedings{legras_guide_1996,
	title = {A guide to {Liapunov} vectors},
	volume = {1},
	booktitle = {Proceedings 1995 {ECMWF} {Seminar} on {Predictability}},
	author = {Legras, B. and Vautard, R.},
	year = {1996},
	pages = {143--156}
}

@article{gustafsson_convergence_1981,
	title = {The {Convergence} {Rate} for {Difference} {Approximations} to {General} {Mixed} {Initial}-{Boundary} {Value} {Problems}},
	volume = {18},
	issn = {0036-1429},
	url = {http://epubs.siam.org/doi/abs/10.1137/0718014},
	doi = {10.1137/0718014},
	abstract = {The convergence rate is investigated for the solutions to difference schemes approximating the mixed initial boundary value problem for general systems of differential equations. It is shown that if an energy estimate holds, then the extra boundary conditions can be of one order lower accuracy without destroying the convergence rate expected from the approximation at inner points. If the maximal order of the derivatives occurring in the boundary conditions is low enough, then even lower accuracy can be permitted for the extra boundary conditions.},
	number = {2},
	urldate = {2017-11-01},
	journal = {SIAM Journal on Numerical Analysis},
	author = {Gustafsson, B.},
	month = apr,
	year = {1981},
	pages = {179--190}
}

@article{gustafsson_stability_1972,
	title = {Stability {Theory} of {Difference} {Approximations} for {Mixed} {Initial} {Boundary} {Value} {Problems}. {II}},
	volume = {26},
	issn = {0025-5718},
	url = {http://www.jstor.org/stable/2005093},
	doi = {10.2307/2005093},
	abstract = {A stability theory is developed for general difference approximations to mixed initial boundary value problems. The results are applied to certain commonly used difference approximations which are stable for the Cauchy problem, and different ways of defining boundary conditions are analyzed.},
	number = {119},
	urldate = {2017-11-01},
	journal = {Mathematics of Computation},
	author = {Gustafsson, Bertil and Kreiss, Heinz-Otto and Sundström, Arne},
	year = {1972},
	pages = {649--686}
}

@article{ballish_simple_1981,
	title = {A {Simple} {Test} of the {Initialization} of {Gravity} {Modes}},
	volume = {109},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281981%29109%3C1318%3AASTOTI%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1981)109<1318:ASTOTI>2.0.CO;2},
	abstract = {The initialization schemes of Machenhauer (1977), Baer and Tribbia (1977), and one requiring the initial second time derivatives of gravity modes to be zero are tested by application to a simple differential equation, which partially simulates the behavior of gravity modes in a forecast model. These initialization schemes are tested to see under what conditions they converge, and they are tested on how well they eliminate future gravity wave oscillations. Preliminary results of initialization experiments with the National Meteorological Center's spectral forecast model are in support of the conclusions derived from analyzing this differential equation.},
	number = {6},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Ballish, Bradley A.},
	month = jun,
	year = {1981},
	pages = {1318--1321}
}

@book{greenbaum_iterative_1997,
	title = {Iterative methods for solving linear systems},
	publisher = {SIAM},
	author = {Greenbaum, Anne},
	year = {1997}
}

@article{latif_review_1998,
	title = {A review of the predictability and prediction of {ENSO}},
	volume = {103},
	number = {C7},
	journal = {Journal of Geophysical Research: Oceans},
	author = {Latif, Mojib and Anderson, D. and Barnett, T. and Cane, M. and Kleeman, R. and Leetmaa, A. and O'Brien, J. and Rosati, A. and Schneider, E.},
	year = {1998},
	pages = {14375--14393}
}

@article{ballabrera-poy_application_2001,
	title = {Application of a {Reduced}-{Order} {Kalman} {Filter} to {Initialize} a {Coupled} {Atmosphere}–{Ocean} {Model}: {Impact} on the {Prediction} of {El} {Niño}},
	volume = {14},
	issn = {0894-8755},
	shorttitle = {Application of a {Reduced}-{Order} {Kalman} {Filter} to {Initialize} a {Coupled} {Atmosphere}–{Ocean} {Model}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0442(2001)014%3C1720%3AAOAROK%3E2.0.CO%3B2},
	doi = {10.1175/1520-0442(2001)014<1720:AOAROK>2.0.CO;2},
	abstract = {A reduced-order Kalman filter is used to assimilate observed fields of the surface wind stress, sea surface temperature, and sea level into the coupled ocean–atmosphere model of Zebiak and Cane. The method projects the Kalman filter equations onto a subspace defined by the eigenvalue decomposition of the error forecast matrix, allowing its application to high-dimensional systems. The Zebiak and Cane model couples a linear, reduced-gravity ocean model with a single, vertical-mode atmospheric model. The compatibility between the simplified physics of the model and each observed variable is studied separately and together. The results show the ability of the empirical orthogonal functions (EOFs) of the model to represent the simultaneous value of the wind stress, SST, and sea level, when the fields are limited to the latitude band 10°S–10°N, and when the number of EOFs is greater than the number of statistically significant modes. In this first application of the Kalman filter to a coupled ocean–atmosphere prediction model, the sea level fields are assimilated in terms of the Kelvin and Rossby modes of the thermocline depth anomaly. An estimation of the error of these modes is derived from the projection of an estimation of the sea level error over such modes. The ability of the method to reconstruct the state of the equatorial Pacific and to predict its time evolution is shown. The method is quite robust for predictions up to 6 months, and able to predict the onset of the 1997 warm event 15 months before its occurrence.},
	number = {8},
	urldate = {2017-11-01},
	journal = {Journal of Climate},
	author = {Ballabrera-Poy, Joaquim and Busalacchi, Antonio J. and Murtugudde, Ragu},
	month = apr,
	year = {2001},
	pages = {1720--1737}
}

@techreport{grell_description_1994,
	title = {A description of the fifth-generation {Penn} {State}/{NCAR} mesoscale model ({MM5}). {NCAR}/{TN}-398+{STR}},
	institution = {NCAR},
	author = {Grell, Georg A. and Dudhia, Jimy and Stauffer, David R.},
	year = {1994},
	pages = {121}
}

@article{latif_review_1994,
	title = {A review of {ENSO} prediction studies},
	volume = {9},
	issn = {0930-7575, 1432-0894},
	url = {https://link.springer.com/article/10.1007/BF00208250},
	doi = {10.1007/BF00208250},
	abstract = {A hierarchy of ENSO (El Niño/Southern Oscillation) prediction schemes has been developed which includes statistical schemes and physical models. The statistical models are, in general, based on advanced statistical techniques and can be classified into models which use either low-frequency variations in the atmosphere (sea level pressure or surface wind) or upper ocean heat content as predictors. The physical models consist of coupled ocean-atmosphere models of varying degrees of complexity, ranging from simplified coupled models of the ‘shallow water’-type to coupled general circulation models. All models, statistical and physical, perform considerably better than the persistence forecast on predicting typical indices of ENSO on lead times of 6 to 12 months. The most successful prediction schemes, the fully physical coupled ocean-atmosphere models, show significant prediction abilities at lead times exceeding one year period. We therefore conclude that ENSO is predictable at least one year in advance. However, all of this applies to gross indices of ENSO such as the Southern Oscillation Index. Despite the demonstrated predictability, little is known about the predictability of specific features known to be associated with ENSO (e.g. Indian Monsoon rainfall, Southern African drought, or even off-equatorial sea surface temperature). Nor has the relative importance for prediction of different regional anomalies or different physical processes yet been established. A seasonal dependence in predictability is well established, but the processes responsible for it are not fully understood.},
	language = {en},
	number = {4-5},
	urldate = {2017-11-01},
	journal = {Climate Dynamics},
	author = {Latif, M. and Barnett, T. P. and Cane, M. A. and Flügel, M. and Graham, N. E. and Storch, H. von and Xu, J.-S. and Zebiak, S. E.},
	month = jan,
	year = {1994},
	pages = {167--179}
}

@article{rabier_sensitivity_1996,
	title = {Sensitivity of forecast errors to initial conditions},
	volume = {122},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49712252906/abstract},
	doi = {10.1002/qj.49712252906},
	abstract = {The adjoint method has been used to calculate the sensitivity of short-range forecast errors to the initial conditions. The gradient of the energy of the day 2 forecast error with respect to the initial conditions can be interpreted as a sum of rapidly growing components of the analysis error. An analysis modified by subtracting an appropriately scaled vector, proportional to the gradient, provides initial conditions for a ‘sensitivity integration’ that can be used to diagnose the effect of initial-data errors on forecast errors. Statistics of sensitivity calculations for the month of April 1994 characterize the sensitivity patterns as small-scale, middle or lower tropospheric structures which are tilted in the vertical. The general pattern of these structures is known to be associated with the fastest possible growth of forecast error. When used as initial perturbations, they evolve rapidly into synoptic-scale structures, propagating both downstream and to higher atmospheric levels. On average, the sensitivity integration corrects for about a tenth of the day 2 forecast error, which indicates that indeed not all of the error is in the fastest-amplifying modes. But the fraction of the error corrected at day 2 is important for an improvement in the medium-range, as this fraction continues to grow substantially in the non-linear regime. These results have proved that there is still scope for great improvement in the medium-range forecast, particularly over Europe, by a better description of the initial conditions. The sensitivity experimentation suggests that many cases of major forecast-errors may be explained by defects in the analysis. A small but well-chosen change in the analysis can frequently improve the forecast quality.},
	language = {en},
	number = {529},
	urldate = {2017-11-01},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Rabier, F. and Klinker, E. and Courtier, P. and Hollingsworth, A.},
	month = jan,
	year = {1996},
	keywords = {Adjoint method, Analysis error, Forecast error, Sensitivity studies},
	pages = {121--150}
}

@article{laprise_formulation_1997,
	title = {The {Formulation} of the {André} {Robert} {MC2} ({Mesoscale} {Compressible} {Community}) {Model}},
	volume = {35},
	issn = {0705-5900},
	url = {http://dx.doi.org/10.1080/07055900.1997.9687348},
	doi = {10.1080/07055900.1997.9687348},
	abstract = {A description of the numerical formulation of the dynamics module of the Mesoscale Compressible Community (MC2) model is presented. This model is based on the fully elastic, semi-implicit semi-Lagrangian model developed by Tanguay et al. (1990). This version was extended to incorporate topography by Denis (1990), and later variable vertical resolution was added as an option. This article is a condensed version of an extensive report by Bergeron et al. (1994) that documents all the numerical aspects of the MC2 model. The performance of the model is illustrated through a sample of results obtained on a wide range of physical problems.},
	number = {sup1},
	urldate = {2017-11-01},
	journal = {Atmosphere-Ocean},
	author = {Laprise, René and Caya, Daniel and Bergeron, Guy and Giguère, Michel},
	month = jan,
	year = {1997},
	pages = {195--220}
}

@article{langland_north_1999,
	title = {The {North} {Pacific} {Experiment} ({NORPEX}-98): {Targeted} {Observations} for {Improved} {North} {American} {Weather} {Forecasts}},
	volume = {80},
	issn = {0003-0007},
	shorttitle = {The {North} {Pacific} {Experiment} ({NORPEX}-98)},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0477(1999)080%3C1363%3ATNPENT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0477(1999)080<1363:TNPENT>2.0.CO;2},
	abstract = {The objectives and preliminary results of an interagency field program, the North Pacific Experiment (NORPEX), which took place between 14 January and 27 February 1998, are described. NORPEX represents an effort to directly address the issue of observational sparsity over the North Pacific basin, which is a major contributing factor in short-range (less than 4 days) forecast failures for land-falling Pacific winter-season storms that affect the United States, Canada, and Mexico. The special observations collected in NORPEX include approximately 700 targeted tropospheric soundings of temperature, wind, and moisture from Global Positioning System (GPS) dropsondes obtained in 38 storm reconnaissance missions using aircraft based primarily in Hawaii and Alaska. In addition, wind data were provided every 6 h over the entire North Pacific during NORPEX, using advanced and experimental techniques to extract information from multispectral geostationary satellite imagery. Preliminary results of NORPEX data impact studies using the U.S. Navy and National Weather Service forecast models include reductions of approximately 10\% in mean 2-day forecast error over western North America (30°–60°N, 100°–130°W) from assimilation of targeted dropsonde and satellite wind data (when measured against control forecasts that contain no special NORPEX observations). There are local reductions of up to 50\% in 2-day forecast error for individual cases, although some forecasts are degraded by the addition of the special dropsonde or satellite wind data. In most cases, the positive impact of the targeted dropsonde data on short-range forecast skill is reduced when the full set of advanced satellite wind data is already included in the model analyses. The NORPEX dataset is being used in research to improve objective methods for targeting observations, to study the "mix" of in situ and space-based observations, and to understand the structure and dynamics of fast-growing errors that limit our ability to provide more accurate forecasts of Pacific winter storms.},
	number = {7},
	urldate = {2017-11-01},
	journal = {Bulletin of the American Meteorological Society},
	author = {Langland, R. H. and Toth, Z. and Gelaro, R. and Szunyogh, I. and Shapiro, M. A. and Majumdar, S. J. and Morss, R. E. and Rohaly, G. D. and Velden, C. and Bond, N. and Bishop, C. H.},
	month = jul,
	year = {1999},
	pages = {1363--1384}
}

@article{balgovind_stochastic-dynamic_1983,
	title = {A {Stochastic}-{Dynamic} {Model} for the {Spatial} {Structure} of {Forecast} {Error} {Statistics}},
	volume = {111},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1983)111%3C0701:ASDMFT%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1983)111<0701:ASDMFT>2.0.CO;2},
	abstract = {A simple model that yields the spatial correlation structure of global atmospheric mass-field forecast errors is derived. The model states that the relative potential vorticity of the forecast error is forced by spatially multi-dimensional white noise. The forecast error equation contains a nondimensional parameter c0, which depends on the Rossby radius of deformation. From this stochastic-dynamic equation, a deterministic equation for the spatial covariance function of the 500 mb geopotential error field is obtained. Three methods of solution are examined: 1) an analytic method based on spherical harmonics, 2) a numerical method based on stratified sampling of Monte-Carlo realizations of the stochastic-dynamic equation, and 3) a combined analytic-numerical method based on two successive applications of a fast Poisson solver to the deterministic covariance equation. The three methods are compared for accuracy and efficiency, and the third (combined) method is found to be clearly superior. The model's covariance function is compared with global correlation data of forecast-minus-observed geopoteniial fields for the DST-6 period February–March 1976. The data are based on the GLAS forecast-assimilation system in use at that lime (Ghil et al., 1979). The model correlations agree well with the latitude dependence of the data correlations. The fit between model and data confirms that the forecast error between 24 and 36 h is largely random, rather than systematic; the value of the parameter c0 which gives the best fit suggests that much of this error can be attributed to baroclinic, rather than barotropic effects. Deterministic influences not included in the model appear at 12 and 48 h. They suggest possibilities of improving the forecast system by a better objective analysis and initialization procedure, and a better treatment of planetary-wave propagation, respectively. An analytic formula is obtained which locally approximates well the model's global correlations. This formula is convenient to use in the calculation of weighting coefficients for analysis and assimilation schemes. It shows that Gaussian functions are a poor approximation for the forecast error correlations of the mass field, and their derivatives an even poorer approximation to wind field correlations.},
	number = {4},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Balgovind, R. and Dalcher, A. and Ghil, M. and Kalnay, E.},
	month = apr,
	year = {1983},
	pages = {701--722}
}

@article{courant_uber_1928,
	title = {Über die partiellen {Differenzengleichungen} der mathematischen {Physik}},
	volume = {100},
	issn = {0025-5831, 1432-1807},
	url = {https://link.springer.com/article/10.1007/BF01448839},
	doi = {10.1007/BF01448839},
	abstract = {No Abstract available for this article.},
	language = {de},
	number = {1},
	urldate = {2017-11-01},
	journal = {Mathematische Annalen},
	author = {Courant, R. and Friedrichs, K. and Lewy, H.},
	month = dec,
	year = {1928},
	pages = {32--74}
}

@article{lacarra_short-range_1988,
	title = {Short-range evolution of small perturbations in a barotropic model},
	volume = {40},
	issn = {null},
	url = {http://dx.doi.org/10.3402/tellusa.v40i2.11784},
	doi = {10.3402/tellusa.v40i2.11784},
	abstract = {The short-range evolution of small initial errors is numerically investigated with an f-plane shallow-water model. It is shown that this evolution can be approximated by a linearized model for meteorologically realistic situations, and for ranges of up to about 48 hours. The results are consistent with a description of the slow manifold as an attracting set along which the dynamics of the flow is dominated by an instability process. As a consequence of the relatively large time scale for the meteorologically significant components of the flow, the linear model valid for short periods can befurther simplified to a constant coefficient model describing only the evolution of the large-scale components of the error. The possible implicationsof this result for the improvement of assimilation procedures are briefly discussed.},
	number = {2},
	urldate = {2017-11-01},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Lacarra, Jean-Françis and Talagrand, Olivier},
	month = jan,
	year = {1988},
	pages = {81--95}
}

@article{cotton_real-time_1994,
	title = {Real-{Time} {Mesoscale} {Prediction} on workstations},
	volume = {75},
	issn = {0003-0007},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0477%281994%29075%3C0349%3ARTMPOW%3E2.0.CO%3B2},
	doi = {10.1175/1520-0477(1994)075<0349:RTMPOW>2.0.CO;2},
	abstract = {Experience in performing real-time mesoscale numerical prediction forecasts using the Regional Atmospheric Modeling System (RAMS) over Colorado for a winter season on high-performance workstations is summarized. Performance evaluation is done for specific case studies and, statistically, for the entire winter season. RAMS forecasts are also compared with nested grid model forecasts. In addition, RAMS precipitation forecasts with a simple “dump bucket” scheme are compared with explicit, bulk microphysics parameterization schemes. The potential applications and political/ social problems of having a readily accessible, real-time mesoscale forecasting capability on low-cost, high-performance workstations is discussed.},
	number = {3},
	journal = {Bulletin of the American Meteorological Society},
	author = {Cotton, William R. and Thompson, Gregory and Mieike, Paul W.},
	month = mar,
	year = {1994},
	pages = {349--362}
}

@article{kurihara_numerical_1965,
	title = {Numerical integration of the primitive equations on a spherical grid},
	volume = {93},
	number = {7},
	journal = {Mon. Wea. Rev},
	author = {Kurihara, Yoshio},
	year = {1965},
	pages = {399--415}
}

@article{cote_variable-resolution_1993,
	title = {A {Variable}-{Resolution} {Semi}-{Lagrangian} {Finite}-{Element} {Global} {Model} of the {Shallow}-{Water} {Equations}},
	volume = {121},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281993%29121%3C0231%3AAVRSLF%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1993)121<0231:AVRSLF>2.0.CO;2},
	abstract = {To meet the needs of short- and medium-range operational forecasting, the authors propose a unified strategy based on the use of a global variable-resolution model, run in two different configurations. These are as follows: (i) a variable-resolution “regional” configuration (with resolution focused over an area of interest) for detailed forecasts to 2 days, and (ii) a uniform-resolution “medium-range” one, for forecasts to 7 days or longer. This otters significant economy in an operational environment, since there is only one model—instead of the usual two—to maintain, develop, and optimize. It also provides an efficient and conceptually simple solution to the nesting problem for regional forecasting: the planetary waves are adequately resolved around a high-resolution subdomain (which resolves mesoscale disturbances), there are no artificial lateral boundaries with their attendant problems, and there is no abrupt change of resolution across an internal boundary since the resolution varies smoothly away from the area of interest. To demonstrate the potential of this strategy, we have developed a shallow-water prototype using highly efficient numerical techniques, such as a two time-level semi-implicit semi-Lagrangian integration scheme. This model is a generalization of that of Côté and Staniforth (1990) to variable resolution on an arbitrarily rotated latitude-longitude mesh. Sample integrations indicate that it is possible to almost exactly reproduce a 2-day forecast on an 80° × 60° uniform-resolution (0.5°) subdomain (covering North America) of the variable-resolution mesh, for one-seventh the cost (both computational and storage) of running the model with uniform resolution (0.5°) everywhere, and for a cost about two orders of magnitude lower than running a conventional uniform-resolution Eulerian spectral model. For this variable-resolution mesh, fully 70\% of the points in each direction are on the uniform-resolution area of interest. Thus, the overhead associated with using a model of global extent for short-range forecasting is indeed small, and is a small price to pay to avoid the lateral boundary condition problems of regional models.},
	number = {1},
	journal = {Monthly Weather Review},
	author = {Côté, Jean and Roch, Michel and Staniforth, Andrew and Fillion, Luc},
	month = jan,
	year = {1993},
	pages = {231--243}
}

@article{corby_general_1972,
	title = {A general circulation model of the atmosphere suitable for long period integrations},
	volume = {98},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49709841808/abstract},
	doi = {10.1002/qj.49709841808},
	abstract = {The design of a general circulation model using the primitive equations in spherical form is described, including a statement of the finite difference forms used to integrate the system and explanations of the motives for unusual aspects of the finite difference scheme. The model incorporates the hydrological cycle, topography, a simple scheme for the radiative exchanges and arrangements for the simulation of deep free convection (sub grid-scale) and for the representation of exchanges of momentum, sensible and latent heat with the underlying surface. An experiment performed with the model forms the subject of a separate paper.},
	language = {en},
	number = {418},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Corby, G. A. and Gilchrist, A. and Newson, R. L.},
	month = oct,
	year = {1972},
	pages = {809--832}
}

@article{grell_prognostic_1993,
	title = {Prognostic {Evaluation} of {Assumptions} {Used} by {Cumulus} {Parameterizations}},
	volume = {121},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1993)121%3C0764:PEOAUB%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1993)121<0764:PEOAUB>2.0.CO;2},
	abstract = {Using a spectral-type cumulus parameterization that includes moist downdrafts within a three-dimensional mesoscale model, various disparate closure assumptions are systematically tested within the generalized framework of dynamic control, static control, and feedback. Only one assumption at a time is changed and tested using a midlatitude environment of severe convection. A control run is presented, which shows good agreement with observations in many aspects. Results of the sensitivity tests are compared to observations in terms of sea level pressure, rainfall patterns, and domain-averaged bias errors (compared to the control run) of various properties. The dynamic control is the part that determines the modulation of the convection by the environment. It is shown that rate of destabilization, as well as instantaneous stability, work well for the dynamic control. Integrated moisture convergence leads to underprediction of rainfall rates and subsequent degrading of the results in terms of movement and structure of the mesoscale convective system (MCS). The feedback determines the modification of the environment by the convection, and in this study is considered together with the static control, which determines cloud properties. All feedback and static-control assumptions tested here seem very important for the prediction of sea level pressure and rainfall. The most crucial ones were downdrafts and lateral mixing. As an interesting by-product, it is shown that a very simplistic and computationally highly efficient convective parameterization scheme leads to a very realistic simulation of the MCS, if the scheme uses a stability closure, assumes a large cloud size, parameterizes moist downdrafts, and does not assume unrealistically law lateral mixing.},
	number = {3},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Grell, Georg A.},
	month = mar,
	year = {1993},
	pages = {764--787}
}

@mastersthesis{grant_william_initialization_1975,
	title = {Initialization of primitive equation models},
	school = {MIT},
	author = {{Grant, William}},
	year = {1975}
}

@article{collins_operational_2001,
	title = {The {Operational} {Complex} {Quality} {Control} of {Radiosonde} {Heights} and {Temperatures} at the {National} {Centers} for {Environmental} {Prediction}. {Part} {II}: {Examples} of {Error} {Diagnosis} and {Correction} from {Operational} {Use}},
	volume = {40},
	issn = {0894-8763},
	shorttitle = {The {Operational} {Complex} {Quality} {Control} of {Radiosonde} {Heights} and {Temperatures} at the {National} {Centers} for {Environmental} {Prediction}. {Part} {II}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0450(2001)040%3C0152%3ATOCQCO%3E2.0.CO%3B2},
	doi = {10.1175/1520-0450(2001)040<0152:TOCQCO>2.0.CO;2},
	abstract = {The method of complex quality control of radiosonde heights and temperatures (CQCHT) has been under continuous development and improvement at the National Centers for Environmental Prediction since 1988. Part I of this paper gives the background for the method and details for the currently operational version of the code, which contains significant improvements over previous versions. Part II shows a number of interesting examples of operation of the algorithm and gives statistics on its performance during the first year of operation, September 1997 through August 1998. In a few examples, it is seen how even complicated errors may be corrected. The statistics show that of the 5700 hydrostatically detected errors each month, 77\% were corrected. There is a great variation in the geographical distribution of errors, but it is found that a majority of all stations have at least one hydrostatically suspected error during a month’s time. In addition to hydrostatically detected errors, the CQCHT detects almost 16 000 so-called observation errors in height and temperature each month.},
	number = {2},
	journal = {Journal of Applied Meteorology},
	author = {Collins, William G.},
	month = feb,
	year = {2001},
	pages = {152--168}
}

@article{collins_operational_2001-1,
	title = {The {Operational} {Complex} {Quality} {Control} of {Radiosonde} {Heights} and {Temperatures} at the {National} {Centers} for {Environmental} {Prediction}. {Part} {I}: {Description} of the {Method}},
	volume = {40},
	issn = {0894-8763},
	shorttitle = {The {Operational} {Complex} {Quality} {Control} of {Radiosonde} {Heights} and {Temperatures} at the {National} {Centers} for {Environmental} {Prediction}. {Part} {I}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0450%282001%29040%3C0137%3ATOCQCO%3E2.0.CO%3B2},
	doi = {10.1175/1520-0450(2001)040<0137:TOCQCO>2.0.CO;2},
	abstract = {The quality control of meteorological data has always been an important, if not always fully appreciated, step in the use of the data for analysis and forecasting. In most quality-control approaches, erroneous data are treated as nonrandom “outliers” to the data distribution, which must be eliminated. The elimination of such data traditionally proceeds from coarse to finer filters. More recent methods use the fit (or lack of fit) of such data to an analysis, excluding the data, to determine whether data are acceptable. The complex quality-control (CQC) approach, on the other hand, recognizes that most rough errors are caused by human error and can likely be corrected. In the CQC approach, several independent checks are made that provide numerical measures of any error magnitude. It is only after all check magnitudes, called residuals, are calculated that data quality is determined and errors are corrected when possible. The data-quality assessment and correction is made by the sophisticated logic of the decision-making algorithm (DMA). The principles and development of the method of CQC for radiosonde data were given by Gandin. The development of CQC at the National Centers for Environmental Protection (NCEP) for the detection and correction of errors in radiosonde heights and temperatures, called the complex quality control for heights and temperatures (CQCHT), has progressed from the use of a complex of hydrostatic checks only to the use of statistical and other checks as well, thereby becoming progressively sophisticated. This paper describes a major restructuring in the use of the radiosonde data and in the logical basis of the DMA in the operational CQCHT algorithm at NCEP so that, unlike the previous implementations, all data levels are treated together, thus potentially allowing the correction at any level to influence subsequent correction at adjacent levels, whether they are mandatory or significant. At each level, treated one by one from the surface upward, all available checks are used to make the appropriate decisions. Several vertical passes may be made through the data until no more corrections are possible. Final passes look for “observation” errors. The methods of error determination are outlined, and the effect of errors on the residuals is illustrated. The calculation of residuals is described, their availability for each type of data surface (e.g., earth’s surface, mandatory level, significant level) is given, and their use by the DMA is presented. The limitations of the use of various checks are discussed.},
	number = {2},
	journal = {Journal of Applied Meteorology},
	author = {Collins, William G.},
	month = feb,
	year = {2001},
	pages = {137--151}
}

@article{collins_complex_1998,
	title = {Complex {Quality} {Control} of {Significant} {Level} {Rawinsonde} {Temperatures}},
	volume = {15},
	issn = {0739-0572},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0426%281998%29015%3C0069%3ACQCOSL%3E2.0.CO%3B2},
	doi = {10.1175/1520-0426(1998)015<0069:CQCOSL>2.0.CO;2},
	abstract = {Rawinsonde heights and temperatures have been quality controlled using complex quality control at the National Centers for Atmospheric Prediction since December 1988 when an algorithm using only hydrostatic checking was introduced for the checking of mandatory level heights and temperatures. The quality control of significant level temperatures was added to the hydrostatic code in April 1990. In November 1991, the mandatory level checking was greatly expanded and improved by the inclusion of additional checks: increment (observation minus 6-h forecast), horizontal, and vertical. This paper describes a major improvement to the significant level quality control, introduced in May 1994, using complex quality control techniques. The philosophy of the method and the various checks are described. The principles of the decision-making algorithm are stated, examples are shown, and some statistics of the use of the significant level checking are presented.},
	number = {1},
	journal = {Journal of Atmospheric and Oceanic Technology},
	author = {Collins, William G.},
	month = feb,
	year = {1998},
	pages = {69--79}
}

@book{gleick_chaos:_1987,
	title = {Chaos: {Making} a {New} {Science}},
	shorttitle = {Chaos},
	publisher = {Viking Penguin},
	author = {Gleick, James},
	year = {1987}
}

@article{glahn_use_1972,
	title = {The {Use} of {Model} {Output} {Statistics} ({MOS}) in {Objective} {Weather} {Forecasting}},
	volume = {11},
	issn = {0021-8952},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0450(1972)011%3C1203:TUOMOS%3E2.0.CO;2},
	doi = {10.1175/1520-0450(1972)011<1203:TUOMOS>2.0.CO;2},
	abstract = {Model Output Statistics (MOS) is an objective weather forecasting technique which consists of determining a statistical relationship between a predictand and variables forecast by a numerical model at some projection time(s). It is, in effect, the determination of the “weather related” statistics of a numerical model. This technique, together with screening regression, has been applied to the prediction of surface wind, probability of precipitation, maximum temperature, cloud amount, and conditional probability of frozen precipitation. Predictors used include surface observations at initial time and predictions from the Subsynoptic Advection Model (SAM) and the Primitive Equation model used operationally by the National Weather Service. Verification scores have been computed, and, where possible, compared to scores for forecasts from other objective techniques and for the official forecasts. MOS forecasts of surface wind, probability of precipitation, and conditional probability of frozen precipitation are being disseminated by the National Weather Service over teletype and facsimile. It is concluded that MOS is a useful technique in objective weather forecasting.},
	number = {8},
	urldate = {2017-11-01},
	journal = {Journal of Applied Meteorology},
	author = {Glahn, Harry R. and Lowry, Dale A.},
	month = dec,
	year = {1972},
	pages = {1203--1211}
}

@article{baker_experiments_1987,
	title = {Experiments with a {Three}-{Dimensional} {Statistical} {Objective} {Analysis} {Scheme} {Using} {FGGE} {Data}},
	volume = {115},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281987%29115%3C0272%3AEWATDS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1987)115<0272:EWATDS>2.0.CO;2},
	abstract = {A three-dimensional (3D), multivariate, statistical objective analysis scheme (referred to as optimum interpolation or OI) has been developed for use in numerical weather prediction studies with the FGGE data. Some novel aspects of the present scheme include 1) a multivariate surface analysis over the oceans, which employs an Ekman balance instead of the usual geostrophic relationship, to model the pressure-wind error cross correlations, and 2) the capability to use an error correlation function which is geographically dependent. A series of 4-day data assimilation experiments are conducted to examine the importance of some of the key features of the OI in terms of their effects on forecast skill, as well as to compare the forecast skill using the OI with that utilizing a successive correction method (SCM) of analysis developed earlier. For the three cases examined, the forecast skill is found to be rather insensitive to varying the error correlation function geographically. However, significant differences are noted between forecasts from a two-dimensional (2D) version of the OI and those from the 3D OI, with the 3D OI forecasts exhibiting better forecast skill. The 3D OI forecasts are also more accurate than those from the SCM initial conditions. The 3D OI with the multivariate oceanic surface analysis was found to produce forecasts which were slightly more accurate, on the average, than a univariate version.},
	number = {1},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Baker, Wayman E. and Bloom, Stephen C. and Woollen, John S. and Nestler, Mark S. and Brin, Eugenia and Schlatter, Thomas W. and Branstator, Grant W.},
	month = jan,
	year = {1987},
	pages = {272--296}
}

@article{kurihara_use_1980,
	title = {Use of a {Movable} {Nested}-{Mesh} {Model} for {Tracking} a {Small} {Vortex}},
	volume = {108},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1980)108%3C1792%3AUOAMNM%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1980)108<1792:UOAMNM>2.0.CO;2},
	abstract = {The mesh nesting strategy proposed by Kurihara et al.(1979) was used to construct a movable, nested-mesh, 11-level primitive equation model. The framework of the model is described in detail. With the use of a triply nested mesh system with 1°,⅓° and ⅙° longitude-latitude resolution, a small intense dry vortex in a zonal flow of 10 m s-1 was successfully advected for 48 h. The shape of the vortex was well preserved during the time integration which involved over 50 movements of the innermost mesh. The noise, which was excited when a mesh moved, was suppressed in ∼4 min after the movement. For comparison. the results from similar experiments performed with reduced inner mesh resolutions are also presented.},
	number = {11},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Kurihara, Yoshio and Bender, Morris A.},
	month = nov,
	year = {1980},
	pages = {1792--1809}
}

@article{giorgi_development_1993,
	title = {Development of a {Second}-{Generation} {Regional} {Climate} {Model} ({RegCM2}). {Part} {II}: {Convective} {Processes} and {Assimilation} of {Lateral} {Boundary} {Conditions}},
	volume = {121},
	issn = {0027-0644},
	shorttitle = {Development of a {Second}-{Generation} {Regional} {Climate} {Model} ({RegCM2}). {Part} {II}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1993)121%3C2814:DOASGR%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1993)121<2814:DOASGR>2.0.CO;2},
	abstract = {In this paper we continue the description of a second-generation regional climate model (RegCM2) initiated in the companion paper by Giorgi et al. We first discuss the inclusion in the model of the cumulus cloud scheme developed by Grell (referred to as OCC). The sensitivity of summertime and wintertime results to different closures and parameter settings in the GCC scheme are examined in model simulations conducted over Europe. While wintertime precipitation is found to vary only slightly between the experiments, a wide range of results is found in the summer runs. The GCC scheme produces more rain than a Kuo-type scheme, responds strongly to variations in the surface energy and moisture fluxes, and performs best when used in conjunction with the most advanced physics processes of RegCM2. Modifications to the standard model relaxation boundary condition procedure, which allow smoother assimilation of driving lateral boundary data, are also discussed. Further testing of RegCM2, which is more physically comprehensive, about three times more computationally efficient, and more portable than the previous version of the model, is continuing.},
	number = {10},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Giorgi, Filippo and Marinucci, Maria Rosaria and Bates, Gary T. and De Canio, Gerardo},
	month = oct,
	year = {1993},
	pages = {2814--2832}
}

@article{kuo_feasibility_1987,
	title = {Feasibility of {Short}-{Range} {Numerical} {Weather} {Prediction} {Using} {Observations} from a {Network} of {Profilers}},
	volume = {115},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1987)115%3C2402:FOSRNW%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1987)115<2402:FOSRNW>2.0.CO;2},
	abstract = {A series of observing system simulation experiments was conducted to investigate the feasibility of shortrange numerical weather prediction using a network of profilers. A mesoscale model was used to generate datasets which mimic observations from a network of profilers and from an array of rawinsondes. The sensitivity of the model forecast to the characteristic measurement errors of a number of hypothetical profiler networks was tested. Our results demonstrate that profiler wind observations would have a positive impact on short-range numerical weather prediction with a simple static initialization. We also found that forecasts based on retrieved temperatures (calculated from profiler wind data) are significantly better than those based on direct radiometric temperature measurements (using climatology as the first guess for radiometric retrieval). However, the temperature fields from either radiometric measurements or from thermodynamic retrieval need further improvement-before they can be as accurate as the radiosonde temperature observations for model initialization. Various hypothetical networks, each having a regular array of stations at a separation of 360 km, provided the initial conditions for short-range numerical forecasts. These predictions can be ranked by performance in the following order. (1) profiler wind with radiosonde temperature and moisture; (2) mixed profiler and rawinsonde wind with rawinsonde temperature and moisture; (3) rawinsonde wind; temperature and moisture; (4) profiler wind and moisture with retrieved temperature., and (5) profiles wind, temperature and moisture. It was found that, with a domain of 4320 × 2880 km centered at 40°N and a grid spacing of 40 km, accuracy in both the wind field and the temperature field is needed to define the initial state of the model properly. Even within the mesoscale range, the wind field and the temperature field adjust to each other during the course of the model integration. This is because temperature and wind errors associated with observing systems are often projected onto several different vertical modes at a wide range of horizontal scales, both larger and smaller than the Rossby radius of deformation, thus forcing the mutual adjustment of wind and mass fields. These conclusions are considered tentative because only one synoptic situation was tested with a simple static initialization procedure. Further modeling studies should utilize a four-dimensional data assimilation technique to take advantage of the high temporal resolution of the profiler observations. Also, the experimental procedure should be repeated for more synoptic events to obtain statistically significant results.},
	number = {10},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Kuo, Ying-Hwa and Donall, Evelyn G. and Shapiro, Melvyn A.},
	month = oct,
	year = {1987},
	pages = {2402--2427}
}

@book{gill_practical_1981,
	title = {Practical optimization},
	publisher = {Academic Press},
	author = {Gill, Philip E. and Murray, Walter and Wright, Margaret H.},
	year = {1981}
}

@article{kuo_accuracy_1984,
	title = {Accuracy of {Diagnostic} {Heat} and {Moisture} {Budgets} {Using} {SESAME}-79 {Field} {Data} as {Revealed} by {Observing} {System} {Simulation} {Experiments}},
	volume = {112},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1984)112%3C1465:AODHAM%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1984)112<1465:AODHAM>2.0.CO;2},
	abstract = {The accuracy of diagnostic heat and moisture budgets using the AVE-SESAME 1979 data is investigated through a series of observing system simulation experiments. The four-dimensional (including time) data set provided by a mesoscale model is used to simulate rawinsonde observations taken during the AVE-SESAME 1979 regional-scale experiment. Budget calculations using the simulated data set show that the average root-mean-square error is about 5°C day−1 for the heat budget and 2 g kg−1 day−1 for the moisture budget, on a spatial scale of 550 × 550 km and a temporal scale of 6 h. These magnitudes of error indicate difficulties in diagnosing the heating rate in weak convective systems. However, for strong convective systems, such as the 10–11 April 1979 case, the convective effects can be estimated with the AVE-SESAME data. The influences of observational frequency, objective analysis, observational density, vertical interpolation, and observational errors on the budget results are also studied. It is shown that the temporal and spatial resolution of the SESAME regional network is marginal for diagnosing the convective effects on a horizontal scale of 550 × 550 km, and so improved resolution in space and time is needed in future field programs in order to obtain improved budget results.},
	number = {8},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Kuo, Ying-Hwa and Anthes, Richard A.},
	month = aug,
	year = {1984},
	pages = {1465--1481}
}

@article{kuo_further_1974,
	title = {Further {Studies} of the {Parameterization} of the {Influence} of {Cumulus} {Convection} on {Large}-{Scale} {Flow}},
	volume = {31},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1974)031%3C1232:FSOTPO%3E2.0.CO;2},
	doi = {10.1175/1520-0469(1974)031<1232:FSOTPO>2.0.CO;2},
	abstract = {The parameterization scheme devised by the author in a previous study has been extended to include both deep cumulus convection and shallow convection and a more rigorous derivation is given. In this scheme, the amounts and the vertical distributions of the latent heat released and the sensible heat transported by the deep cumulus are expressed solely in terms of the temperature difference between the cloud and the environment and the convergence of moisture produced by the large-scale flow. It is shown that the often stressed heating by compression in the descending region is automatically taken into consideration in this formulation. A comparison between the calculated results and the observational data of Reed and Recker for the composite easterly wave show that they are in good agreement in the regions of low-level convergence. A separate scheme is devised from the energy equations to represent the transports of heat and moisture by the shallow convection maintained by the thermal boundary layer.},
	number = {5},
	urldate = {2017-11-01},
	journal = {Journal of the Atmospheric Sciences},
	author = {Kuo, H. L.},
	month = jul,
	year = {1974},
	pages = {1232--1240}
}

@article{kuo_formation_1965,
	title = {On {Formation} and {Intensification} of {Tropical} {Cyclones} {Through} {Latent} {Heat} {Release} by {Cumulus} {Convection}},
	volume = {22},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1965)022%3C0040:OFAIOT%3E2.0.CO;2},
	doi = {10.1175/1520-0469(1965)022<0040:OFAIOT>2.0.CO;2},
	abstract = {The effect on large scale motions of latent heat release by deep cumulus convection in a conditionally unstable atmosphere is investigated and a method devised to include this effect directly in the equations for large scale flow. This method is then applied to the hurricane formation problem by incorporating it into time-dependent, circular symmetric dynamic hurricane models, either in gradient-wind balance or unbalanced. Numerical integrations of a two-level approximation of the balanced model have been carried out for two different formulations of the problem (including or not including a frictional radial flow), both starting from a hypothetical initial state characterized by a weak barotropic circular vortex with a maximum tangential velocity of 10 m sec−1 at a distance of 141.2 km from the center. The results obtained without frictional radial flow showed slow intensification of the tangential flow, to about 25 m sec−1, and establishment of a strong radial temperature gradient in the upper troposphere, from sixteen to twenty-four hours after the initial time, after which a steady state ensued. The radial flow obtained from this model remained less than 2 m sec−1. On the other hand, the results obtained with a superimposed frictional radial flow either decayed after reaching a moderate tangential velocity, or developed very rapidly after attaining higher velocity, and did not approach any steady state. The results further show that while the two-level approximation of the balanced model is able to reveal many important aspects of the development problem, it is not able to describe the further development associated with the upper level temperature gradient.},
	number = {1},
	urldate = {2017-11-01},
	journal = {Journal of the Atmospheric Sciences},
	author = {Kuo, H. L.},
	month = jan,
	year = {1965},
	pages = {40--63}
}

@article{collins_comprehensive_1990,
	title = {Comprehensive {Hydrostatic} {Quality} {Control} at the {National} {Meteorological} {Center}},
	volume = {118},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281990%29118%3C2752%3ACHQCAT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1990)118<2752:CHQCAT>2.0.CO;2},
	abstract = {The Comprehensive Hydrostatic Quality Control (CHQC) of rawinsonde data on height and temperature at mandatory isobaric surfaces designed and implemented at the National Meteorological Center in Washington is described in detail. Main principles of the quality control design are discussed, followed by a brief description of the CHQC design and implementation at NMC. The CHQC algorithm is presented with particular emphasis on the Decision Making Algorithm. Numerous examples taken from the operational CHQC outputs illustrate the CHQC performance in general as well as its reaction to errors of various types and to their combinations.},
	number = {12},
	journal = {Monthly Weather Review},
	author = {Collins, William G. and Gandin, Lev S.},
	month = dec,
	year = {1990},
	pages = {2752--2767}
}

@article{colella_piecewise_1984,
	title = {The {Piecewise} {Parabolic} {Method} ({PPM}) for gas-dynamical simulations},
	volume = {54},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/0021999184901438},
	doi = {10.1016/0021-9991(84)90143-8},
	abstract = {We present the piecewise parabolic method, a higher-order extension of Godunov's method. There are several new features of this method which distinguish it from other higher-order Godunov-type methods. We use a higher-order spatial interpolation than previously used, which allows for a steeper representation of discontinuities, particularly contact discontinuities. We introduce a simpler and more robust algorithm for calculating the nonlinear wave interactions used to compute fluxes. Finally, we recognize the need for additional dissipation in any higher-order Godunov method of this type, and introduce it in such a way so as not to degrade the quality of the results.},
	number = {1},
	journal = {Journal of Computational Physics},
	author = {Colella, Phillip and Woodward, Paul R},
	month = apr,
	year = {1984},
	pages = {174--201}
}

@book{gill_atmosphere-ocean_1982,
	title = {Atmosphere-ocean {Dynamics}},
	shorttitle = {International {Geophysics}, 30},
	publisher = {Elsevier},
	author = {Gill, Adrian E.},
	year = {1982}
}

@article{cohn_assessing_1998,
	title = {Assessing the {Effects} of {Data} {Selection} with the {DAO} {Physical}-{Space} {Statistical} {Analysis} {System}},
	volume = {126},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281998%29126%3C2913%3AATEODS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1998)126<2913:ATEODS>2.0.CO;2},
	abstract = {Conventional optimal interpolation (OI) analysis systems solve the standard statistical analysis equations approximately, by invoking a local approximation and a data selection procedure. Although solution of the analysis equations is essentially exact in the recent generation of global spectral variational analysis systems, these new systems also include substantial changes in error covariance modeling, making it difficult to discern whether improvements in analysis and forecast quality are due to exact, global solution of the analysis equations, or to changes in error covariance modeling. The formulation and implementation of a new type of global analysis system at the Data Assimilation Office, termed the Physical-space Statistical Analysis System (PSAS), is described in this article. Since this system operates directly in physical space, it is capable of employing error covariance models identical to those of the predecessor OI system, as well as more advanced models. To focus strictly on the effect of global versus local solution of the analysis equations, a comparison between PSAS and OI analyses is carried out with both systems using identical error covariance models and identical data. Spectral decomposition of the analysis increments reveals that, relative to the PSAS increments, the OI increments have too little power at large horizontal scales and excessive power at small horizontal scales. The OI increments also display an unrealistically large ratio of divergence to vorticity. Dynamical imbalances in the OI-analyzed state can therefore be attributed in part to the approximate local method of solution, and are not entirely due to the simple geostrophic constraint built into the forecast error covariance model. Root-mean-square observation minus 6-h forecast errors in the zonal wind component are substantially smaller for the PSAS system than for the OI system.},
	number = {11},
	journal = {Monthly Weather Review},
	author = {Cohn, Stephen E. and da Silva, Arlindo and Guo, Jing and Sienkiewicz, Meta and Lamich, David},
	month = nov,
	year = {1998},
	pages = {2913--2926}
}

@article{gilchrist_experiment_1954,
	title = {An {Experiment} in {Objective} {Analysis}},
	volume = {6},
	issn = {0040-2826},
	url = {http://dx.doi.org/10.3402/tellusa.v6i4.8762},
	doi = {10.3402/tellusa.v6i4.8762},
	abstract = {An experiment in two-dimensional objective analysis, conducted at The Institute for Advanced Study is described. The method consists of fitting a second degree polynomial by the method of least squares to the meteorological data in a limited area around each point in a rectangular grid, and then interpolating for the height of the pressure surface at the grid point. The results of machine computations give analyses which are comparable in quality to the subjective analyses ordinarily encountered. When used in a three-parameter atmospheric model for a numerical forecast, the objective analyses led to a more accurate forecast than carefully prepared subjective analyses did. Also a satisfactory representation of the field of vertical stability (over North America) was obtained by the two-dimensional analyses, made for three different pressure surfaces.The greatest obstacle encountered in producing a completely objective analysis arises from errors of computation and transmission of raw meteorological data. This obstacle has not been overcome, and necessitates a preliminary subjective examination of the data for detection of errors.},
	number = {4},
	urldate = {2017-11-01},
	journal = {Tellus},
	author = {Gilchrist, B. and Cressman, G. P.},
	month = jan,
	year = {1954},
	pages = {309--318}
}

@article{cohn_approximate_1996,
	title = {Approximate {Data} {Assimilation} {Schemes} for {Stable} and {Unstable} {Dynamics}},
	volume = {74},
	doi = {10.2151/jmsj1965.74.1_63},
	abstract = {Two suboptimal data assimilation schemes for stable and unstable dynamics are introduced. The first scheme, the partial singular value decomposition filter, is based on the most dominant singular modes of the tangent linear propagator. The second scheme, the partial eigendecomposition filter, is based on the most dominant eigenmodes of the propagated analysis error covariance matrix. Both schemes rely on iterative procedures like the Lanczos algorithm to compute the relevant modes.The performance of these schemes is evaluated for a shallow-water model linearized about an unstable Bickley jet. The results are contrasted against those of a reduced resolution filter, in which the gains used to update the state vector are calculated from a lower-dimensional dynamics than the dynamics that evolve the state itself. The results are also contrasted against the exact results given by the Kalman filter. These schemes are validated for the case of stable dynamics as well.The two new approximate assimilation schemes are shown to perform well with relatively few modes computed. Adaptive tuning of a modeled trailing error covariance for all three of these low-rank approximate schemes enhances performance and compensates for the approximation employed.},
	number = {1},
	journal = {Journal of the Meteorological Society of Japan},
	author = {Cohn, Stephen E. and Todling, Ricardo},
	year = {1996},
	pages = {63--75}
}

@article{ghil_michael_advances_1997,
	title = {Advances in {Sequential} {Estimation} for {Atmospheric} and {Oceanic} {Flows}},
	volume = {75},
	url = {https://www.jstage.jst.go.jp/article/jmsj1965/75/1B/75_1B_289/_article},
	urldate = {2017-11-01},
	journal = {J. Meteor. Soc. Japan},
	author = {{Ghil, Michael}},
	year = {1997},
	pages = {289--304}
}

@article{cohn_introduction_1997,
	title = {An {Introduction} to {Estimation} {Theory}},
	volume = {75},
	shorttitle = {An {Introduction} to {Estimation} {Theory} ({gtSpecial} {IssueltData} {Assimilation} in {Meteology} and {Oceanography}},
	doi = {10.2151/jmsj1965.75.1B_257},
	abstract = {Despite the explosive growth of activity in the field of Earth System data assimilation over the past decade or so, there remains a substantial gap between theory and practice. The present article attempts to bridge this gap by exposing some of the central concepts of estimation theory and connecting them with current and future data assimilation approaches. Estimation theory provides a broad and natural mathematical foundation for data assimilation science. Stochastic-dynamic modeling and stochastic observation modeling are described first. Optimality criteria for linear and nonlinear state estimation problems are then explored, leading to conditional-mean estimation procedures such as the Kalman filter and some of its generalizations, and to conditional/mode estimation procedures such as variational methods. A detailed derivation of the Kalman filter is given to illustrate the role of key probabilistic concepts and assumptions. Extensions of the Kalman filter to nonlinear observation operators and to non-Gaussian errors are then described. In a simple illustrative example, rigorous treatment of representativeness error and model error is highlighted in finite-dimensional estimation procedures for continuum dynamics and observations of the continuum state.},
	number = {1B},
	journal = {Journal of the Meteorological Society of Japan},
	author = {Cohn, Stephen E.},
	year = {1997},
	pages = {257--288}
}

@article{krishnamurti_improved_1999,
	title = {Improved {Weather} and {Seasonal} {Climate} {Forecasts} from {Multimodel} {Superensemble}},
	volume = {285},
	issn = {0036-8075, 1095-9203},
	url = {http://science.sciencemag.org/content/285/5433/1548},
	doi = {10.1126/science.285.5433.1548},
	abstract = {A method for improving weather and climate forecast skill has been developed. It is called a superensemble, and it arose from a study of the statistical properties of a low-order spectral model. Multiple regression was used to determine coefficients from multimodel forecasts and observations. The coefficients were then used in the superensemble technique. The superensemble was shown to outperform all model forecasts for multiseasonal, medium-range weather and hurricane forecasts. In addition, the superensemble was shown to have higher skill than forecasts based solely on ensemble averaging.},
	language = {en},
	number = {5433},
	urldate = {2017-11-01},
	journal = {Science},
	author = {Krishnamurti, T. N. and Kishtawal, C. M. and LaRow, Timothy E. and Bachiochi, David R. and Zhang, Zhan and Williford, C. Eric and Gadgil, Sulochana and Surendran, Sajani},
	month = sep,
	year = {1999},
	pmid = {10477515},
	pages = {1548--1550}
}

@book{krishnamurti_introduction_1995,
	title = {An introduction to numerical weather prediction techniques},
	publisher = {CRC press},
	author = {Krishnamurti, Tiruvalam Natarajan and Bounoua, Lahouari},
	year = {1995}
}

@article{ghil_data_1997,
	title = {Data assimilation in meteorology and oceanography},
	journal = {Meteorological Society of Japan},
	author = {Ghil, Michael and Ide, K. and Bennett, A. and Courtier, P. and Kimoto, M. and Nagata, M. and Saiki, M. and Sato, M.},
	year = {1997},
	pages = {300}
}

@article{ghil_tracking_1996,
	title = {Tracking {Atmospheric} {Instabilities} with the {Kalman} {Filter}. {Part} {II}: {Two}-{Layer} {Results}},
	volume = {124},
	issn = {0027-0644},
	shorttitle = {Tracking {Atmospheric} {Instabilities} with the {Kalman} {Filter}. {Part} {II}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1996)124%3C2340%3ATAIWTK%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1996)124<2340:TAIWTK>2.0.CO;2},
	abstract = {Sequential data assimilation schemes approaching true optimality for sizable atmospheric models are becoming a reality. The behavior of the Kalman filter (KF) under difficult conditions needs therefore to be understood. In this two-part paper the authors implemented a KF for a two-dimensional shallow-water model with one or two layers. The model is linearized about a basic flow that depends on latitude; this permits the one-layer (1-L) case to be barotropically unstable. Constant vertical shear in the two-layer (2-L) case induces baroclinic instability. The stable and unstable 1-L cases were studied in Part I. In the unstable case, even a very small number of observations can keep the forecast and analysis errors from the exponential growth induced by the flow's instability. In Part II, the authors now consider the 2-L, baroclinically stable and unstable cases. Simple experiments show that both cases are, quite similar to their barotropic counterparts. Once again, the KF is shown to keep the estimated flow's error bars bounded, even when a small number of observations—taken with realistic frequency—is utilized.},
	number = {10},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Ghil, Michael and Todling, Ricardo},
	month = oct,
	year = {1996},
	pages = {2340--2352}
}

@incollection{ghil_data_1991,
	title = {Data {Assimilation} in {Meteorology} and {Oceanography}},
	volume = {33},
	url = {http://www.sciencedirect.com/science/article/pii/S0065268708604422},
	abstract = {This chapter provides a review of current operational practice and of advanced data assimilation techniques in meteorology. Numerical models can be used to assimilate meteorological and oceanographic data, creating a dynamically consistent, complete and accurate “movie” of the two geofluids, atmosphere, and ocean in motion. The ocean's strong stratification helps determine the most energetic scales and processes for the global ocean circulation. Active research on data assimilation is burgeoning rapidly in both meteorology and oceanography. Operational NWP requirements have produced a mature data-assimilation technology in meteorology, from which climatic research has benefitted as well. Ocean is characterized by transient, energetic motions with a broad spectrum in frequency and wave number. A steady component of the circulation may not even exist, and be only a model resulting from the analysis of data sets sparse in space and time, like hydrographic data sets, for which steadiness is assumed a priori. Thus, in oceanic data-assimilation problems, the choice of a model and related data assimilation scheme and the definition of success of the assimilation process itself depend crucially on the scientific issue of interest as the starting point.},
	urldate = {2017-11-01},
	booktitle = {Advances in {Geophysics}},
	publisher = {Elsevier},
	author = {Ghil, Michael and Malanotte-Rizzoli, Paola},
	editor = {Dmowska, Renata and Saltzman, Barry},
	month = jan,
	year = {1991},
	doi = {10.1016/S0065-2687(08)60442-2},
	pages = {141--266}
}

@article{ghil_nonlinear_1991,
	title = {Nonlinear {Dynamics} and {Predictability} in the {Atmospheric} {Sciences}},
	volume = {29},
	issn = {1944-9208},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/rog.1991.29.s1.46/abstract},
	doi = {10.1002/rog.1991.29.s1.46},
	abstract = {Contributions by American scientists to the nonlinear dynamics of intraseasonal, interannual and Quaternary 
climate changes are summarized for the period 1987–90. Applications of the successive bifurcation approach
and of the ergodic theory of dynamical systems to our understanding and prediction of these changes are
emphasized.},
	language = {en},
	number = {S1},
	urldate = {2017-11-01},
	journal = {Reviews of Geophysics},
	author = {Ghil, M. and Kimoto, M. and Neelin, J. D.},
	month = jan,
	year = {1991},
	pages = {46--55}
}

@book{ghil_topics_1987,
	title = {Topics in {Geophysical} {Fluid} {Dynamics}: {Atmospheric} {Dynamics}, {Dynamo} {Theory}, and {Climate} {Dynamics}},
	shorttitle = {Topics in {Geophysical} {Fluid} {Dynamics}},
	abstract = {The vigorous stirring of a cup of tea gives rise, as we all know, to interesting fluid dynamical phenomena, some of which are very hard to explain. In this book our "cup of tea" contains the currents of the Earth's atmosphere, oceans, mantle, and fluid core. Our goal is to under stand the basic physical processes which are most important in describing what we observe, directly or indirectly, in these complex systems. While in many respects our understanding is measured by the ability to predict, the focus here will be on relatively simple models which can aid our physical intuition by suggesting useful mathematical methods of investiga tion. These elementary models can be viewed as part of a hierarchy of models of increasing complexity, moving toward those which might be use fully predictive. The discussion in this book will deal primarily with the Earth. Interplanetary probes of Venus, Mars, Jupiter and Saturn have revealed many exciting phenomena which bear on geophysical fluid dynamics. They have also enabled us to see the effect of changing the values of certain parameters, such as gravity and rotation rate, on geophysical flows. On the other hand, satellite observations of our own planet on a daily and hourly basis have turned it into a unique laboratory for the study of fluid motions on a scale never dreamt of before: the motion of cyclones can be observed via satellite just as wing tip vortices are studied in a wind tunnel.},
	language = {en},
	publisher = {Springer-Verlag},
	author = {Ghil, M. and Childress, S.},
	year = {1987},
	note = {Google-Books-ID: LozfBwAAQBAJ},
	keywords = {Science / Physics / Mathematical \& Computational, Science / Physics / General}
}

@book{ghil_turbulence_1985,
	title = {Turbulence and predictability in geophysical fluid dynamics and climate dynamics},
	publisher = {North-Holland Amsterdam et al.},
	author = {Ghil, Michael and Benzi, R and Parisi, G},
	year = {1985}
}

@incollection{ghil_applications_1981,
	series = {Applied {Mathematical} {Sciences}},
	title = {Applications of {Estimation} {Theory} to {Numerical} {Weather} {Prediction}},
	isbn = {978-0-387-90632-4 978-1-4612-5970-1},
	url = {https://link.springer.com/chapter/10.1007/978-1-4612-5970-1_5},
	abstract = {Numerical weather prediction (NWP) is an initial-value problem for a system of nonlinear partial differential equations (PDEs) in which the initial values are known only incompletely and inaccurately. Data at initial time can be supplemented, however, by observations of the system distributed over a time interval preceding it. Estimation theory has been successful in approaching such problems for models governed by systems of ordinary differential equations and of linear PDEs. We develop methods of sequential estimation for NWP.A model exhibiting many features of large-scale atmospheric flow important in NWP is the one governed by the shallow-fluid equations. We study first the estimation problem for a linearized version of these equations. The vector of observations corresponds to the different atmospheric quantities measured and space-time patterns associated with conventional and satellite-borne meteorological observing systems. A discrete Kalman-Bucy (K-B) filter is applied to a finite-difference version of the equations, which simulates the numerical models used in NWP.The specific character of the equations’ dynamics gives rise to the necessity of modifying the usual K-B filter. The modification consists in eliminating the high-frequency inertia-gravity waves which would otherwise be generated by the insertion of observational data. The modified filtering procedure developed here combines in an optimal way dynamic initialization (i.e., elimination of fast waves) and four-dimensional (space-time) assimilation of observational data, two procedures which traditionally have been carried out separately in NWP. Comparisons between the modified filter and the standard K-B filter have been made.The matrix of weighting coefficients, or filter, applied to the observational corrections of state variables converges rapidly to an asymptotic, constant matrix. Using realistic values of observational noise and system noise, this convergence has been shown to occur in numerical experiments with the linear system studied; it has also been analyzed theoretically in a simplified, scalar case. The relatively rapid convergence of the filter in our simulations leads us to expect that the filter will be efficiently computable for operational NWP models and real observation patterns.Our program calls for the study of the asymptotic filter’s dependence on observation patterns, noise levels, and the system’s dynamics. Furthermore, the covariance matrices of system noise and observational noise will be determined from the data themselves in the process of sequential estimation, rather than be assigned predetermined, heuristic values. Finally, the estimation procedure will be extended to the full, nonlinear shallow-fluid equations.},
	language = {en},
	urldate = {2017-11-01},
	booktitle = {Dynamic {Meteorology}: {Data} {Assimilation} {Methods}},
	publisher = {Springer, New York, NY},
	author = {Ghil, M. and Cohn, S. and Tavantzis, J. and Bube, K. and Isaacson, E.},
	year = {1981},
	doi = {10.1007/978-1-4612-5970-1_5},
	pages = {139--224}
}

@article{gelaro_sensitivity_1998,
	title = {Sensitivity {Analysis} of {Forecast} {Errors} and the {Construction} of {Optimal} {Perturbations} {Using} {Singular} {Vectors}},
	volume = {55},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1998)055%3C1012:SAOFEA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1998)055<1012:SAOFEA>2.0.CO;2},
	abstract = {The sensitivity of forecast errors to initial conditions is used to examine the optimality of perturbations constructed from the singular vectors of the tangent propagator of the European Centre for Medium-Range Weather Forecasts model. Sensitivity and pseudo-inverse perturbations based on the 48-h forecast error are computed as explicit linear combinations of singular vectors optimizing total energy over the Northern Hemisphere. It is assumed that these perturbations are close to the optimal perturbation that can be constructed from a linear combination of these singular vectors. Optimality is measured primarily in terms of the medium-range forecast improvement obtained by adding the perturbations a posteriori to the initial conditions. Several issues are addressed in the context of these experiments, including the ability of singular vectors to describe forecast error growth beyond the optimization interval, the number of singular vectors required, and the implications of nonmodal error growth. Supporting evidence for the use of singular vectors based on a total energy metric for studying atmospheric predictability is also presented. In general, less than 30 singular vectors capture a large fraction of the variance of the Northern Hemisphere sensitivity pattern obtained from a T63 adjoint model integration, especially in cases of low forecast skill. The sensitivity patterns for these cases tend to be highly localized with structures determined by the dominant singular vectors. Forecast experiments with these perturbations show significant improvements in skill in the medium range, indicating that singular vectors optimized for a short-range forecast continue to provide a useful description of error growth well beyond this time. The results suggest that ensemble perturbations based on 10–30 singular vectors should provide a reasonable description of the medium-range forecast uncertainty, although the inclusion of additional singular vectors is likely to be beneficial. Nonmodality is a key consideration in the construction of optimal perturbations. There is virtually no projection between the contemporaneous unstable subspaces at the end of one forecast trajectory portion and the beginning of a second, consecutive portion. Sensitivity and ensemble perturbations constructed using the evolved singular vectors from a previous (day−2) forecast are suboptimal for the current (day+0) forecast initial conditions. It is argued that these results have implications for a range of issues in atmospheric predictability including ensemble weather prediction, data assimilation, and the development of adaptive observing techniques.},
	number = {6},
	urldate = {2017-11-01},
	journal = {Journal of the Atmospheric Sciences},
	author = {Gelaro, R. and Buizza, R. and Palmer, T. N. and Klinker, E.},
	month = mar,
	year = {1998},
	pages = {1012--1037}
}

@article{gates_overview_1999,
	title = {An {Overview} of the {Results} of the {Atmospheric} {Model} {Intercomparison} {Project} ({AMIP} {I})},
	volume = {80},
	issn = {0003-0007},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0477(1999)080%3C0029:AOOTRO%3E2.0.CO;2},
	doi = {10.1175/1520-0477(1999)080<0029:AOOTRO>2.0.CO;2},
	abstract = {The Atmospheric Model Intercomparison Project (AMIP), initiated in 1989 under the auspices of the World Climate Research Programme, undertook the systematic validation, diagnosis, and intercomparison of the performance of atmospheric general circulation models. For this purpose all models were required to simulate the evolution of the climate during the decade 1979—88, subject to the observed monthly average temperature and sea ice and a common prescribed atmospheric CO2 concentration and solar constant. By 1995, 31 modeling groups, representing virtually the entire international atmospheric modeling community, had contributed the required standard output of the monthly means of selected statistics. These data have been analyzed by the participating modeling groups, by the Program for Climate Model Diagnosis and Intercomparison, and by the more than two dozen AMIP diagnostic subprojects that have been established to examine specific aspects of the models' performance. Here the analysis and validation of the AMIP results as a whole are summarized in order to document the overall performance of atmospheric general circulation—climate models as of the early 1990s. The infrastructure and plans for continuation of the AMIP project are also reported on. Although there are apparent model outliers in each simulated variable examined, validation of the AMIP models' ensemble mean shows that the average large-scale seasonal distributions of pressure, temperature, and circulation are reasonably close to what are believed to be the best observational estimates available. The large-scale structure of the ensemble mean precipitation and ocean surface heat flux also resemble the observed estimates but show particularly large intermodel differences in low latitudes. The total cloudiness, on the other hand, is rather poorly simulated, especially in the Southern Hemisphere. The models' simulation of the seasonal cycle (as represented by the amplitude and phase of the first annual harmonic of sea level pressure) closely resembles the observed variation in almost all regions. The ensemble's simulation of the interannual variability of sea level pressure in the tropical Pacific is reasonably close to that observed (except for its underestimate of the amplitude of major El Niños), while the interannual variability is less well simulated in midlatitudes. When analyzed in terms of the variability of the evolution of their combined space-time patterns in comparison to observations, the AMIP models are seen to exhibit a wide range of accuracy, with no single model performing best in all respects considered. Analysis of the subset of the original AMIP models for which revised versions have subsequently been used to revisit the experiment shows a substantial reduction of the models' systematic errors in simulating cloudiness but only a slight reduction of the mean seasonal errors of most other variables. In order to understand better the nature of these errors and to accelerate the rate of model improvement, an expanded and continuing project (AMIP II) is being undertaken in which analysis and intercomparison will address a wider range of variables and processes, using an improved diagnostic and experimental infrastructure.},
	number = {1},
	urldate = {2017-11-01},
	journal = {Bulletin of the American Meteorological Society},
	author = {Gates, W. Lawrence and Boyle, James S. and Covey, Curt and Dease, Clyde G. and Doutriaux, Charles M. and Drach, Robert S. and Fiorino, Michael and Gleckler, Peter J. and Hnilo, Justin J. and Marlais, Susan M. and Phillips, Thomas J. and Potter, Gerald L. and Santer, Benjamin D. and Sperber, Kenneth R. and Taylor, Karl E. and Williams, Dean N.},
	month = jan,
	year = {1999},
	pages = {29--55}
}

@article{gates_amip:_1992,
	title = {{AMIP}: {The} {Atmospheric} {Model} {Intercomparison} {Project}},
	volume = {73},
	issn = {0003-0007},
	shorttitle = {{AMIP}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0477(1992)073%3C1962:ATAMIP%3E2.0.CO;2},
	doi = {10.1175/1520-0477(1992)073<1962:ATAMIP>2.0.CO;2},
	abstract = {The Atmospheric Model Intercomparison Project (AMIP) is an international effort to determine the systematic climate errors of atmospheric models under realistic conditions, and calls for the simulation of the climate of the decade 1979–1988 using the observed monthly averaged distributions of sea surface temperature and sea ice as boundary conditions. Organized by the Working Group on Numerical Experimentation as a contribution to the World Climate Research Programme, AMIP involves the international atmospheric modeling community in a major test and intercomparison of model performance; in addition to an agreed-to set of monthly averaged output variables, each of the participating models will generate a daily history of state. These data will be stored and made available in standard format by the Program for Climate Model Diagnosis and Intercomparison at the Lawrence Livermore National Laboratory. Following completion of the computational phase of AMIP in 1993, emphasis will shift to a series of diagnostic sub-projects, now being planned, for the detailed examination of model performance and the simulation of specific physical processes and phenomena. AMIP offers an unprecedented opportunity for the comprehensive evaluation and validation of current atmospheric models, and is expected to provide valuable information for modal improvement.},
	number = {12},
	urldate = {2017-11-01},
	journal = {Bulletin of the American Meteorological Society},
	author = {Gates, W. Lawrence},
	month = dec,
	year = {1992},
	pages = {1962--1970}
}

@book{garratt_atmospheric_1994,
	title = {The {Atmospheric} {Boundary} {Layer}},
	publisher = {Cambridge University Press},
	author = {Garratt, J. R.},
	year = {1994}
}

@article{cohn_analysis_1989,
	title = {An analysis of the vertical structure equation for arbitrary thermal profiles},
	volume = {115},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49711548508/abstract},
	doi = {10.1002/qj.49711548508},
	abstract = {The vertical structure equation is a singular Sturm-Liouville problem whose eigenfunctions describe the vertical dependence of the normal modes of the primitive equations linearized about a given thermal profile. The eigenvalues give the equivalent depths of the modes. We study, for arbitrary thermal profiles, the spectrum of the vertical structure equation and the appropriateness of various upper boundary conditions. Our results depend critically upon whether or not the thermal profile is such that the basic state atmosphere is bounded. This is not surprising since, as we point out, the vertical structure equation is not meaningful at large heights because of the traditional shallowness approximations which are used to derive the primitive equations. The nature of the spectrum of a singular Sturm-Liouville problem depends only on the behaviour of the coefficients of the differential equation near the singular boundary. Spectral results therefore have no physical significance for unbounded atmospheres. For all bounded atmospheres we show that the spectrum is totally discrete, regardless of details of the thermal profile. For the barotropic equivalent depth, which corresponds to the lowest eigenvalue, we obtain upper and lower bounds which depend only on the surface temperature and the atmosphere height. All eigenfunctions are bounded, but always have first derivatives which become unbounded near the top. We prove that the commonly invoked upper boundary condition that vertical velocity must vanish as pressure tends to zero, as well as a number of alternative conditions, are well posed. For unbounded atmospheres, on the other hand, we show that typically there is a continuous spectrum, that the boundary condition of vanishing vertical velocity is not well posed, and that the eigenfunctions. if any. are unbounded.},
	language = {en},
	number = {485},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Cohn, Stephen E. and Dee, Dick P.},
	month = jan,
	year = {1989},
	pages = {143--171}
}

@article{cohn_observability_1988,
	title = {Observability of {Discretized} {Partial} {Differential} {Equations}},
	volume = {25},
	issn = {0036-1429},
	url = {http://epubs.siam.org/doi/abs/10.1137/0725037},
	doi = {10.1137/0725037},
	abstract = {The situation in which one cannot solve a numerical initial value problem for lack of complete initial data is arising ever more frequently in applied sciences and engineering. The procedure of estimating the evolving solution by inserting incomplete data into a numerical model as they become available at different instants of time is called data assimilation or filtering.We show that if data generated by a linear system of partial differential equations (PDE) are inserted properly, then complete observability of the discrete numerical model is necessary and sufficient for asymptotic stability of the data assimilation process. This complete observability means that if the data had been generated by the discrete model rather than by the PDE system, then the data would define the state of the model uniquely after some finite time.Simple observability criteria for discretizations of linear, constant-coefficient PDE on periodic domains are formulated in terms of properties of the symbol of the numerical scheme. It is shown that spurious numerical dispersion can detract from observability by yielding a multivalued symbol. While observability for the advection equation demands the addition of dissipation to the leapfrog and Crank–Nicolson schemes, dissipation is not needed for second-order and sixth-order accurate box schemes.},
	number = {3},
	journal = {SIAM Journal on Numerical Analysis},
	author = {Cohn, S. and Dee, D.},
	month = jun,
	year = {1988},
	pages = {586--617}
}

@article{gandin_two_1993,
	title = {Two {Years} of {Operational} {Comprehensive} {Hydrostatic} {Quality} {Control} at the {National} {Meteorological} {Center}},
	volume = {8},
	issn = {0882-8156},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0434(1993)008%3C0057%3ATYOOCH%3E2.0.CO%3B2},
	doi = {10.1175/1520-0434(1993)008<0057:TYOOCH>2.0.CO;2},
	abstract = {A comprehensive hydrostatic quality control (CHQC) procedure for rawinsonde heights and temperatures was implemented into operational use at the National Meteorological Center (NMC) in December 1988. The CHQC uses a sophisticated decision-making algorithm to detect so-called rough errors in rawinsonde observations and to confidently correct many of them. Statistics gathered over a two-year period are presented to provide information on the frequency, geographical distribution, and origin of these errors. During this period, approximately 7\% of the rawinsonde reports received at the NMC contained a hydrostatically detectable error. The number of errors has stayed relatively constant over the two-year period. The geographic distribution of the errors is uneven, with most of them originating in countries where many of the steps involved in computing and coding the reports are performed manually. Other characteristics as well indicate that almost all problems that are detected by the CHQC are caused by human error. This article proposes several measures as a means of reducing these errors. An analysis of the performance of the CHQC, which reveals that fully 50\% of the errors that are detected by the CHQC are corrected automatically by it as well, is also presented. Information about the remaining errors along with suggested corrections is made available to specialists in NMC's Meteorological Operations Division where a final decision is made. This type of information has been discovered to also be quite useful in monitoring the quality of data in near-real time. Its use has led to a quick resolution of many problems associated with data transmission and decoding procedures. Several examples are discussed.},
	number = {1},
	urldate = {2017-11-01},
	journal = {Weather and Forecasting},
	author = {Gandin, Lev S. and Morone, Lauren L. and Collins, William G.},
	month = mar,
	year = {1993},
	pages = {57--72}
}

@article{gandin_complex_1988,
	title = {Complex {Quality} {Control} of {Meteorological} {Observations}},
	volume = {116},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1988)116%3C1137:CQCOMO%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1988)116<1137:CQCOMO>2.0.CO;2},
	abstract = {A survey of the so-called complex quality control (CQC) of meteorological information is presented. The principles of the CQC approach are formulated. The CQC of rawinsonde height and temperature data at mandatory isobaric surfaces is described in detail. This CQC has been implemented into routine practice at the Hydro-meteorological Center in Moscow. It has been also applied at the World Data Center in Obninsk for the quality control of the FGGE Level IIb data. Some results of the CQC operations are presented. Possibilities and ways to apply the CQC approach to other kinds of meteorological information are also discussed.},
	number = {5},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Gandin, Lev S.},
	month = may,
	year = {1988},
	pages = {1137--1156}
}

@article{chen_impact_1997,
	title = {Impact of {Atmospheric} {Surface}-layer {Parameterizations} in the new {Land}-surface {Scheme} of the {NCEP} {Mesoscale} {Eta} {Model}},
	volume = {85},
	issn = {0006-8314, 1573-1472},
	url = {https://link.springer.com/article/10.1023/A:1000531001463},
	doi = {10.1023/A:1000531001463},
	abstract = {We tested three atmospheric surface-layer parameterization schemes (Mellor-Yamadalevel 2, Paulson, and modified Louis), both ina 1-D mode in the new NCEP land-surface scheme against long-term FIFE and HAPEX observations, and in a coupled 3-D mode withthe NCEP mesoscale Eta model. The differences inthese three schemes and the resulting surface exchange coefficients do not, in general, lead to significant differences in model simulated surface fluxes, skin temperature, andprecipitation, provided the same treatment of roughness length for heat is employed.Rather, the model is more sensitive to the choice of the roughness length for heat. To assess the latter, we also tested two approaches to specifythe roughness length for heat: 1) assuming the roughness length for heat is a fixed ratio of the roughness length for momentum, and 2) relating this ratio to the roughness Reynolds number as proposed by Zilitinkevich.Our 1-D column model sensitivity tests suggested that the Zilitinkevich approach can improve the surface heat fluxand skin temperature simulations. A long-term test with the NCEP mesoscaleEta model indicated that this approach can also reduce forecast precipitation bias. Based on these simulations, in January 1996 we operationally implemented the Paulsonscheme with the new land-surface scheme of the NCEP Eta model, along with the Zilitinkevich formulation to specify the roughness length for heat.},
	language = {en},
	number = {3},
	urldate = {2017-11-01},
	journal = {Boundary-Layer Meteorology},
	author = {Chen, Fei and Janjić, Zavisă and Mitchell, Kenneth},
	month = dec,
	year = {1997},
	pages = {391--421}
}

@incollection{gal-chen_initialization_1983,
	series = {{NATO} {ASI} {Series}},
	title = {Initialization of {Mesoscale} {Models}: {The} {Possible} {Impact} of {Remotely} {Sensed} {Data}},
	isbn = {978-90-481-8390-6 978-94-017-2241-4},
	shorttitle = {Initialization of {Mesoscale} {Models}},
	url = {https://link.springer.com/chapter/10.1007/978-94-017-2241-4_6},
	abstract = {The numerical models discussed in this book (and elsewhere) are formulated as Initial Value problems. That is at the start of the integration (t = 0) all the prognostic variables (wind, temperature, humidity) need to be specified. At a later time, all the prognostic (and diagnostic) variables are predicted by the model. Virtually all the numerical models require that the continuum equations, which describe the atmospheric dynamics, thermodynamics and radiation, be replaced by their discrete analogues. Regardless of the specific method of discretization, there is an explicit or implicit requirement that the initial conditions be specified at grid points which are often different than “observation points”.},
	language = {en},
	urldate = {2017-11-01},
	booktitle = {Mesoscale {Meteorology} — {Theories}, {Observations} and {Models}},
	publisher = {Springer, Dordrecht},
	author = {Gal-Chen, Tzvi},
	year = {1983},
	doi = {10.1007/978-94-017-2241-4_6},
	pages = {157--171}
}

@article{baker_case_1984,
	title = {A {Case} {Study} of {Forecast} {Sensitivity} to {Data} and {Data} {Analysis} {Techniques}},
	volume = {112},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281984%29112%3C1544%3AACSOFS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1984)112<1544:ACSOFS>2.0.CO;2},
	abstract = {In this study we examine the sensitivity of forecast to individual components of the First GARP (Global Atmospheric Research Programme) Global Experiment database as well as to some modifications in the data analysis techniques. Several short assimilation experiments (0000 GMT 18 January 1979 through 0000 21 January) are performed in order to test the effects of each database or analysis change. Forecasts are then generated from the initial conditions provided by these experiments. The 0000 21 January case is chosen for a detailed investigation because or the poor forecast skill obtained earlier over North America for that particular case. Specifically, we conduct experiments to test the sensitivity of forecast skill to: 1) the addition of individual satellite observing system components; 2) temperature data obtained with different satellite retrieval methods; and 3) the method of vertical interpolation between the mandatory pressure analysis levels and the model sigma levels. For the single case examined, TIROS-N infrared land retrievals produced operationally are found to degrade the forecast, while the use of TIROS-N retrievals produced with a physical inversion method as part of an analysis/forecast cycle results in an improved forecast. The use of oceanic VTPR (Vertical Temperature Profile Radiometer) satellite retrievals also results in an improved forecast over North America. The forecast is also found to be sensitive to the method of vertical interpolation between the mandatory pressure analysis levels and the model sigma levels.},
	number = {8},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Baker, W. E. and Atlas, R. and Halem, M. and Susskind, J.},
	month = aug,
	year = {1984},
	pages = {1544--1561}
}

@article{gal-chen_use_1975,
	title = {On the use of a coordinate transformation for the solution of the {Navier}-{Stokes} equations},
	volume = {17},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/0021999175900376},
	doi = {10.1016/0021-9991(75)90037-6},
	abstract = {The equations of fluid motion have been formulated in a generalized noncartesian, non-orthogonal coordinate system. A particular coordinate transformation, which transforms a domain with an irregular lower boundary into a cube, has been constructed. The transformed system, unlike the original one, has flat boundaries and homogeneous boundary conditions. Where the topography is flat, the original and transformed systems are identical, and extra terms do not appear. A finite difference scheme for solving the transformed equations has been constructed and will be described in a subsequent issue of this journal.},
	number = {2},
	urldate = {2017-11-01},
	journal = {Journal of Computational Physics},
	author = {Gal-Chen, Tzvi and Somerville, Richard C. J},
	month = feb,
	year = {1975},
	pages = {209--228}
}

@article{fritsch_model_2000,
	title = {Model {Consensus}},
	volume = {15},
	issn = {0882-8156},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0434(2000)015%3C0571:MC%3E2.0.CO%3B2},
	doi = {10.1175/1520-0434(2000)015<0571:MC>2.0.CO;2},
	abstract = {Consensus forecasts from the control runs of several operational numerical models are compared to 1) the control-run forecasts of the individual models that compose the consensus and to 2) other consensus forecasts generated by varying the initial conditions of the various individual models. It is found that the multimodel consensus is superior to the individual control runs and to the consensus forecasts constructed from ensembles of runs generated by varying model initial conditions. The source of the forecast improvement by model consensus is not the result of a simple cancellation of errors as a result of an overall positive bias in one model and an overall negative bias in another. Rather the main improvement stems from overlapping differences in the sign of the errors associated with forecasts of individual traveling disturbances. The results suggest that variations in model physics and numerics play a substantial role in generating the full spectrum of possible solutions that can arise in a given numerical forecast.},
	number = {5},
	urldate = {2017-11-01},
	journal = {Weather and Forecasting},
	author = {Fritsch, J. M. and Hilliker, J. and Ross, J. and Vislocky, R. L.},
	month = oct,
	year = {2000},
	pages = {571--582}
}

@article{baer_complete_1977,
	title = {On {Complete} {Filtering} of {Gravity} {Modes} {Through} {Nonlinear} {Initialization}},
	volume = {105},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281977%29105%3C1536%3AOCFOGM%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1977)105<1536:OCFOGM>2.0.CO;2},
	abstract = {A procedure is outlined which adjusts the initial conditions for any prediction model of a planetary fluid such that no motions of the fluid will evolve with high-frequency, gravity-type time scales despite the model's nonlinearity. Any model which can be characterized by a reasonably small Rossby number may be balanced by the method. The technique requires the determination of the normal modes of the linear part of the equations to be integrated—finite difference or spectral—and proceeds by an expansion technique to build up higher order, nonlinear adjustments to the initial state.},
	number = {12},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Baer, F. and Tribbia, J. J.},
	month = dec,
	year = {1977},
	pages = {1536--1539}
}

@article{baer_integration_1964,
	title = {Integration with the {Spectral} {Vorticity} {Equation}},
	volume = {21},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469%281964%29021%3C0260%3AIWTSVE%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1964)021<0260:IWTSVE>2.0.CO;2},
	abstract = {The barotropic vorticity equation in spectral form is integrated for a time period exceeding 80 days in two cases of hypothetical initial conditions with a time step of three hours without appreciable truncation error at the end of the period. The computational stability and truncation properties of the spectral system are discussed, the stability criterion for the two cases is computed, and the truncation errors are to some extent explained. The results of the integrations show systematic periods of very pronounced energy exchange among the long waves, with little energy filtering down to the short waves. An analytic solution of a low-order spectral system suggests that the periodic exchange may be characteristic of the differential equation rather than dependent entirely on the initial conditions. The high-frequency components are examined for equilibrium of energy exchange after extended integration. Our results suggest that such an equilibrium does not exist in the model we have formulated.},
	number = {3},
	urldate = {2017-11-01},
	journal = {Journal of the Atmospheric Sciences},
	author = {Baer, Ferdinand},
	month = may,
	year = {1964},
	pages = {260--276}
}

@article{frederiksen_adjoint_1997,
	title = {Adjoint {Sensitivity} and {Finite}-{Time} {Normal} {Mode} {Disturbances} during {Blocking}},
	volume = {54},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1997)054%3C1144:ASAFTN%3E2.0.CO;2},
	doi = {10.1175/1520-0469(1997)054<1144:ASAFTN>2.0.CO;2},
	abstract = {The finite-time normal mode instability of four-dimensional space–time basic states has been studied for cases of block development over the Gulf of Alaska, over the North Atlantic, and over southern Greenland using a two-level tangent linear model. The authors find three generic types of finite-time normal modes, denoted as “recurring,” “traveling,” and “flip” modes. The dominant finite-time normal modes associated with block development have large-scale structures in the respective blocking regions; they tend to closely reflect the structures of the developing blocks. The time evolution in the tangent linear model of finite-time adjoint modes has been examined for each of the three cases of block development. These adjoint modes have faster than normal mode exponential growth. The initial structures of the dominant adjoint modes are characterized by small-scale baroclinic wave trains located primarily upstream of the blocking region. As the disturbances grow explosively, they increase their scale and propagate eastward into the blocking region where, within a few days, they take up large-scale structures similar to the respective fastest growing finite-time normal modes. The structures and time evolution of maximum sensitivity perturbations during blocking have been analyzed. Dominant normal mode structures focused in the blocking regions have been chosen as weight functions in response functions measuring forecast sensitivity. The maximum sensitivity perturbations are found to be very similar to respective finite-time adjoint modes in their structures and time developments. It is suggested that, during periods of rapid regime transition, the error structure at the end of a 2–4-day period of weather prediction is likely to resemble the dominant finite-time normal modes for the period in question.},
	number = {9},
	urldate = {2017-11-01},
	journal = {Journal of the Atmospheric Sciences},
	author = {Frederiksen, Jorgen S.},
	month = may,
	year = {1997},
	pages = {1144--1165}
}

@article{kistler_ncepncar_2001,
	title = {The {NCEP}–{NCAR} 50–year reanalysis: {Monthly} means {CD}–{ROM} and documentation},
	volume = {82},
	shorttitle = {The {NCEP}–{NCAR} 50–year reanalysis},
	number = {2},
	journal = {Bulletin of the American Meteorological society},
	author = {Kistler, Robert and Collins, William and Saha, Suranjana and White, Glenn and Woollen, John and Kalnay, Eugenia and Chelliah, Muthuvel and Ebisuzaki, Wesley and Kanamitsu, Masao and Kousky, Vernon},
	year = {2001},
	pages = {247--267}
}

@phdthesis{kistler_study_1974,
	title = {A study of data assimilation techniques in an autobarotropic, primitive equation, channel model},
	school = {Pennsylvania State University},
	author = {Kistler, Robert Edward},
	year = {1974}
}

@article{fox-rabinovitz_finite-difference_1997,
	title = {A {Finite}-{Difference} {GCM} {Dynamical} {Core} with a {Variable}-{Resolution} {Stretched} {Grid}},
	volume = {125},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1997)125%3C2943:AFDGDC%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1997)125<2943:AFDGDC>2.0.CO;2},
	abstract = {A finite-difference atmospheric model dynamics, or dynamical core using variable resolution, or stretched grids, is developed and used for regional–global medium-term and long-term integrations. The goal of the study is to verify whether using a variable-resolution dynamical core allows us to represent adequately the regional scales over the area of interest (and its vicinity). In other words, it is shown that a significant downscaling is taking place over the area of interest, due to better-resolved regional fields and boundary forcings. It is true not only for short-term integrations, but also for medium-term and, most importantly, long-term integrations. Numerical experiments are performed with a stretched grid version of the dynamical core of the Goddard Earth Observing System (GEOS) general circulation model (GCM). The dynamical core includes the discrete (finite-difference) model dynamics and a Newtonian-type rhs zonal forcing, which is symmetric for both hemispheres about the equator. A flexible, portable global stretched grid design allows one to allocate the area of interest with uniform fine-horizontal (latitude by longitude) resolution over any part of the globe, such as the U.S. territory used in these experiments. Outside the region, grid intervals increase, or stretch, with latitude and longitude. The grids with moderate to large total (global) stretching factors or ratios of maximum to minimum grid intervals on the sphere are considered. Dynamical core versions with the total stretching factors ranging from 4 to 32 are used. The model numerical scheme, with all its desirable conservation and other properties, is kept unchanged when using stretched grids. Two model basic horizontal filtering techniques, the polar or high-latitude Fourier filter and the Shapiro filter, are applied to stretched grid fields. Two filtering approaches based on the projection of a stretched grid onto a uniform one are tested. One of them does not provide the necessary computational noise control globally. Another approach provides a workable monotonic global solution. The latter is used within the developed stretched grid version of the GEOS GCM dynamical core that can be run in both the middle-range and long-term modes. This filtering approach allows one to use even large stretching factors. The successful experiments were performed with the dynamical core for several stretched grid versions with moderate to large total stretching factors ranging from 4 to 32. For these versions, the fine resolutions (in degrees) used over the area of interest are 2 × 2.5, 1 × 1.25, 0.5 × 0.625, and 0.25 × 0.3125. Outside the area of interest, grid intervals are stretching to 4 × 5 or 8 × 10. The medium-range 10-day integrations with summer climate initial conditions show a pronounced similarity of synoptic patterns overthe area of interest and its vicinity when using a stretched grid or a control global uniform fine-resolution grid. For a long-term benchmark integration performed with the first aforementioned grid, the annual mean circulation characteristics obtained with the stretched grid dynamical core appeared to be profoundly similar to those of the control run with the global uniform fine-resolution grid over the area of interest, or the United States. The similarity is also evident over the best resolved within the used stretched grid northwestern quadrant, whereas it does not take place over the least-resolved southeastern quadrant. In the better-resolved Northern Hemisphere, the jet and Hadley cell are close to those of the control run, which does not take place for the Southern Hemisphere with coarser variable resolution. The stretched grid dynamical core integrations have shown no negative computational effects accumulating in time. The major result of the study is that a stretched grid approach allows one to take advantage of enhanced resolution over the region of interest. It provides a better representation of regional fields for both medium-term and long-term integrations. The developed stretched grid model dynamics is supposed to be the first stage of the development of the full diabatic stretched grid GEOS GCM. It will be implemented, within a portable stretched grid approach, for various regional studies with a consistent representation of interactions between global and regional scales and phenomena.},
	number = {11},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Fox-Rabinovitz, Michael S. and Stenchikov, Georgiy L. and Suarez, Max J. and Takacs, Lawrence L.},
	month = nov,
	year = {1997},
	pages = {2943--2968}
}

@inproceedings{fletcher_computational_1988,
	title = {Computational techniques for fluid dynamics. {Volume} 1-{Fundamental} and general techniques.},
	volume = {1},
	booktitle = {Springer-{Verlag}},
	author = {Fletcher, Clive AJ},
	year = {1988},
	pages = {409}
}

@article{kimoto_ocean_1997,
	title = {An {Ocean} {Data} {Assimilation} {System} for {Climate} {Monitoring} ({gtSpecial} {IssueltData} {Assimilation} in {Meteology} and {Oceanography}: {Theory} and {Practice})},
	volume = {75},
	shorttitle = {An {Ocean} {Data} {Assimilation} {System} for {Climate} {Monitoring} ({gtSpecial} {IssueltData} {Assimilation} in {Meteology} and {Oceanography}},
	doi = {10.2151/jmsj1965.75.1B_471},
	abstract = {An ocean data assimilation system developed for climate monitoring at the Japan Meteorological Agency (JMA) is described. The system consists of an ocean general circulation model (OGCM) and a subsurface temperature analysis scheme using optimal interpolation. The analyzed temperatures are continuously assimilated into the wind-driven OGCM. The atmospheric forcing is obtained from the operational numerical weather prediction system. The dynamical ocean model helps synthesize information in the forcing and data, neither of which is complete for analyzing subsurface structures. The temporary and spatially continuous estimates given by the system aid the operational long-range forecasters to monitor climatically important phenomena such as El Nino-Southern Oscillation more closely on intraseasonal to interannual time scales. The introduction of temperature data significantly improves the quality of the wind-forced simulation of subsurface thermal fields. However, the model's inability to reproduce the Equatorial Undercurrent with sufficient strength appears to limit the impact of data on the current field. Improvements in the model and in the data assimilation scheme and introduction of other types of observational data are required for further development of the system.},
	number = {1B},
	journal = {Journal of the Meteorological Society of Japan. Ser. II},
	author = {Kimoto, Masahide and Yoshikawa, Ikuo and Ishii, Masayoshi},
	year = {1997},
	pages = {471--487}
}

@book{trenberth_climate_1992,
	title = {Climate {System} {Modeling}},
	isbn = {978-0-521-43231-3},
	abstract = {"It is widely recognized that human activities are transforming the global environment. What will be the changes in climate caused by anthropogenic influences and how do these compare with natural variations? To address these questions there is an urgent need to understand and model the global climate system effectively. A central role of climate system models will be to help determine possible impacts and help guide possible future policies. First published in 1992, Climate System Modeling provides a thorough grounding in climate dynamics and the issues involved in predicting climate change. It not only discusses the primary concepts involved but also the mathematical, physical, chemical and biological basis for the component models and the sources of uncertainty, the assumptions made and the approximations introduced. Climate system models go beyond climate models to include all aspects of the climate system: the atmosphere, the ocean, the cryosphere (including snow, sea ice, and glaciers), the biosphere and terrestrial ecosystems, other land surface processes and additional parts of the hydrosphere including rivers, and all the complex interactions between these components. The biogeochemical cycles in both the atmosphere and the ocean are dealt with in detail, potentially allowing the carbon cycle, for instance, to be treated with some veracity. Instead of projecting and specifying what future atmospheric concentrations of carbon dioxide and methane might be, the goal of these models is to deal comprehensively with the carbon cycle and predict the future evolution of greenhouse gas concentrations, as well as the impact of those changes on the physical climate."--Publisher's description.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Trenberth, Kevin E.},
	year = {1992},
	note = {Google-Books-ID: EDClFW7JWrQC},
	keywords = {Mathematics / Applied, Science / Earth Sciences / Meteorology \& Climatology, Computers / Computer Science}
}

@article{fjortoft_changes_1953,
	title = {On the changes in the spectral distribution of kinetic energy for twodimensional, nondivergent flow},
	volume = {5},
	number = {3},
	journal = {Tellus},
	author = {Fjørtoft, Ragnar},
	year = {1953},
	pages = {225--230}
}

@article{morton_iterative_1995,
	title = {Iterative methods for linear and nonlinear equations},
	journal = {SIAM, Philadelphia},
	author = {Morton, K. and Mayers, D.},
	year = {1995},
	pages = {166}
}

@article{fjortoft_numerical_1952,
	title = {On a {Numerical} {Method} of {Integrating} the {Barotropic} {Vorticity} {Equation}},
	volume = {4},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.2153-3490.1952.tb01003.x/full},
	urldate = {2017-11-01},
	journal = {Tellus},
	author = {FJØRTOFT, R},
	year = {1952},
	pages = {179--194}
}

@article{kasahara_nonlinear_1982,
	title = {Nonlinear normal mode initialization and the bounded derivative method},
	volume = {20},
	issn = {1944-9208},
	url = {http://onlinelibrary.wiley.com/doi/10.1029/RG020i003p00385/abstract},
	doi = {10.1029/RG020i003p00385},
	abstract = {Recently, two new approaches have been proposed for the initialization of primitive equation models. One is called the nonlinear normal mode procedure, developed by Baer and Machenhauer. It is suitable for a global primitive equation model in which the construction of the model normal modes is feasible. The other approach is called the bounded derivative method, proposed by Kreiss. It can be applicable to both pure initial value and initial boundary value problems. Leith established a connection between the nonlinear normal mode procedure and the classical balancing based on quasi-geostrophic theory. The purpose of this paper is to compare the three procedures of initialization for a baroclinic primitive equation model with beta plane geometry in pressure coordinates. To the degree of approximation employed, the initialization by the bounded derivative method agrees with the classical balance procedure with quasi-geostrophic assumptions. We demonstrate for the same prediction model that nonlinear normal mode balancing leads to an initialization scheme identical to the one derived from the bounded derivative method within the degree of approximations. Since both new approaches to initialization are more general than the classical procedures, the connection of the two approaches with the quasi-geostrophic formulation will enhance our understanding of the dynamics of large-scale motions beyond the classical quasi-geostrophic theory.},
	language = {en},
	number = {3},
	urldate = {2017-11-01},
	journal = {Reviews of Geophysics},
	author = {Kasahara, Akira},
	month = aug,
	year = {1982},
	keywords = {3319 General circulation, 3384 Acoustic-gravity waves, 3399 General or miscellaneous},
	pages = {385--397}
}

@article{charnock_wind_1955,
	title = {Wind stress on a water surface},
	volume = {81},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49708135027/abstract},
	doi = {10.1002/qj.49708135027},
	abstract = {The vertical distribution of horizontal mean wind in the lowest 8 metres over a reservoir (1·6 km × 1 km) has been measured using sensitive anemometers freely exposed from a fixed mast in water 16 m deep, the fetch being more than 1 km. The resulting profiles are closely logarithmic, the small differences being systematic and possibly due to the thermal instability which existed when the measurements were made. The usual law for wind profiles in neutral stability is {\textbackslash}documentclass\{article\}{\textbackslash}pagestyle\{empty\}{\textbackslash}begin\{document\}\$\$ {\textbackslash}frac\{u\}\{\{u\_* \}\}{\textbackslash}; = {\textbackslash};{\textbackslash}frac\{1\}\{k\}{\textbackslash};{\textbackslash}log {\textbackslash};{\textbackslash}frac\{z\}\{\{z(0)\}\} \$\${\textbackslash}end\{document\} where u is the wind speed at height z, k is von Kármán's constant, log z (0) the intercept on the log z axis, and u* the so-called friction velocity defined by τ0 = pu *2, τ0 being the surface drag and rH the density of the air. To characterize the profiles u*/k, their slope, was plotted in relation to z (0), their intercept; this allowed a direct comparison with other profiles, in particular those recently measured in a laboratory channel by Sibul. The agreement was better than expected and indicated that z (0) was comparatively independent of fetch and stability but was largely determined by u*. The relation between u* and z (0) agreed roughly with the simplest non-dimensional relation between them, gz (0)/u *2 = constant, so that one is led to a generalized wind profile for flow over a water surface {\textbackslash}documentclass\{article\}{\textbackslash}pagestyle\{empty\}{\textbackslash}begin\{document\}\$\$ {\textbackslash}frac\{u\}\{\{u\_* \}\}{\textbackslash}; = {\textbackslash};{\textbackslash}frac\{1\}\{k\}{\textbackslash};{\textbackslash}log {\textbackslash};{\textbackslash}frac\{\{gz\}\}\{\{u\_* {\textasciicircum}2 \}\}{\textbackslash}; + {\textbackslash};\{{\textbackslash}rm constant\} \$\${\textbackslash}end\{document\} which specifies the drag, given the wind at one known height. An approximate value of the constant is 12·5. This expression can be compared with earlier work. The better wind-profile observations show rough agreement; the experimental scatter is necessarily large since a water surface is aerodynamically much smoother than most land surfaces, precision anemometry in difficult circumstances being required to provide sufficiently precise values. Oceanographic measurements of the tilt of water surfaces are in fair agreement at high wind speeds but at low wind speeds the data are conflicting. The early results which imply that the drag-coefficient (u *2/u2) increases with decreasing wind speed in light winds are thought to be in error; some support for this belief comes from recent estimates of drag using a modified ageostrophic technique, which agree roughly among themselves and with the general expression.},
	language = {en},
	number = {350},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Charnock, H.},
	month = oct,
	year = {1955},
	pages = {639--640}
}

@article{fischer_giotto:_2000,
	title = {{GIOTTO}: {A} coupled atmosphere-ocean general-circulation model: {The} tropical {Pacific}},
	volume = {126},
	issn = {1477-870X},
	shorttitle = {{GIOTTO}},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49712656702/abstract},
	doi = {10.1002/qj.49712656702},
	abstract = {A new coupled general-circulation model (GIOTTO) has been developed. The individual components are composed of the atmosphere model, ECHAM-4, and the ocean model, MOM (Modular Ocean Model)-1.2. The model domain is global, and no flux correction is applied. The coupling is active between 60°N and 60° S. Poleward of 60° the atmosphere is forced by the climatological sea surface temperature (SST), and the ocean is relaxed towards the climatological SST and sea surface salinity. Further, the sea-ice coverage is prescribed. The coupling interval is set to two hours to resolve the diurnal cycle. In this paper we describe the design of the model, and discuss results of a coupled 20-year integration. The representation of the mean state is realistic, although there is an overall cold SST bias of about one degree centigrade in the tropics, and a tendency to simulate a double Inter Tropical Convergence Zone. The annual cycle, as simulated in the equatorial Pacific, is too weak in the east Pacific and too strong in the warm-pool region. The phase, however, is well captured. The SST variability in the equatorial Pacific is underestimated by about 30\%, and the anomalies are too confined to the equator. The main features of El Niño-Southern Oscillation (ENSO) dynamics, like propagation of heat-content anomalies, reflection of equatorial Kelvin and Rossby waves, and westerly wind bursts, however, are correctly represented by the model. A variability analysis based on empirical orthogonal functions indicates that the ENSO mechanisms are simulated correctly. The model also appears to be well balanced with a remarkably low SST drift (0.5 degC decade−1), and a realistic equatorial thermal structure. We are, therefore, confident that the model can be used for experimental seasonal predictions.},
	language = {en},
	number = {567},
	urldate = {2017-11-01},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Fischer, Martin and Navarra, Antonio},
	month = jul,
	year = {2000},
	keywords = {Numerical modelling, Sesonal forecasting},
	pages = {1991--2012}
}

@incollection{kaplan_chaotic_1979,
	title = {Chaotic behavior of multidimensional difference equations},
	booktitle = {Functional differential equations and approximation of fixed points},
	publisher = {Springer},
	author = {Kaplan, James L. and Yorke, James A.},
	year = {1979},
	pages = {204--227}
}

@techreport{fisher_estimating_1995,
	title = {Estimating the covariance matrices of analysis and forecast error in variational data assimilation},
	institution = {European Centre for Medium-Range Weather Forecasts},
	author = {Fisher, Michael and Courtier, Philippe},
	year = {1995}
}

@inproceedings{kalnay_forecasting_1989,
	title = {Forecasting forecast skill in the {Southern} {Hemisphere}},
	booktitle = {Preprints of the 3rd {International} {Conference} on {Southern} {Hemisphere} {Meteorology} and {Oceanography}, {Buenos} {Aires}},
	author = {Kalnay, E. and Ham, M.},
	year = {1989},
	pages = {13--17}
}

@inproceedings{kalnay_breeding_1996,
	title = {The breeding method},
	volume = {1},
	booktitle = {Proceedings 1995 {ECMWF} {Seminar} on {Predictability}},
	author = {Kalnay, E. and Toth, Z.},
	year = {1996},
	pages = {69--82}
}

@article{fillion_variational_1989,
	title = {Variational {Implicit} {Normal} {Mode} {Initialization}},
	volume = {117},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1989)117%3C2219%3AVINMI%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1989)117<2219:VINMI>2.0.CO;2},
	abstract = {It is shown that implicit normal mode initialization can be combined with a variational technique, in order to control the relative magnitudes of the changes to the analyzed mass and wind fields. Since the initialization procedure is expressed entirely in physical space, the use of locally varying weights in the variational integral becomes more straightforward than in previous efforts to combine variational methods with normal mode initialization. We present details of the application to a finite-element model of the shallow water equations on a stereographic projection. It is demonstrated that the use of variational initialization can change the slowly evolving component of the subsequent forecast, as well as eliminate the unrealistic fast component.},
	number = {10},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Fillion, Luc and Temperton, Clive},
	month = oct,
	year = {1989},
	pages = {2219--2229}
}

@article{ferranti_tropical-extratropical_1989,
	title = {Tropical-{Extratropical} {Interaction} {Associated} with the 30–60 {Day} {Oscillation} and {Its} {Impact} on {Medium} and {Extended} {Range} {Prediction}},
	volume = {47},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1990)047%3C2177:TEIAWT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1990)047<2177:TEIAWT>2.0.CO;2},
	abstract = {An observational and modeling study is made of tropical-extratropical interactions on time scales relevant to medium and extended range forecasting. First, an empirical orthogonal function (EOF) analysis is made of outgoing longwave radiation (OLR) in the tropics over seven winters. Having removed the seasonal cycle and interannual variability, the two leading EOFs describe the 30–60 day oscillation. A composite of extratropical 500 mb geopotential height correlated simultaneously with this mode of tropical variability is constructed. In its two phase-quadrature components, this composite has significant projection onto the Pacific/North American teleconnection pattern and onto the North Atlantic oscillation pattern, respectively. The 500 mb height composite is compared with the Simmons, Wallace and Branstator (SWB) mode of barotropic instability, which has similar periodicity and similar spatial structure in both its phase-quadrature components. A simple theoretical analysis shows that the SWB mode can be strongly excited by a periodic forcing in the tropics whose spatial structure resembles the oscillation in convective activity described by the first two EOFs of OLR. This is confirmed in a barotropic model integration, which is forced using the observed EOFs of OLR. The model response in the extratropics compares well with the observed composite oscillation in 500 mb height. In the final phase of this study, the ECMWF model has been integrated over four wintertime 20-day periods. For each period, five integrations have been performed; a control forecast, an integration in which the tropics are relaxed towards the verifying analysis, an integration in which the tropics are relaxed towards the initial analysis, an integration in which the extratropics are relaxed towards the verifying analysis and finally an integration in which the extratropics are relaxed towards the initial analysis. The four initial dates were chosen on the basis that in the succeeding 20 days, observed OLR and extratropical height provided a reasonable realization of each separate quarter of the composite oscillation. It was found that in the extratropics, skill scores in the range of 11–20 days were noticeably improved, particularly over the Pacific/North American region (consistent with expectations from the data analysis). The mean geopotential height error in the extratropics; i.e., the error averaged over the four experiments, was also reduced (mainly in the Pacific area) when the model tropical fields were relaxed towards the verifying analysis. Indeed, maps showing the time evolution of geopotential height from the first 5 days of the forecast were generally correlated with the differences between the integrations with tropics relaxed to the verifying analysis and to the initial analysis indicating a link between tropical and extratropical low-frequency variability. The impact of the extratropics on the tropics was also studied where it was shown that the largest response was on the nondivergent component of the wind over the tropical east Pacific. Tropical skill scores and model systematic error in upper tropospheric streamfunction were significantly improved with the extratropics relaxed to the verifying analysis. By contrast, extratropical relaxation had a much smaller impact on the divergent component of the tropical wind.},
	number = {18},
	urldate = {2017-11-01},
	journal = {Journal of the Atmospheric Sciences},
	author = {Ferranti, L. and Palmer, T. N. and Molteni, F. and Klinker, E.},
	month = sep,
	year = {1989},
	pages = {2177--2199}
}

@article{farrell_optimal_1988,
	title = {Optimal {Excitation} of {Neutral} {Rossby} {Waves}},
	volume = {45},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1988)045%3C0163%3AOEONRW%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1988)045<0163:OEONRW>2.0.CO;2},
	abstract = {Properly configured disturbances are known to be effective in transferring the kinetic energy of a mean shear flow to neutrally stable modal and nonmodal waves. Consideration of perturbation energetics requires that such disturbances produce down-gradient momentum fluxes which are associated with perturbation phase lines oriented against the mean shear. Initial conditions chosen arbitrarily, except that they satisfy this requirement, have been shown to result in robust excitation of neutral waves. A question naturally arising from such studies is whether there exists, in some well-defined sense, a best or most effective choice of initial conditions which optimally excites the waves. This question is addressed as a variational problem, and examples of optimal initial conditions are identified for the barotropic β-plane channel. These examples include the most effective excitation of a given neutral Rossby mode and the most rapidly growing perturbation for a given time period without restriction on spectra composition.},
	number = {2},
	urldate = {2017-11-01},
	journal = {Journal of the Atmospheric Sciences},
	author = {Farrell, Brian},
	month = jan,
	year = {1988},
	pages = {163--172}
}

@article{falkovich_new_2000,
	title = {A new methodology of rainfall retrievals from indirect measurements},
	volume = {75},
	issn = {0177-7971, 1436-5065},
	url = {https://link.springer.com/article/10.1007/s007030070005},
	doi = {10.1007/s007030070005},
	abstract = {Summary A new methodology for rainfall retrievals from indirect measurements is proposed and illustrated using IR brightness temperature and radar rainfall observations collected during TOGA-COARE. Since (1) rain rate has a mixed distribution with a delta-function for a zero rain and lognormal distribution for nonzero and (2) the least squares method which is used to calculate regression coefficients gives a priori consistent estimates only for normally distributed data, it is proposed to convert the rain rate to a normally distributed set and only after that to develop a retrieval method and estimate the skill of this method. Consideration of the physics of clouds and cloud ensembles, the goal to minimize errors in the radar data, and the desire to remove the influence of cirrus clouds lead us to use: a) minimum of IR brightness temperatures over a 1° × 1° area and a 3 hour interval as a predictor, and b) radar rainfall, averaged over 3 hours over a 1° × 1° area, with the radar in its center, as the truth. Results using the TOGA-COARE data show that the correlation of the rain rate transformed to normal distribution is significantly higher with minimum temperature than with the fraction of area covered by high clouds. The sizes of heavy rainfall areas obtained using the new methodology are reasonable. The regression coefficients should change with latitude, season and location. Taken together, the results indicate that it is possible, in principle, to retrieve rainfall from IR satellite observations and obtain reliable rainfall data. To realize this goal it is necessary to process radar and IR data using the new methodology for different latitudes, seasons, over land and ocean.},
	language = {en},
	number = {3-4},
	urldate = {2017-11-01},
	journal = {Meteorology and Atmospheric Physics},
	author = {Falkovich, A. and Lord, S. and Treadon, R.},
	month = dec,
	year = {2000},
	pages = {217--232}
}

@article{evensen_assimilation_1996,
	title = {Assimilation of {Geosat} {Altimeter} {Data} for the {Agulhas} {Current} {Using} the {Ensemble} {Kalman} {Filter} with a {Quasigeostrophic} {Model}},
	volume = {124},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1996)124%3C0085:AOGADF%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1996)124<0085:AOGADF>2.0.CO;2},
	abstract = {The ring-shedding process in the Agulhas Current is studied using the ensemble Kalman filter to assimilate Geosat altimeter data into a two-layer quasigeostrophic ocean model. The properties of the ensemble Kalman filter are further explored with focus on the analysis scheme and the use of gridded data. The Geosat data consist of 10 fields of gridded sea surface height anomalies separated 10 days apart that are added to a climatic mean field. This corresponds to a huge number of data values, and a data reduction scheme must be applied to increase the efficiency of the analysis procedure. Further, it is illustrated how one can resolve the rank problem occurring when a too large dataset or a small ensemble is used.},
	number = {1},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Evensen, Geir and van Leeuwen, Peter Jan},
	month = jan,
	year = {1996},
	pages = {85--96}
}

@article{ertel_neuer_1942,
	title = {Ein neuer hydrodynamischer {Wirbelsatz}},
	volume = {59},
	journal = {Meteorol. Z.},
	author = {Ertel, H},
	year = {1942},
	pages = {277--281}
}

@article{errico_notes_1999,
	title = {Notes on the appropriateness of “bred modes” for generating initial perturbations used in ensemble prediction},
	volume = {51},
	issn = {null},
	url = {http://dx.doi.org/10.3402/tellusa.v51i3.13519},
	doi = {10.3402/tellusa.v51i3.13519},
	abstract = {Papers by Szunyogh and co-workers and Iyengar and co-workers, among others, claim that “bred growing vectors” (BGVs) are appropriate for generating initial perturbations for applicationto ensemble weather prediction. The theoretical bases for this claim are purported relationshipsbetween the bred vectors and what are called local Lyapunov vectors (LLVs). Severalstatements in these papers are inaccurate, however, regarding: the properties of LLVs in contrastto those of singular vectors; the relationship between LLVs and BGVs; the relationship betweenBGVs and analysis errors; the relationship between singular vectors and dynamic imbalances;and the adequacy of very low-resolution models to characterize singular vectors of models usedfor numerical weather prediction. These inaccuracies and their implications for the use of BGVsin ensemble weather prediction are discussed here.},
	number = {3},
	urldate = {2017-11-01},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Errico, Ronald M. and Langland, Rolf},
	month = jan,
	year = {1999},
	pages = {431--441}
}

@article{engquist_radiation_1979,
	title = {Radiation boundary conditions for acoustic and elastic wave calculations},
	volume = {32},
	issn = {1097-0312},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/cpa.3160320303/abstract},
	doi = {10.1002/cpa.3160320303},
	language = {en},
	number = {3},
	urldate = {2017-11-01},
	journal = {Communications on Pure and Applied Mathematics},
	author = {Engquist, Bjorn and Majda, Andrew},
	month = may,
	year = {1979},
	pages = {313--357}
}

@misc{noauthor_radiation_nodate,
	title = {Radiation boundary conditions for acoustic and elastic wave calculations - {Engquist} - 1979 - {Communications} on {Pure} and {Applied} {Mathematics} - {Wiley} {Online} {Library}},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/cpa.3160320303/full},
	urldate = {2017-11-01}
}

@techreport{kallberg_test_1977,
	title = {Test of a boundary relaxation scheme in a barotropic model, {ECMWF} {Res}},
	institution = {Dept Internal Report},
	author = {Kallberg, Per},
	year = {1977},
	pages = {21}
}

@incollection{niiler_chapter_1992,
	address = {Cambridge, UK},
	title = {Chapter 4: {The} ocean circulation},
	isbn = {978-0-521-43231-3},
	language = {en},
	booktitle = {Climate {System} {Modeling}},
	publisher = {Cambridge University Press},
	author = {Niiler, Pearn P.},
	editor = {Trenberth, Kevin E.},
	year = {1992},
	note = {Google-Books-ID: EDClFW7JWrQC},
	keywords = {Mathematics / Applied, Science / Earth Sciences / Meteorology \& Climatology, Computers / Computer Science}
}

@article{janjic_step-mountain_1990,
	title = {The {Step}-{Mountain} {Coordinate}: {Physical} {Package}},
	volume = {118},
	issn = {0027-0644},
	shorttitle = {The {Step}-{Mountain} {Coordinate}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1990)118%3C1429:TSMCPP%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1990)118<1429:TSMCPP>2.0.CO;2},
	abstract = {A comprehensive physical package has been developed for a regional eta coordinate model with the steplike mountain representation. This paper describes the basic problems, concepts and numerical techniques developed, and reviews primarily those aspects of the performance of the model which reflect the effects of the parameterized physical processes. The Level 2.5 turbulence closure model in the Mellor-Yamada hierarchy was chosen to represent the turbulence above the surface layer. A severe instability encountered in the early experiments in the turbulent kinetic energy (TKF) equation was found to be of a numerical origin. The instability was removed by a suitably designed time-differencing scheme. As implemented in the eta-coordinate model, the Level 2.5 turbulence closure model is computationally remarkably inexpensive. An unconditionally stable, trivially implicit, time-differencing scheme is proposed for the vertical diffusion. The Mellor-Yamada Level 2 turbulence closure scheme is used for the surface layer. For additional flexibility, a shallow logarithmic, dynamical turbulence layer, is introduced at the bottom of the Level 2 surface layer. A rather conventional formulation has been chosen for the ground surface processes and surface hydrology. The nonlinear fourth order lateral diffusion scheme was implemented in the model. The diffusion coefficient depends on deformation and TKE. The ratio of the horizontal turbulent coefficients for momentum and heat was estimated. The divergence damping is used as another mechanism for maintaining the smoothness of prognostic fields and/or accelerating the geostrophic adjustment. The Betts and Miller approach has been adopted for deep and shallow cumulus convection. The formulation of the large-scale condensation is rather conventional, and includes the evaporation of precipitating water in the unsaturated layers below the condensation level. A review of the available results of numerical experiments suggests that the eta model is competitive with other sophisticated models using similar resolutions, and requiring similar computational effort. Thus, it is believed that the viability of the eta coordinate step-mountain approach in grid point models has been finally demonstrated.},
	number = {7},
	urldate = {2017-10-19},
	journal = {Monthly Weather Review},
	author = {Janjić, Zaviša I.},
	month = jul,
	year = {1990},
	pages = {1429--1443}
}

@book{howcroft_local_1971,
	address = {Camp Spring, MD, USA},
	title = {Local {Forecast} {Model}, {Present} {Status} and {Preliminary} {Verification}},
	publisher = {US Department of Commerce, National Oceanic and Atmospheric Administration, National Weather Service, National Meteorological Center},
	author = {Howcroft, James G.},
	year = {1971}
}

@article{houtekamer_system_1996,
	title = {A {System} {Simulation} {Approach} to {Ensemble} {Prediction}},
	volume = {124},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1996)124%3C1225:ASSATE%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1996)124<1225:ASSATE>2.0.CO;2},
	abstract = {For many aspects of numerical weather prediction it is important to have good error statistics. Here one can think of applications as diverse as data assimilation, model improvement, and medium-range forecasting. In this paper, a method for producing these statistics from a representative ensemble of forecast states at the appropriate forecast time is proposed and examined. To generate the ensemble, an attempt is made to simulate the process of error growth in a forecast model. For different ensemble members the uncertain elements of the forecasts are perturbed in different ways. First the authors attempt to obtain representative initial perturbations. For each perturbation, an independent 6-h assimilation cycle is performed. For this the available observations are randomly perturbed. The perturbed observations are input to the statistical interpolation assimilation scheme, giving a perturbed analysis. This analysis is integrated for 6 h with a perturbed version of the T63 forecast model, using perturbed surface fields, to obtain a perturbed first guess for the next assimilation. After cycling for 4 days it was found that the ensemble statistics have become stable. To obtain perturbations to the model, different model options for the parameterization of horizontal diffusion, deep convection, radiation, gravity wave drag, and orography were selected. As part of the forecast error is due to model deficiencies, perturbing the model will lead to an improved ensemble forecast. This also creates the opportunity to use the ensemble forecast for model sensitivity experiments. It is observed that the response, after several assimilation cycles, to the applied perturbations is strongly nonlinear. This fact makes it difficult to motivate the use of opposite initial perturbations. The spread in the ensemble of first-guess fields is validated against statistics available from the operational data assimilation scheme. It is seen that the spread in the ensemble is too small. Apparently, the simulation of the error sources is incomplete. In particular, we might have to generate less conventional perturbations to the model.},
	number = {6},
	urldate = {2017-10-19},
	journal = {Monthly Weather Review},
	author = {Houtekamer, P. L. and Lefaivre, Louis and Derome, Jacques and Ritchie, Harold and Mitchell, Herschel L.},
	month = jun,
	year = {1996},
	pages = {1225--1242}
}

@article{houtekamer_prediction_1994,
	title = {Prediction {Experiments} with {Two}-{Member} {Ensembles}},
	volume = {122},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1994)122%3C2179%3APEWTME%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1994)122<2179:PEWTME>2.0.CO;2},
	abstract = {Numerical experiments have been performed to determine whether it is possible to improve the quality of atmospheric forecasts by using the average of two predictions starting from slightly perturbed initial conditions. The predictions are made with a T21 quasi-nondivergent three-level model and a “perfect model” approach is used, so that all prediction errors are due to the uncertainty in the initial conditions. The two perturbed predictions are initialized by adding to and subtracting from the control initial state a small-amplitude disturbance called a “bred” mode, obtained as the fastest-growing small-amplitude perturbation of the model over a 20-day period preceding the beginning of the forecast. The results indicate that for initial states that contain very small analysis errors the two-member ensemble yields a mean forecast of lower quality than the control forecast. For larger-amplitude analysis error fields, however, the ensemble prediction outperforms the control forecast. When a statistical distribution of possible analysis errors is considered, it is found that on average the mean of the two perturbed predictions is of higher quality than the control forecast. The study has also shown that the spread between the two perturbed predictions is correlated with the magnitude of the forecast error for every day of the forecast period from day 1 to day 10. The same approach has been applied to Lorenz's three-component model and similar results have been obtained.},
	number = {9},
	urldate = {2017-10-19},
	journal = {Monthly Weather Review},
	author = {Houtekamer, P. L. and Derome, Jacques},
	month = sep,
	year = {1994},
	pages = {2179--2191}
}

@book{houghton_remote_1986,
	title = {Remote {Sounding} of {Atmospheres}},
	isbn = {978-0-521-31065-9},
	abstract = {When this book was first published in 1984, the technique of remote sounding was growing rapidly in importance as a means for studying the structure, climate and weather of the atmospheres of the Earth and planets. Measurements from Earth satellites and interplanetary spacecraft proved particularly useful because they allowed good coverage of atmospheric systems in space and time, often with high resolution. This book describes how measurements can be made of the properties of the Earth and planets using this method. It includes descriptions of the scientific principles, technical implementation, mathematical methods for analysing the measurements, a history of measurements that have been made and discussions of the phenomena that have been discovered and studied using remote sounding. The technique is important for meteorology, climatology and an understanding of humankind's impact on the Earth's atmosphere.},
	language = {en},
	publisher = {CUP Archive},
	author = {Houghton, John Theodore and Taylor, F. W. and Rodgers, C. D.},
	month = mar,
	year = {1986},
	note = {Google-Books-ID: SSY4AAAAIAAJ},
	keywords = {Science / Earth Sciences / Meteorology \& Climatology}
}

@article{hough_application_1898,
	title = {On the application of harmonic analysis to the dynamical theory of the tides. {Part} {II}: {On} the general integration of {Laplace}'s dynamical equations},
	volume = {191},
	shorttitle = {On the application of harmonic analysis to the dynamical theory of the tides. {Part} {II}},
	journal = {Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character},
	author = {Hough, Sydney Samuel},
	year = {1898},
	pages = {139--185}
}

@article{hough_application_1897,
	title = {On the {Application} of {Harmonic} {Analysis} to the {Dynamical} {Theory} of the {Tides}. {Part} {I}. {On} {Laplace}'s' {Oscillations} of the {First} {Species},'and on the {Dynamics} of {Ocean} {Currents}.},
	volume = {61},
	number = {369-377},
	journal = {Proceedings of the Royal Society of London},
	author = {Hough, Sydney Samuel},
	year = {1897},
	pages = {236--238}
}

@article{hou_objective_2001,
	title = {Objective {Verification} of the {SAMEX} ’98 {Ensemble} {Forecasts}},
	volume = {129},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(2001)129%3C0073%3AOVOTSE%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(2001)129<0073:OVOTSE>2.0.CO;2},
	abstract = {During May 1998, the Center for Analysis and Prediction of Storms (CAPS) at the University of Oklahoma coordinated a multi-institution numerical forecast project known as the Storm and Mesoscale Ensemble Experiment (SAMEX). SAMEX involved, for the first time, the real-time operation of four different ensembles of mesoscale models over the same region of the United States. The main purpose of this paper is the evaluation of the ensemble forecasts, performed at a relatively coarse resolution of 30 km. An additional SAMEX goal not discussed here is to compare the value of the ensemble forecasts against single forecasts made over smaller subregions of the Great Plains at both intermediate (10 km) and high (3 km) resolution. The SAMEX ’98 ensembles consisted of a single 36-h control forecast from the ARPS (at CAPS), the Penn State–NCAR fifth-generation Mesoscale Model (at NSSL), and the Eta Model and Regional Spectral Model (at NCEP), all with horizontal resolutions of approximately 30 km, and perturbed runs, resulting in a grand ensemble of 25 members. The forecasts of geopotential heights, temperatures, and moisture were verified against the Eta operational analyses, rather than observations. Unlike global ensembles, which tend to be useful in the medium range, the mesoscale SAMEX ensembles provided useful information in the short range. A major result is that the performance of the ensemble of multiple forecast systems is much better than that of each individual ensemble system, probably because it represents more realistically the current uncertainties in both models and initial conditions. A similar advantage from the use of multimodel, multianalysis systems has been observed with global ensembles. The SAMEX results also show that perturbations to model physics parameterizations, as well as the use of consistent perturbations in the boundary conditions, are important for regional ensemble forecasting. Efforts are now under way to compare the ensemble forecasts against those made using higher spatial resolution, and follow-on SAMEX experiments are anticipated in other geographical areas and weather regimes. Although the main results of this paper appear to be very robust, they were based on a small number of cases, and similar experiments carried out during other periods will help to test their significance.},
	number = {1},
	urldate = {2017-10-19},
	journal = {Monthly Weather Review},
	author = {Hou, Dingchen and Kalnay, Eugenia and Droegemeier, Kelvin K.},
	month = jan,
	year = {2001},
	pages = {73--91}
}

@article{hoskins_use_1985,
	title = {On the use and significance of isentropic potential vorticity maps},
	volume = {111},
	number = {470},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Hoskins, Brian J. and McIntyre, M. E. and Robertson, Andrew W.},
	year = {1985},
	pages = {877--946}
}

@article{horel_planetary-scale_1981,
	title = {Planetary-{Scale} {Atmospheric} {Phenomena} {Associated} with the {Southern} {Oscillation}},
	volume = {109},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1981)109%3C0813:PSAPAW%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1981)109<0813:PSAPAW>2.0.CO;2},
	abstract = {Atmospheric phenomena associated with the Southern Oscillation are examined, with emphasis on vertical structure and teleconnections to middle latitudes. This paper is specifically concerned with the interannual variability of seasonal means for the Northern Hemisphere winter during the period 1951–78. Among the variables considered are sea surface temperature in the equatorial Pacific, precipitation at selected equatorial Pacific stations, a “Southern Oscillation Index” of sea level pressure, 200 mb height and tropospheric mean temperature at stations throughout the tropics, and Northern Hemisphere geopotential height fields. Selected statistics derived from surface data also are examined for the period 1910–45. Results are presented in the form of time series and correlation statistics for the variables listed above. Results concerning the relationships between sea surface temperature, sea level pressure and rainfall are consistent with the major conclusions of previous studies by J. Bjerknes and others. Fluctuations in mean tropospheric temperature and 200 mb height are shown to vary simultaneously with equatorial Pacific sea surface temperature fluctuations, not only in the Pacific sector, but at stations throughout the tropics. The zonally symmetric component of these 200 mb height fluctuations is considerably larger than the Southern Oscillation in 1000 mb height, and the corresponding fluctuations in the mean temperature of the tropical troposphere are on the order of nearly 1 K. The correlations between the tropical time series and Northern Hemisphere geopotential height fields exhibit well-defined teleconnection patterns. Warm episodes in equatorial Pacific sea surface temperature tend to be accompanied by below-normal heights in the North Pacific and the south–eastern United States and above-normal heights over western Canada. Recent theoretical work by Opsteegh and Van den Dool (1980), Hoskins and Karoly (1981) and Webster (1981) on Rossby wave propagation on a sphere provides a basis for understanding the teleconnection in terms of the distribution of sea surface temperature and rainfall in the equatorial Pacific. The theory successfully explains several characteristics of the observed teleconnection patterns, including their horizontal scale and shape, their vertical structure and their seasonal dependence.},
	number = {4},
	urldate = {2017-10-19},
	journal = {Monthly Weather Review},
	author = {Horel, John D. and Wallace, John M.},
	month = apr,
	year = {1981},
	pages = {813--829}
}

@article{hong_role_2000,
	title = {Role of sea surface temperature and soil-moisture feedback in the 1998 {Oklahoma}–{Texas} drought},
	volume = {408},
	copyright = {© 2000 Nature Publishing Group},
	issn = {0028-0836},
	url = {http://www.nature.com/nature/journal/v408/n6814/abs/408842a0.html},
	doi = {10.1038/35048548},
	abstract = {The drought that affected the US states of Oklahoma and Texas in the summer of 1998 was strong and persistent, with soil moisture reaching levels comparable to those of the 1930s 'dust bowl'. Although other effects of the record-strength 1997–98 El Niño were successfully predicted over much of the United States, the Oklahoma–Texas drought was not. Whereas the response of the tropical atmosphere to strong anomalies in sea surface temperature is quite predictable, the response of the extratropical atmosphere is more variable. Here we present results from mechanistic experiments to clarify the origin and maintenance of this extratropical climate extreme. In addition to global atmospheric models, we use a regional model to isolate regional climate feedbacks. We conclude that during April and May 1998, sea surface temperature anomalies combined with a favourable atmospheric circulation to establish the drought. In June–August, the regional positive feedback associated with lower evaporation and precipitation contributed substantially to the maintenance of the drought. The drought ended in the autumn, when stronger large-scale weather systems were able to penetrate the region and overwhelm the soil-moisture feedback. Our results show the potential for numerical models including appropriate physical processes to make skilful predictions of regional climate.},
	language = {en},
	number = {6814},
	urldate = {2017-10-19},
	journal = {Nature},
	author = {Hong, Song-You and Kalnay, Eugenia},
	month = dec,
	year = {2000},
	pages = {842--844}
}

@article{hong_nonlocal_1996,
	title = {Nonlocal {Boundary} {Layer} {Vertical} {Diffusion} in a {Medium}-{Range} {Forecast} {Model}},
	volume = {124},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1996)124%3C2322:NBLVDI%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1996)124<2322:NBLVDI>2.0.CO;2},
	abstract = {In this paper, the incorporation of a simple atmospheric boundary layer diffusion scheme into the NCEP Medium-Range Forecast Model is described. A boundary layer diffusion package based on the Troen and Mahrt nonlocal diffusion concept has been tested for possible operational implementation. The results from this approach are compared with those from the local diffusion approach, which is the current operational scheme, and verified against FIFE observations during 9–10 August 1987. The comparisons between local and nonlocal approaches are extended to the forecast for a heavy rain case of 15–17 May 1995. The sensitivity of both the boundary layer development and the precipitation forecast to the tuning parameters in the nonlocal diffusion scheme is also investigated. Special attention is given to the interaction of boundary layer processes with precipitation physics. Some results of parallel runs during August 1995 are also presented.},
	number = {10},
	urldate = {2017-10-19},
	journal = {Monthly Weather Review},
	author = {Hong, Song-You and Pan, Hua-Lu},
	month = oct,
	year = {1996},
	pages = {2322--2339}
}

@book{holton_introduction_1992,
	edition = {3rd},
	series = {International {Geophysics} ({Book} 48)},
	title = {Introduction to {Dynamic} {Meteorology}},
	url = {https://www.textbooks.com/Introduction-to-Dynamic-Meteorology-3rd-Edition/9780123543554/James-R-Holton.php},
	language = {en},
	urldate = {2017-10-19},
	publisher = {Academic Press, Inc.},
	author = {Holton, James},
	month = apr,
	year = {1992}
}

@incollection{cane_tropical_1992,
	title = {Tropical {Pacific} {ENSO} models: {ENSO} as a mode of the coupled system},
	booktitle = {Climate {System} {Modeling}},
	publisher = {Cambridge University Press},
	author = {Cane, Mark A.},
	editor = {Trenberth, Kevin E.},
	year = {1992}
}

@book{eliassen_quasi-static_1949,
	title = {The quasi-static equations of motion with pressure as independent variable},
	volume = {17},
	publisher = {Grøndahl \& Sons boktr., I kommisjon hos Cammermeyers boghandel},
	author = {Eliassen, Arnt},
	year = {1949}
}

@article{charney_use_1969,
	title = {Use of {Incomplete} {Historical} {Data} to {Infer} the {Present} {State} of the {Atmosphere}},
	volume = {26},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469%281969%29026%3C1160%3AUOIHDT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1969)026<1160:UOIHDT>2.0.CO;2},
	abstract = {No abstract available.},
	number = {5},
	journal = {Journal of the Atmospheric Sciences},
	author = {Charney, J. and Halem, M. and Jastrow, R.},
	month = sep,
	year = {1969},
	pages = {1160--1163}
}

@inproceedings{holloway_predictability_1984,
	title = {Predictability of {Fluid} {Motions}},
	url = {https://www.osti.gov/scitech/biblio/5004329},
	language = {English},
	urldate = {2017-10-18},
	publisher = {American Institute of Physics,New York, NY},
	author = {Holloway, G. and West, B. J. (eds )},
	month = jan,
	year = {1984},
	keywords = {mathematics, -- environment, -- mathematical physics-- (-1987), abstracts, atmospheric-- basic studies-- (-1989), classical and quantum mechanics, condensed matter physics, document types, environmental sciences, fluid flow, fluid mechanics, forecasting, general physics, hydrodynamics, leading abstract, mathematical models, mechanics 640410*  -- fluid physics-- general fluid dynamics, meetings, meteorology, nonlinear problems, probability, statistics, superconductivity and superfluidity, turbulent flow, weather}
}

@article{charney_feasibility_1966,
	title = {The feasibility of a global observation and analysis experiment},
	volume = {47},
	journal = {Bulletin of the American Meteorological Society},
	author = {Charney, J. G. and Fleagle, R. G. and Riehl, H. and Lally, V. E. and Wark, D. Q.},
	year = {1966},
	pages = {200--220}
}

@article{ehrendorfer_predicting_1997,
	title = {Predicting the uncertainty of numerical weather forecasts: a review},
	volume = {6},
	shorttitle = {Predicting the uncertainty of numerical weather forecasts},
	journal = {METEOROLOGISCHE ZEITSCHRIFT-BERLIN-},
	author = {Ehrendorfer, Martin},
	year = {1997},
	pages = {147--183}
}

@article{egbert_topex/poseidon_1994,
	title = {{TOPEX}/{POSEIDON} tides estimated using a global inverse model},
	volume = {99},
	issn = {2156-2202},
	url = {http://onlinelibrary.wiley.com/doi/10.1029/94JC01894/abstract},
	doi = {10.1029/94JC01894},
	abstract = {Altimetric data from the TOPEX/POSEIDON mission will be used for studies of global ocean circulation and marine geophysics. However, it is first necessary to remove the ocean tides, which are aliased in the raw data. The tides are constrained by two distinct types of information: the hydrodynamic equations which the tidal fields of elevations and velocities must satisfy, and direct observational data from tide gauges and satellite altimetry. Here we develop and apply a generalized inverse method, which allows us to combine rationally all of this information into global tidal fields best fitting both the data and the dynamics, in a least squares sense. The resulting inverse solution is a sum of the direct solution to the astronomically forced Laplace tidal equations and a linear combination of the representers for the data functionals. The representer functions (one for each datum) are determined by the dynamical equations, and by our prior estimates of the statistics of errors in these equations. Our major task is a direct numerical calculation of these representers. This task is computationally intensive, but well suited to massively parallel processing. By calculating the representers we reduce the full (infinite dimensional) problem to a relatively low-dimensional problem at the outset, allowing full control over the conditioning and hence the stability of the inverse solution. With the representers calculated we can easily update our model as additional TOPEX/POSEIDON data become available. As an initial illustration we invert harmonic constants from a set of 80 open-ocean tide gauges. We then present a practical scheme for direct inversion of TOPEX/POSEIDON crossover data. We apply this method to 38 cycles of geophysical data records (GDR) data, computing preliminary global estimates of the four principal tidal constituents, M2, S2, K1, and O1. The inverse solution yields tidal fields which are simultaneously smoother, and in better agreement with altimetric and ground truth data, than previously proposed tidal models. Relative to the “default” tidal corrections provided with the TOPEX/POSEIDON GDR, the inverse solution reduces crossover difference variances significantly (≈20–30\%), even though only a small number of free parameters (≈1000) are actually fit to the crossover data.},
	language = {en},
	number = {C12},
	urldate = {2017-10-18},
	journal = {Journal of Geophysical Research: Oceans},
	author = {Egbert, Gary D. and Bennett, Andrew F. and Foreman, Michael G. G.},
	month = dec,
	year = {1994},
	keywords = {4275 Remote sensing and electromagnetic processes, 4560 Surface waves and tides, 4594 Instruments and techniques},
	pages = {24821--24852}
}

@inproceedings{hollingsworth_experiment_1980,
	address = {Shinfield Park, reading, UK},
	title = {An experiment in {Monte} {Carlo} forecasting},
	language = {English},
	booktitle = {Proc. {Workshop} on {Stochastic}-{Dynamic} {Forecasting}},
	author = {Hollingsworth, A.},
	year = {1980},
	pages = {65--85}
}

@article{hollingsworth_monitoring_1986,
	title = {Monitoring of {Observation} and {Analysis} {Quality} by a {Data} {Assimilation} {System}},
	volume = {114},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1986)114%3C0861:MOOAAQ%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1986)114<0861:MOOAAQ>2.0.CO;2},
	abstract = {The purpose of this paper is to demonstrate the ability of a modern data assimilation system to provide long-term diagnostic facilities to monitor the performance of the observational network. Operational data assimilation systems use short-range forecasts to provide the background, or first-guess, field for the analysis. We make a detailed study of the apparent or perceived error of these forecasts when they are verified against radiosondes. On the assumption that the observational error of the radiosondes is horizontally uncorrelated, the perceived forecast error can be partitioned into prediction error, which is horizontally correlated, and observation error, which is not. The calculations show that in areas where there is adequate radiosonde coverage, the 6-hour prediction error is comparable with the observation error. This statement is discussed from a number of viewpoints. We demonstrate in the Northern Hemisphere midlatitudes, for example, that the forecasts account for most of the evolution of the atmospheric state from one analysis to the next, so that the analysis algorithm needs to make only a small correction to an accurate first-guess field; the situation is rather different in the Southern Hemisphere. If the doubling time for small errors is two days, then analysis error will amplify by less than 10\% in 6 hours. This being the case, the statistics of the forecast/observation differences have a simple statistical structure. Large variations of the statistics from station to station, or large biases, are indicative of problems in the data or in the assimilation system. Case studies demonstrate the ability of simple statistical tools to identify systematically erroneous radiosonde wind data in data sparse, as well as in data rich areas, errors which would have been difficult to detect in any other way. The statistical tools are equally effective in diagnosing the performance of the assimilation system. The results suggest that it is possible to provide regular feedback on the quality of observations of winds and heights to operators of radiosonde networks and other observational systems. This capability has become available over the last decade through improvements in the techniques of numerical weather analysis and prediction.},
	number = {5},
	urldate = {2017-10-18},
	journal = {Monthly Weather Review},
	author = {Hollingsworth, A. and Shaw, D. B. and Lönnberg, P. and Illari, L. and Arpe, K. and Simmons, A. J.},
	month = may,
	year = {1986},
	pages = {861--879}
}

@article{hollingsworth_statistical_1986,
	title = {The statistical structure of short-range forecast errors as determined from radiosonde data. {Part} {I}: {The} wind field},
	volume = {38A},
	issn = {1600-0870},
	shorttitle = {The statistical structure of short-range forecast errors as determined from radiosonde data. {Part} {I}},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1600-0870.1986.tb00460.x/abstract},
	doi = {10.1111/j.1600-0870.1986.tb00460.x},
	abstract = {This paper analyses the statistical structure of the errors of the short-range wind forecasts used in the global data assimilation system at ECMWF, by verifying the forecasts against radiosonde data over North America. The kinematics of two-dimensional homogeneous turbulence is used to partition the perceived forecast errors into prediction errors which are horizontally correlated, and observational errors which are assumed to be horizontally uncorrelated. The theory further partitions the wind prediction errors into three components, viz. large-scale, rotational and divergent components, and provides a spectral description of the covariance and cross-covariance functions for stream function and velocity potential. The calculations also provide an estimate of the vertical error covariance matrices for prediction error and for radiosonde observational error, by which we mean the combined effects of instrumental error and errors of representativeness. The basic assumptions are that the forecast errors are horizontally homogeneous and that the observational errors are horizontally uncorrelated. Several important results are found. The wind prediction errors are comparable in magnitude with the wind observation errors. The prediction errors are dominated by the synoptic scales, but there is a substantial large scale wind error which reverses phase between the stratosphere and troposphere. The synoptic scale errors are largely non-divergent in the troposphere. There are good grounds for increasing the resolution of the analysis system, both in the horizontal and the vertical, over North America and other data-rich regions.},
	language = {en},
	number = {2},
	urldate = {2017-10-18},
	journal = {Tellus A},
	author = {Hollingsworth, A. and Lönnberg, P.},
	month = mar,
	year = {1986},
	pages = {111--136}
}

@article{hoke_initialization_1976,
	title = {The {Initialization} of {Numerical} {Models} by a {Dynamic}-{Initialization} {Technique}},
	volume = {104},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281976%29104%3C1551%3ATIONMB%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1976)104<1551:TIONMB>2.0.CO;2},
	abstract = {A dynamic-initialization technique is tested with three models of fluid flow. In this technique data are assimilated through the inclusion of terms in the forecast equations which force the model atmosphere toward the observations. Results indicate that accurate, dynamically balanced mass and momentum fields can be obtained from unbalanced, inexact first guesses. In midlatitudes for horizontal scales less than 2000 km, observations of the wind are more important than observations of mass in producing a successful initialization for the systems presented here. There is also evidence that forcing the model winds toward the divergent wind component may slow the initialization process.},
	number = {12},
	urldate = {2017-10-18},
	journal = {Monthly Weather Review},
	author = {Hoke, James E. and Anthes, Richard A.},
	month = dec,
	year = {1976},
	pages = {1551--1556}
}

@article{hoffman_distortion_1995,
	title = {Distortion {Representation} of {Forecast} {Errors}},
	volume = {123},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1995)123%3C2758:DROFE%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1995)123<2758:DROFE>2.0.CO;2},
	abstract = {Forecast error is decomposed into three components, termed displacement error, amplitude error, mid residual error, respectively. Displacement error measures how much of the forecast error can be accounted for by moving the forecast to best fit the analysis. Amplitude error measures how much of the forecast error can be accounted for by changing the amplitude of the displaced forecast to best fit the analysis. The combination of a displacement and an amplification is called a distortion. The part of the forecast error unaccounted for by the distortion is called the residual error. The distortion must be large scale, in line with the basic premise that forecast errors are best described by reference to large-scale meteorological features. A general mathematical formalism for defining distortions and decomposing forecast errors into distortion and residual errors is formulated. The distortion representation of forecast errors should prove useful for describing forecast skill and for representing the statistics of the background errors in objective data analysis. Examples using nonstandard satellite data–SSM/I precipitable water and ERS-1 backscatter—demonstrate the detection and characterization of analysis errors in terms of position mid amplitude errors. In addition, a 48-h forecast of Northern Hemisphere 500-hPa geopotential height is decomposed. For this case a large-scale distortion is capable of representing the larger part of the forecast error field and the displacement error is predominant over the amplification error. These examples indicate the feasibility of implementing the proposed method in an operational setting.},
	number = {9},
	urldate = {2017-10-18},
	journal = {Monthly Weather Review},
	author = {Hoffman, Ross N. and Liu, Zheng and Louis, Jean-Francois and Grassoti, Christopher},
	month = sep,
	year = {1995},
	pages = {2758--2770}
}

@article{hoffman_four-dimensional_1986,
	title = {A {Four}-{Dimensional} {Analysis} {Exactly} {Satisfying} {Equations} {Of} {Motion}},
	volume = {114},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1986)114%3C0388%3AAFDAES%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1986)114<0388:AFDAES>2.0.CO;2},
	abstract = {For a discretized deterministic model of the atmosphere, a single point in the model's phase space defines a complete trajectory. It is possible to choose a point which minimizes the differences between the model trajectory starting at the chosen point and all data observed during an analysis period (−T≤t≤0). In this way data and model dynamics are combined to yield a four-dimensional analysis exactly satisfying the model equations. This analysis is the solution of the model's equations of motion defined by the optimal initial conditions chosen at t=−T. Therefore, provided T is larger than the adjustment time of the model, there should be no need for any initialization at the start of the forecast at t = 0. This report describes some preliminary experiments which use highly simplified filtered and primitive equation models of an atmosphere with f-plane geometry. These simple models are used because of the substantial computational resources required by the minimization method. It is demonstrated that the method is stable in an assimilation cycle, is able to maintain an accurate estimate of the motion field from temperature observations alone and yields a small analysis error. Unfortunately, forecasts made from the four-dimensional analyses exhibit rapid error growth initially; as a result these forecasts are better than ordinary forecasts only for the first 24 h. Beyond 24 h both types of forecasts have the same skill.},
	number = {2},
	urldate = {2017-10-18},
	journal = {Monthly Weather Review},
	author = {Hoffman, Ross N.},
	month = feb,
	year = {1986},
	pages = {388--397}
}

@article{hoffman_sass_1984,
	title = {{SASS} {Wind} {Ambiguity} {Removal} by {Direct} {Minimization}. {Part} {II}: {Use} of {Smoothness} and {Dynamical} {Constraints}},
	volume = {112},
	issn = {0027-0644},
	shorttitle = {{SASS} {Wind} {Ambiguity} {Removal} by {Direct} {Minimization}. {Part} {II}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1984)112%3C1829%3ASWARBD%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1984)112<1829:SWARBD>2.0.CO;2},
	abstract = {Variational analysis methods allow information from a variety of sources, including current observations and a priori statistics and constraints, to be combined by minimizing the lack of fit to the various sources of information. In this study, the ambiguity of the SASS winds is removed by a variational analysis method which combines the following information: a variety of current surface wind observations (radiosonde, ship, satellite scatterometer), earlier observations in the form of a forecast, smoothness constraints on the horizontal winds, its divergence and vorticity, and a dynamical constraint on the time rate of change of Vorticity of the surface wind. The constraints used are “weak” constraints in the sense of Sasaki. In an earlier work, constraints were not used. The scatterometer wind magnitudes are nearly unambiguous and are considered specially. The lack of fit to data and constraints is measured by the so-called objective function. Here, a discrete form of the solution is assumed, the objective function is described in terms of discrete variables and a minimum is found by a conjugate gradient method. Global analyses are possible. Compared to previous results, the use of constraints results in a more robust analysis procedure and produces better transitions between data-rich and data-poor regions, but the analyses, like all objective analyses, are still lacking common sense in some important respects. The scatterometer data have been processed by two methods, one which bins and one which pairs the individual scatterometer values. Both data sets are analyzed for the case of an intense cyclone centered south of Japan at 0000 GMT 6 September 1978. Only slightly better results are obtained with the finer resolution winds produced by the pairing algorithm, although it is clear they contain far more detailed information.},
	number = {9},
	urldate = {2017-10-18},
	journal = {Monthly Weather Review},
	author = {Hoffman, Ross N.},
	month = sep,
	year = {1984},
	pages = {1829--1852}
}

@article{hoffman_lagged_1983,
	title = {Lagged average forecasting, an alternative to {Monte} {Carlo} forecasting},
	volume = {35A},
	issn = {1600-0870},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1600-0870.1983.tb00189.x/abstract},
	doi = {10.1111/j.1600-0870.1983.tb00189.x},
	abstract = {In order to use the information present in past observations and simultaneously to take advantage of the benefits of stochastic dynamic prediction we formulate the lagged average forecast (LAF) method. In a LAF, just as in a Monte Carlo forecast (MCF), sample statistics are calculated from an ensemble of forecasts. Each LAF ensemble member is an ordinary dynamical forecast (ODF) started from the initial conditions observed at a time lagging the start of the forecast period by a different amount. These forecasts are averaged at their proper verification times to obtain an LAF. The LAF method is operationally feasible since the LAF ensemble members are produced during the normal operational cycle. To test the LAF method, we use a two-layer, f-plane, highly truncated spectral model, forced by asymmetric Newtonian heating of the lower layer. In the experiments, a long run is generated by the primitive equation version of the model which is taken to represent nature, while forecasts are made by the quasigeostrophic version of the model. On the basis of forecast skill, the LAF and MCF are superior to the ODF; this occurs principally because ensemble averaging hedges the LAF and MCF toward the climate mean. The LAF, MCF and ODF are all improved when tempered by a simple regression filter; this procedure yields different weights for the different members of the LAF ensemble. The tempered LAF is the most skillful of the forecast methods tested. The LAF and MCF can provide a priori estimates of forecast skill because there is a strong correlation between the dispersion of the ensemble and the loss of predictability. In this way the time at which individual forecasts lose their skill can be predicted. The application of the LAF method to more realistic models and to monthly or seasonally averaged forecasts is briefly discussed.},
	language = {en},
	number = {2},
	urldate = {2017-10-18},
	journal = {Tellus A},
	author = {Hoffman, Ross N. and Kalnay, Eugenia},
	month = mar,
	year = {1983},
	pages = {100--118}
}

@misc{noauthor_lagged_nodate,
	title = {Lagged average forecasting, an alternative to {Monte} {Carlo} forecasting - {Hoffman} - 1983 - {Tellus} {A} - {Wiley} {Online} {Library}},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1600-0870.1983.tb00189.x/full},
	urldate = {2017-10-18}
}

@article{errico_what_1997,
	title = {What {Is} an {Adjoint} {Model}?},
	volume = {78},
	issn = {0003-0007},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0477(1997)078%3C2577:WIAAM%3E2.0.CO;2},
	doi = {10.1175/1520-0477(1997)078<2577:WIAAM>2.0.CO;2},
	abstract = {Adjoint models are powerful tools for many studies that require an estimate of sensitivity of model output (e.g., a forecast) with respect to input. Actual fields of sensitivity are produced directly and efficiently, which can then be used in a variety of applications, including data assimilation, parameter estimation, stability analysis, and synoptic studies. The use of adjoint models as tools for sensitivity analysis is described here using some simple mathematics. An example of sensitivity fields is presented along with a short description of adjoint applications. Limitations of the applications are discussed and some speculations about the future of adjoint models are offered.},
	number = {11},
	urldate = {2017-10-18},
	journal = {Bulletin of the American Meteorological Society},
	author = {Errico, Ronald M.},
	month = nov,
	year = {1997},
	pages = {2577--2591}
}

@article{errico_sensitivity_1992,
	title = {Sensitivity {Analysis} {Using} an {Adjoint} of the {PSU}-{NCAR} {Mesoseale} {Model}},
	volume = {120},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1992)120%3C1644%3ASAUAAO%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1992)120<1644:SAUAAO>2.0.CO;2},
	abstract = {An adjoint of the Pennsylvania State University-National Center for Atmospheric Research (PSU-NCAR) Mesoscale Model has been developed for use in sensitivity analysis following Cacuci. Sensitivity analysis is defined as the determination of the potential impact on some quantitative measure of a forecast aspect due to arbitrary perturbations of the model dynamic fields at earlier times. Input to the adjoint operator is the gradient of the forecast-aspect measure with respect to the model fields at the verification time, and output is the corresponding gradients defined at earlier times. The adjoint is exactly determined from a tangent linear model, which is itself an approximation to the dry nonlinear model. This approximation is shown to be accurate even when evaluated with regard to the moist nonlinear model for periods up to 36 h, although this accuracy is necessarily case and perturbation dependent. The mathematics describing the scheme are applied to the model in its spatially and temporally discrete form, which greatly simplifies the scheme's presentation. Examples of adjoint fields for three forecast aspects and two synoptic cases are shown, and their meanings and implications are discussed. They are valuable for determinations of forecast dependencies on data, predictability, and the relationships between consecutive synoptic conditions. The uses of the adjoint model therefore have much greater scope than only variational analysis and parameter filling.},
	number = {8},
	urldate = {2017-10-18},
	journal = {Monthly Weather Review},
	author = {Errico, Ronald M. and Vukicevic, Tomislava},
	month = aug,
	year = {1992},
	pages = {1644--1660}
}

@article{errico_normal_1982,
	title = {Normal {Mode} {Initialization} and the {Generation} of {Gravity} {Waves} by {Quasi}-{Geostrophic} {Forcing}},
	volume = {39},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1982)039%3C0573:NMIATG%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1982)039<0573:NMIATG>2.0.CO;2},
	abstract = {Several numerical weather prediction models now use nonlinear normal-mode initialization schemes. These schemes describe balanced states which act to limit the initial presence of high-frequency gravity waves and their subsequent growth by internal dynamics. It has been suggested that there may be states that are so balanced that these waves are never excited except through external forcing. These states have been termed “superbalanced” or “belonging to the slow manifold.” The degrees to which various balance conditions describe solutions to primitive equations are determined using a sparse-spectral model. The degrees of balance are measured in terms of the portion of energy remaining in the unbalanced fields. Time scales of solutions are measured in terms of the power spectra of their normal linear modes. These measures are determined as a function of heating and dissipation rates and Rossby number. The dynamics of imbalances is examined also. The tendency for an energy-conserving primitive-equation system to equipartition its energy among each independent mode is demonstrated. For non-adiabatic systems, the portion of the fields not described by superbalance conditions is shown to consist primarily of inertial- gravity waves, especially at the largest horizontal scales. These gravity waves occur intermittently and coincide with maxima in the Rossby number and with small-scale energy cascades. They are damped by eddy viscosity. Mechanisms for generating imbalances are investigated by comparing various filtered versions of the model. Results indicate that high-frequency components of the quasi-geostrophic forcing terms are the, energy source. The gravity waves are amplified further by near-resonant ageostrophic interactions. However, the gravity modes act on the geostrophic field to increase the balance, probably by acting to damp high-frequency eddies. A true slow manifold does not exist in this model for time-mean Ro{\textgreater}0.1.},
	number = {3},
	urldate = {2017-10-18},
	journal = {Journal of the Atmospheric Sciences},
	author = {Errico, Ronald M.},
	month = mar,
	year = {1982},
	pages = {573--586}
}

@article{epstein_stochastic_1969,
	title = {Stochastic dynamic prediction},
	volume = {21},
	issn = {0040-2826},
	url = {http://dx.doi.org/10.3402/tellusa.v21i6.10143},
	doi = {10.3402/tellusa.v21i6.10143},
	abstract = {Stochastic dynamic prediction assumes the laws governing atmospheric behavior are entirely deterministic, but seeks solutions corresponding to probabilistic statements of the initial conditions, thus recognizing the impossibility of exact or sufficiently dense observations. The equation that must be solved is the continuity equation for probability. For practical reasons only approximate solutions to this equation are possible in general. Deterministic forecasts represent a very low order of approximation. More exact methods are developed and some of the attributes and advantages of stochastic dynamic predictions are illustrated by applying them to a low order set of dynamic equations.Stochastic dynamic predictions have significantly smaller mean square errors than deterministic procedures, and also give specific information on the nature and extent of the uncertainty of the forecast. Also the range of time over which useful forecasts can be obtained is extended. However, they also require considerably more extensive calculations.The question of analysis to obtain the initial stochastic statement of the atmospheric state is considered and one finds here too a promise of significant advantages over present deterministic methods. It is shown how the stochastic method can be used to assess the value of new or improved data by considering their influence on the decrease in the uncertainty of the forecast. Comparisons among physical-numerical models are also made more effectively by applying stochastic methods. Finally the implications of stochastic dynamic prediction on the question of predictability are briefly considered, with the conclusion that some earlier estimates have been too pessimistic.},
	number = {6},
	urldate = {2017-10-18},
	journal = {Tellus},
	author = {Epstein, Edward S.},
	month = jan,
	year = {1969},
	pages = {739--759}
}

@article{navon_variational_1992,
	title = {Variational {Data} {Assimilation} with an {Adiabatic} {Version} of the {NMC} {Spectral} {Model}},
	volume = {120},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1992)120%3C1433%3AVDAWAA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1992)120<1433:VDAWAA>2.0.CO;2},
	abstract = {Variational four-dimensional (4D) data assimilation is performed using an adiabatic version of the National Meteorological Center (NMC) baroclinic spectral primitive equation model with operationally analyzed fields as well as simulated datasets. Two limited-memory quasi-Newton minimization techniques were used to iteratively find the minimum of a cost function, with the NMC forecast as a constraint. The cost function consists of a weighted square sum of the differences between the model forecast and observations over a time interval. In all the experiments described in this paper, observations are available for all degrees of freedom of the model. The derivation of the adjoint of the discretized adiabatic NMC spectral model is presented. The creation of this adjoint model allows the gradient of the cost function with respect to the initial conditions to be computed using a single backward-in-time integration of the adjoint equations. As an initial evaluation of the variational data-assimilation procedure, an assimilation system with a low-resolution version of the NMC spectral model was tested using fields from a Rossby-Haurwitz-wave solution as observations. The results were encouraging, with a significant reduction in the magnitudes of both the cost function and the norm of its gradient during the minimization process. In particular, the high-frequency noise exhibited in the rms of the divergence field, produced by random perturbation in the initial conditions, is largely eliminated after the variational data assimilation. The performance of the assimilation scheme was examined in a more realistic configuration using the adiabatic NMC spectral model truncated at T40. Both operationally analyzed observations, consisting of vorticity, divergence, temperature, surface pressure and moisture fields (distributed at two time levels separated by a 6-h time interval), and model-generated data were variationally assimilated. The effect of the number of observation fields in time on the convergence rate of the minimization and the impacts due to the inclusion of the horizontal diffusion and the surface drag in the model and its adjoint on the convergence rate and the accuracy of the retrieval are addressed.},
	number = {7},
	urldate = {2017-10-18},
	journal = {Monthly Weather Review},
	author = {Navon, I. M. and Zou, X. and Derber, J. and Sela, J.},
	month = jul,
	year = {1992},
	pages = {1433--1446}
}

@article{navon_conjugate-gradient_1987,
	title = {Conjugate-{Gradient} {Methods} for {Large}-{Scale} {Minimization} in {Meteorology}},
	volume = {115},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1987)115%3C1479%3ACGMFLS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1987)115<1479:CGMFLS>2.0.CO;2},
	abstract = {During the last few years new meteorological variational analysis methods have evolved, requiring large-scale minimization of a nonlinear objective function described in terms of discrete variables. The conjugate-gradient method was found to represent a good compromise in convergence rates and computer memory requirements between simpler and more complex methods of nonlinear optimization. In this study different available conjugate-gradient algorithms are presented with the aim of assessing their use in large-scale typical minimization problems in meteorology. Computational efficiency and accuracy are our principal criteria. Four different conjugate-gradient methods, representative of up-to-date available scientific software, were compared by applying them to two different meteorological problems of interest using criteria of computational economy and accuracy. Conclusions are presented as to the adequacy of the different conjugate algorithms for large-scale minimization problems in different meteorological applications.},
	number = {8},
	urldate = {2017-10-18},
	journal = {Monthly Weather Review},
	author = {Navon, I. M. and Legler, David M.},
	month = aug,
	year = {1987},
	pages = {1479--1502}
}

@article{eliasen_study_1965,
	title = {A study of the fluctuations of the atmospheric planetary flow patterns represented by spherical harmonics},
	volume = {17},
	issn = {0040-2826},
	url = {http://dx.doi.org/10.3402/tellusa.v17i2.9032},
	doi = {10.3402/tellusa.v17i2.9032},
	abstract = {A procedure used for expanding the height of a pressure surface over the Northern Hemisphere in a series of spherical-harmonic components is described. The corresponding spherical-harmonic representation of the stream function is obtained by utilizing the geostrophic balance condition. From this representation mean values for the spectral distribution of the kinetic energy at the 500 mb level for January 1957 is presented.The behaviour of the components with the largest horizontal scales is considered at the 500 mb and the 1000 mb levels during the 90 days period from 1 December 1956 to 28 February 1957. In general each of these components exhibits smaller or larger fluctuations, and it is attempted to investigate the character of the shorter periodic fluctuations by eliminating the constant and the long periodic parts of the stream field. For the components with wavenumber 1, 2, and 3, and with the most large-scale meridional variation, the 24 hours tendency fields show a more or less regular westward propagation with mean values for the velocity of propagation, corresponding to periods about 5 days. For the components with the same wavenumbers but with the second largest meridional scales we find for the daily deviations from the 15 days mean flow displacements also mainly towards the west and also with mean values for the velocity of propagation, decreasing with decreasing horizontal scale. The mean values of the velocity of propagation obtained in this way for the different components are nearly in accordance with the velocities determined by the Rossby effect, especially if this effect is reduced somewhat by a weak divergence effect.On the basis of the spectral form of the barotropic vorticity equation the time derivatives for the expansion coefficients as well as for the amplitude and phase angle of the stream function at the 500 mb level have been computed for each day in January 1957, for some components of the zonal flow and some of the components with wave-number 1, 2, 5, and 6. From these time derivatives 48 hours tendencies have been evaluated and compared with the corresponding observed ones. In general it is found that the agreement is better for components with moderately large scales than for components with very large scales. To some extent this may be explained by the neglect of quasi-stationary effects, and as a very simple attempt, these are represented by a constant term. Finally the contributions from the barotropic interactions between different groups of components to the change of kinetic energy of individual components are considered.},
	number = {2},
	urldate = {2017-10-18},
	journal = {Tellus},
	author = {Eliasen, Erik and Machenhauer, Bannert},
	month = jan,
	year = {1965},
	pages = {220--238}
}

@article{ehrendorfer_optimal_1997,
	title = {Optimal {Prediction} of {Forecast} {Error} {Covariances} through {Singular} {Vectors}},
	volume = {54},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1997)054%3C0286%3AOPOFEC%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1997)054<0286:OPOFEC>2.0.CO;2},
	abstract = {Optimal perturbations, also referred to as singular vectors (SVs), currently constitute an important guideline for the generation of initial ensembles to be used for ensemble prediction. The optimality of these perturbations refers to their property of maximizing prespecified quadratic measures of error growth, given that tangent-linear error evolution is assumed. The goal of ensemble prediction is the accurate prediction of the uncertainty of forecasts made with dynamical numerical weather prediction models. In the present paper the theoretical justification for the use of SVs in ensemble prediction systems is investigated. It is shown that, in a tangent-linear framework, SVs—constructed using covariance information valid at the initial time—evolve into the eigenvectors of the forecast error covariance matrix valid for the end of the optimization interval. As such, SVs represent the most efficient means for predicting the forecast error covariance matrix, given a prespecified number of allowable (tangent-linear) model integrations. Such optimal prediction is of particular importance in light of the fact that the forecast error covariance matrix is summarizing important information about the probability density function of the model state at a given future time. Based on the above result, optimal covariance prediction through appropriately determined SVs is demonstrated here for a three-dimensional Lorenz model, as well as for a barotropic model of intermediate dimensionality, both within a perfect-model framework. In the case of the barotropic model it is found that less than 15\% of the SVs suffice to account for more than 95\% of the total final error variance. Viewed differently, at least 80\% of the final error variance is accounted for by retaining those SVs that are amplifying in terms of an enstrophy norm. In addition, variances and covariances predicted through SVs agree closely with independently obtained Monte Carlo estimates, as long as the tangent-linear approximation is sufficiently accurate. Further, the problem of approximating the forecast error covariance matrix in the presence of a state-independent model-error representation is briefly considered. The paper is concluded with a summary of the results and a discussion of their possible implications on data assimilation procedures and on the further development of ensemble prediction systems.},
	number = {2},
	urldate = {2017-10-18},
	journal = {Journal of the Atmospheric Sciences},
	author = {Ehrendorfer, Martin and Tribbia, Joseph J.},
	month = jan,
	year = {1997},
	pages = {286--313}
}

@inproceedings{campana_use_1994,
	address = {Shinfield Park, Reading, England},
	title = {Use of cloud analyses to validate and improve model-diagnostic clouds at {NMC}},
	publisher = {ECMWF},
	author = {Campana, K.},
	month = nov,
	year = {1994}
}

@article{mullen_monte_1994,
	title = {Monte {Carlo} {Simulations} of {Explosive} {Cyclogenesis}},
	volume = {122},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1994)122%3C1548%3AMCSOEC%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1994)122<1548:MCSOEC>2.0.CO;2},
	abstract = {The impact of initial condition uncertainty on short-range (0–48 h) simulations of explosive surface cyclogenesis is examined within the context of a perfect model environment. Eleven Monte Carlo simulations are performed on 10 cases of rapid oceanic cyclogenesis that occurred in a long-term, perpetual January integration of a global spectral model. The perturbations used to represent the initial condition error have a magnitude and spatial decomposition that closely matches estimates of global analysis error. Large variability characterizes the error growth rates, both among the individual Monte Carlo simulations and among the case-average values. Some individual simulations display error growth doubling times as fast as approximately 12 h during the 24-h period of most rapid intensification, while others exhibit virtually no error growth. The variability is also reflected in the wide 90\% confidence bounds for many surface weather elements such as the cyclone position and central pressure. However, no statistically significant differences are found between the initial states leading to large simulation errors and those leading to negligible errors. These results attest to the importance of initial condition uncertainty as the major cause of forecast variability and indicate a strong sensitivity to subtle differences in initial perturbation location and structure. The effect that simple ensemble averaging has on reducing uncertainty is discussed. Averaging a 16-member ensemble decreases the random component of the initial data error by 80\%–90\% and the 90\% confidence bounds by 70\%–80\% for cyclone position, central pressure, and 12-h pressure change. It is hypothesized that ensemble forecasting could benefit the utility of short-range forecasts for many weather elements of operational interest and conclude that research efforts should be directed at examining its effectiveness in an operational setting.},
	number = {7},
	urldate = {2017-10-18},
	journal = {Monthly Weather Review},
	author = {Mullen, Steven L. and Baumhefner, David P.},
	month = jul,
	year = {1994},
	pages = {1548--1567}
}

@article{moorthi_relaxed_1992,
	title = {Relaxed {Arakawa}-{Schubert}. {A} {Parameterization} of {Moist} {Convection} for {General} {Circulation} {Models}},
	volume = {120},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1992)120%3C0978:RASAPO%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1992)120<0978:RASAPO>2.0.CO;2},
	abstract = {A simple implementation of the Arakawa and Schubert (1974) cumulus parameterization is presented. The major simplification made is to “relax”the state toward equilibrium each time the parameterization is invoked, rather than requiring that the final state be balanced, as in the original Arakawa-Schubert implementation. This relaxed Arakawa-Schubert (RAS) scheme is evaluated in off-line tests using the Global Atmospheric Research Programme (GARP) Atlantic Tropical Experiment (GATE) Phase III data. The results show that RAS is equivalent to the standard implementation of Arakawa-Schubert but is more economical and simpler to code. RAS also avoids the ill-posed problem that occurs in Arakawa-Schubert as a result of having to solve for a balanced state.},
	number = {6},
	urldate = {2017-10-18},
	journal = {Monthly Weather Review},
	author = {Moorthi, Shrinivas and Suarez, Max J.},
	month = jun,
	year = {1992},
	pages = {978--1002}
}

@book{isaacson_analysis_1966,
	address = {New York, NY, USA},
	title = {Analysis of numerical methods},
	language = {en},
	publisher = {Wiley},
	author = {Isaacson, Eugene and Keller, Herbert Bishop},
	year = {1966},
	note = {Google-Books-ID: 2\_NQAAAAMAAJ},
	keywords = {Mathematics / Mathematical Analysis, Mathematics / Probability \& Statistics / General, Numerical analysis}
}

@book{monin_statistical_2013,
	title = {Statistical {Fluid} {Mechanics}, {Volume} {II}: {Mechanics} of {Turbulence}},
	isbn = {978-0-486-31814-1},
	shorttitle = {Statistical {Fluid} {Mechanics}, {Volume} {II}},
	abstract = {"If ever a field needed a definitive book, it is the study of turbulence; if ever a book on turbulence could be called definitive, it is this book." — ScienceWritten by two of Russia's most eminent and productive scientists in turbulence, oceanography, and atmospheric physics, this two-volume survey is renowned for its clarity as well as its comprehensive treatment. The first volume begins with an outline of laminar and turbulent flow. The remainder of the book treats a variety of aspects of turbulence: its statistical and Lagrangian descriptions, shear flows near surfaces and free turbulence, the behavior of thermally stratified media, and diffusion.Volume Two continues and concludes the presentation. Topics include spectral functions, homogeneous fields, isotropic random fields, isotropic turbulence, self-preservation hypotheses, spectral energy transfer, the Millionshchikov hypothesis, acceleration fields, equations for higher moments and the closure problem, and turbulence in a compressible fluid. Additional subjects include general concepts of the local structure of turbulence at high Reynolds numbers, the theory of fully developed turbulence, the propagation of electromagnetic and acoustic waves through a turbulent medium, and the twinkling of stars. The book closes with a discussion of the functional formulation of the problem of turbulence, presenting the equations for the characteristic functional and methods for their solution.},
	language = {en},
	publisher = {Courier Corporation},
	author = {Monin, A. S. and Yaglom, A. M.},
	month = jul,
	year = {2013},
	note = {Google-Books-ID: 6xPEAgAAQBAJ},
	keywords = {Science / Physics / General}
}

@techreport{monin_basic_1959,
	title = {{BASIC} {LAWS} {OF} {TURBULENT} {MIXING} {IN} {THE} {GROUND} {LAYER} {OF} {THE} {ATMOSPHERE} ({OSNOVNE} {ZAKONOMERNOSTI} {TURBULENTNOGO} {PEREMESHIVANIYA} {V} {PRIZEMNOM} {SLOE} {ATMOSFERY})},
	url = {http://www.dtic.mil/docs/citations/AD0672723},
	abstract = {The article contains an analysis of the processes of mixing in a turbulent atmosphere, based on systematic application of the methods of the theory of similitude. Empirical data on the distribution of wind velocity under various conditions of temperature stratification are generalized and a method is proposed for computing the austausch characteristics on the basis of measuring wind velocity and temperature gradient.},
	urldate = {2017-10-18},
	institution = {AMERICAN METEOROLOGICAL SOCIETY BOSTON MA, AMERICAN METEOROLOGICAL SOCIETY BOSTON MA},
	author = {Monin, A. S. and Obukhov, A. M.},
	month = jan,
	year = {1959}
}

@article{molteni_ecmwf_1996,
	title = {The {ECMWF} {Ensemble} {Prediction} {System}: {Methodology} and validation},
	volume = {122},
	issn = {1477-870X},
	shorttitle = {The {ECMWF} {Ensemble} {Prediction} {System}},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49712252905/abstract},
	doi = {10.1002/qj.49712252905},
	abstract = {The European Centre for Medium-Range Weather Forecasts (ECMWF) Ensemble Prediction System (EPS) is described. In addition to an unperturbed (control) forecast, each ensemble comprises 32 10-day forecasts starting from initial conditions in which dynamically defined perturbations have been added to the operational analysis. The perturbations are constructed from singular vectors of a time-evolution operator linearized around the short-range-forecast trajectory. These singular vectors approximately determine the most unstable phase-space directions in the early part of the forecast period, and are estimated using a forward and adjoint linear version of the ECMWF numerical weather-prediction model. An appropriate norm is chosen, and relationships between the structures of these singular vectors at initial time and patterns showing the sensitivity of short-range forecast error to changes in the analysis are discussed. A methodology to perform a phase-space rotation of the singular vectors is described, which generates hemispheric-wide perturbations and renormalizes them according to analysis-error estimates from the data-assimilation system. The validation of the ensembles is given firstly in terms of scatter diagrams and contingency tables of ensemble spread and control-forecast skill. The contingency tables are compared with those from a perfect-model ensemble system; no significant differences are found in some cases. Brier scores for the probability of European flow clusters are presented, which indicate predictive skill up to forecast-day 8 with respect to climatological probabilities. The dependence of these scores on flow-dependent model errors is also discussed. Finally, ensemble-member skill-score distributions are presented, which confirm the overall satisfactory performance of the EPS, particularly in summer and autumn 1993. In winter, cases of poor performance over Europe were associated with the occurrence of a split westerly flow with a blocking high and/or a cut-off low in the verifying analysis. Two cases are studied in detail, one having large ensemble dispersion, the other corresponding to a more predictable situation. The case studies are used to illustrate the range of ensemble products routinely disseminated to ECMWF Member States. These products include clusters of flow types, and probability fields of weather elements.},
	language = {en},
	number = {529},
	urldate = {2017-10-18},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Molteni, F. and Buizza, R. and Palmer, T. N. and Petroliagis, T.},
	month = jan,
	year = {1996},
	keywords = {Ensemble prediction, Forecasting skill, Medium-range forecasts, Singular vectors},
	pages = {73--119}
}

@article{charney_numerical_1950,
	title = {Numerical {Integration} of the {Barotropic} {Vorticity} {Equation}},
	volume = {2},
	issn = {2153-3490},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.2153-3490.1950.tb00336.x/abstract},
	doi = {10.1111/j.2153-3490.1950.tb00336.x},
	abstract = {A method is given for the numerical solution of the barotropic vorticity equation over a limited area of the earth's surface. The lack of a natural boundary calls for an investigation of the appropriate boundary conditions. These are determined by a heuristic argument and are shown to be sufficient in a special case. Approximate conditions necessary to insure the mathematical stability of the difference equation are derived. The results of a series of four 24-hour forecasts computed from actual data at the 500 mb level are presented, together with an interpretation and analysis. An attempt is made to determine the causes of the forecast errors. These are ascribed partly to the use of too large a space increment and partly to the effects of baroclinicity. The rôle of the latter is investigated in some detail by means of a simple baroclinic model.},
	language = {en},
	number = {4},
	journal = {Tellus},
	author = {Charney, J. G. and Fjörtoft, R. and von Neumann, J.},
	month = nov,
	year = {1950},
	pages = {237--254}
}

@article{moeng_evaluation_1988,
	title = {Evaluation of {Turbulent} {Transport} and {Dissipation} {Closures} in {Second}-{Order} {Modeling}},
	volume = {46},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1989)046%3C2311:EOTTAD%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1989)046<2311:EOTTAD>2.0.CO;2},
	abstract = {We show that the turbulence statistics from our (96)3 large-eddy-simulation (LES) studies of a convective boundary layer are in excellent agreement with those from the Deardorff–Willis laboratory convection tank. Using these LES data, we evaluate contemporary parameterizations for turbulent transport and dissipation in second-order closure models of the convective boundary layer. The gradient-diffusion parameterization for turbulent transport fares poorly, due in large part to the direct influence of buoyancy. This leads to poor predictions of the vertical profiles of some turbulence statistics. We also find that the characteristic length scales for the mechanical and thermal dissipation rates typically used in second-order closure models are a factor of 2–3 too small; this leads to underpredictions of turbulence kinetic energy levels. Finally, we find that the flux and variance budgets for conservative scalars are substantially different in top-down and bottom-up diffusion. In order to reproduce these differences accurately, it seems necessary to model the turbulent transport, pressure covariance, and molecular destruction terms differently in top-down and bottom-up diffusion.},
	number = {14},
	urldate = {2017-10-18},
	journal = {Journal of the Atmospheric Sciences},
	author = {Moeng, Chin-Hoh and Wyngaard, John C.},
	month = jul,
	year = {1988},
	pages = {2311--2330}
}

@article{charney_use_1955,
	title = {The {Use} of the {Primitive} {Equations} of {Motion} in {Numerical} {Prediction}},
	volume = {7},
	issn = {2153-3490},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.2153-3490.1955.tb01138.x/abstract},
	doi = {10.1111/j.2153-3490.1955.tb01138.x},
	abstract = {An obstacle to the use of the primitive hydrodynamical equations for numerical prediction is that the initial wind and pressure fields determined by conventional means give rise to spurious large-amplitude inertio-gravitational oscillations which obscure the meteorologically significant large-scale motions. It is shown how this difficulty may be overcome by the use of a relationship between wind and pressure which enables one to determine these fields in such a manner that the noise motions do not arise. The method is illustrated by a numerically computed example. The wind-pressure relationship is in a sense a generalization of the geostrophic approximation and may be used where the latter approximation is inapplicable, either to determine initial conditions or to derive a set of filtering equations for numerical prediction analogous to the quasi-geostrophic equations.},
	language = {en},
	number = {1},
	journal = {Tellus},
	author = {Charney, J. G.},
	month = feb,
	year = {1955},
	pages = {22--26}
}

@article{ehrendorfer_mesoscale_1995,
	title = {Mesoscale {Predictability} and the {Spectrum} of {Optimal} {Perturbations}},
	volume = {52},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1995)052%3C3475:MPATSO%3E2.0.CO;2},
	doi = {10.1175/1520-0469(1995)052<3475:MPATSO>2.0.CO;2},
	abstract = {The spectrum of finite-time most unstable structures, also referred to as singular vectors (SVs), is computed for a regional, mesoscale primitive-equation model. The number of growing SVs present in this spectrum is of interest for investigating mesoscale predictability since it provides an estimate of the dimension of the unstable subspace of the model phase space. This dimension is used to critically assess the contrasting conclusions that have been reached by different authors in mesoscale predictability studies. Computations are carried out for two different synoptic cases (explosive cyclogenesis over the North Atlantic and Alpine lee cyclogenesis) using two different norms. The first is loosely related to total perturbation energy and the second measures the energy of rotational normal modes only. The latter is designed to reduce the influence of geostrophic adjustment on the measure of growth. The models used are the tangent-linear and adjoint components of the dry-adiabatic version of the primitive-equation regional model denoted as the National Center for Atmospheric Research Mesoscale Adjoint Modeling System version 1. Spectra are obtained for a 24-hour optimization time interval by partially solving the relevant eigenproblems in an iterative fashion using a Lanczos algorithm. The spectra relevant for the first norm are found to possess a very large number of growing SVs, a considerable part of which, however, is growing purely due to adjustment processes. The number of growing structures relevant for the second norm is between 150 and 200, which is approximately 3\% of the total degrees of freedom allowed for the perturbations in this situation. This percentage becomes as small as 0.25\% if all degrees of freedom are taken into account. The first few SVs amplify by factors between 5 and 10 and are strongly related to the synoptic situation under consideration, being quite localized and possessing baroclinic structure. Also, similar characteristics are found for the first few SVs, independent of which norm is being used. Based on the small number of growing perturbations, it is concluded that it is quite likely that a randomly chosen perturbation will decay because its projection on the growing part of the spectrum is small. Nevertheless, this does not necessarily imply that mesoscale circulations are more, predictable than synoptic-scale circulations due to neglected larger growing scales, the neglect of physical processes like convection, and the short timescale considered. Implications of the results regarding the role of SVs for data assimilation and ensemble prediction are briefly discussed.},
	number = {20},
	urldate = {2017-10-18},
	journal = {Journal of the Atmospheric Sciences},
	author = {Ehrendorfer, Martin and Errico, Ronald M.},
	month = oct,
	year = {1995},
	pages = {3475--3500}
}

@article{miyakoda_near-real-time_1976,
	title = {The {Near}-{Real}-{Time}, {Global}, {Four}-{Dimensional} {Analysis} {Experiment} {During} the {GATE} {Period}, {Part} {I}},
	volume = {33},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1976)033%3C0561%3ATNRTGF%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1976)033<0561:TNRTGF>2.0.CO;2},
	abstract = {Global upper air and surface data for the entire GATE period from 15 June to 24 September 1974, were collected by the Data Assimilation Branch of NMC and mailed to GFDL. After processing these data, a four-dimensional analysis technique was applied for the entire GATE period, using a global numerical model. For a selected period, several different versions of the data processing scheme were tested. The resulting analyses were compared with each other and with the objective analysis of NMC in Washington D.C., and ANMRC in Melbourne. Overall, the analyses for the extratropics were satisfactory for the Northern Hemisphere, and to a lesser extent, for the Southern Hemisphere, though flow patterns are somewhat excessively smoothed. The analyses for the tropics were not of the same quality as those for the extratropics, and yet they were much improved compared with those of several years ago. A noteworthy point is that tropical cyclones were successfully represented in several cases.},
	number = {4},
	urldate = {2017-10-18},
	journal = {Journal of the Atmospheric Sciences},
	author = {Miyakoda, K. and Umscheid, L. and Lee, D. H. and Sirutis, J. and Lusen, R. and Pratte, F.},
	month = apr,
	year = {1976},
	pages = {561--591}
}

@inproceedings{charney_integration_1962,
	address = {Tokyo, Japan},
	title = {Integration of the primitive and balance equations},
	booktitle = {Proceedings of the {International} {Symposium} on {Numerical} {Weather} {Prediction}},
	publisher = {Meteorological Society of Japan},
	author = {Charney, J. G.},
	year = {1962}
}

@article{miyakoda_method_1968,
	title = {A method of initialization for dynamical weather forecasting},
	volume = {20},
	issn = {0040-2826},
	url = {http://dx.doi.org/10.3402/tellusa.v20i1.9934},
	doi = {10.3402/tellusa.v20i1.9934},
	abstract = {A new technique to solve the balance equation for a given geopotential field is tested. The technique may offer a substitute for conventional methods of solving the ω- and the ω-equations. The non-filtered thermo-hydrodynamical equations are used as the basis, and the balance solution is obtained iteratively by filtering out the high-frequency modes through the use of the Euler-backward time differencing scheme.The merit of this technique as compared to conventional methods is that equations which include complicated processes, such as friction or heating, can be treated without difficulty, and that the balanced solution thus obtained appears completely consistent with the prognostic equations. Furthermore, it is no longer necessary to artificially modify the observed geopotential as in conventional schemes, so as to meet the ellipticity condition of the differential equations.},
	number = {1},
	urldate = {2017-10-18},
	journal = {Tellus},
	author = {Miyakoda, K. and Moyer, R. W.},
	month = jan,
	year = {1968},
	pages = {115--128}
}

@article{mitchell_revised_1990,
	title = {Revised {Interpolation} {Statistics} for the {Canadian} {Data} {Assimilation} {Procedure}: {Their} {Derivation} and {Application}},
	volume = {118},
	issn = {0027-0644},
	shorttitle = {Revised {Interpolation} {Statistics} for the {Canadian} {Data} {Assimilation} {Procedure}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1990)118%3C1591:RISFTC%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1990)118<1591:RISFTC>2.0.CO;2},
	abstract = {The first part of this paper presents the results of a study of the structure of the observed residuals, or differences, between radiosonde data and the short-range forecasts that are used as trial fields in an operational hemispheric data assimilation scheme. The study is based on fitting appropriate functional representations to horizontal correlations of observed height and wind residuals. Rather than represent the height residuals by the sum of a degenerate second-order autoregressive function and an additive constant to account for long-wave error, as in a previous study, we use a representation consisting of a sum of two degenerate third-order autoregressive functions of the form (1 + cr + c2r2/3) exp(−cr), where r represents radial distance. For the wind residuals, we use the functional form that follows by geostrophy. In addition to examining the structure of the horizontal and vertical correlations, we also present other statistics relating to the performance of the data assimilation procedure, such as vertical profiles of the magnitude of the observed wind and height residuals for various regions. In the second part of the paper, the results of the study are used as a basis for specifying interpolation statistics for the objective analysis. To evaluate the impact of the new interpolation statistics, various objective measures of analysis performance are examined and parallel 48-h forecasts are performed. It is found that significant improvements result when the new interpolation statistics are used in the data assimilation procedure.},
	number = {8},
	urldate = {2017-10-18},
	journal = {Monthly Weather Review},
	author = {Mitchell, Herschel L. and Charette, Cécilien and Chouinard, Clément and Brasnett, Bruce},
	month = aug,
	year = {1990},
	pages = {1591--1614}
}

@article{miller_data_1994,
	title = {Data {Assimilation} in {Models} with {Convective} {Adjustment}},
	volume = {122},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1994)122%3C2607:DAIMWC%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1994)122<2607:DAIMWC>2.0.CO;2},
	abstract = {Practical hydrostatic ocean models are often restricted to statically stable configurations by the use of a convective adjustment. A common way to do this is to assign an infinite boat conductivity to the water at a given level if the water column should become statically unstable. This is implemented in the form of a switch. When a statically unstable configuration is detected, it is immediately replaced with a statically stable one in which heat is conserved. In this approach, the model is no longer governed by a smooth set of equations, and usual techniques of variational data assimilation must be modified. In this note, a simple one-dimensional diffusive model is presented. Despite its simplicity, this model captures the essential behavior of the convective adjustment scheme in a widely used ocean general circulation model. Since this simple model can be derived from the more complex general circulation model, it then follows that many of the properties of the constrained system can be observed in this very simple scalar ordinary differential equation with a constraint on the solution. Techniques from the theory of optimal control are used to find solutions of a simple formulation of the variational data assimilation problem in this simple case. The optimal solution involves the solution of a nonlinear problem, even when the unconstrained dynamics are linear. In cases with discontinuous dynamics, one cannot define the adjoint of the linearized system in a straightforward manner. The very simplest variational formulation is shown to have nonunique stationary points and undesirable physical consequences. Modifications that lead to better behaved calculations and more meaningful solutions are presented. Whereas it is likely that the underlying principles from control theory are applicable to practical ocean models, the technique used to solve the simple problem may be applicable only to steady problems. Derivation of suitable techniques for initial value problems will involve a major research effort.},
	number = {11},
	urldate = {2017-10-18},
	journal = {Monthly Weather Review},
	author = {Miller, Robert N. and Zaron, Edward D. and Bennett, Andrew F.},
	month = nov,
	year = {1994},
	pages = {2607--2613}
}

@incollection{miller_dynamics_1983,
	series = {{NATO} {ASI} {Series}},
	title = {The {Dynamics} and {Simulation} of {Organized} {Deep} {Convection}},
	isbn = {978-90-481-8390-6 978-94-017-2241-4},
	url = {https://link.springer.com/chapter/10.1007/978-94-017-2241-4_25},
	abstract = {The dynamical implications of certain observational models of deep convection are discused. Various approximations to equations representing the macroscale dynamics of deep, organised convection are presented and compared, and distinctive finite difference techniques are discussed. Dynamical models of important basic types of deep convection in two and three space dimensions are collated using analytical and numerical approaches. The basis for a dynamical classification of deep convection is discussed. The importance of these models in the observational interpretation of convection experiments in the atmosphere is emphasised.},
	language = {en},
	urldate = {2017-10-18},
	booktitle = {Mesoscale {Meteorology} — {Theories}, {Observations} and {Models}},
	publisher = {Springer, Dordrecht},
	author = {Miller, M. J. and Moncrieff, M. W.},
	year = {1983},
	doi = {10.1007/978-94-017-2241-4_25},
	pages = {451--495}
}

@techreport{black_step-mountain_1993,
	address = {Silver Spring, MD, USA},
	type = {{NWS} {Technical} {Procedures} {Bull}.},
	title = {The step-mountain eta coordinate model: 80 km'early'version and objective verifications},
	shorttitle = {The step-mountain eta coordinate model},
	number = {412},
	institution = {US Department of Commerce, National Oceanic and Atmospheric Administration, National Weather Service, Office of Meteorology, Program Requirements and Development Division},
	author = {Black, Thomas and Deaven, Dennis and DiMego, Geoffrey and Glackin, Mary M.},
	year = {1993},
	pages = {31}
}

@article{charney_numerical_1954,
	title = {Numerical prediction of cyclogenesis},
	volume = {40},
	issn = {0027-8424},
	language = {eng},
	number = {2},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Charney, J. G.},
	month = feb,
	year = {1954},
	pmid = {16589442},
	pmcid = {PMC527948},
	pages = {99--110}
}

@article{charney_numerical_1953,
	title = {Numerical integration of the quasi-geostrophic equations for barotropic and simple baroclinic flows},
	volume = {10},
	issn = {0095-9634},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1953)010%3C0071%3ANIOTQG%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1953)010<0071:NIOTQG>2.0.CO;2},
	abstract = {An n-level generalization of the 2½-dimensional model is derived by specialization of the complete three-dimensional quasi-geostrophic equations. In the case n = 1, it reduces to the two-dimensional single-layer barometric model. In the case N = 2, it reduces to the double-layer barotropic model, or — what is shown to be mathematically equivalent —the 2½-dimensional model. Methods of numerical integration of the 2- and 2½-dimensional equations, and the machine requirements for such integrations, are discussed. The results of a series of six two-dimensional and six 2½-dimensional forecasts for 12 and 24 hours are presented. Although the 2½-dimensional forecasts are noticeably superior to the two-dimensional forecasts, it is apparent that considerable improvement will be possible with models in which there are fewer artificial constraints. A method of integration is therefore proposed for the n-level generalization of the 2½-dimensional model, and computation schemes are outlined for the general three-dimensional quasi-geostrophic equations. The semi-Lagrangian coordinate system with potential temperature as vertical coordinate is shown to exhibit favorable properties for machine integration.},
	number = {2},
	journal = {Journal of Meteorology},
	author = {Charney, J. G. and Phillips, N. A.},
	month = apr,
	year = {1953},
	pages = {71--99}
}

@incollection{charney_dynamic_1951,
	title = {Dynamic {Forecasting} by {Numerical} {Process}},
	isbn = {978-1-940033-70-9},
	url = {https://link.springer.com/chapter/10.1007/978-1-940033-70-9_40},
	abstract = {As meteorologists have long known, the atmosphere exhibits no periodicities of the kind that enable one to predict the weather in the same way one predicts the tides. No simple set of causal relationships can be found which relate the state of the atmosphere at one instant of time to its state at another. It was this realization that led V. Bjerknes in 1904 [1] to define the problem of prognosis as nothing less than the integration of the equations of motion of the atmosphere. But it remained for Richardson [12] to suggest in 1922 the practical means for the solution of this problem. He proposed to integrate the equations of motion numerically and showed exactly how this might be done. That the actual forecast used to test his method was unsuccessful was in no sense a measure of the value of his work. In retrospect, it becomes obvious that the inadequacies of observation alone would have doomed any attempt however well conceived, a circumstance of which Rich­ardson was aware. The real value of his work lay in the fact that it crystallized once and for all the essential problems that would have to be faced by future workers in the field and that it laid down a thorough ground­work for their solution.},
	language = {en},
	urldate = {2017-10-18},
	booktitle = {Compendium of {Meteorology}},
	publisher = {American Meteorological Society, Boston, MA},
	author = {Charney, J. G.},
	year = {1951},
	doi = {10.1007/978-1-940033-70-9_40},
	pages = {470--482}
}

@article{carter_statistical_1989,
	title = {Statistical {Forecasts} {Based} on the {National} {Meteorological} {Center}'s {Numerical} {Weather} {Prediction} {System}},
	volume = {4},
	issn = {0882-8156},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0434%281989%29004%3C0401%3ASFBOTN%3E2.0.CO%3B2},
	doi = {10.1175/1520-0434(1989)004<0401:SFBOTN>2.0.CO;2},
	abstract = {The production of interpretive weather element forecasts from dynamical model output variables is now an integral part of the centralized guidance systems of weather services throughout the world. The statistical forecasting system in the United States probably generates the most extensive suite of operational products, although other nations including Australia, Canada, France, Italy, The Netherlands, and the United Kingdom also routinely provide guidance for many weather elements and locations. The United States' statistical guidance system has evolved throughout the past 20 yr. The two principal formulation methods that have been employed are the model output statistics (MOS) and “perfect prog” approaches. These techniques have advantages and disadvantages that influence both aggregate and specific day-to-day performance characteristics of the associated weather element forecasts. Verification results indicate that forecasts from both statistical approaches provide useful guidance for most weather elements and projections for locations throughout the contiguous United States and Alaska. The MOS forecasts have generally been superior to the perfect prog guidance; the drawback to MOS is the necessity to rely on a relatively stable numerical prediction model. As dynamical models change and increase in skill, the perfect prog approach may be preferred for some applications.},
	number = {3},
	journal = {Weather and Forecasting},
	author = {Carter, Gary M. and Dallavalle, J. Paul and Glahn, Harry R.},
	month = sep,
	year = {1989},
	pages = {401--412}
}

@article{caplan_performance_1989,
	title = {Performance of the {National} {Meteorological} {Center}'s {Medium}-{Range} {Model}},
	volume = {4},
	issn = {0882-8156},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0434%281989%29004%3C0391%3APOTNMC%3E2.0.CO%3B2},
	doi = {10.1175/1520-0434(1989)004<0391:POTNMC>2.0.CO;2},
	abstract = {The operational model used to generate medium-range forecasts at the National Meteorological Center (NMC) has undergone significant changes in the last few years, resulting in considerable improvement in the skill of its forecasts. The introduction of interactive clouds in late 1988 significantly reduced a cold bias present in model forecasts since April 1985. Model errors during recent Northern Hemisphere summers appear linked to thermal forcing, causing temperatures and upper tropospheric heights over cooler ocean areas to be too low, and heights over the western United States to be too high.},
	number = {3},
	journal = {Weather and Forecasting},
	author = {Caplan, Peter M. and White, Glenn H.},
	month = sep,
	year = {1989},
	pages = {391--400}
}

@article{cane_experimental_1986,
	title = {Experimental forecasts of {El} {Niño}},
	volume = {321},
	copyright = {© 1986 Nature Publishing Group},
	issn = {0028-0836},
	url = {https://www.nature.com/nature/journal/v321/n6073/abs/321827a0.html},
	doi = {10.1038/321827a0},
	abstract = {Experimental forecasts of El Niño events occurring since 1970, made with a deterministic model of the coupled ocean-atmosphere system, indicate that El Niño is generally predictable one or two years ahead. A forecast for 1986 is also presented.},
	language = {en},
	number = {6073},
	urldate = {2017-10-18},
	journal = {Nature},
	author = {Cane, Mark A. and Zebiak, Stephen E. and Dolan, Sean C.},
	month = jun,
	year = {1986},
	pages = {827--832}
}

@article{miller_radiation_1981,
	title = {Radiation conditions for the lateral boundaries of limited-area numerical models},
	volume = {107},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49710745310/abstract},
	doi = {10.1002/qj.49710745310},
	abstract = {Attention is focused on the use of numerical formulations of the Sommerfeld radiation condition δΦ/δt + cδΦ/δx = 0 as a lateral boundary condition. This numerical boundary condition which originally used the leap frog scheme (Orlanski 1976) is shown to be made more accurate by the use of the upstream method. In this form it is tested in a two-dimensional model of a density current and is stable. the boundary becomes effectively transparent to incident disturbances, even under the severe test of allowing the density current head to propagate upstream and through the boundary, thus changing initial inflow to strong outflow. An analysis is presented of various extrapolation and radiation boundary conditions, involving calculation of their accuracy for waves and more general solutions. the leading terms in the truncation error are compared, and for general disturbances some have second order accuracy, while for solutions of the wave equation, it is shown that the radiation condition is third order. It can be made fourth order, for both leapfrog and upstream differencing, by the use of an extrapolation formula to give a better numerical estimate for c. This condition derives its greater accuracy from the use of values at seven (space and time) gridpoints, in contrast to the original scheme which used four, and standard extrapolation formulae which use, at most, three points.},
	language = {en},
	number = {453},
	urldate = {2017-10-18},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Miller, M. J. and Thorpe, A. J.},
	month = jul,
	year = {1981},
	pages = {615--628}
}

@misc{noauthor_computer_nodate,
	title = {Computer {Solution} of {Large} {Linear} {Systems} - {Gerard} {Meurant} - {Google} {Books}},
	url = {https://books.google.com/books?hl=en&lr=&id=fSqfb5a3WrwC&oi=fnd&pg=PP1&dq=Computer+solution+of+large+linear+systems.+&ots=ESSw6K2sk0&sig=7L7aO8amXIapKuxjxNuwUiEGyJo#v=onepage&q=Computer%20solution%20of%20large%20linear%20systems.&f=false},
	urldate = {2017-10-18}
}

@book{bengtsson_dynamic_1981,
	address = {New York, NY},
	series = {Applied {Mathematical} {Sciences}},
	title = {Dynamic {Meteorology}: {Data} {Assimilation} {Methods}},
	volume = {36},
	isbn = {978-0-387-90632-4 978-1-4612-5970-1},
	shorttitle = {Dynamic {Meteorology}},
	url = {http://link.springer.com/10.1007/978-1-4612-5970-1},
	publisher = {Springer New York},
	editor = {Bengtsson, Lennart and Ghil, Michael and Källén, Erland},
	year = {1981},
	doi = {10.1007/978-1-4612-5970-1}
}

@article{mesinger_dynamics_1997,
	title = {Dynamics of limited-area models: {Formulation} and numerical methods},
	volume = {63},
	issn = {0177-7971, 1436-5065},
	shorttitle = {Dynamics of limited-area models},
	url = {https://link.springer.com/article/10.1007/BF01025360},
	doi = {10.1007/BF01025360},
	abstract = {SummaryFollowing a few historical remarks, approximations used in formulating the “dynamics” of limited-area and variable resolution atmospheric forecasting models are reviewed. Particular attention is given to current efforts to relax or remove the hydrostatic approximation.Turning to numerical methods used in discretizing the equations, an attempt is made to record recent work and to clarify the motivation for the various approaches being followed by different modeling centers. Topics commented upon include: semi-Lagrangian methods, numerical formulation of nonhydrostatic models, resolution, the eta (step-mountain) vs sigma or isentropic/sigma vertical coordinate, choice of the vertical grid, numerics of the propagation of gravity waves, and the box-average vs pointsample treatment of predicted variables.It is finally pointed out that the extraordinary diversity of roads being taken shows that a lot remains to be discovered as to what possible rewards may be found in exploring one or the other of the principles underlying the methods being developed.},
	language = {en},
	number = {1-2},
	urldate = {2017-10-18},
	journal = {Meteorology and Atmospheric Physics},
	author = {Mesinger, F.},
	month = mar,
	year = {1997},
	pages = {3--14}
}

@article{mesinger_improvements_1996,
	title = {Improvements in {Quantitative} {Precipitation} {Forecasts} with the {Eta} {Regional} {Model} at the {National} {Centers} for {Environmental} {Prediction}: {The} 48-km {Upgrade}},
	volume = {77},
	issn = {0003-0007},
	shorttitle = {Improvements in {Quantitative} {Precipitation} {Forecasts} with the {Eta} {Regional} {Model} at the {National} {Centers} for {Environmental} {Prediction}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0477(1996)077%3C2637%3AIIQPFW%3E2.0.CO%3B2},
	doi = {10.1175/1520-0477(1996)077<2637:IIQPFW>2.0.CO;2},
	abstract = {Since 9 June 1993, the eta coordinate regional model has been run twice daily at the National Centers for Environmental Prediction (NCEP, previously the National Meteorological Center) as the NCEP's “early” operational model. Its performance is regularly monitored in a variety of ways, with particular attention given to precipitation forecasts. Throughout this period, the eta model has demonstrated significantly increased accuracy in forecasting daily precipitation amounts compared to NCEP's Nested Grid Model (NGM). The model has shown a smaller but equally consistent advantage in skill against that of NCEP's global spectral model. Precipitation scores of these three operational models for the 6-month period March-August 1995 are presented. This interval is chosen because the 6-month-long periods September-February and March-August have been used in previous model comparisons and because an upgraded version of the eta model, run at 48-km resolution, was also regularly executed twice daily during the March-August 1995 period. It is thus included and highlighted in the present comparison. The 48-km eta carries cloud water as a prognostic variable and is coupled to a 12-h eta-based intermittent data assimilation system. It replaced the 80-km eta as the NCEP's early operational model on 12 October 1995. Compared to the then-operational 80-km eta, the 48-km eta has demonstrated substantially increased skill at all eight precipitation categories for which verifications are made. The increase in skill was greatest for the most intense precipitation, at the threshold of 2 in. (24 h)−1. A 24–48-h forecast of accumulated precipitation, resulting from Hurricane Allison as it was crossing the extreme southeastern United States, is shown as an example of a successful forecast of intense precipitation by the 48-km model. Reasons for the advantage of the eta model over its predecessor, the NGM, are reviewed. The work in progress is outlined.},
	number = {11},
	urldate = {2017-10-18},
	journal = {Bulletin of the American Meteorological Society},
	author = {Mesinger, Fedor},
	month = nov,
	year = {1996},
	pages = {2637--2649}
}

@article{mesinger_step-mountain_1988,
	title = {The {Step}-{Mountain} {Coordinate}: {Model} {Description} and {Performance} for {Cases} of {Alpine} {Lee} {Cyclogenesis} and for a {Case} of an {Appalachian} {Redevelopment}},
	volume = {116},
	issn = {0027-0644},
	shorttitle = {The {Step}-{Mountain} {Coordinate}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1988)116%3C1493:TSMCMD%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1988)116<1493:TSMCMD>2.0.CO;2},
	abstract = {The problem of the pressure gradient force error in the case of the terrain-following (sigma) coordinate does not appear to have a solution. The problem is not one of truncation error in the calculation of space derivatives involved. Thus, with temperature profiles resulting in large errors, an increase in vertical resolution may not reduce and is even likely to increase the error. Therefore, an approach abandoning the sigma system has been proposed. It involves the use of “step” mountains with coordinate surfaces prescribed to remain at fixed elevations at places where they touch (and define) or intersect the ground surface. Thus, the coordinate surfaces are quasi-horizontal, and the sigma system problem is not present. At the same time, the simplicity of the sigma system is maintained. In this paper, design of the model (“silhouette” averaged) mountains, properties of the wall boundary condition, and the scheme for calculation of the potential to kinetic energy conversion are presented. For an advection scheme achieving a strict control of the nonlinear energy cascade on the semistaggered grid, it is demonstrated that a straightforward no-slip wall boundary condition maintains conservation properties of the scheme with no vertical walls, which are important from the point of view of the control of this energy cascade from large to small scales. However, with that simple boundary condition considered, momentum is not conserved. The scheme conserving energy in conversion between the potential and kinetic energy, given earlier for the one-dimensional case, is extended to two dimensions. Results of real data experiments are described, testing the performance of the resulting “Step-mountain” model. An attractive feature of a step-mountain (“eta”) model is that it can easily be run as a sigma system model, the only difference being the definition of ground surface grid point values of the vertical coordinate. This permits a comparison of the sigma and the eta formulations. Two experiments of this kind have been made, with a model version including realistic steep mountains (steps at 290, 1112 and 2433 m). They have both revealed a substantial amount of noise resulting from the sigma, as compared to the eta, formulation. One of these experiments, especially with the step mountains, gave a rather successful simulation of the perhaps difficult “historic” Buzzi–Tibaldi case of Genoa lee cyclogenesis. A parallel experiment showed that, starting with the same initial data, one obtains no cyclogenesis without mountains. Still, the mountains experiment did simulate the accompanying midtropospheric cutoff, a phenomenon that apparently has not been reproduced in previous simulations of mountain-induced Genoa lee cyclogeneses. For a North American limited area region, experimental step-mountain simulations were performed for a case of March 1984, involving development of a secondary storm southeast of the Appalachians. Neither the then operational U.S. National Meteorological Center's Limited Area Forecast Model (LFM) nor the recently introduced Nested Grid Model (NGM) were successful in simulating the redevelopment. On the other hand, the step-mountain model, with a space resolution set up to mimic that of NGM, successfully simulated the ridging that indicates the redevelopment.},
	number = {7},
	urldate = {2017-10-18},
	journal = {Monthly Weather Review},
	author = {Mesinger, Fedor and Janjić, Zaviša I. and Ničković, Slobodan and Gavrilov, Dušanka and Deaven, Dennis G.},
	month = jul,
	year = {1988},
	pages = {1493--1518}
}

@article{mesinger_problems_1985,
	title = {Problems and numerical methods of the incorporation of mountains in atmospheric models},
	volume = {22},
	journal = {Lectures in Applied Mathematics},
	author = {Mesinger, Fedor and Janjic, Zavisa I.},
	year = {1985},
	pages = {81--120}
}

@article{cahalan_albedo_1994,
	title = {The {Albedo} of {Fractal} {Stratocumulus} {Clouds}},
	volume = {51},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469%281994%29051%3C2434%3ATAOFSC%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1994)051<2434:TAOFSC>2.0.CO;2},
	abstract = {An increase in the planetary albedo of the earth-atmosphere system by only 10\% can decrease the equilibrium surface temperature to that of the last ice age. Nevertheless, albedo biases of 10\% or greater would be introduced into large regions of current climate models if clouds were given their observed liquid water amounts, because of the treatment of clouds as plane parallel. Past work has addressed the effect of cloud shape on albedo; here the focus is on the within-cloud variability of the vertically integrated liquid water. The main result is an estimate of the “plane-parallel albedo bias” using the “independent pixel approximation,” which ignores net horizontal photon transport, from a simple fractal model of marine stratocumulus clouds that ignores the cloud shape. The use of the independent pixel approximation in this context will be justified in a separate Monte Carlo study. The focus on marine stratocumulus clouds is due to their important role in cloud radiative forcing and also that, of the wide variety of earth's cloud types, they are most nearly plane parallel, so that they have the least albedo bias. The fractal model employed here reproduces both the probability distribution and the wavenumber spectrum of the stratocumulus liquid water path, as observed during the First ISCCP Regional Experiment (FIRE). The model distributes the liquid water by a cascade process, related to the upscale cascade of energy transferred from the cloud thickness scale to the mesoscale by approximately 2D motions. For simplicity, the cloud microphysical parameters are assumed homogeneous, as is the geometrical cloud thickness; and the mesoscale-averaged vertical optical thickness is kept fixed at each step of the cascade. A single new fractal parameter, 0 ≤ f ≤ 1, is introduced and determined empirically by the variance of the logarithm of the vertically integrated liquid water. In the case of conservative scattering, the authors are able to estimate the albedo bias analytically as a function of the fractal parameter f, mean vertical optical thickness Tν, and sun angle θ. Typical observed values are f = 0.5, Tν = 15, and θ = 60°, which give an absolute bias of 0.09, or a relative bias equal to 15\% of the plane-parallel albedo of 0.60. The reduced reflectivity of fractal stratocumulus clouds is approximately given by the plane-parallel reflectivity evaluated at a reduced “effective optical thickness,” which when f = 0.5 is Teff ≈ 10. Study of the diurnal cycle of stratocumulus liquid water during FIRE leads to a key unexpected result: the plane-parallel albedo bias is largest when the cloud fraction reaches 100\%, that is, when any bias associated with the cloud fraction vanishes. This is primarily due to the variability increase with cloud fraction. Thus, the within-cloud fractal structure of stratocumulus has a more significant impact on estimates of its mesoscale-average albedo than does the cloud fraction.},
	number = {16},
	journal = {Journal of the Atmospheric Sciences},
	author = {Cahalan, Robert F. and Ridgway, William and Wiscombe, Warren J. and Bell, Thomas L. and Snider, Jack B.},
	month = aug,
	year = {1994},
	pages = {2434--2455}
}

@article{baer_extended_1961,
	title = {The extended numerical integration of a simple barotropic model},
	volume = {18},
	issn = {0095-9634},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1961)018%3C0319%3ATENIOA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1961)018<0319:TENIOA>2.0.CO;2},
	abstract = {A simple barotropic model is integrated for 39 days by one-hour time steps over 94 per cent of the earth's surface. By suitably smoothing the stream function at each time step, time truncation errors are controlled and the total energy of the system varies within only two per cent of the initial value over the entire integration period. By initiating the integration with energy in the mean flow and in planetary waves one and three, a pronounced periodic exchange of energy is observed over the integration period. The predominant periodicity is a six-day exchange between planetary wave number three and the mean flow. The energy distribution in the higher wave numbers appears to be capable of a statistical interpretation.},
	number = {3},
	journal = {Journal of Meteorology},
	author = {Baer, Ferdinand},
	month = jun,
	year = {1961},
	pages = {319--339}
}

@article{caian_limits_1997,
	title = {Some limits to the variable-mesh solution and comparison with the nested-lam solution},
	volume = {123},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49712353911/abstract},
	doi = {10.1002/qj.49712353911},
	abstract = {The solution at high resolution of a global spectral model with a conformally-variable mesh, obtained through a stretched coordinate, is compared as fairly as possible to the ‘classical’ solution of a limited-area nested model. We compare the global, variable-mesh, ARPEGE model at hyper-stretched values (which is integrated operationally at Météo-France with a ‘low’ value of stretching) with its limited-area version, the ALADIN model. Having the same physics, the same grid-point dynamics and a high code-compatibility, they allow clean comparisons on real situations. to conclude on their efficiency and accuracy, comparisons are made choosing configurations of the two models having either the same resolution or the same computational price. The limits of the variable-mesh strategy on the sphere are also investigated through a set of experiments with increasing stretching. We found that there is indeed a limit to the stretching factor in the interval [7, 9]: a stretching factor c = 7 keeps an accurate spectral solution and gives satisfying results, even when compared with the limited-area model at the same computational price. We show that the value c = 10.5 cannot be reached without paying the price of a spectral deformation of the fields which becomes too obvious. Additional tests showed the occurrence of this deformation, even if less pronounced, at the stretching value c = 8.75. At the same resolution ALADIN does not manifest any similar weakness. Although the solution remains stable for at least 72 hours, its accuracy when increasing the stretching above the critical value becomes questionable. This problem seems to be due to a particular behaviour of the truncation error, which does not decrease with increasing resolution through stretching, thus leading to an energy accumulation in the tail of the spectra. As a conclusion of this study, it follows that one can extend the idea of Courtier and Geleyn, currently used in operations at Météo-France for c = 3.5, to ‘medium’ stretched configurations up to c = 7 at least (at the current computer's power). Above a value found to be about c = 9, our results show that increasing the resolution does not produce any improvement and, hence, that the use of a limited-area model appears a better choice for very high resolutions.},
	language = {en},
	number = {539},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Caian, Mihaela and Geleyn, Jean-François},
	month = apr,
	year = {1997},
	keywords = {Numerical methods, Global spectral model, Regional forecasting, Stretched coordinates},
	pages = {743--766}
}

@article{mesinger_blocking_1984,
	title = {A blocking technique for representation of mountains in atmospheric models},
	volume = {44},
	issn = {0035-6328},
	url = {http://cat.inist.fr/?aModele=afficheN&cpsidt=8419610},
	language = {eng},
	number = {1-4},
	urldate = {2017-10-18},
	journal = {Rivista di Meteorologia Aeronautica},
	author = {Mesinger, F.},
	year = {1984},
	pages = {195--202}
}

@article{burridge_split_1975,
	title = {A split semi-implict reformulation of the {Bushby}-{Timpson} 10-level model},
	volume = {101},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49710143006/abstract},
	doi = {10.1002/qj.49710143006},
	abstract = {A split semi-implicit reformulation of the Bushby-Timpson 10–level model is described. The integration cycle is split into two main parts. Firstly, the dependent variables are advected by the wind using the explicit two-step Lax-Wendroff integration scheme with the grid staggered in time and space. Secondly, these advected values are adjusted to account for the terms that govern the motion of small amplitude inertio-gravity waves in the model, using a combination of an unconditionally stable implicit scheme and a conditionally stable explicit scheme. A novel feature of the scheme is the implicit treatment of only two of the model's ten gravity wave modes. This split semi-implicit scheme is more than four times as efficient as the original explicit scheme designed by Bushby and Timpson. The results of one semi-implicit integration to 36 hours are described and compared with an integration made with Bushby and Timpson's original explicit scheme.},
	language = {en},
	number = {430},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Burridge, D. M.},
	month = oct,
	year = {1975},
	pages = {777--792}
}

@article{burgers_analysis_1998,
	title = {Analysis {Scheme} in the {Ensemble} {Kalman} {Filter}},
	volume = {126},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281998%29126%3C1719%3AASITEK%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1998)126<1719:ASITEK>2.0.CO;2},
	abstract = {This paper discusses an important issue related to the implementation and interpretation of the analysis scheme in the ensemble Kalman filter. It is shown that the observations must be treated as random variables at the analysis steps. That is, one should add random perturbations with the correct statistics to the observations and generate an ensemble of observations that then is used in updating the ensemble of model states. Traditionally, this has not been done in previous applications of the ensemble Kalman filter and, as will be shown, this has resulted in an updated ensemble with a variance that is too low. This simple modification of the analysis scheme results in a completely consistent approach if the covariance of the ensemble of model states is interpreted as the prediction error covariance, and there are no further requirements on the ensemble Kalman filter method, except for the use of an ensemble of sufficient size. Thus, there is a unique correspondence between the error statistics from the ensemble Kalman filter and the standard Kalman filter approach.},
	number = {6},
	journal = {Monthly Weather Review},
	author = {Burgers, Gerrit and Jan van Leeuwen, Peter and Evensen, Geir},
	month = jun,
	year = {1998},
	pages = {1719--1724}
}

@article{bubnova_integration_1995,
	title = {Integration of the {Fully} {Elastic} {Equations} {Cast} in the {Hydrostatic} {Pressure} {Terrain}-{Following} {Coordinate} in the {Framework} of the {ARPEGE}/{Aladin} {NWP} {System}},
	volume = {123},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281995%29123%3C0515%3AIOTFEE%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1995)123<0515:IOTFEE>2.0.CO;2},
	abstract = {ARPEGE/Aladin is a limited-area 3D primitive equation model, which belongs to the integrated NWP ARPEGE/IFS system. Like its global counterpart, the limited-area version has a spectral representation of variables in the horizontal but uses double-Fourier series instead of the classical spherical harmonies, in the manner introduced by Machenhauer and Haugen. Following the suggestion of Laprise, a nonhydrostatic version of ARPEGE/Aladin has been developed using hydrostatic pressure as an independent variable. The dynamics employ the fully elastic Euler equations of motion, orography being introduced via a terrain-following hybrid coordinate. A semi-implicit scheme has been formulated to control both acoustic and gravity waves. The discrete linear operators appear to have the same form as in the hydrostatic dynamics, except an additional one representing the vertical part of the Laplacian operator. To keep an elegant elimination, it was necessary to modify the approximation of logarithmic thicknesses of the model layers. It is noteworthy that the Helmholtz matrix has a tridiagonal form, confirming a local character to the nonhydrostatic dynamics. The representation of the horizontal pressure gradient term fulfills the rules of conservation of energy and angular momentum. Some instability problems were encountered and it was thus necessary to introduce an additional semi-implicit type of correction of the nonlinear part of the total 3D divergence, a solution that calls for iterations of the semi-implicit scheme. The results of a few idealized numerical simulations and of a real situation are presented.},
	number = {2},
	journal = {Monthly Weather Review},
	author = {Bubnová, Radmila and Hello, Gwenaëlle and Bénard, Pierre and Geleyn, Jean-François},
	month = feb,
	year = {1995},
	pages = {515--535}
}

@article{buizza_stochastic_1999,
	title = {Stochastic representation of model uncertainties in the {ECMWF} ensemble prediction system},
	volume = {125},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49712556006/abstract},
	doi = {10.1002/qj.49712556006},
	abstract = {A stochastic representation of random error associated with parametrized physical processes (‘stochastic physics’) is described, and its impact in the European Centre for Medium-Range Weather Forecasts Ensemble Prediction System (ECMWF EPS) is discussed. Model random errors associated with physical parametrizations are simulated by multiplying the total parametrized tendencies by a random number sampled from a uniform distribution between 0.5 and 1.5. A number of diagnostics are described and a choice of parameters is made. It is shown how the scheme increases the spread of the ensemble, and improves the skill of the probabilistic prediction of weather parameters such as precipitation. A choice of stochastic parameters is made for operational implementation. the scheme was implemented successfully in the operational ECMWF EPS on 21 October 1998.},
	language = {en},
	number = {560},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Buizza, R. and Milleer, M. and Palmer, T. N.},
	month = oct,
	year = {1999},
	keywords = {Numerical weather prediction, Ensemble forecasting, Model errors, Parametrization},
	pages = {2887--2908}
}

@article{mesinger_forward-backward_1977,
	title = {Forward-backward scheme, and its use in a limited area model},
	volume = {50},
	number = {1977},
	journal = {Contrib. Atmos. Phys},
	author = {Mesinger, Fedor},
	year = {1977},
	pages = {200--210}
}

@article{buizza_potential_1997,
	title = {Potential {Forecast} {Skill} of {Ensemble} {Prediction} and {Spread} and {Skill} {Distributions} of the {ECMWF} {Ensemble} {Prediction} {System}},
	volume = {125},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281997%29125%3C0099%3APFSOEP%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1997)125<0099:PFSOEP>2.0.CO;2},
	abstract = {Ensemble forecasting is a feasible method to integrate a deterministic forecast with an estimate of the probability distribution of atmospheric states. At the European Centre for Medium-Range Weather Forecasts (ECMWF), the Ensemble Prediction System (EPS) comprises 32 perturbed and 1 unperturbed nonlinear integrations, at T63 spectral triangular truncation and with 19 vertical levels. The perturbed initial conditions are generated using the most unstable directions growing over a 48-h time period, computed at T42L19 resolution. This work describes the performance of the ECMWF EPS during the first 21 months of daily operation, from 1 May 1994 to 31 January 1996, focusing on the 500-hPa geopotential height fields. First, the EPS is described, and the validation approach followed throughout this work is discussed. In particular, spread and skill distribution functions are introduced to define a more integral validation methodology for ensemble prediction. Then, the potential forecast skill of ensemble prediction is estimated considering one ensemble member as verification (perfect ensemble assumption). In particular, the ratio between ensemble spread and control error is computed, and the potential correlation between ensemble spread and control forecast skill is evaluated. The results obtained within the perfect ensemble hypothesis give estimates of the limits of forecast skill to be expected for the ECMWF EPS. Finally, the EPS is validated against analysis fields, and the EPS skill is compared with the skill of the perfect ensemble. Results indicate that the EPS spread is smaller than the distance between the control forecast and the analysis. Considering ensemble spread–control skill scatter diagrams, a so-called faulty index is introduced to estimate the percentage of wrongly predicted cases with small spread/high control skill. Results suggest that there is some correspondence between small ensemble spread and high control skill. Considering the 500-hPa geopotential height field over the Northern Hemisphere at forecast day 7, approximately 20\% (45\%) of the perturbed ensemble members have anomaly correlation skill higher than 0.6 during warm (cold) seasons, respectively. The percentage of analysis values lying outside the EPS forecast range is thought to be still too high.},
	number = {1},
	journal = {Monthly Weather Review},
	author = {Buizza, Roberto},
	month = jan,
	year = {1997},
	pages = {99--119}
}

@article{buizza_singular-vector_1995,
	title = {The {Singular}-{Vector} {Structure} of the {Atmospheric} {Global} {Circulation}},
	volume = {52},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469%281995%29052%3C1434%3ATSVSOT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1995)052<1434:TSVSOT>2.0.CO;2},
	abstract = {The local phase-space instability Of the atmospheric global circulation is Characterized by its (nonmodal) singular vectors. The formalism of singular vector analysis is described. The relations between singular vectors, normal modes, adjoint modes, Lyapunov vectors, perturbations produced by the so-called breeding method, and wave pseudomomentum are outlined. Techniques to estimate the dominant part of the singular spectrum using large-dimensional primitive equation models are discussed. These include the use of forward and adjoint tangent propagators with a Lanczos iterative algorithm. Results are described, based first on statistics of routine calculations made between December 1992 and August 1993, and second on three specific case studies. Results define three dominant geographical areas of instability in the Northern Hemisphere: the two regions of storm track cyclogenesis, and the North African subtropical jet Singular vectors can amplify as much as tenfold over 36 hours, and in winter there are typically at least 35 independent singular vectors, which quadruple in amplitude over this timescale. Qualitatively, the distribution of singular vectors can be associated with a simple diagnostic of baroclinic instability from the basic-state flow. However, this relationship is not quantitatively reliable, as, for example, the chosen diagnostic takes no account of the horizontal or time-varying structure of the basic-state flow. Three basic types of singular vector are identified The most important and most frequent is located in mid latitudes. At initial time, the singular vector is localized in the horizontal, with most amplitude in the lower troposphere. Energy growth can be interpreted qualitatively in terms of wave pseudomomentum propagation into the jet, resulting in peak amplitudes in the upper troposphere at optimization time. During evolution the dominant horizontal wavenumber of the singular vector decreases. Singular vector growth is therefore fundamentally nonmodal. Singular vectors 1ocalized first in the tropical upper troposphere. and second with equivalent barotropic structure in the high-latitude troposhpere, are also identified.},
	number = {9},
	journal = {Journal of the Atmospheric Sciences},
	author = {Buizza, R. and Palmer, T. N.},
	month = may,
	year = {1995},
	pages = {1434--1456}
}

@article{bushby_use_1956,
	title = {The use of a stream function in a two-parameter model of the atmosphere},
	volume = {82},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49708235404/abstract},
	doi = {10.1002/qj.49708235404},
	abstract = {In an attempt to obtain a better approximation to the horizontal flow of a non-divergent fluid than the geostrophic approximation, a Monge-Ampère type of partial differential equation, similar to that of Charney (1955), is derived to enable a stream function to be found from the contour height field. A method is given for the numerical solution of this equation. The stream function has been used in place of the contour height parameter to represent the flow at the mean level in computing three 24 hr forecasts based on the Sawyer-Bushby two-parameter model of the atmosphere, and the results are compared with similar computations without the stream function. In one situation, the use of the stream function produced a marked improvement in the computation.},
	language = {en},
	number = {354},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Bushby, F. H. and Huckle, Vera M.},
	month = oct,
	year = {1956},
	pages = {409--418}
}

@article{buell_variability_1972,
	title = {Variability of {Wind} with {Distance} and {Time} on an {Isobaric} {Surface}},
	volume = {11},
	issn = {0021-8952},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0450%281972%29011%3C1085%3AVOWWDA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0450(1972)011<1085:VOWWDA>2.0.CO;2},
	abstract = {Maps of the contours for the two-point wind correlation coefficient for zonal and meridional components over North America are shown for time lags of −3, −2, −1, 0, +1, +2, +3 days at the 500-mb level, winter. The applications to Taylor's hypothesis and to diffusion in the atmosphere are discussed.},
	number = {7},
	journal = {Journal of Applied Meteorology},
	author = {Buell, C. Eugene},
	month = oct,
	year = {1972},
	pages = {1085--1091}
}

@article{buell_correlation_1972,
	title = {Correlation {Functions} for {Wind} and {Geopotential} on {Isobaric} {Surfaces}},
	volume = {11},
	issn = {0021-8952},
	url = {http://www.jstor.org/stable/26175541},
	abstract = {The fact that the geostrophic wind equations describe a large fraction of the relation between wind and geopotential and that the atmosphere approximates horizontal homogeneity and is nearly isotropic leads to two differential equations relating the correlation coefficients for geopotential with those for longitudinal and transverse wind components. Consequently, empirical formulas for any one of these correlation coefficients cannot be reasonably considered without reference to both the others. A family of three such related correlation coefficients must simultaneously fit observed correlations for all three quantities concerned. Several such self-consistent sets of correlation coefficients are compared with the data.},
	number = {1},
	journal = {Journal of Applied Meteorology (1962-1982)},
	author = {Buell, C. Eugene},
	year = {1972},
	pages = {51--59}
}

@article{buell_two-point_1971,
	title = {Two-{Point} {Wind} {Correlations} on an {Isobaric} {Surface} in a {Nonhomogeneous} {Non}-{Isotropic} {Atmosphere}},
	volume = {10},
	issn = {0021-8952},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0450%281971%29010%3C1266%3ATPWCOA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0450(1971)010<1266:TPWCOA>2.0.CO;2},
	abstract = {The approximate relations between the correlation coefficient for geopotential, the longitudinal wind component, and the transverse wind component on an isobaric surface in the case of an homogeneous isotropic atmosphere are discussed briefly. Corresponding approximate relations for a nonhomogeneous and non-isotropic atmosphere are presented. The mixed correlations for wind component (longitudinal with transverse, and vice versa) are no longer identically zero (as was the case for the homogeneous isotropic atmosphere). Approximate expressions for these mixed correlation coefficient functions are presented in terms of the correlation coefficient for geopotential. It is shown that the general configuration of values computed from observed winds are those expected from theoretical considerations.},
	number = {6},
	journal = {Journal of Applied Meteorology},
	author = {Buell, C. Eugene},
	month = dec,
	year = {1971},
	pages = {1266--1274}
}

@incollection{bube_assimilation_1981,
	series = {Applied {Mathematical} {Sciences}},
	title = {Assimilation of {Asynoptic} {Data} and the {Initialization} {Problem}},
	isbn = {978-0-387-90632-4 978-1-4612-5970-1},
	url = {https://link.springer.com/chapter/10.1007/978-1-4612-5970-1_4},
	abstract = {We discuss a mathematical framework for the use of asynoptic data in determining initial states for numerical weather prediction (NWP) models. A set of measured data, synoptic and asynoptic, is termed complete if it determines the solution of an NWP model uniquely. We derive theoretical criteria for the completeness of data sets. The practical construction of the solution from a complete data set by intermittent updating is analyzed, and the rate of convergence of some updating procedures is given.It is shown that the time history of the mass field constitutes a complete data set for the shallow-water equations. Given that the time derivatives of the mass field are small at initial time, we prove that the velocity field obtained by the diagnostic equations we derive will also have small time derivatives. Hence our diagnostic equations also solve the initialization problem for this system, namely they provide an initial state which leads to a slowly evolving solution to the system.Finally, we review the bounded derivative principle of Kreiss. It states that in systems with a fast and a slow time scale, initial data can be chosen so that the solution starts out slowly. For such initial data, the solution will actually stay slow for a length of time comparable to the slow time scale. The application of the principle to the initialization problem of NWP is discussed.},
	language = {en},
	urldate = {2017-10-18},
	booktitle = {Dynamic {Meteorology}: {Data} {Assimilation} {Methods}},
	publisher = {Springer, New York, NY},
	author = {Bube, K. P. and Ghil, M.},
	year = {1981},
	doi = {10.1007/978-1-4612-5970-1_4},
	pages = {111--138}
}

@book{bruaset_survey_1995,
	title = {A {Survey} of {Preconditioned} {Iterative} {Methods}},
	isbn = {978-0-582-27654-3},
	abstract = {The problem of solving large, sparse, linear systems of algebraic equations is vital in scientific computing, even for applications originating from quite different fields. A Survey of Preconditioned Iterative Methods presents an up to date overview of iterative methods for numerical solution of such systems. Typically, the methods considered are well suited for the kind of systems arising from the discretization of partial differential equations. The focus of this presentation is on the family of Krylov subspace solvers, of which the Conjugate Gradient algorithm is a typical example. In addition to an introduction to the basic principles of such methods, a large number of specific algorithms for symmetric and nonsymmetric problems are discussed.When solving linear systems by iteration, a preconditioner is usually introduced in order to speed up convergence. In many cases, the selection of a proper preconditioner is crucial to the resulting computational performance. For this reason, this book pays special attention to different preconditioning strategies.Although aimed at a wide audience, the presentation assumes that the reader has basic knowledge of linear algebra, and to some extent, of partial differential equations. The comprehensive bibliography in this survey is provides an entry point to the enormous amount of published research in the field of iterative methods.},
	language = {en},
	publisher = {CRC Press},
	author = {Bruaset, Are Magnus},
	month = may,
	year = {1995},
	note = {Google-Books-ID: hubxyVnwW2kC},
	keywords = {Mathematics / Applied}
}

@article{atlas_atmospheric_1997,
	title = {Atmospheric {Observations} and {Experiments} to {Assess} {Their} {Usefulness} in {Data} {Assimilation} ({gtSpecial} {IssueltData} {Assimilation} in {Meteology} and {Oceanography}: {Theory} and {Practice})},
	volume = {75},
	shorttitle = {Atmospheric {Observations} and {Experiments} to {Assess} {Their} {Usefulness} in {Data} {Assimilation} ({gtSpecial} {IssueltData} {Assimilation} in {Meteology} and {Oceanography}},
	abstract = {Atmospheric observations consist of a mixture of in situ, visual, and remotely sensed observations. These provide an extensive database for research and numerical weather prediction. However, significant data deficiencies still exist, and new observing systems are continually being proposed. Observing system experiments (OSE's) are conducted to assess the usefulness of different types of existing atmospheric observations. Observing system simulation experiments (OSSE's) are conducted to evaluate the potential impact of proposed observing systems, as well as to determine tradeoffs in their design, and to evaluate data assimilation methodology. This paper contains a review of the development of the global atmospheric observing system, a description of the principal types of data, an overview of OSE and OSSE methodology, and results from recent experiments to evaluate the relative utility of the principal atmospheric observing systems and the potential for new observing systems. These experiments show the critical contributions being made by both conventional and space-based observations, and indicate considerable potential for future satellite observing systems to improve data assimilation.},
	number = {1B},
	journal = {Journal of the Meteorological Society of Japan. Ser. II},
	author = {Atlas, Robert},
	year = {1997},
	pages = {111--130}
}

@book{anderson_computational_1984,
	title = {Computational fluid mechanics and heat transfer},
	isbn = {978-0-89116-471-5},
	language = {en},
	publisher = {Hemisphere Pub. Corp.},
	author = {Anderson, Dale A. and Tannehill, John C. and Pletcher, Richard H.},
	month = jan,
	year = {1984},
	keywords = {Science / Mechanics / Fluids, Science / Mechanics / General, Technology \& Engineering / Mechanical, fluid mechanics, Heat, Science / Mechanics / Thermodynamics}
}

@article{arakawa_adjustment_1997,
	title = {Adjustment mechanisms in atmospheric models},
	volume = {75},
	journal = {JOURNAL-METEOROLOGICAL SOCIETY OF JAPAN SERIES 2},
	author = {Arakawa, Akio},
	year = {1997},
	pages = {45--69}
}

@article{arakawa_numerical_1970,
	series = {Proceedings of the {American} {Mathematical} {Society}},
	title = {Numerical simulation of large-scale atmospheric motions},
	volume = {2},
	url = {http://books.google.com/books?hl=en&lr=&id=UL-AKvVJV3cC&oi=fnd&pg=PA24&dq=arakawa+1970+numerical&ots=WHXgq00L1F&sig=o9miTw-flVX1vl2Z_a1Yv_3wOkE},
	urldate = {2013-09-13},
	journal = {Numerical Solution of Field Problems in Continuum Physics},
	author = {Arakawa, Akio},
	year = {1970},
	pages = {24--40}
}

@incollection{aber_terrestrial_1992,
	title = {Terrestrial ecosystems},
	isbn = {978-0-521-43231-3},
	language = {English},
	booktitle = {Climate {System} {Modeling}},
	publisher = {Cambridge University Press},
	author = {Aber, John D.},
	editor = {Trenberth, Kevin E.},
	year = {1992},
	pages = {Chapter 6: 173 -- 200}
}

@article{asselin_frequency_1972,
	title = {Frequency filter for time integrations},
	volume = {100},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1972)100%3C0487:FFFTI%3E2.3.CO;2},
	number = {6},
	urldate = {2013-09-13},
	journal = {Monthly Weather Review},
	author = {Asselin, Richard},
	year = {1972},
	pages = {487--490}
}

@article{anderson_method_1996,
	title = {A method for producing and evaluating probabilistic forecasts from ensemble model integrations},
	volume = {9},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0442(1996)009%3C1518%3AAMFPAE%3E2.0.CO%3B2},
	number = {7},
	urldate = {2013-09-13},
	journal = {Journal of Climate},
	author = {Anderson, Jeffrey L.},
	year = {1996},
	pages = {1518--1530}
}

@article{andersson_ecmwf_1998,
	title = {The {ECMWF} implementation of three-dimensional variational assimilation ({3D}-{Var}). {III}: {Experimental} results},
	volume = {124},
	shorttitle = {The {ECMWF} implementation of three-dimensional variational assimilation ({3D}-{Var}). {III}},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49712455004/abstract},
	number = {550},
	urldate = {2013-09-13},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Andersson, Erik and Haseler, Jan and Undén, Per and Courtier, Philippe and Kelly, Graeme and Vasiljevic, Drasko and Brankovic, Cedo and Gaffard, Catherine and Hollingsworth, Anthony and Jakob, Christian},
	year = {1998},
	pages = {1831--1860}
}

@article{arakawa_vertical_1996,
	title = {Vertical {Differencing} of the {Primitive} {Equations} {Based} on the {Charney}-{Phillips} {Grid} in {Hybrid} \${\textbackslash}sigma-p\$ {Vertical} {Coordinates}},
	volume = {124},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1996)124%3C0511%3AVDOTPE%3E2.0.CO%3B2},
	number = {3},
	urldate = {2013-09-13},
	journal = {Monthly weather review},
	author = {Arakawa, Akio and Konor, Celal S.},
	year = {1996},
	pages = {511--528}
}

@book{alligood_chaos_1996,
	edition = {1st - Corrected},
	title = {Chaos - {An} {Introduction} to {Dynamical} {Systems}},
	isbn = {0-387-94677-2},
	publisher = {Springer},
	author = {Alligood, Kathleen T. and Sauer, Tim D. and Yorke, James A.},
	month = nov,
	year = {1996}
}

@article{atger_skill_1999,
	title = {The skill of ensemble prediction systems},
	volume = {127},
	url = {http://journals.ametsoc.org/doi/pdf/10.1175/1520-0493(1999)127%3C1941:TSOEPS%3E2.0.CO;2},
	number = {9},
	urldate = {2013-09-13},
	journal = {Monthly Weather Review},
	author = {Atger, Frédéric},
	year = {1999},
	pages = {1941--1953}
}

@techreport{anthes_description_1987,
	title = {Description of the {Penn} {State}/{NCAR} {Mesoscale} {Model}, {Version} 4 ({MM4}). {Technical} note},
	url = {http://www.osti.gov/energycitations/product.biblio.jsp?osti_id=6419439},
	urldate = {2013-09-13},
	institution = {National Center for Atmospheric Research, Boulder, CO (USA)},
	author = {Anthes, R. A. and Hsie, E. Y. and Kuo, Y. H.},
	year = {1987}
}

@article{arakawa_computational_1966,
	title = {Computational design for long-term numerical integration of the equations of fluid motion: {Two}-dimensional incompressible flow. {Part} {I}},
	volume = {1},
	shorttitle = {Computational design for long-term numerical integration of the equations of fluid motion},
	url = {http://www.sciencedirect.com/science/article/pii/0021999166900155},
	number = {1},
	urldate = {2013-09-13},
	journal = {Journal of Computational Physics},
	author = {Arakawa, Akio},
	year = {1966},
	pages = {119--143}
}

@article{arakawa_interaction_1974,
	title = {Interaction of a cumulus cloud ensemble with the large-scale environment, {Part} {I}},
	volume = {31},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1974)031%3C0674:IOACCE%3E2.0.CO;2},
	number = {3},
	urldate = {2013-09-13},
	journal = {Journal of the Atmospheric Sciences},
	author = {Arakawa, Akio and Schubert, Wayne Howard},
	year = {1974},
	pages = {674--701}
}

@article{arakawa_vertical_1983,
	title = {Vertical differencing of the primitive equations in sigma coordinates},
	volume = {111},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1983)111%3C0034:VDOTPE%3E2.0.CO%3B2},
	number = {1},
	urldate = {2013-09-13},
	journal = {Monthly Weather Review},
	author = {Arakawa, Akio and Suarez, Max J.},
	year = {1983},
	pages = {34--45}
}

@article{arakawa_baroclinic_1988,
	title = {Baroclinic instability in vertically discrete systems},
	volume = {45},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1988)045%3C1688%3ABIIVDS%3E2.0.CO%3B2},
	number = {11},
	urldate = {2013-09-13},
	journal = {Journal of the atmospheric sciences},
	author = {Arakawa, Akio and Moorthi, Shrinivas},
	year = {1988},
	pages = {1688--1708}
}

@article{anthes_numerical_1970,
	title = {Numerical experiments with a two-dimensional horizontal variable grid},
	volume = {98},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1970)098%3C0810:NEWATD%3E2.3.CO%3B2},
	number = {11},
	urldate = {2013-09-13},
	journal = {Monthly Weather Review},
	author = {Anthes, Richard A.},
	year = {1970},
	pages = {810--822}
}

@article{arakawa_computational_1977,
	title = {Computational design of the basic dynamical processes of the {UCLA} general circulation model},
	volume = {17},
	url = {http://books.google.com/books?hl=en&lr=&id=nN_4561KTIIC&oi=fnd&pg=PA173&dq=arakawa+lamb+1977+ucla&ots=yJU84ij1es&sig=lYru9kLDsOA5q4COgzUJp30P6BE},
	urldate = {2013-09-13},
	journal = {Methods in computational physics},
	author = {Arakawa, Akio and Lamb, Vivian R.},
	year = {1977},
	pages = {173--265}
}

@article{anderson_variational_1999,
	title = {Variational quality control},
	volume = {125},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49712555416/abstract},
	number = {554},
	urldate = {2013-09-13},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Anderson, Erik and Järvinen, Heikki},
	year = {1999},
	pages = {697--722}
}

@article{anthes_regional_1983,
	title = {Regional models of the atmosphere in middle latitudes},
	volume = {111},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1983)111%3C1306:RMOTAI%3E2.0.CO%3B2},
	number = {6},
	urldate = {2013-09-13},
	journal = {Monthly weather review},
	author = {Anthes, Richard A.},
	year = {1983},
	pages = {1306--1335}
}

@book{mccormick_multigrid_1988,
	title = {multigrid methods: theory, applications, and supercomputing},
	isbn = {978-0-8247-7979-5},
	shorttitle = {multigrid methods},
	language = {en},
	publisher = {CRC Press},
	author = {Mccormick},
	month = may,
	year = {1988},
	note = {Google-Books-ID: fzTM33IcqEIC},
	keywords = {Mathematics / Number Systems, Computers / General}
}

@incollection{royer_review_1993,
	series = {{NATO} {ASI} {Series}},
	title = {Review of {Recent} {Advances} in {Dynamical} {Extended} {Range} {Forecasting} for the {Extratropics}},
	isbn = {978-3-642-76962-7 978-3-642-76960-3},
	url = {https://link.springer.com/chapter/10.1007/978-3-642-76960-3_3},
	abstract = {Within current definitions, Dynamical Extended Range Forecasting (DERF) refers to numerical forecasts performed beyond the medium range until all dynamical influence of the initial conditions has been lost. The numerical approach to extended range predictions was formulated more than 20 years ago by Smagorinsky (1969) under the name “Deterministic Extended Range Forecasting”. DP Baumhefner (personal communication) has suggested that the term “Numerical Extended Range Forecasting” would be preferable, but for this review we will use the expression “Dynamic Extended Range Forecasting” (DERF), since it has already been used in several publications. The current use of the adjective “dynamical” rather than “deterministic”, or “numerical”, puts more emphasis on the dynamical mechanisms by which the initial conditions can influence the time averaged properties of the flow (Shukla, 1981), and is an implicit recognition that, while the model used is deterministic, the forecasts contain a stochastic element due to the growth of the initial uncertainties. Initial conditions and boundary conditions need to be specified in order to be able to integrate a numerical model. The DERF can be considered as a transition between the two extreme kinds of predictions: deterministic short range prediction where the influence of the initial conditions is dominant, and climate prediction which is by its nature a statistical concept and where the key role is played by the boundary conditions.},
	language = {en},
	urldate = {2017-11-06},
	booktitle = {Prediction of {Interannual} {Climate} {Variations}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Royer, J. F.},
	year = {1993},
	doi = {10.1007/978-3-642-76960-3_3},
	pages = {49--69}
}

@article{bourke_nonlinear_1983,
	title = {A {Nonlinear} {Vertical} {Mode} {Initialization} {Scheme} for a {Limited} {Area} {Prediction} {Model}},
	volume = {111},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1983)111%3C2285%3AANVMIS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1983)111<2285:ANVMIS>2.0.CO;2},
	abstract = {A vertical mode initialization scheme for a limited area baroclinic primitive equations prediction model is proposed. The scheme is based on the approach employed in nonlinear normal mode initialization but incorporates a substantial simplification: the linearized equations with respect to which the model modes are defined admit only gravity modes. A variational constraint on induced increments is possible within the scheme. In the framework of the Australian Region Primitive Equations model the approach has been found to effectively control spurious model oscillations. A number of filtering conditions are considered and tested within the overall approach of this vertical mode scheme.},
	number = {12},
	urldate = {2017-11-06},
	journal = {Monthly Weather Review},
	author = {Bourke, W. and Mcgregor, J. L.},
	month = dec,
	year = {1983},
	pages = {2285--2297}
}

@book{chang_general_2012,
	title = {General {Circulation} {Models} of the {Atmosphere}},
	isbn = {978-0-323-15482-6},
	abstract = {Methods in Computational Physics, Volume 17: General Circulation Models of the Atmosphere is a five-chapter text that covers the fundamentals and application of general circulation models to solving practical problems related to the atmosphere. The first chapter describes the various options in modeling physical processes and computational procedures. The next two chapters illustrate the influence of practical considerations to the compromise between a detailed physical description and reasonable computing time. Other chapters outline the computational details of two different numerical schemes for general circulation models. These chapters particularly provide an in-depth analysis of finite difference methods by proceeding from general considerations of homogeneous incompressible flow to the fine details of the particular numerical scheme. The final chapter discusses the fundamentals of the alternative spectral method for a multilevel spectral model that illustrates the capability of that approach. This book is of value to geoscientists, mathematicians, and physicists.},
	language = {en},
	publisher = {Elsevier},
	author = {Chang, Julius},
	month = dec,
	year = {2012},
	note = {Google-Books-ID: nN\_4561KTIIC},
	keywords = {Science / Physics / Mathematical \& Computational}
}

@article{bourke_multi-level_1974,
	title = {A {Multi}-{Level} {Spectral} {Model}. {I}. {Formulation} and {Hemispheric} {Integrations}},
	volume = {102},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1974)102%3C0687%3AAMLSMI%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1974)102<0687:AMLSMI>2.0.CO;2},
	abstract = {The formulation of a multi-level spectral model suitable for simulation of atmospheric flow on a hemispheric or global scale is presented. The derived primitive equations are employed together with spectral-grid transform procedures in the multi-level domain. An efficient semi-implicit time integration scheme is detailed and results of numerical integrations initialized from analytic fields and Southern Hemisphere data sets are presented. A simple initializing device of divergence dissipation is suggested and shown to be most effective in eliminating spurious large-scale inertia-gravity oscillations.},
	number = {10},
	urldate = {2017-11-06},
	journal = {Monthly Weather Review},
	author = {Bourke, William},
	month = oct,
	year = {1974},
	pages = {687--701}
}

@article{bourke_efficient_1972,
	title = {An {Efficient}, {One}-{Level}, {Primitive}-{Equation} {Spectral} {Model}},
	volume = {100},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1972)100%3C0683:AEOPSM%3E2.3.CO;2},
	doi = {10.1175/1520-0493(1972)100<0683:AEOPSM>2.3.CO;2},
	abstract = {A one-level, global, spectral model using the primitive equations is formulated in terms of a concise form of the prognostic equations for vorticity and divergence. The model integration incorporates a grid transform technique to evaluate nonlinear terms; the computational efficiency of the model is found to be far superior to that of an equivalent model based on the traditional interaction coefficients. The transform model, in integrations of 116 days, satisfies principles of conservation of energy, angular momentum, and square potential vorticity to a high degree.},
	number = {9},
	urldate = {2017-11-06},
	journal = {Monthly Weather Review},
	author = {Bourke, William},
	month = sep,
	year = {1972},
	pages = {683--689}
}

@article{bougeault_non-reflective_1983,
	title = {A {Non}-{Reflective} {Upper} {Boundary} {Condition} for {Limited}-{Height} {Hydrostatic} {Models}},
	volume = {111},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1983)111%3C0420:ANRUBC%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1983)111<0420:ANRUBC>2.0.CO;2},
	abstract = {A simple upper boundary condition for hydrostatic, Boussinesq models is derived from a linear internal wave theory, assuming a uniform stratification and no Coriolis effects. This condition is applied in a two-dimentional nonlinear model of the planetary boundary layer. The numerical implementation and some stability problems are discussed. A comparison of the results of numerical experiments using different vertical extensions with analytical solutions is used to show that the condition provides a satisfactory solution to the problems of radiation of upward propagating energy.},
	number = {3},
	urldate = {2017-11-06},
	journal = {Monthly Weather Review},
	author = {Bougeault, Philippe},
	month = mar,
	year = {1983},
	pages = {420--429}
}

@article{bolin_carl-gustaf_1999,
	title = {Carl-{Gustaf} {Rossby} {The} stockholm period 1947-1957},
	volume = {51},
	issn = {null},
	url = {http://dx.doi.org/10.3402/tellusb.v51i1.16255},
	doi = {10.3402/tellusb.v51i1.16255},
	number = {1},
	urldate = {2017-11-06},
	journal = {Tellus B: Chemical and Physical Meteorology},
	author = {Bolin, Bert},
	month = jan,
	year = {1999},
	pages = {4--12}
}

@article{bolin_improved_1956,
	title = {An {Improved} {Barotropic} {Model} and some {Aspects} of {Using} the {Balance} {Equation} for {Three}-dimensional {Flow}},
	volume = {8},
	issn = {0040-2826},
	url = {http://dx.doi.org/10.3402/tellusa.v8i1.8941},
	doi = {10.3402/tellusa.v8i1.8941},
	abstract = {A few suggestions for improving the barotropic model presented in a previous article (Bolin, 1955) have been tested. The results show that replacing the geostrophic relation by a more general balance equation improves the forecasts over 24 hours in certain respects. Furthermore the incorporation of the effects of a stratosphere in a very approximate way gives a better description of the behaviour of the largest scales of motion in the atmosphere.The application of the balance equation in numerical forecasting is extended to three-dimensional baroclin flow. It is shown that the criterion of integrability of the balance equation to obtain the stream function from a knowledge of the pressure field has to be satisfied in the course of the computations to maintain elliptic character of the equations.},
	number = {1},
	urldate = {2017-11-06},
	journal = {Tellus},
	author = {Bolin, Bert},
	month = jan,
	year = {1956},
	pages = {61--75}
}

@article{bolin_numerical_1955,
	title = {Numerical {Forecasting} with the {Barotropic} {Model}},
	volume = {7},
	issn = {0040-2826},
	url = {http://dx.doi.org/10.3402/tellusa.v7i1.8770},
	doi = {10.3402/tellusa.v7i1.8770},
	abstract = {The experiments with numerical forecasting using the barotropic model have been continued and a number of 24, 48 and 72 hour forecasts are presented. The initial data for these forecasts covered an area of about 9,000 by 12,000 km. The results indicate that the boundary influences have been reduced to be unimportant in the centre of the area in the 24-hour forecasts but they may still cause errors in the 72-hour forecasts. In view of the approximations made very good 72-hour forecasts have been obtained in some cases. The most successful one gave a correlation of 0.87 and a relative error of the forecast height changes of 0.58. Most of these extended forecasts should be of definite value in forecasting the weather. Large errors are, however, still obtained in some cases. The neglection of baroclinic process is one of the reasons for these errors but it is quite obvious that the largest errors are of a different nature. Experiments are at present conducted to find the sources of these errors. One line of this research is a general re-analysis of the assumptions made in deriving the barotropic model which is presented in the latter part of this paper. A number of improvements are suggested for further tests.},
	number = {1},
	urldate = {2017-11-06},
	journal = {Tellus},
	author = {Bolin, Bert},
	month = jan,
	year = {1955},
	pages = {27--49}
}

@article{boer_large-scale_1983,
	title = {Large-{Scale} {Two}-{Dimensional} {Turbulence} in the {Atmosphere}},
	volume = {40},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1983)040%3C0164:LSTDTI%3E2.0.CO;2},
	doi = {10.1175/1520-0469(1983)040<0164:LSTDTI>2.0.CO;2},
	abstract = {Global FGGE data are used to investigate several aspects of large-scale turbulence in the atmosphere. The approach follows that for two-dimensional, nondivergent turbulent flows which are homogeneous and isotropic on the sphere. Spectra of kinetic energy, enstrophy and available potential energy are obtained for both the stationary and transient parts of the flow. Nonlinear interaction terms and fluxes of energy and enstrophy through wavenumber space are calculated and compared with the theory. A possible method of parameterizing the interactions with unresolved scales is considered. Two rather different flow regimes are found in wavenumber space. The high-wavenumber regime is dominated by the transient components of the flow and exhibits, at least approximately, several of the conditions characterizing homogeneous and isotropic turbulence. This region of wavenumber space also displays some of the features of an enstrophy-cascading inertial subrange. The low-wavenumber region, on the other hand, is dominated by the stationary component of the flow, exhibits marked anisotropy and, in contrast to the high-wavenumber regime, displays a marked change between January and July.},
	number = {1},
	urldate = {2017-11-06},
	journal = {Journal of the Atmospheric Sciences},
	author = {Boer, G. J. and Shepherd, T. G.},
	month = jan,
	year = {1983},
	pages = {164--184}
}

@article{blumen_geostrophic_1972,
	title = {Geostrophic adjustment},
	volume = {10},
	issn = {1944-9208},
	url = {http://onlinelibrary.wiley.com/doi/10.1029/RG010i002p00485/abstract},
	doi = {10.1029/RG010i002p00485},
	abstract = {The conservation of potential vorticity of a rotating homogeneous or stratified fluid may, in principle, be used to determine steady-state field distributions from a given initial state. If the governing equations are linear, if the basic-state is one of rest, and if the initial field of motion is geostrophically balanced, then no change in this equilibrium state occurs. However, nongeostrophic initial conditions excite transient gravity-inertia waves that redistribute mass and momentum to ultimately establish a geostrophic steady state, whose potential vorticity is equal to the potential vorticity of the initial state. A steady state may not become established if, for example, hydrodynamic instabilities occur or if wave energy becomes trapped because of inherent refractive properties of the medium. Some examples, which illustrate the properties of geostrophic adjustment and nonadjustment, are presented and discussed. A simple model, which incorporates gross features of atmospheric and ocean flows, is also presented in order to summarize the relationships between the spatial scales associated with the initial conditions and the partition of energy between the allowable modes of oscillation, both transient and steady. The oceanic response to imposed stresses from atmospheric circulation systems and the atmospheric response to sources of wave energy, which includes the introduction of incorrect initial data into numerical simulations, provide practical applications of the theory.},
	language = {en},
	number = {2},
	urldate = {2017-11-06},
	journal = {Reviews of Geophysics},
	author = {Blumen, William},
	month = may,
	year = {1972},
	pages = {485--528}
}

@article{bloom_data_1996,
	title = {Data {Assimilation} {Using} {Incremental} {Analysis} {Updates}},
	volume = {124},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1996)124%3C1256:DAUIAU%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1996)124<1256:DAUIAU>2.0.CO;2},
	abstract = {The IAU (incremental analysis updating) process incorporates analysis increments into a model integration in a gradual manner. It does this by using analysis increments as constant forcings in a model's prognostic equations over a 6-h period centered on an analysis time. A linear analysis of the IAU procedure shows it to have the attractive properties of a low-pass time filter. The IAU process affects the response of the model to the analysis increments, and it leaves the model state unaffected where there were no data to assimilate. This result is contrasted with a simple dynamical relaxation (or “nudging”) scheme, which is shown, in this linear analysis, to have less desirable response characteristics, both from the analysis increments and from the background state of the model. The behavior of IAU in the context of the Goddard Earth Observing System (GEOS) Data Assimilation System is examined using a combination of large-scale diagnostics from month-long assimilations and detailed diagnostics from short assimilations. These studies indicate that IAU assimilations have improved observed-minus-forecast statistics and improved globally averaged precipitation by removing spinup effects. The detailed diagnostics of the behavior of the GEOS system with IAU corroborate the results of the linear analysis of the response behavior of IAU.},
	number = {6},
	urldate = {2017-11-06},
	journal = {Monthly Weather Review},
	author = {Bloom, S. C. and Takacs, L. L. and da Silva, A. M. and Ledvina, D.},
	month = jun,
	year = {1996},
	pages = {1256--1271}
}

@article{bleck_regional_1993,
	title = {Regional {Weather} {Prediction} with a {Model} {Combining} {Terrain}-following and {Isentropic} {Coordinates}. {Part} {I}: {Model} {Description}},
	volume = {121},
	issn = {0027-0644},
	shorttitle = {Regional {Weather} {Prediction} with a {Model} {Combining} {Terrain}-following and {Isentropic} {Coordinates}. {Part} {I}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1993)121%3C1770%3ARWPWAM%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1993)121<1770:RWPWAM>2.0.CO;2},
	abstract = {A short-range numerical prediction model, which is part of a real-time 3-h data assimilation and forecast system, is described. The distinguishing feature of the model is the use of terrain-following (σ) coordinate surfaces in the lower troposphere combined with isentropic (θ) surfaces aloft. Such a hybrid coordinate system allows modeling of processes in a convectively unstable boundary layer while retaining tile advantages of θ coordinates in representing upper-tropospheric frontal and jet-stream structures. The hybrid approach used in this model represents a in major departure from previous hybrid formulations in atmospheric models, oven though it has been used for more than ten years in oceanic modeling. Part I of this two-part paper contains a thorough description of the model and the results of validation experiments. Results of North American case studies wig be reported in Part II.},
	number = {6},
	urldate = {2017-11-06},
	journal = {Monthly Weather Review},
	author = {Bleck, Rainer and Benjamin, Stanley G.},
	month = jun,
	year = {1993},
	pages = {1770--1785}
}

@article{bleck_use_1978,
	title = {On the {Use} of {Hybrid} {Vertical} {Coordinates} in {Numerical} {Weather} {Prediction} {Models}},
	volume = {106},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1978)106%3C1233:OTUOHV%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1978)106<1233:OTUOHV>2.0.CO;2},
	abstract = {A comparison is made of several ways to combine isentropic with sigma coordinates in a numerical weather prediction model in order to benefit from the advantage of either coordinate. The resulting hybrid model versions appear to be well-behaved numerically. A noise index introduced to provide a measure of external gravitational imbalances shows that hybrid models are somewhat “quieter” than isentropic coordinate models. Results from a related experiment suggest that this reduction in gravitational noise is not simply due to a fundamental noise difference between isentropic and sigma coordinate models but is likely to be a result of the hybridization.},
	number = {9},
	urldate = {2017-11-06},
	journal = {Monthly Weather Review},
	author = {Bleck, Rainer},
	month = sep,
	year = {1978},
	pages = {1233--1244}
}

@article{black_new_1994,
	title = {The {New} {NMC} {Mesoscale} {Eta} {Model}: {Description} and {Forecast} {Examples}},
	volume = {9},
	issn = {0882-8156},
	shorttitle = {The {New} {NMC} {Mesoscale} {Eta} {Model}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0434(1994)009%3C0265%3ATNNMEM%3E2.0.CO%3B2},
	doi = {10.1175/1520-0434(1994)009<0265:TNNMEM>2.0.CO;2},
	abstract = {In mid-1994 a new version of the Eta Model will begin producing operational forecast guidance down to mesoscale ranges. This version will have a horizontal resolution of approximately 30 km and about 50 layers in the vertical. A summary of the primary aspects of the model is presented that includes a description of the eta coordinate and of the dynamical and physical components. Advantages of the mesoscale model are indicated in precipitation skill scores for November 1993. Specific examples are discussed that describe the mesoscale model's ability to capture small-scale circulations under fundamentally different circumstances: (i) the propagation of a strong cold front where the forcing was primarily internal and not orographic; and (ii) a rainfall event where the forcing arose from the interaction of topography with the synoptic-scale flow.},
	number = {2},
	urldate = {2017-11-06},
	journal = {Weather and Forecasting},
	author = {Black, Thomas L.},
	month = jun,
	year = {1994},
	pages = {265--278}
}

@book{bjerknes_dynamic_1910,
	title = {Dynamic {Meteorology} and {Hydrography}},
	language = {en},
	publisher = {Carnegie},
	author = {Bjerknes, Vilhelm},
	year = {1910},
	note = {Google-Books-ID: kxZKAQAAMAAJ}
}

@article{bjerknes_atmospheric_1969,
	title = {Atmospheric teleconnections from the equatorial pacific},
	volume = {97},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1969)097%3C0163:ATFTEP%3E2.3.CO%3B2},
	doi = {10.1175/1520-0493(1969)097<0163:ATFTEP>2.3.CO;2},
	abstract = {The “high index” response of the northeast Pacific westerlies to big positive anomalies of equatorial sea temperature, observed in the winter of 1957–58, has been found to repeat during the major equatorial sea temperature maxima in the winters of 1963–64 and 1965–66. The 1963 positive temperature anomaly started early enough to exert the analogous effect on the atmosphere of the south Indian Ocean during its winter season. The maxima of the sea temperature in the eastern and central equatorial Pacific occur as a result of anomalous weakening of the trade winds of the Southern Hemisphere with inherent weakening of the equatorial upwelling. These anomalies are shown to be closely tied to the “Southern Oscillation” of Sir Gilbert Walker.},
	number = {3},
	urldate = {2017-11-06},
	journal = {Monthly Weather Review},
	author = {Bjerknes, J.},
	month = mar,
	year = {1969},
	pages = {163--172}
}

@article{bishop_ensemble_1999,
	title = {Ensemble {Transformation} and {Adaptive} {Observations}},
	volume = {56},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1999)056%3C1748%3AETAAO%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1999)056<1748:ETAAO>2.0.CO;2},
	abstract = {Suppose that the geographical and temporal resolution of the observational network could be changed on a daily basis. Of all the possible deployments of observational resources, which particular deployment would minimize expected forecast error? The ensemble transform technique answers such questions by using nonlinear ensemble forecasts to rapidly construct ensemble-based approximations to the prediction error covariance matrices associated with a wide range of different possible deployments of observational resources. From these matrices, estimates of the expected forecast error associated with each distinct deployment of observational resources are obtained. The deployment that minimizes the chosen measure of forecast error is deemed optimal. The technique may also be used to find the perturbation that evolves into the leading eigenvector or singular vector of an ensemble-based prediction error covariance matrix. This time-evolving perturbation “explains” more of the ensemble-based prediction error variance than any other perturbation. It may be interpreted as the fastest growing perturbation on the subspace of ensemble perturbations. The ensemble-based approximations to the prediction error covariance matrices are constructed from transformation matrices derived from estimates of the analysis error covariance matrices associated with each possible deployment of observational resources. The authors prove that the ensemble transform technique would precisely recover the prediction error covariance matrices associated with each possible deployment of observational resources provided that (i) estimates of the analysis error covariance matrix were precise, (ii) the ensemble perturbations span the vector space of all possible perturbations, and (iii) the evolution of errors were linear and perfectly modeled. In the absence of such precise information, the ensemble transform technique links available information on analysis error covariances associated with different observational networks with error growth estimates contained in the ensemble forecast to estimate the optimal configuration of an adaptive observational network. Tests of the technique will be presented in subsequent publications. Here, the objective is to describe the theoretical basis of the technique and illustrate it with an example from the Fronts and Atlantic Storm Tracks Experiment (FASTEX).},
	number = {11},
	urldate = {2017-11-06},
	journal = {Journal of the Atmospheric Sciences},
	author = {Bishop, Craig H. and Toth, Zoltan},
	month = jun,
	year = {1999},
	pages = {1748--1765}
}

@article{betts_new_1986,
	title = {A new convective adjustment scheme. {Part} {II}: {Single} column tests using {GATE} wave, {BOMEX}, {ATEX} and arctic air-mass data sets},
	volume = {112},
	issn = {1477-870X},
	shorttitle = {A new convective adjustment scheme. {Part} {II}},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49711247308/abstract},
	doi = {10.1002/qj.49711247308},
	abstract = {The schemes proposed in part I are tested using single-column data sets from tropical field experiments (GATE, BOMEX, ATEX) and an arctic air-mass transformation. Both the deep and shallow schemes perform well. The sensitivity of the schemes to adjustable parameters is also studied. Preliminary global forecasts show significant improvements in the global surface fluxes and mean tropical temperature tendency over the operational Kuo convection scheme.},
	language = {en},
	number = {473},
	urldate = {2017-11-06},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Betts, A. K. and Miller, M. J.},
	month = jul,
	year = {1986},
	pages = {693--709}
}

@article{bergthorsson_routine_1955,
	title = {Routine {Forecasting} with the {Barotropic} {Model}},
	volume = {7},
	issn = {0040-2826},
	url = {http://dx.doi.org/10.3402/tellusa.v7i2.8775},
	doi = {10.3402/tellusa.v7i2.8775},
	abstract = {Since 1 December 1954 the Royal Swedish Air Force Weather Service has been conducting a series of test forecasts of the 500-mb topography under operational conditions. Forecasts for 24, 48 and 72 hours have been prepared on a routine basis, using the barotropic model and the digital computer BESK. The tests to date have covered the periods 1-16 December 1954, 17 January-25 February 1955 and from 12 April 1955 to the time of writing. It was originally planned to issue 42 sets of three forecasts during the first two periods, but some forecasts failed due to minor breakdowns of the computer (see tables).},
	number = {2},
	urldate = {2017-11-06},
	journal = {Tellus},
	author = {Bergthorsson, P. and DÖÖs, B. R. and Fryklund, S. and Haug, O. and Lindquist, R.},
	month = jan,
	year = {1955},
	pages = {272--274}
}

@article{bergman_analysis_1976,
	title = {Analysis {Error} as a {Function} of {Observation} {Density} for {Satellite} {Temperature} {Soundings} with {Spatially} {Correlated} {Errors}},
	volume = {104},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1976)104%3C1308%3AAEAAFO%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1976)104<1308:AEAAFO>2.0.CO;2},
	abstract = {A simple numerical experiment demonstrates that if the errors in satellite-derived temperatures are correlated spatially, the error of an optimum interpolation objective analysis using such temperature data is increased. Moreover, increasing the density of such observations beyond a, threshold value (a spacing of about 400 km in the experiment) does not yield any significant improvement in analysis accuracy, in contrast to the cage of observations with spatially uncorrelated errors.},
	number = {10},
	urldate = {2017-11-06},
	journal = {Monthly Weather Review},
	author = {Bergman, Kenneth H. and Bonner, William D.},
	month = oct,
	year = {1976},
	pages = {1308--1316}
}

@article{benoit_canadian_1997,
	title = {The {Canadian} {MC2}: {A} {Semi}-{Lagrangian}, {Semi}-{Implicit} {Wideband} {Atmospheric} {Model} {Suited} for {Finescale} {Process} {Studies} and {Simulation}},
	volume = {125},
	issn = {0027-0644},
	shorttitle = {The {Canadian} {MC2}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1997)125%3C2382%3ATCMASL%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1997)125<2382:TCMASL>2.0.CO;2},
	abstract = {This paper attempts to document the developmental research and early mesoscale results of the new fully nonhydrostatic atmospheric model called MC2 (mesoscale compressible community). Its numerical scheme is the semi-implicit semi-Lagrangian approach conceived and demonstrated by Tanguay, Robert, and Laprise. The dominant effort required to become a full-fledged mesoscale model was to connect it properly to a full-scale and evolving physics package; the enlarged scope of a package previously dedicated to hydrostatic pressure coordinate-type models posed some new questions. The one-way nesting is reviewed and particularly the self-nesting or cascade mode; the potential implication of this mode is explored with a stand-alone forecast experiment and related to the other existing approach employing hemispheric or global variable meshes. One of the strong assets of MC2 is its growing community of users and developers. To demonstrate the wideband characteristic of MC2, that is, its applicability to a large range of atmospheric flows, two very different cases are studied: an Atlantic winter East Coast cyclogenesis (meso-α scale, mostly hydrostatic) and a local (meso-γ scale, partly nonhydrostatic) downslope windstorm occuring over unexpectedly modest topography (Cape Breton Highlands of Nova Scotia, Canada).},
	number = {10},
	urldate = {2017-11-06},
	journal = {Monthly Weather Review},
	author = {Benoit, Robert and Desgagné, Michel and Pellerin, Pierre and Pellerin, Simon and Chartier, Yves and Desjardins, Serge},
	month = oct,
	year = {1997},
	pages = {2382--2415}
}

@article{benoit_inclusion_1989,
	title = {Inclusion of a {TKE} {Boundary} {Layer} {Parameterization} in the {Canadian} {Regional} {Finite}-{Element} {Model}},
	volume = {117},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1989)117%3C1726:IOATBL%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1989)117<1726:IOATBL>2.0.CO;2},
	abstract = {The formulation of the regional model recently implemented by the Atmospheric Environment Service of Canada for its operational 48 h NWP forecasts is presented. The emphasis is put on the parameterization of the physical processes, especially those affecting the atmospheric boundary layer. The originality of this model, in addition to the use of 3-D finite elements, of variable meshes in both the horizontal and vertical, and of being non-nested (as previously described by Staniforth and Daley), consists in the treatment of the time-dependent turbulent Kinetic energy (TKE) and the inclusion of the full diurnal cycle. The overall organization of the model calculations it also presented in order to convey a more accurate description of this integrated system. Sample results from the well-known case of the Presidents' Day Cyclone of 1979 and general performance are covered in the last section.},
	number = {8},
	urldate = {2017-11-06},
	journal = {Monthly Weather Review},
	author = {Benoit, R. and Côté, J. and Mailhot, J.},
	month = aug,
	year = {1989},
	pages = {1726--1750}
}

@article{bennett_generalized_1996,
	title = {Generalized inversion of a global numerical weather prediction model},
	volume = {60},
	issn = {0177-7971, 1436-5065},
	url = {https://link.springer.com/article/10.1007/BF01029793},
	doi = {10.1007/BF01029793},
	abstract = {SummaryWe construct the generalized inverse of a global numerical weather prediction (NWP) model, in order to prepare initial conditions for the model at time “t=0 hrs”. The inverse finds a weighted, least-squares best-fit to the dynamics for −24{\textless}t{\textless}0, to the previous initial condition att=−24, and to data att=−24,t=−18,t=−12 andt=0. That is, the inverse is a weak-constraint, four-dimensional variational assimilation scheme. The best-fit is found by solving the nonlinear Euler-Lagrange (EL) equations which determine the local extrema of a penalty functional. The latter is quadratic in the dynamical, initial and data residuals. The EL equations are solved using iterated representer expansions. The technique yields optimal conditioning of the very large minimization problem, which has ∼109 hydrodynamical and thermodynamical variables defined on a 4-dimensional, space-time grid.In addition to introducing the inverse NWP model, we demonstrate it on a medium-sized problem, namely, a study of the impact of reprocessed cloud track wind observations (RCTWO) from the 1990 Tropical Cyclone Motion Experiment (TCM-90). The impact is assessed in terms of the improvement of forecasts in the South China Sea att=+48 hours. The calculation shows that the computations are manageable, the iteration scheme converges, and that the RCTWO have a beneficial impact.},
	language = {en},
	number = {1-3},
	urldate = {2017-11-06},
	journal = {Meteorology and Atmospheric Physics},
	author = {Bennett, A. F. and Chua, B. S. and Leslie, L. M.},
	month = mar,
	year = {1996},
	pages = {165--178}
}

@article{benjamin_accuracy_1999,
	title = {Accuracy of {ACARS} {Wind} and {Temperature} {Observations} {Determined} by {Collocation}},
	volume = {14},
	issn = {0882-8156},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0434(1999)014%3C1032:AOAWAT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0434(1999)014<1032:AOAWAT>2.0.CO;2},
	abstract = {A collocation study of meteorological reports from commercial aircraft relayed through the Aircraft Communications, Addressing, and Reporting System (ACARS) has been performed to estimate standard deviations of observation errors for wind and temperature. ACARS observations were collected over an area in the western and central United States for a 13-month period, and this dataset was examined for pairs of reports within small spatial (⩽10 km) and temporal (⩽10 min) windows. The results showed an observation error of a single horizontal component of wind of 1.1 m s−1 and 0.5 K for temperature above the boundary layer. Within the boundary layer, the rms difference of wind and temperature between aircraft was larger, presumably due to larger small-scale variations in the atmosphere and, in the case of wind, from aircraft maneuvers. These observation error estimates are valuable for use in data assimilation and for determination of forecast error from ACARS observation-minus-forecast differences. By comparing standard deviations at different levels, estimates of mesoscale variability at a 10-km scale in the lower troposphere were also calculated. These values (rms vector error of 1.8 m s−1 for wind, rms error of 0.5 K for temperature) can be interpreted as estimates of the 10-km lower-tropospheric error of representativeness, also useful for data assimilation.},
	number = {6},
	urldate = {2017-11-06},
	journal = {Weather and Forecasting},
	author = {Benjamin, Stanley G. and Schwartz, Barry E. and Cole, Rodney E.},
	month = dec,
	year = {1999},
	pages = {1032--1038}
}

@article{bengtsson_short-range_1999,
	title = {From short-range barotropic modelling to extended-range global weather prediction: a 40-year perspective},
	volume = {51},
	issn = {null},
	shorttitle = {From short-range barotropic modelling to extended-range global weather prediction},
	url = {http://dx.doi.org/10.3402/tellusa.v51i1.12286},
	doi = {10.3402/tellusa.v51i1.12286},
	abstract = {At the end of the 20th century, we can look back on a spectacular development of numericalweather prediction, which has, practically uninterrupted, been going on since the middle of thecentury. High-resolution predictions for more than a week ahead for any part of the globe arenow routinely produced and anyone with an Internet connection can access many of theseforecasts for anywhere in the world. Extended predictions for several seasons ahead are alsobeing done–the latest El Ninño event in 1997/1998 is an example of such a successful prediction.The great achievement is due to a number of factors including the progress in computationaltechnology and the establishment of global observing systems, combined with a systematicresearch program with an overall strategy towards building comprehensive prediction systemsfor climate and weather. In this article, I will discuss the different evolutionary steps in thisdevelopment and the way new scientific ideas have contributed to efficiently explore the computingpower and in using observations from new types of observing systems. Weather predictionis not an exact science due to unavoidable errors in initial data and in the models. To quantifythe reliability of a forecast is therefore essential and probably more so the longer the forecastsare. Ensemble prediction is thus a new and important concept in weather and climate prediction,which I believe will become a routine aspect of weather prediction in the future. The limitbetween weather and climate prediction is becoming more and more diffuse and in the finalpart of this article I will outline the way I think development may proceed in the future.},
	number = {1},
	urldate = {2017-11-06},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Bengtsson, Lennart},
	month = jan,
	year = {1999},
	pages = {13--32}
}

@article{bengtsson_experiment_1971,
	title = {An experiment in the {Assimilation} of {Data} in {Dynamical} {Analysis}},
	volume = {23},
	issn = {0040-2826},
	url = {http://dx.doi.org/10.3402/tellusa.v23i4-5.10513},
	doi = {10.3402/tellusa.v23i4-5.10513},
	abstract = {A system for continuous data assimilation is presented and discussed. To simulate the dynamical development a channel version of a balanced barotropic model is used and geopotential (height) data are assimilated into the models computations as data become available. In the first experiment the updating is performed every 24th, 12th and 6th hours with a given network. The stations are distributed at random in 4 groups in order to simulate 4 areas with different density of stations. Optimum interpolation is performed for the difference between the forecast and the valid observations. The RMS-error of the analyses is reduced in time, and the error being smaller the more frequent the updating is performed. The updating every 6th hour yields an error in the analysis less than the RMS-error of the observation. In a second experiment the updating is performed by data from a moving satellite with a side-scan capability of about 15°. If the satellite data are analysed at every time step before they are introduced into the system the error of the analysis is reduced to a value below the RMS-error of the observation already after 24 hours and yields as a whole a better result than updating from a fixed network. If the satellite data are introduced without any modification the error of the analysis is reduced much slower and it takes about 4 days to reach a comparable result to the one where the data have been analysed.},
	number = {4-5},
	urldate = {2017-11-06},
	journal = {Tellus},
	author = {Bengtsson, Lennart and Gustavsson, Nils},
	month = jan,
	year = {1971},
	pages = {328--336}
}

@article{skamrock_truncation_1989,
	title = {Truncation {Error} {Estimates} for {Refinement} {Criteria} in {Nested} and {Adaptive} {Models}},
	volume = {117},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1989)117%3C0872%3ATEEFRC%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1989)117<0872:TEEFRC>2.0.CO;2},
	abstract = {Truncation error estimates are considered as criteria for fine-grid placement and movement in nested and adaptive finite-difference atmospheric models. A simple method for calculating the truncation error at any time during an integration is described. Two cases using the shallow-water equations and the hydrostatic primitive equations are examined to demonstrate the accuracy of the method and illuminate the relationships among the truncation error, a particular discretization, the equations being solved and the flow physics. The relationship between the truncation error and the solution error is also discussed and it is argued that minimization of the truncation error is the necessary consideration for producing more accurate numerical solutions. Examples of use of the truncation error estimates in adaptive models are also presented.},
	number = {4},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Skamrock, William C.},
	month = apr,
	year = {1989},
	pages = {872--886}
}

@inproceedings{smith_maintenance_1997,
	series = {Proceedings of the {International} {School} of {Physics} {Enrico} {Fermi}},
	title = {The maintenance of predictability.{Past} and present variability of the solar-terrestrial system: measurement data analysis and theoretical models: proceedings of the {International}},
	shorttitle = {Past and present variability of the solar-terrestrial system},
	booktitle = {Proceedings of the {International} {School} of {Physics} {Enrico} {Fermi}},
	publisher = {Italian Physical Society, IOS Press},
	author = {Smith, L. A},
	year = {1997},
	pages = {177--246}
}

@article{sellers_biophysical_1992,
	title = {Biophysical models of land surface processes},
	journal = {Climate system modeling},
	author = {Sellers, P. J.},
	year = {1992},
	pages = {451--490}
}

@article{seaman_directional_1980,
	title = {Directional dependence of zonal and meridional wind correlation coefficients},
	volume = {28},
	journal = {Aust. Met. Mag},
	author = {Seaman, R. S. and Gauntlett, F. J.},
	year = {1980},
	pages = {217--218}
}

@article{stauffer_use_1990,
	title = {Use of {Four}-{Dimensional} {Data} {Assimilation} in a {Limited}-{Area} {Mesoscale} {Model}. {Part} {I}: {Experiments} with {Synoptic}-{Scale} {Data}},
	volume = {118},
	issn = {0027-0644},
	shorttitle = {Use of {Four}-{Dimensional} {Data} {Assimilation} in a {Limited}-{Area} {Mesoscale} {Model}. {Part} {I}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1990)118%3C1250%3AUOFDDA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1990)118<1250:UOFDDA>2.0.CO;2},
	abstract = {A four-dimensional data assimilation (FDDA) scheme based on Newtonian relaxation or “nudging” is tested using standard rawinsonde data in the Penn State/NCAR limited-area mesoscale model. It is imperative that we better understand these FDDA-generated datasets, which are widely used for model initialization and diagnostic analysis. The main hypothesis to be tested is that use of coarse-resolution rawinsonde observations throughout a model integration, rather than at only the initial time, can limit large-scale model error growth (amplitude and phase errors) while the model generates realistic mesoscale structures not resolved by the data. The main objective of this study is to determine what assimilation strategies and what meteorological fields (mass, wind or both) have the greatest positive impact via FDDA on the numerical simulators for two midlatitude, real-data cases using the full-physics version of a limited-area model. Seven experiments are performed for each case: one control experiment (no nudging), five experiments which nudge the model solution to analyses of observations, and a seventh experiment in which the actual rawinsonde observations are assimilated directly into the model. Subjective and statistical evaluation of the results include verification of the primitive variable fields, plus a detailed precipitation verification which is especially valuable since rainfall is the result of many complex physical processes and is usually characterized by small-scale variability, which makes it much more difficult to simulate accurately than the other variables. The results show that the assimilation of both wind and thermal data throughout the model atmosphere had a consistently positive impact on the synoptic-scale and mesoscale mass and wind fields for both cases and for the precipitation simulations in the case dominated by large-scale forcing. However, in the other case for which small-scale convection was the dominant precipitation mechanism, the FDDA system using only rawinsonde data showed only a minor improvement in the rainfall. This may be attributed to 1) the fact that time scales of small convective systems am less than 12 h, the temporal resolution of the data used for FDDA, and 2) assimilation of 12-hourly temperature data near the surface may adversely affect the model's diurnal cycle and low-level stability, which are very important for convection. Other results show that nudging vorticity or the rawinsonde-based mixing ratio analyses tended to seriously degrade the precipitation simulators for both cases and should be avoided. The transfer of information on the mesoscale from the wind (mass) fields to the mass (wind) fields was found to be significant: for shallow forcing (small equivalent depth), the winds were shown to adjust to the mass fields, while for large-scale forcing through the depth of the troposphere (large equivalent depth), wind data were generally more effective than mass data. The most accurate mass and wind fields in both cases, however, were produced by assimilating both wind and temperature information. Nudging the model' wind and temperature fields directly to the rawinsonde observations generally produced results comparable to nudging to the gridded analyses of these data.},
	number = {6},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Stauffer, David R. and Seaman, Nelson L.},
	month = jun,
	year = {1990},
	pages = {1250--1277}
}

@article{staniforth_regional_1997,
	title = {Regional modeling: {A} theoretical discussion},
	volume = {63},
	issn = {0177-7971, 1436-5065},
	shorttitle = {Regional modeling},
	url = {https://link.springer.com/article/10.1007/BF01025361},
	doi = {10.1007/BF01025361},
	abstract = {SummaryThe goal of regional modeling is to make a detailed forecast for a given limited area of interst by focusing resolution over it and the immediate vicinity. As a consequence, the period of validity is necessarily more restricted than would otherwise be the case, and this is the price that must be paid for locally-enhanced resolution. The principal attributes of the non-interactive and interactive strategies for regional modeling are described. For the non0interactive strategy, particular emphasis is placed on the importance, difficulty, and impact, of well-posedness for open-domain problems. A methodology is given for estimating the size of numerical buffer zones required to obtain a forecast uncontaminated by the inward propagation of inaccurately-specified lateral boundary conditions. The interactive strategy addresses the well-posedness issue of (non-interactive) limited-area models. A computational overhead is incurred but this can be reduced through the use of variable resolution. It is argued that regardless of the preferred regional modeling strategy, experiments should be undertaken to today's regional models under carefully-controlled conditions, to reflect the significant reduction over the past two decades of other sources of error.},
	language = {en},
	number = {1-2},
	urldate = {2017-11-01},
	journal = {Meteorology and Atmospheric Physics},
	author = {Staniforth, A.},
	month = mar,
	year = {1997},
	pages = {15--29}
}

@article{staniforth_finite-element_1977,
	title = {A {Finite}-{Element} {Formulation} for the {Vertical} {Discretization} of {Sigma}-{Coordinate} {Primitive} {Equation} {Models}},
	volume = {105},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1977)105%3C1108%3AAFEFFT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1977)105<1108:AFEFFT>2.0.CO;2},
	abstract = {A finite-element formulation for the vertical structure of primitive equation models has been developed. The finite-element method is a variant of the Galerkin procedure in which the dependent variables are expanded in a finite, set of basis functions and then the truncation error is orthogonalized to each of the basis functions. In the present case, the basis functions are Châpeau functions in sigma, the vertical coordinate. The procedure has been designed for use with a semi-implicit time discretization algorithm. Although this vertical representation has been developed for ultimate implementation in a three-dimensional finite-element model, it has been first tested in a spherical harmonic, baroclinic, primitive equations model. Short-range forecasts made with this model are very encouraging.},
	number = {9},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Staniforth, Andrew N. and Daley, Roger W.},
	month = sep,
	year = {1977},
	pages = {1108--1118}
}

@article{staniforth_review:_1987,
	title = {Review: {Formulating} efficient finite-element codes for flows in regular domains},
	volume = {7},
	issn = {1097-0363},
	shorttitle = {Review},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/fld.1650070102/abstract},
	doi = {10.1002/fld.1650070102},
	abstract = {Many fluid flow problems of current interest occur in domains that are mappable to a rectangle or a box; conformal mappings are particularly useful in this regard. We are concerned here with the efficient solution of such problems using finite elements. The central issue is the element choice, and this issue is addressed in terms of operation counts, computer memory and I/0 requirements, and the extent to which code vectorization is possible. It is concluded that rectangular (box) elements generally lead to more efficient algorithms that triangular (tetrahedral) elements. A synthesis of algorithms, based on bilinear (trilinear) elements, is presented. The algorithms have the attributes of simplicity, accuracy, stability and straightforward incorporation of boundary conditions. For bilinear and trilinear elements, it is found that product and first-derivative terms are well-handled by the Galerkin FE method, but that it is advantageous to go outside of the Galerkin framework when treating second-derivative terms. It is particularly important to consider the form of the governing equations, vis-à-vis the choice of staggered, non-staggered and/or mixed-order elements, and to choose an appropriate time scheme. The described techniques have been successfully applied to a variety of problems in regular domains, including the solution of the three-dimensional time-dependent hydrostatic primitive equations; these are stiff and include first and second derivative terms, non-linearities and variable coefficients due to a conformal mapping.},
	language = {en},
	number = {1},
	urldate = {2017-11-01},
	journal = {International Journal for Numerical Methods in Fluids},
	author = {Staniforth, A.},
	month = jan,
	year = {1987},
	keywords = {Finite Element, Separable Basis, Tensor Product, Vectorized code},
	pages = {1--16}
}

@article{staniforth_baroclinic_1979,
	title = {A {Baroclinic} {Finite}-{Element} {Model} for {Regional} {Forecasting} with the {Primitive} {Equations}},
	volume = {107},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1979)107%3C0107:ABFEMF%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1979)107<0107:ABFEMF>2.0.CO;2},
	abstract = {A baroclinic primitive equations model is formulated using a variable resolution finite-element discretization in all three space dimensions. The horizontal domain over which the model is integrated is a rectangle on a polar stereographic projection which approximately covers the Northern Hemisphere. A wall boundary condition is imposed at this rectangular boundary giving rise to a well-posed initial boundary value problem. The mesh is specified to be of Cartesian product form with arbitrary non-uniform spacing. By choosing the mesh to be uniformly high over an area of interest and degrading smoothly away from this area, it is possible to use the model to produce a high-resolution local forecast for a limited time period. This choice of mesh avoids the noise problems of a so-called nested grid. A semi-implicit time discretization is used for efficiency. Some results for forecast periods of 24 and 48 h are also given to demonstrate its viability in an operational context.},
	number = {2},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Staniforth, Andrew N. and Daley, Roger W.},
	month = feb,
	year = {1979},
	pages = {107--121}
}

@article{staniforth_variable-resolution_1978,
	title = {A {Variable}-{Resolution} {Finite}-{Element} {Technique} for {Regional} {Forecasting} with the {Primitive} {Equations}},
	volume = {106},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1978)106%3C0439:AVRFET%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1978)106<0439:AVRFET>2.0.CO;2},
	abstract = {A barotropic primitive-equation model using the finite-element method of space discretization is generalized to allow variable resolution. The overhead incurred in going from a uniform mesh to a variable mesh having the same number of degrees of freedom is found to be approximately 20\% overall. The variable-mesh model is used with several grid configurations, each having uniform high resolution over a specified area of interest and lower resolution elsewhere to produce short-term forecasts over this area without the necessity of high resolution everywhere. It is found that the forecast produced on a uniform high-resolution mesh can be essentially reproduced for a limited time over the limited area by a variable-mesh model having only a fraction of the number of degrees of freedom and requiring significantly less computer time. As expected, the period of validity of forecasts on variable meshes can be lengthened by refining the mesh in the outer region. It is concluded that from the point of view of efficiency, accuracy and stability the variable-mesh finite-element technique appears to be well-suited to the practical problem of limited area/time forecasting.},
	number = {4},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Staniforth, Andrew N. and Mitchell, Herschel L.},
	month = apr,
	year = {1978},
	pages = {439--447}
}

@book{sparrow_lorenz_2012,
	title = {The {Lorenz} {Equations}: {Bifurcations}, {Chaos}, and {Strange} {Attractors}},
	isbn = {978-1-4612-5767-7},
	shorttitle = {The {Lorenz} {Equations}},
	abstract = {The equations which we are going to study in these notes were first presented in 1963 by E. N. Lorenz. They define a three-dimensional system of ordinary differential equations that depends on three real positive parameters. As we vary the parameters, we change the behaviour of the flow determined by the equations. For some parameter values, numerically computed solutions of the equations oscillate, apparently forever, in the pseudo-random way we now call "chaotic"; this is the main reason for the immense amount of interest generated by the equations in the eighteen years since Lorenz first presented them. In addition, there are some parameter values for which we see "preturbulence", a phenomenon in which trajectories oscillate chaotically for long periods of time before finally settling down to stable stationary or stable periodic behaviour, others in which we see "intermittent chaos", where trajectories alternate be tween chaotic and apparently stable periodic behaviours, and yet others in which we see "noisy periodicity", where trajectories appear chaotic though they stay very close to a non-stable periodic orbit. Though the Lorenz equations were not much studied in the years be tween 1963 and 1975, the number of man, woman, and computer hours spent on them in recent years - since they came to the general attention of mathematicians and other researchers - must be truly immense.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Sparrow, Colin},
	month = dec,
	year = {2012},
	note = {Google-Books-ID: ttviBwAAQBAJ},
	keywords = {Science / Physics / Mathematical \& Computational, Science / Physics / General, Science / Mechanics / Thermodynamics}
}

@article{smolarkiewicz_multidimensional_1990,
	title = {The multidimensional positive definite advection transport algorithm: nonoscillatory option},
	volume = {86},
	issn = {0021-9991},
	shorttitle = {The multidimensional positive definite advection transport algorithm},
	url = {http://www.sciencedirect.com/science/article/pii/002199919090105A},
	doi = {10.1016/0021-9991(90)90105-A},
	abstract = {This paper presents a nonoscillatory option (i.e., free of dispersive ripples) of the advection algorithm described previously in J. Comput. Phys. (54 (1984), 325; 67 (1986), 396). The approach adopted merges the flux-corrected transport methodology with the iterative formalism of the algorithm. Further discussion of the algorithm's accuracy is included. Theoretical considerations are illustrated through numerical tests and examples of applications to atmospheric fluid dynamics problems.},
	number = {2},
	urldate = {2017-11-01},
	journal = {Journal of Computational Physics},
	author = {Smolarkiewicz, Piotr K and Grabowski, Wojciech W},
	month = feb,
	year = {1990},
	pages = {355--375}
}

@article{smolarkiewicz_fully_1984,
	title = {A fully multidimensional positive definite advection transport algorithm with small implicit diffusion},
	volume = {54},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/0021999184901219},
	doi = {10.1016/0021-9991(84)90121-9},
	abstract = {The idea of the simple positive definite advection scheme presented previously in Monthly Weather Review (III (1983), 479) is improved for an optional multidimensional case and is presented in a generalized format. The accuracy of the scheme is discussed and a review of existing options is presented and illustrated through numerical tests.},
	number = {2},
	urldate = {2017-11-01},
	journal = {Journal of Computational Physics},
	author = {Smolarkiewicz, Piotr K},
	month = may,
	year = {1984},
	pages = {325--362}
}

@article{smith_bmrc_1995,
	title = {The {BMRC} ocean thermal analysis system},
	volume = {44},
	number = {93},
	journal = {Aust. Met. Mag},
	author = {Smith, Neville R.},
	year = {1995},
	pages = {110}
}

@article{smith_tiros-n_1979,
	title = {{TIROS}-{N} operational vertical sounder},
	volume = {60},
	number = {10},
	journal = {Bulletin of the American Meteorological Society},
	author = {Smith, W. L. and Woolf, H. M. and Hayden, C. M. and Wark, D. Q. and McMillin, L. M.},
	year = {1979},
	pages = {1177--1187}
}

@article{smagorinsky_inclusion_1956,
	title = {On the inclusion of moist adiabatic processes in numerical prediction models},
	volume = {5},
	journal = {Beitr. Dtsch. Wetterdien},
	author = {Smagorinsky, J.},
	year = {1956},
	pages = {82--90}
}

@article{slingo_development_1987,
	title = {The {Development} and {Verification} of {A} {Cloud} {Prediction} {Scheme} {For} the {Ecmwf} {Model}},
	volume = {113},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49711347710/abstract},
	doi = {10.1002/qj.49711347710},
	abstract = {This paper describes the development of a fractional cloud cover scheme which was implemented operationally in the ECMWF medium range forecast model in May 1985. the scheme is based on a diagnostic approach in which cloudiness is related empirically to the large-scale model variables, including convective activity. an example of the performance of the scheme is given, showing that a fair degree of skill is achieved in forecasting tropical and extratropical cloudiness. an attempt to verify the results using retrieved cloudiness from Nimbus 7 is described. Considerable difficulties were experienced due to the different height classifications of clouds in the model and in the satellite data. the importance of cloud radiative properties as well as cloud amount is considered briefly, based on a comparison of model earth radiation budget diagnostics with similar data from the NOAA polar-orbiting satellites. the sensitivity of the simulated outgoing long-wave radiance to changes in the prescribed cloud liquid water content is discussed. Two examples of the effects of cloudradiation interaction on boundary layer processes are described which demonstrate the importance of an integrated approach to the treatment of clouds, radiation and turbulent fluxes.},
	language = {en},
	number = {477},
	urldate = {2017-11-01},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Slingo, J. M.},
	month = jul,
	year = {1987},
	pages = {899--927}
}

@article{skamarock_stability_1992,
	title = {The {Stability} of {Time}-{Split} {Numerical} {Methods} for the {Hydrostatic} and the {Nonhydrostatic} {Elastic} {Equations}},
	volume = {120},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1992)120%3C2109:TSOTSN%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1992)120<2109:TSOTSN>2.0.CO;2},
	abstract = {The mathematical equivalence of the linearized two-dimensional (2D) shallow-water system and the 2D acoustic-advection system strongly suggests that time-split schemes designed for the hydrostatic equations can be employed in nonhydrostatic models and vice versa. Stability analyses are presented for several time-split numerical methods for integrating the two systems. The primary interest is in the nonhydrostatic system and in explicit numerical schemes where no multidimensional elliptic equations arise; thus, a detailed analysis of the Klemp and Wilhelmson (KW) explicit technique for integrating the time-split nonhydrostatic system is undertaken. It is found that the interaction between propagating and advecting acoustic modes can introduce severe constraints on the maximum allowable time steps. Proper filtering can remove these constraints. Other explicit time-split schemes are analysed, and, of all the explicit schemes considered, it is believed that the KW time-split method offers the best combination of stability, minimal filtering, simplicity, and freedom from spurious noise for integrating the nonhydrostatic or hydrostatic equations. Schemes wherein the fast modes are integrated implicitly and the slow modes explicitly are also analyzed. These semi-implicit schemes can be used with a greater variety of advection schemes than the explicit time-split approaches and generally require less filtering than the split-explicit schemes for stability. However, a multidimensional elliptic equation must be solved with each time step. For nonhydrostatic elastic models using the KW time-split method, an acoustic filter is presented that allows a reduction of previously necessary filtering in the KW scheme, and a method for integrating the buoyancy equation is discussed that results in the large time step being limited by a Courant condition based on the advection velocity and not on the fastest gravity-wave speed.},
	number = {9},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Skamarock, William C. and Klemp, Joseph B.},
	month = sep,
	year = {1992},
	pages = {2109--2127}
}

@article{simmons_error_1995,
	title = {Error growth and estimates of predictability from the {ECMWF} forecasting system},
	volume = {121},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49712152711/abstract},
	doi = {10.1002/qj.49712152711},
	abstract = {Examination has been made of the skill of ECMWF forecasts of the 500 hPa height field produced daily out to ten days ahead, verifying in the period from 1 December 1980 to 31 May 1994. Over this time accuracy has been improved substantially over the first half of the forecast range. the systematic (seasonal-mean) component of the error has been greatly reduced at all forecast times, but there has been little reduction in the non-systematic (transient) component later in the range. The simple model proposed by Lorenz for the intrinsic growth of forecast error has been applied to the evolution of differences between consecutive forecasts. the implied growth-rates of small forecast errors have increased significantly since 1981. They do not show much variation with season, and are a little lower in the southern than in the northern hemisphere. the most recent error-doubling times are around 1.5 days for the northern hemisphere and 1.7 days for the southern hemisphere. Error saturation levels are at present similar to or greater than those of the 1981 version of the model, having been significantly lower in intermediate years. the accuracy of recent short- and early medium-range forecasts and realism of the climatology of the forecast model support the view that estimates of intrinsic error-growth parameters from the current forecasting system are more reliable than those obtained earlier. Forecast accuracy later in the medium range may thus not have benefited fully from improvements earlier in the range because of the faster error-growth associated with a more active, though more realistic, forecast model. Overprediction of variance may nevertheless detrimentally affect present levels of skill and estimates of predictability in all seasons other than summer. The error-growth model currently indicates that it is possible, in principle, to make deterministic mediumrange forecasts for the extratropical 500 hPa height field of the northern hemisphere that are as accurate five days ahead as present forecasts are three days ahead, provided the one-day forecast error can be reduced by the same factor in the future as has actually been achieved in the years since 1981. the level of error currently reached at day seven would then be reached at around day ten. the scope for improvement of forecasts for the southern hemisphere appears to be rather larger. Improvements seem to be possible throughout the spectral range studied, up to total wave-number 40. This is found also for the rotational and divergent wind components at 850 and 200 hPa. For these components, particularly the divergent component, there is a quite pronounced error in the representation of the largest scales.},
	language = {en},
	number = {527},
	urldate = {2017-11-01},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Simmons, A. J. and Mureau, R. and Petroliagis, T.},
	month = oct,
	year = {1995},
	keywords = {Numerical weather prediction, Medium-range forecasting, Error growth, Predictability},
	pages = {1739--1771}
}

@article{simmons_energy_1981,
	title = {An {Energy} and {Angular}-{Momentum} {Conserving} {Vertical} {Finite}-{Difference} {Scheme} and {Hybrid} {Vertical} {Coordinates}},
	volume = {109},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1981)109%3C0758:AEAAMC%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1981)109<0758:AEAAMC>2.0.CO;2},
	abstract = {An energy and angular-momentum conserving vertical finite-difference scheme is introduced for a general terrain-following vertical coordinate which is a function of pressure and its surface value. A corresponding semi-implicit time scheme is also defined. These schemes am used to compare the usual sigma coordinate with the hybrid coordinate which reduces to pressure above a fixed level and with a modified hybrid coordinate which tends uniformly to pressure at upper levels. Error in the representation of the stratospheric pressure gradient over steep orography can be significantly reduced by use of the hybrid coordinate but the semi-implicit scheme is less stable. The modified hybrid coordinate offers a useful compromise.},
	number = {4},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Simmons, A. J. and Burridge, D. M.},
	month = apr,
	year = {1981},
	pages = {758--766}
}

@article{shuman_history_1989,
	title = {History of {Numerical} {Weather} {Prediction} at the {National} {Meteorological} {Center}},
	volume = {4},
	issn = {0882-8156},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0434(1989)004%3C0286:HONWPA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0434(1989)004<0286:HONWPA>2.0.CO;2},
	abstract = {The first modern numerical weather prediction (NWP) models were developed for the computer that was announced in 1932 at the Institute for Advanced Study, in Princeton, New Jersey. Within 3 yr three agencies of the United States Government jointly created a numerical weather prediction service, but it was quickly discovered that current models had very serious defects. After considerable research, the first operationally effective model was achieved in 1958—a barotropic model covering most of the Northern Hemisphere. Over the years, models have evolved through multilevel filtered equation models and several primitive equation models. Analysis and data assimilation systems necessary for timeliness were also developed, and have likewise evolved. The result has been a revolution in weather forecasting.},
	number = {3},
	urldate = {2017-11-01},
	journal = {Weather and Forecasting},
	author = {Shuman, Frederick G.},
	month = sep,
	year = {1989},
	pages = {286--296}
}

@article{shuman_operational_1968,
	title = {An {Operational} {Six}-{Layer} {Primitive} {Equation} {Model}},
	volume = {7},
	issn = {0021-8952},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0450(1968)007%3C0525:AOSLPE%3E2.0.CO;2},
	doi = {10.1175/1520-0450(1968)007<0525:AOSLPE>2.0.CO;2},
	abstract = {In mid-1966 a new baroclinic numerical weather prediction model became operational at the National Meteorological Center, an event made possible by advances in computer and communications technology. The new model integrates directly the primitive (hydrostatic) hydrodynamic and thermodynamic equations, a departure from previous operational models whose central dynamic equation was that of conservation of vorticity. In its first fourteen months of operational use, it has resulted in highly significant improvements in the Center's products.},
	number = {4},
	urldate = {2017-11-01},
	journal = {Journal of Applied Meteorology},
	author = {Shuman, Frederick G. and Hovermale, John B.},
	month = aug,
	year = {1968},
	pages = {525--547}
}

@article{shuman_numerical_1957,
	title = {Numerical methods in weather prediction: i. the balance equation},
	volume = {85},
	issn = {0027-0644},
	shorttitle = {Numerical methods in weather prediction},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1957)085%3C0329:NMIWPI%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1957)085<0329:NMIWPI>2.0.CO;2},
	abstract = {Two methods of solving the balance equation are outlined. Both methods have been used successfully on a daily operational basis at the Joint Numerical Weather Prediction Unit for a period of more than a year. Solutions were on the operational grid of 30 × 34 points spaced at 381-km. intervals.},
	number = {10},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Shuman, Frederick G.},
	month = oct,
	year = {1957},
	pages = {329--332}
}

@article{shukla_dynamical_2000,
	title = {Dynamical {Seasonal} {Prediction}},
	volume = {81},
	issn = {0003-0007},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0477(2000)081%3C2593%3ADSP%3E2.3.CO%3B2},
	doi = {10.1175/1520-0477(2000)081<2593:DSP>2.3.CO;2},
	abstract = {Dynamical Seasonal Prediction (DSP) is an informally coordinated multi-institution research project to investigate the predictability of seasonal mean atmospheric circulation and rainfall. The basic idea is to test the feasibility of extending the technology of routine numerical weather prediction beyond the inherent limit of deterministic predictability of weather to produce numerical climate predictions using state-of-the-art global atmospheric models. Atmospheric general circulation models (AGCMs) either forced by predicted sea surface temperature (SST) or as part of a coupled forecast system have shown in the past that certain regions of the extratropics, in particular, the Pacific-North America (PNA) region during Northern Hemisphere winter, can be predicted with significant skill especially during years of large tropical SST anomalies. However, there is still a great deal of uncertainty about how much the details of various AGCMs impact conclusions about extratropical seasonal prediction and predictability. DSP is designed to compare seasonal simulation and prediction results from five state-of-the-art U.S. modeling groups (NCAR, COLA, GSFC, GFDL, NCEP) in order to assess which aspects of the results are robust and which are model dependent. The initial emphasis is on the predictability of seasonal anomalies over the PNA region. This paper also includes results from the ECMWF model, and historical forecast skill over both the PNA region and the European region is presented for all six models. It is found that with specified SST boundary conditions, all models show that the winter season mean circulation anomalies over the Pacific-North American region are highly predictable during years of large tropical sea surface temperature anomalies. The influence of large anomalous boundary conditions is so strong and so reproducible that the seasonal mean forecasts can be given with a high degree of confidence. However, the degree of reproducibility is highly variable from one model to the other, and quantities such as the PNA region signal to noise ratio are found to vary significantly between the different AGCMs. It would not be possible to make reliable estimates of predictability of the seasonal mean atmosphere circulation unless causes for such large differences among models are understood.},
	number = {11},
	urldate = {2017-11-01},
	journal = {Bulletin of the American Meteorological Society},
	author = {Shukla, J. and Marx, L. and Paolino, D. and Straus, D. and Anderson, J. and Ploshay, J. and Baumhefner, D. and Tribbia, J. and Brankovic, C. and Palmer, T. and Chang, Y. and Schubert, S. and Suarez, M. and Kalnay, E.},
	month = nov,
	year = {2000},
	pages = {2593--2606}
}

@article{shukla_dynamical_1981,
	title = {Dynamical {Predictability} of {Monthly} {Means}},
	volume = {38},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1981)038%3C2547%3ADPOMM%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1981)038<2547:DPOMM>2.0.CO;2},
	abstract = {We have attempted to determine the theoretical upper limit of dynamical predictability of monthly means for prescribed nonfluctuating external forcings. We have extended the concept of “classical” predictability, which primarily refers to the lack of predictability due mainly to the instabilities of synoptic-scale disturbances, to the predictability of time averages, which are determined by the predictability of low-frequency planetary waves. We have carded out 60-day integrations of a global general circulation model with nine different initial conditions but identical boundary conditions of sea surface temperature, snow, sea ice and soil moisture. Three of these initial conditions are the observed atmospheric conditions on 1 January of 1975, 1976 and 1977. The other six initial conditions are obtained by superimposing over the observed initial conditions a random perturbation comparable to the errors of observation. The root-mean-square (rms) error of random perturbations at all the grid points and all the model levels is 3 m s−1 in u and v components of wind. The rms vector wind error between the observed initial conditions is {\textgreater}15 m s−1. It is hypothesized that for a given averaging period, if the rms error among the time averages predicted from largely different initial conditions becomes comparable to the rms error among the time averages predicted from randomly perturbed initial conditions, the time averages are dynamically unpredictable. We have carried out the analysis of variance to compare the variability, among the three groups, due to largely different initial conditions, and within each group due to random perturbations. It is found that the variances among the first 30-day means, predicted from largely different initial conditions, are significantly different from the variances due to random perturbations in the initial conditions, whereas the variances among 30-day means for days 31–60 are not distinguishable from the variances due to random initial perturbations. The 30-day means for days 16–46 over certain areas are also significantly different from the valances due to random perturbations. These results suggest that the evolution of long waves remains sufficiently predictable at least up to one month, and possibly up to 45 days, so that the combined effects of their own nonpredictability and their depredictabilization by synoptic-scale instabilities is not large enough to degrade the dynamical prediction of monthly means. The Northern Hemisphere appears to be more predictable than the Southern Hemisphere. It is noteworthy that the lack of predictability for the second month is not because the model simulations relax to the same model state but because of very large departures in the simulated model states. This suggests that, with improvements in model resolution and physical parameterizations, there is potential for extending the predictability of time averages even beyond one month. Here, we have examined only the dynamical predictability, because the boundary conditions are identical in all the integrations. Based on these results, and the possibility of additional predictability due to the influence of persistent anomalies of sea surface temperature, sea ice, snow and soil moisture, it is suggested that there is sufficient physical basis to undertake a systematic program to establish the feasibility of predicting monthly means by numerical integrations of realistic dynamical models.},
	number = {12},
	urldate = {2017-11-01},
	journal = {Journal of the Atmospheric Sciences},
	author = {Shukla, J.},
	month = dec,
	year = {1981},
	pages = {2547--2572}
}

@article{shaw_data_1987,
	title = {Data {Assimilation}: the 1984/85 {Revisions} of the {Ecmwf} {Mass} and {Wind} {Analysis}},
	volume = {113},
	issn = {1477-870X},
	shorttitle = {Data {Assimilation}},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49711347607/abstract},
	doi = {10.1002/qj.49711347607},
	abstract = {A comprehensive evaluation of the ECMWF operational data assimilation system has been made, based largely on statistics of its performance over a long period of time. the evaluation has identified many deficiencies, covering such aspects of the analysis as the optimum interpolation statistics, the data selection algorithms, and the quality control criteria applied within the analysis. The observation and forecast error variances were seriously in error in the stratosphere and in the tropics. A more faithful model of the forecast error spectrum is provided by the Bessel function expansion than by the Gaussian model. the vertical structure of the height error is assumed to be composed of two components: a ‘barotropic’ part related to a horizontally constant mode and a ‘baroclinic’ structure for the horizontally varying modes. the wind field errors also have a large-scale component. the extratropical vertical correlation remained similar to the earlier correlations, but the tropical height and wind structures changed dramatically. Reasonable rejection limits were defined from the distributions of the observation departures from the first guess, as were observation errors for satellite and aircraft wind reports and Australian pseudo-observations. A comprehensive and homogeneous data selection algorithm has been devised. However, it has been found necessary to exclude land surface wind reports from the analysis process as the wind departures from a first-guess field commonly contradict the surface pressure departures due to difficulties in generating a reasonable 10 m first-guess wind. the omission of surface winds alleviated the data selection problem in data-dense regions. The representation of the vertical correlations was changed to a continuous representation in the vertical which enabled a multivariate interpolation from data on standard pressure levels directly to model coordinates. the earlier procedure used a multivariate interpolation to constant pressure surfaces in the model grid, followed by a univariate interpolation to model surfaces in the vertical. The results of these improvements, in a series of tests covering in total some 30 days of assimilations, are also described. In summary they yield an analysis and a subsequent first guess which are in closer agreement with observations. the analysis scheme yields more balanced fields in the sense that the subsequent initialization produces more modest changes. the major impact on forecasts, in particular in the short range, is also judged to be positive. These improvements have been incorporated in the ECMWF operational data assimilation system. They have also been incorporated in the reassimilation of the final FGGE level IIb data set at ECMWF.},
	language = {en},
	number = {476},
	urldate = {2017-11-01},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Shaw, D. B. and Lönnberg, P. and Hollingsworth, A. and Undén, P.},
	month = apr,
	year = {1987},
	pages = {533--566}
}

@article{shapiro_smoothing_1970,
	title = {Smoothing, filtering, and boundary effects},
	volume = {8},
	issn = {1944-9208},
	url = {http://onlinelibrary.wiley.com/doi/10.1029/RG008i002p00359/abstract},
	doi = {10.1029/RG008i002p00359},
	abstract = {Numerical integrations of finite-difference analogs of systems of nonlinear partial differential equations, such as those arising in atmospheric dynamics, are subject to computational instability from a variety of causes. One type of instability is produced by a spurious, nonlinear growth of high-frequency components that may be introduced by roundoff, truncation, and observational error. This type of instability, first discussed by N. A. Phillips, can be suppressed by a suitable choice of finite-difference method or by the use of a filter that selectively damps the high-frequency components. Though much effort is being devoted to the development of stable finite-difference procedures, and considerable success has been achieved, all such methods involve high-frequency smoothing either implicitly or explicitly. It is therefore important that the effects of such filtering be fully understood. Filtering and smoothing operators are developed for use in conjunction with the numerical integration of nonlinear systems and for other purposes. The general procedure is demonstrated for simple one-dimensional operators and the properties of such operators are thoroughly explored. The development is then expanded to allow for compound operators designed to suit some particular requirement and further extended to more than one dimension. Both real and complex operators are discussed. Reverse smoothers or wave amplifiers are introduced, and some of the problems associated with their use are discussed. A general procedure is outlined for the construction of an ‘ideal’ low-pass filter; that is, a filter that removes the shortest resolvable wave component (the 2-grid-interval wave) but restores all other wave components as close as is desired to their original amplitudes without amplifying or changing the phase of any wave component. Finally, the effects, sometimes disastrous, of finite domains on the properties of the smoothing operators are explored for a variety of common boundary assumptions.},
	language = {en},
	number = {2},
	urldate = {2017-11-01},
	journal = {Reviews of Geophysics},
	author = {Shapiro, Ralph},
	month = may,
	year = {1970},
	pages = {359--387}
}

@article{semazzi_comparison_1986,
	title = {A {Comparison} of the {Bounded} {Derivative} and the {Normal}-{Mode} {Initialization} {Methods} {Using} {Real} {Data}},
	volume = {114},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1986)114%3C2106:ACOTBD%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1986)114<2106:ACOTBD>2.0.CO;2},
	abstract = {Application of the bounded-derivative and normal-mode methods to a simple linear barotropic model at a typical middle latitude shows that the two methods lead to identical constraints up to a certain degree of approximation. Beyond this accuracy the two methods may differ from each other. When applied to a global nonlinear barotropic model using real data, again the two methods lead to similar balanced initial states. The parity oscillations in the unbalanced height field, which have amplitudes of up to 60 m with a dominant periodicity of about 5 to 6 h, are practically eliminated by both initialization methods. The rotational wind component is smooth even for the unbalanced initial state. The small-scale spatial features of the irrotational wind component are drastically reduced by initialization. Both the nonlinear normal-mode and the bounded-derivative initialization methods yield similar divergence field centered around the areas of highest orography. The comparison shows that there is no significant loss of information in the man and momentum fields, despite the fact that the bounded-derivative method employs only the original, rotational wind component to construct a balanced initial state compared to the normal-mode method, which, in addition, makes use of the unbalanced divergent wind and height fields.},
	number = {11},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Semazzi, F. H. M. and Navon, I. M.},
	month = nov,
	year = {1986},
	pages = {2106--2121}
}

@article{sellers_simple_1986,
	title = {A {Simple} {Biosphere} {Model} ({SIB}) for {Use} within {General} {Circulation} {Models}},
	volume = {43},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1986)043%3C0505:ASBMFU%3E2.0.CO;2},
	doi = {10.1175/1520-0469(1986)043<0505:ASBMFU>2.0.CO;2},
	abstract = {A simple but realistic biosphere model has been developed for calculating the transfer of energy, mass and momentum between the atmosphere and the vegetated surface of the earth. The model is designed for use in atmospheric general circulation models. The vegetation in each terrestrial model grid area is represented by two distinct layers, either or both of which may be present or absent at any given location and time. The upper vegetation layer represents the perennial canopy of trees or shrubs, while the lower layer represents the annual ground cover of grasses and other herbaceous species. The local coverage of each vegetation layer may be fractional or complete but as the individual vegetation elements are considered to be evenly spaced, their root systems are assumed to extend uniformly throughout the entire grid area. Besides the vegetation morphology, the physical and physiological properties of the vegetation layers are also prescribed. These properties determine (i) the reflection, transmission, absorption and emission of direct and diffuse radiation in the visible, near infrared and thermal wavelength intervals; (ii) the interception of rainfall and its evaporation from the leaf surfaces; (iii) the infiltration, drainage and storage of the residual rainfall in the soil; (iv) the control by the photosynthetically active radiation and the soil moisture potential, inter alia, over the stomatal functioning and thereby over the return transfer of the soil moisture to the atmosphere through the root-stem-leaf system of the vegetation; and (v) the aerodynamic transfer of water vapor, sensible heat and momentum from the vegetation and soil to a reference level within the atmospheric boundary layer. The Simple Biosphere (SiB) has seven prognostic physical-state variables: two temperatures (one for the canopy and one for the ground cover and soil surface); two interception water stores (one for the canopy and one for the ground cover); and three soil moisture stores (two of which can be reached by the vegetation root systems and one underlying recharge layer into and out of which moisture is transferred only by hydraulic diffusion and gravitational drainage).},
	number = {6},
	urldate = {2017-11-01},
	journal = {Journal of the Atmospheric Sciences},
	author = {Sellers, P. J. and Mintz, Y. and Sud, Y. C. and Dalcher, A.},
	month = mar,
	year = {1986},
	pages = {505--531}
}

@article{sela_spectral_1980,
	title = {Spectral {Modeling} at the {National} {Meteorological} {Center}},
	volume = {108},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1980)108%3C1279:SMATNM%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1980)108<1279:SMATNM>2.0.CO;2},
	abstract = {A model with spectral representation in the horizontal and Arakawa quadratic conserving finite differencing in the vertical is formulated. The model includes a moisture cycle consisting of large-scale condensation processes, as well as a convective parameterization. Interactions with the underlying oceans include evaporation and sensible heating. Orography and surface friction are modeled and a semi-implicit time integration is employed. Experiments with global and hemispheric forecasts are described and evaluated.},
	number = {9},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Sela, Joseph G.},
	month = sep,
	year = {1980},
	pages = {1279--1292}
}

@article{segami_operational_1989,
	title = {Operational {MesoScale} {Weather} {Prediction} with {Japan} {Spectral} {Model}},
	volume = {67},
	doi = {10.2151/jmsj1965.67.5_907},
	abstract = {Japan Spectral Model (JSM) was developed for operational forecast use in JMA. The model is a 19-level spectral limited-area model with a horizontal resolution of 40km. The purpose of the model is to predict meso-α-scale phenomena and fine structures of orographically induced disturbances.The model predicts quite well the mesoscale structure within a synoptic scale disturbance and the evolution of a mesoscale cloud system associated with a polar low. The model also shows sufficient ability to predict severe rainfalls in the Baiu season.Forecasts of precipitation show a good performance in spring even in the early hours of the forecast time. However, the scores for the summer season are worse than those for spring. This may be due to the cumulus parameterization scheme used in JSM. Slow spin up of the model is a serious problem in the summer season.},
	number = {5},
	journal = {Journal of the Meteorological Society of Japan. Ser. II},
	author = {Segami, Akihide and Kurihara, Kazuo and Nakamura, Hajime and Ueno, Mitsuru and Takano, Isao and Tatsumi, Yasuo},
	year = {1989},
	pages = {907--924}
}

@article{schwartz_accuracy_2000,
	title = {Accuracy of {RUC}-1 and {RUC}-2 {Wind} and {Aircraft} {Trajectory} {Forecasts} by {Comparison} with {ACARS} {Observations}},
	volume = {15},
	issn = {0882-8156},
	url = {http://journals.ametsoc.org/doi/full/10.1175/1520-0434(2000)015%3C0313:AORARW%3E2.0.CO%3B2},
	doi = {10.1175/1520-0434(2000)015<0313:AORARW>2.0.CO;2},
	abstract = {As part of an investigation into terminal airspace productivity sponsored by the NASA Ames Research Center, a study was performed at the Forecast Systems Laboratory to investigate sources of wind forecast error and to assess differences in wind forecast accuracy between the 60-km Rapid Update Cycle, version 1 (RUC-1), and the newer 40-km RUC-2. Improved knowledge of these errors is important for development of air traffic management automation tools under development at NASA Ames and elsewhere. This information is also useful for operational users of RUC forecast winds. To perform this study, commercial aircraft reports of wind reported through Aircraft Communications, Addressing, and Reporting System (ACARS) were collected in a region over the western and central United States for a 13-month period, along with RUC-1 and RUC-2 wind forecasts. Differences between forecasts and ACARS observations and estimates of ACARS wind observation error itself were both calculated. It was found that rms vector differences between observations and forecasts from either version of the RUC increased as wind speed increased, and also as altitude increased and in winter months (both associated with higher wind speed). Wind errors increased when thunderstorms were nearby and were smaller in wintertime precipitation situations. The study also showed that considerable progress has been made in the accuracy of wind forecasts to be used for air traffic management by the introduction of the RUC-2 system, replacing the previous RUC-1 system. Improvement was made both in the intrinsic accuracy as well as in the time availability, both contributing to the overall improvement in the actual wind forecast available for air traffic management purposes. Using 3-h forecasts, RUC-2 demonstrated a reduction in mean daily rms vectors of approximately 10\% over that for RUC-1 based on accuracy improvements alone. This error reduction increased to about 22\% when time availability improvements were added. It was also found that the degree of improvement from the RUC-2 increased substantially for periods with a large number of significant wind errors. The percentage of individual vector errors greater than 10 m s−1 was reduced by RUC-2 from 8\% (RUC-1) to 3\% overall and from 17\% to 7\% during the worst month. Such peak error periods have a strong impact on air traffic management automation tools. Last, it was found that the estimated trajectory projection errors from the RUC-2 using 1–2-h forecasts averaged 9 s for ascent/descent flight segments of approximately 15 min, and about 10 s for en route segments of the same duration.},
	number = {3},
	urldate = {2017-11-01},
	journal = {Weather and Forecasting},
	author = {Schwartz, Barry E. and Benjamin, Stanley G. and Green, Steven M. and Jardin, Matthew R.},
	month = jun,
	year = {2000},
	pages = {313--326}
}

@article{schubert_assimilated_1993,
	title = {An {Assimilated} {Dataset} for {Earth} {Science} {Applications}},
	volume = {74},
	issn = {0003-0007},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0477(1993)074%3C2331:AADFES%3E2.0.CO%3B2},
	doi = {10.1175/1520-0477(1993)074<2331:AADFES>2.0.CO;2},
	abstract = {The Data Assimilation Office at NASA's Goddard Space Flight Center is currently producing a multiyear gridded global atmospheric dataset for use in climate research, including tropospheric chemistry applications. The data, which are being made available to the scientific community, are well suited for climate research since they are produced by a fixed assimilation system designed to minimize the spinup in the hydrological cycle. By using a nonvarying system, the variability due to algorithm change is eliminated and geophysical variability can be more confidently isolated. The analysis incorporates rawinsonde reports, satellite retrievals of geopotential thickness, cloud-motion winds, and aircraft, ship, and rocketsonde reports. At the lower boundary, the assimilating atmospheric general circulation model is constrained by the observed sea surface temperature and soil moisture derived from observed surface air temperature and precipitation fields. The available output data include all prognostic variables and a large number of diagnostic quantities such as heating rates, precipitation, surface fluxes, cloud fraction, and the height of the planetary boundary layer. These variables were chosen to assure a complete budget of the energy and moisture cycles. The assimilated data should also be useful for estimating transport by cumulus processes. The analysis increments (observation minus first guess) and the estimated analysis errors are provided to help the user assess the quality of the data. All quantities are made available every 6 h at the full resolution of the assimilating general circulation model. Selected surface quantities are made available every 3 h.},
	number = {12},
	urldate = {2017-11-01},
	journal = {Bulletin of the American Meteorological Society},
	author = {Schubert, Siegfried D. and Rood, Richard B. and Pfaendtner, James},
	month = dec,
	year = {1993},
	pages = {2331--2342}
}

@article{schopf_vacillations_1988,
	title = {Vacillations in a {Coupled} {Ocean}–{Atmosphere} {Model}},
	volume = {45},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1988)045%3C0549:VIACOM%3E2.0.CO;2},
	doi = {10.1175/1520-0469(1988)045<0549:VIACOM>2.0.CO;2},
	abstract = {Results are presented from a 35-year integration of a coupled ocean-atmosphere model. Both ocean and atmosphere are two-level, nonlinear primitive equations models. The global atmospheric model is forced by a steady, zonally symmetric Newtonian heating. The ocean model is solved in a rectangular tropical basin. Heat fluxes between ocean and atmosphere are linear in air-sea temperature differences, and the interfacial stress is proportional to lower-level atmospheric winds. The coupled models produce ENSO-like variability on time scales of 3 to 5 years. Since there is no external time-dependent forcing, these are self-sustained vacillations of the nonlinear system. It is argued that the energetics of the vacillations is that of unstable coupled modes and that the time scale is crucially dependent on the effects of ocean waves propagating in a closed basin.},
	number = {3},
	urldate = {2017-11-01},
	journal = {Journal of the Atmospheric Sciences},
	author = {Schopf, Paul S. and Suarez, Max J.},
	month = feb,
	year = {1988},
	pages = {549--566}
}

@article{schlatter_estimation_1979,
	title = {Estimation of {Errors} in {Nimbus} 6 {Temperature} {Profiles} and {Their} {Spatial} {Correlation}},
	volume = {107},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1979)107%3C1402%3AEOEINT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1979)107<1402:EOEINT>2.0.CO;2},
	abstract = {Using an 8-day series (18–26 August 1975) of multivariate statistical analyses of European radiosonde data together with a measure of analysis error, we have estimated error statistics from 959 Nimbus 6 temperature profiles for 10 isobaric layers in the troposphere and lower stratosphere. The mean error or bias is largest near the tropopause (+0.9°C) but changes sign several times in the vertical so that the integrated mean error for the atmospheric column 1000–70 mb is small (−0.1°C). The root-mean-square error peaks at the tropopause (2.9°C) with a minimum in the midtroposphere (1.0°C). In all layers, the horizontal correlation of retrieval error shows little systematic dependence on direction but strong dependence on distance. The correlation is greater than 0.50 at distances less than 400 km and less than 0.10 at 800 km and beyond, and it can be approximated by a Gaussian curve. The vertical correlations are greatest between adjacent layers (∼0.50); negative correlations exist between layers on opposite sides of the tropopause. This information is useful in any statistical objective analysis which accounts for observational error.},
	number = {10},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Schlatter, Thomas W. and Branstator, Grant W.},
	month = oct,
	year = {1979},
	pages = {1402--1413}
}

@article{schlatter_experiments_1975,
	title = {Some {Experiments} with a {Multivariate} {Statistical} {Objective} {Analysis} {Scheme}},
	volume = {103},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1975)103%3C0246:SEWAMS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1975)103<0246:SEWAMS>2.0.CO;2},
	abstract = {A statistical scheme for simultaneous analysis of the wind and geopotential height fields has been developed based upon optimum interpolation. The matrix weights applied to the observation vectors depend upon covariances of observed-minus-forecast differences. The simplest possible forecasts (or first guesses)—climatology, persistence and damped persistence—are used. The geostrophic relationship and the height-height covariances computed from historical data are used to derive the other required covariances. The scheme has been tested at a single point based upon 500-mb winter U.S. radiosonde data. Results are promising; when either climatology or damped persistence is used as a first guess, the root-men-square (rms) differences between analyzed and observed values were about 13 m for the height and 4.0 m s−1 for the u-and v–components of the wind. When persistence is used as a fist guess, results are slightly worse. The multivariate approach is clearly superior to a univariate approach for height analyses. On the other hand, geopotential height data do not significantly improve wind analyses. The applicability of the scheme to objective analysis over large areas is briefly mentioned.},
	number = {3},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Schlatter, Thomas W.},
	month = mar,
	year = {1975},
	pages = {246--257}
}

@article{savijarvi_error_1995,
	title = {Error {Growth} in a {Large} {Numerical} {Forecast} {System}},
	volume = {123},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1995)123%3C0212%3AEGIALN%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1995)123<0212:EGIALN>2.0.CO;2},
	abstract = {Internal and external z500 global total rms errors followed quadratic growth laws quite well in NMC Medium-Range Forecast (MRF) Model 0–10-day forecasts for 1988–93. Growth parameters and model and analysis errors for many winter were estimated using the quadratic rms error growth assumption. Both the MRF model error and analysis error have nearly halved during 1988–93. But at the same time the growth parameters have nearly doubled: smaller errors grow faster. Thus while the limit of deterministic predictability (rms error 71\% of saturation) has been going up, the limit of dynamic predictability (rms error 97.5\% of saturation) seems to be set at around 20 days in large horizontal scales, dropping to 6–7 days in small scales.},
	number = {1},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Savijarvi, Hannu},
	month = jan,
	year = {1995},
	pages = {212--221}
}

@book{isaacson_analysis_1994,
	title = {Analysis of {Numerical} {Methods}},
	isbn = {978-0-486-68029-3},
	abstract = {This excellent text for advanced undergraduates and graduate students covers norms, numerical solution of linear systems and matrix factoring, iterative solutions of nonlinear equations, eigenvalues and eigenvectors, polynomial approximation, and other topics. It offers a careful analysis and stresses techniques for developing new methods, plus many examples and problems. 1966 edition.},
	language = {en},
	publisher = {Courier Corporation},
	author = {Isaacson, Eugene and Keller, Herbert Bishop},
	month = jun,
	year = {1994},
	note = {Google-Books-ID: uODcCgAAQBAJ},
	keywords = {Mathematics / Applied, Mathematics / Mathematical Analysis}
}

@article{sasaki_basic_1970,
	title = {Some basic formalisms in numerical variational analysis},
	volume = {98},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1970)098%3C0875:SBFINV%3E2.3.CO;2},
	doi = {10.1175/1520-0493(1970)098<0875:SBFINV>2.3.CO;2},
	abstract = {This study aims at the theoretical development of a method of “four-dimensional analysis,” namely the numerical variational analysis. The three basic types of variational formalism in the numerical variational analysis method are discussed. The basic formalisms are categorized into three areas: (1) “timewise localized” formalism, (2) formalism with strong constraint, and (3) formalism with weak constraint. Exact satisfaction of selected prognostic equations were formulated as constraints in the functionals for the first two formalisms. However, only the second formalism contains explicitly the time variation terms in the Euler equations. The third formalism is characterized by the subsidiary condition which requires that the prognostic or diagnostic equations must be approximately satisfied. The variational formalisms and the associated Euler-Lagrange equations are obtained in the form of finite-difference analogs. In this article, the filtering of cach formalism and the uniqueness of solutions of the Euler equations are discussed for a limit that time and space increments (Δt and Δx) approach zero. The results from the limited case study can be applied, with some modification, for the cases where these increments are finite. In addition, a numerical method of solving the Euler equations is discussed. The discussion is facilitated, merely for the sake of simplicity, by choosing a linear advection equation as a dynamical constraint. However, the discussion can be applied to more complicated and realistic cases.},
	number = {12},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Sasaki, Yoshikazu},
	month = dec,
	year = {1970},
	pages = {875--883}
}

@article{sasaki_proposed_1969,
	title = {Proposed {Inclusion} of {Time} . {Variation} {Terms}, {Observational} and {Theoretical}, in {Numerical} {Variational} {Objective} {Analysis}},
	volume = {47},
	doi = {10.2151/jmsj1965.47.2_115},
	abstract = {The author's previous study on an objective analysis method (1958) is extended, by introducing terms of time variation and the dynamical equations which describe the time variation, for the purposes : 1) to filter and suppress unnecessary meteorological high frequency noises contained in the initial data and forecast fields and 2) to obtain the dynamically sound initial values for the areas or layers of lacking observation. The fundamental concept of the method is explained using the most simple examples of dynamical constraints; linear advection and linear diffusion.},
	number = {2},
	journal = {Journal of the Meteorological Society of Japan. Ser. II},
	author = {Sasaki, Yoshikazu},
	year = {1969},
	pages = {115--124}
}

@misc{noauthor_step-mountain_nodate,
	title = {The {Step}-{Mountain} {Coordinate}: {Physical} {Package}: {Monthly} {Weather} {Review}: {Vol} 118, {No} 7},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1990)118%3C1429:TSMCPP%3E2.0.CO;2},
	urldate = {2017-11-01}
}

@article{sameh_hybrid_1999,
	title = {Hybrid {Parallel} {Linear} {System} {Solvers}},
	volume = {12},
	issn = {1061-8562},
	url = {http://iahr.tandfonline.com/doi/abs/10.1080/10618569908940826},
	doi = {10.1080/10618569908940826},
	abstract = {This paper presents a new approach to the solution of nonsymmetric linear systems that uses hybrid techniques based on both direct and iterative methods. An implicitly preconditioned modified system is obtained by applying projections onto block rows of the original system. Our technique provides the flexibility of using either direct or iterative methods for the solution of the preconditioned system. The resulting algorithms are robust, and can be implemented with high efficiency on a variety of parallel architectures. The algorithms are used to solve linear systems arising from the discretization of convection-diffusion equations as well as those systems that arise from the simulation of particulate flows. Experiments are presented to illustrate the robustness and parallel efficiency of these methods.},
	number = {3-4},
	urldate = {2017-11-01},
	journal = {International Journal of Computational Fluid Dynamics},
	author = {Sameh, Ahmed H. and Sarin, Vivek},
	month = jan,
	year = {1999},
	pages = {213--223}
}

@article{saltzman_finite_1962,
	title = {Finite {Amplitude} {Free} {Convection} as an {Initial} {Value} {Problem}—{I}},
	volume = {19},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1962)019%3C0329%3AFAFCAA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1962)019<0329:FAFCAA>2.0.CO;2},
	abstract = {The Oberbeck-Boussinesq equations are reduced to a two-dimensional form governing “roll” convection between two free surfaces maintained at a constant temperature difference. These equations are then transformed to a set of ordinary differential equations governing the time variations of the double-Fourier coefficients for the motion and temperature fields. Non-linear transfer processes are retained and appear as quadratic interactions between the Fourier coefficients. Energy and heat transfer relations appropriate to this Fourier resolution, and a numerical method for solution from arbitrary initial conditions are given. As examples of the method, numerical solutions for a highly truncated Fourier representation are presented. These solutions, which are for a fixed Prandtl number and variable Rayleigh numbers, show the transient growth of convection from small perturbations, and in all cases studied approach steady states. The steady states obtained agree favorably with steady-state solutions obtained by previous investigators.},
	number = {4},
	urldate = {2017-11-01},
	journal = {Journal of the Atmospheric Sciences},
	author = {Saltzman, Barry},
	month = jul,
	year = {1962},
	pages = {329--341}
}

@article{sadourny_integration_1968,
	title = {Integration of the nondivergent barotropic vorticity equation with an icosahedral-hexagonal grid for the sphere},
	volume = {96},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1968)096%3C0351:IOTNBV%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1968)096<0351:IOTNBV>2.0.CO;2},
	abstract = {A finite difference scheme is developed for numerical integration of the nondivergent barotropic vorticity equation with an icosahedral-hexagonal grid covering the sphere. The grid is made by dividing the 20 triangular faces of an icosahedron into smaller triangles, the vertices of which are the grid points. Each grid point is surrounded by six neighboring points, except the 12 vertices of the icosahedron which are surrounded by five points. The difference scheme for the advection of vorticity exactly conserves total vorticity, total square vorticity, and total kinetic energy. A numerical test is made, with a stationary Neamtan wave as the initial condition, by integrating over 8 days with 1-hr. time steps and a grid of 1002 points for the sphere. There is practically no distortion of the waves over the 8 days, but there is a phase displacement error of about 1° of long. per day toward the west.},
	number = {6},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Sadourny, Robert and Arakawa, Akio and Mintz, Yale},
	month = jun,
	year = {1968},
	pages = {351--356}
}

@article{rutherford_adjustment_1972,
	title = {Adjustment of the {Wind} {Field} to {Geopotential} {Data} in a {Primitive} {Equations} {Model}},
	volume = {29},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1972)029%3C1059:AOTWFT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1972)029<1059:AOTWFT>2.0.CO;2},
	abstract = {Experiments were made with a divergent-barotropic primitive equations model in order to investigate the adjustment of the wind field to periodically specified geopotentials. A simple time filter was found to be effective in removing the spurious high-frequency divergence produced by the use of geopotential data alone, at a small cost in the adjustment of the rotational part of the wind. When geopotentials were inserted only once per 12 hr, there were serious residual errors in the rotational part of the adjusted winds on space scales of meteorological interest. These errors were reducible by more frequent geopotential specification.},
	number = {6},
	urldate = {2017-11-01},
	journal = {Journal of the Atmospheric Sciences},
	author = {Rutherford, I. D. and Asselin, R.},
	month = sep,
	year = {1972},
	pages = {1059--1063}
}

@article{rutherford_data_1972,
	title = {Data {Assimilation} by {Statistical} {Interpolation} of {Forecast} {Error} {Fields}},
	volume = {29},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1972)029%3C0809%3ADABSIO%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1972)029<0809:DABSIO>2.0.CO;2},
	abstract = {An operational method of combining observations with short-period forecasts of the same quantities is described. The method amounts to performing an interpolation in the field of apparent forecast errors, as defined by the available observations, by a linear least-squares technique similar to Gandin's. Statistics on the errors of observation and prediction are required. The spatial autocorrelations of the forecast error depend on the particular forecast model employed, the forecast period, etc. Those statistics necessary for the assimilation of synoptic data with four-level baroclinic 12-hr forecasts have been derived. They appear to be approximately homogeneous and isotropic and to vary slowly with season. Asynoptic data can be handled by allowing for variations with forecast period. Some practical problems in the determination of empirical statistics are discussed.},
	number = {5},
	urldate = {2017-11-01},
	journal = {Journal of the Atmospheric Sciences},
	author = {Rutherford, Ian D.},
	month = jul,
	year = {1972},
	pages = {809--815}
}

@book{ruelle_chance_1993,
	title = {Chance and {Chaos}},
	isbn = {978-0-691-02100-3},
	abstract = {How do scientists look at chance, or randomness, and chaos in physical systems? In answering this question for a general audience, Ruelle writes in the best French tradition: he has produced an authoritative and elegant book--a model of clarity, succinctness, and a humor bordering at times on the sardonic.How do scientists look at chance, or randomness, and chaos in physical systems? In answering this question for a general audience, Ruelle writes in the best French tradition: he has produced an authoritative and elegant book--a model of clarity, succinctness, and a humor bordering at times on the sardonic.},
	language = {en},
	publisher = {Princeton University Press},
	author = {Ruelle, David},
	year = {1993},
	note = {Google-Books-ID: zJ9\_LGhrg6wC},
	keywords = {Science / Physics / Mathematical \& Computational, Mathematics / Probability \& Statistics / General}
}

@article{rossby_propagation_1945,
	title = {On the propagation of frequencies and energy in certain types of oceanic and atmospheric waves},
	volume = {2},
	issn = {0095-9634},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1945)002%3C0187:OTPOFA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1945)002<0187:OTPOFA>2.0.CO;2},
	abstract = {In this paper the energy and frequency propagation in certain types of plane waves in the atmosphere and in the ocean are investigated, these wave trains being characterized by the property that frequency and wave number are slowly varying functions of the space coordinate and time. The assumption is made that wave crests are conserved, and on this basis a simple kinematic relationship between frequency and wave number is established. Wave trains for which the physical theory results in a frequency equation of such a character that phase velocity and wave length uniquely determine each other are then found to possess a characteristic group velocity, and it is shown that frequencies (and hence group velocities) are propagated with this characteristic group velocity. In the more general case the frequency equation resulting from the physical theory is found to contain a correction term which is an explicit function of the space coordinate and time. In that case observers travelling with the conventionally defined group velocity (obtained by disregarding the correction term) will observe gradual changes in frequency, but it is shown that these changes, at least in the wave types here investigated, are insignificant except in the leading and trailing boundaries of the wave trains. Energy propagation equations are derived for three different types of wave motion. It is found that the relative flow of energy across planes which move with the conventionally defined group velocity (hereafter referred to as group-velocity planes), is nondivergent in those regions where the frequencies associated with individual group velocity planes remain constant. The particular limited wave trains analyzed in this paper possess the property that the boundary regions of the wave trains, where frequencies no longer are conserved, serve as sources and sinks for the energy. These results indicate that the classical energy propagation equation, which is found to be valid in the central portion of the wave trains, must not be interpreted to mean that energy is propagated with group velocity, but rather that the energy transport relative to the group-velocity planes is nondivergent. This conclusion is verified through a computation of the accumulation of energy in the extreme forerunner of a train of surface waves in deep water. The main portion of this wave train is characterized by a non-divergent relative flux of energy across the group-velocity planes. It is shown that the equations which determine the propagation of group-velocity and the nondivergent propagation of energy together form a closed system, the form of which is independent of the special dynamic characteristics of the wave train under consideration. If the distributions of energy and group velocity for one particular time are known, it is possible to compute the distribution of these elements for any subsequent time, provided the relative flux of energy remains nondivergent. As a test of the theory for frequency and energy propagation developed in this paper, exact solutions are given for the train of long gravitational waves following a limited progressive perturbation in a sheet of water on a rotating disc and for a spreading “forerunner” wave train of horizontal, plane, nondivergent shear waves generated by a limited progressive perturbation in the belt of west winds in middle latitudes. These exact solutions are compared with indications furnished by energy and group-velocity considerations. The analysis of wave trains in the westerlies suggests a simple explanation for the rapid-moving isallobaric waves which seem to emanate from the principal cyclonic centers of action in the Northern Hemisphere. Such isallobaric waves normally spread quite rapidly eastward, at the same time losing their intensity, and breaking up into ever more irregular patterns. These observed characteristics appear to be in good accord with the characteristics of theoretical “forerunner” wave trains obtained from the theoretical analysis of waves in the westerlies. It is finally suggested that the well-known retrograde “blocking” action observed in the west wind belt of middle latitudes might be interpreted as the effect of a convergent distribution of the group velocity in the long, quasistationary waves in the westerlies.},
	number = {4},
	urldate = {2017-11-01},
	journal = {Journal of Meteorology},
	author = {Rossby, C-G.},
	month = dec,
	year = {1945},
	pages = {187--204}
}

@article{rossby_mutual_1937,
	title = {On the mutual adjustment of pressure and velocity distributions in certain simple current systems},
	volume = {1},
	number = {1},
	journal = {J. Mar. Res},
	author = {Rossby, C. G.},
	year = {1937},
	pages = {15--27}
}

@book{rossby_dynamics_1936,
	title = {Dynamics of steady ocean currents in the light of experimental fluid mechanics},
	volume = {1},
	url = {http://darchive.mblwhoilibrary.org/handle/1912/1088},
	abstract = {The present investigation may be regarded as a part of a systematic effort to introduce 
into meteorology and physical oceanography methods and results which for a 
number of years have contributed to the rapid growth and increasing practical significance 
of experimental fluid mechanics. This science has recognized that the exact character 
of the forces controlling the motion of a turbulent fluid is not known and that 
consequently there is very little justification for a purely theoretical attack on problems of a practical character. For this reason fluid mechanics has been forced to develop a research technique all of its own, in which the theory is developed on the basis of experiments and then used to predict the behavior of fluids in cases which are not accessible 
to experimentation. In oceanography it has long been regarded as an axiom that the movements of the 
water are controlled by three forces, the horizontal pressure gradient, the deflecting force, 
and the frictional force resulting from the relative motion of superimposed strata. It is 
significant that thirty-five years of intensive theoretical work on this basis have failed 
to produce a theory capable of explaining the major features of the observed oceanic 
circulation below the pure drift current layer. The present investigation considers a force which has been completely disregarded 
by theoretical investigators although its existence has been admitted implicitly by 
practically everyone who has approached physical oceanography from the descriptive 
side, namely the frictional force resulting from large-scale horizontal mixing. The intro- 
. duction of this force permits us to see how motion generated in the surface layers may be 
diffused and finally dissipated without recourse to doubtful frictional forces at the bottom 
of the ocean.},
	language = {en\_US},
	urldate = {2017-11-01},
	publisher = {Massachusetts Institute of Technology and Woods Hole Oceanographic Institution},
	author = {Rossby, Carl-Gustaf},
	month = aug,
	year = {1936},
	doi = {10.1575/1912/1088}
}

@article{rosati_decadal_1995,
	title = {Decadal {Analysis} {Produced} from an {Ocean} {Data} {Assimilation} {System}},
	volume = {123},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1995)123%3C2206%3ADAPFAO%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1995)123<2206:DAPFAO>2.0.CO;2},
	abstract = {A global oceanic four-dimensional data assimilation system has been developed for use in initializing coupled ocean-atmosphere general circulation models and also to study interannual variability. The data inserted into a high-resolution global ocean model consist of conventional sea surface temperature observations and vertical temperature profiles. The data are inserted continuously into the model by updating the model's temperature solution every time step. This update is created using a statistical interpolation routine applied to all data in a 30-day window for three consecutive time steps and then the correction is held constant for nine time steps. Not updating every time step allows for a more computationally efficient system without affecting the quality of the analysis. The data assimilation system was run over a 10-yr period from 1979 to 1988. The resulting analysis product was compared with independent analysis including model-derived fields like velocity. The large-scale features seem consistent with other products based on observations. Using the mean of the 10-yr period as a climatology, the data assimilation system was compared with the Levitus climatological atlas. Looking at the sea surface temperature and the seasonal cycle, as represented by the mixed-layer depth, the agreement is quite good, however, some systematic differences do emerge. Special attention is given to the tropical Pacific examining the El Nin˜o signature. Two other assimilation schemes based on the coupled model using Newtonian nudging of SST and then SST and surface winds are compared to the full data assimilation system. The heat content variability in the data assimilation seemed faithful to the observations. Overall, the results are encouraging, demonstrating that the data assimilation system seems to be able to capture many of the large-scale general circulation features that are observed, both in a climatological sense and in the temporal variability.},
	number = {7},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Rosati, A. and Gudgel, R. and Miyakoda, K.},
	month = jul,
	year = {1995},
	pages = {2206--2228}
}

@article{ropelewski_global_1987,
	title = {Global and {Regional} {Scale} {Precipitation} {Patterns} {Associated} with the {El} {Niño}/{Southern} {Oscillation}},
	volume = {115},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1987)115%3C1606:GARSPP%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1987)115<1606:GARSPP>2.0.CO;2},
	abstract = {We investigate the “typical” global and large-scale regional precipitation patterns that are associated with the El Niño/Southern Oscillation (ENSO). Monthly precipitation time series from over 1700 stations are analyzed using an empirical method designed to identify regions of the globe that have precipitation variations associated with ENSO. Monthly mean ranked precipitation composites are computed over idealized 2-year ENSO episodes for all stations that include data for at least five ENSOs. The amplitude and phase of the Arm harmonic fitted to the 24-month composite values are plotted in the form of a vector for each station. When plotted on a global map, these vectors reveal both the regions of spatially coherent ENSO-related precipitation and the phase of this signal in relation to the evolution of the composite episode. Time cries of precipitation for the coherent regions identified in the harmonic vector map are examined to determine the magnitudes of the ENSO-related precipitation and the percentages of the time the identified relationship actually occurred in conjunction with ENSO episodes. This study expands previous results by placing the regional precipitation relationships into a global framework and by providing a consistent methodology for the definition of the geographical regions and the temporal phase of ENSO-related precipitation. In addition to the Pacific Ocean basin where precipitation patterns could be directly related to the ENSO, several other regions, which showed consistent ENSO-related precipitation, were identified. Specifically, four regions in Australia, two regions each in North America South America, the Indian subcontinent, and Africa and one region in Central America were all found to have coherent ENSO-related precipitation. In most of thew regions, the “season” of ENSO-related precipitation was found to be in phase with the normal annual precipitation cycle. Time series of area-averaged precipitation for the appropriate “seasons” show departures consistent with the composites occurring for at 1east 80\% of the ENSO events in almost every region. The analysis further indicates that variations in precipitation related to ENSO occur as early as April of the composite episode through May of the following year.},
	number = {8},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Ropelewski, C. F. and Halpert, M. S.},
	month = aug,
	year = {1987},
	pages = {1606--1626}
}

@article{rood_numerical_1987,
	title = {Numerical advection algorithms and their role in atmospheric transport and chemistry models},
	volume = {25},
	issn = {1944-9208},
	url = {http://onlinelibrary.wiley.com/doi/10.1029/RG025i001p00071/abstract},
	doi = {10.1029/RG025i001p00071},
	abstract = {During the last 35 years, well over 100 algorithms for modeling advection processes have been described and tested. This review summarizes the development and improvements that have taken place. The nature of the errors caused by numerical approximation to the advection equation are highlighted. Then the particular devices that have been proposed to remedy these errors are discussed. The extensive literature comparing transport algorithms is reviewed. Although there is no clear cut “best” algorithm, several conclusions can be made. The judicious use of simple finite difference schemes (second-order time differences and even-order ( {\textgreater}2) spatial differences) provides a minimum level of accuracy that is suitable for many atmospheric applications. More complex schemes can yield a significant improvement in accuracy, but sometimes at great computational expense. Spectral and pseudospectral techniques consistently provide the highest degree of accuracy, but expense and difficulties assuring positive mixing ratios are serious drawbacks. Schemes which consider fluid slabs bounded by grid points (volume schemes), rather than the simple specification of constituent values at the grid points, provide accurate positive definite results. The computer memory requirements of the volume schemes can be excessive. Recent attempts to maxmize accuracy while keeping cost low have lead to such useful schemes as the one proposed by P. K. Smolarkiewicz.},
	language = {en},
	number = {1},
	urldate = {2017-11-01},
	journal = {Reviews of Geophysics},
	author = {Rood, Richard B.},
	month = feb,
	year = {1987},
	keywords = {3399 General or miscellaneous, 0399 General or miscellaneous, 4255 Numerical modeling},
	pages = {71--100}
}

@inproceedings{rohaly_identifying_1998,
	title = {Identifying regions where the forecast of tropical cyclone tracks is most sensitive to initial condition uncertainty using adjoint methods},
	volume = {337},
	booktitle = {Preprints, 12th {Conf}. on {Numerical} {Weather} {Prediction}, {Phoenix}, {AZ}, {Amer}. {Meteor}. {Soc}},
	author = {Rohaly, G. D. and Langland, R. H. and Gelaro, R.},
	year = {1998},
	pages = {340}
}

@article{rogers_data_1998,
	title = {Data assimilation experiments with the regional 3-{D} variational analysis at the {National} {Centers} for {Environmental} {Prediction}},
	journal = {WORLD METEOROLOGICAL ORGANIZATION-PUBLICATIONS-WMO TD},
	author = {Rogers, E. and Parrish, D. and DiMego, G. J.},
	year = {1998},
	pages = {1--67}
}

@article{rogers_changes_1996,
	title = {Changes to the {Operational} “{Early}” {Eta} {Analysis}/{Forecast} {System} at the {National} {Centers} for {Environmental} {Prediction}},
	volume = {11},
	issn = {0882-8156},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0434(1996)011%3C0391:CTTOEA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0434(1996)011<0391:CTTOEA>2.0.CO;2},
	abstract = {This note describes changes that have been made to the National Centers for Environmental Prediction (NCEP) operational “early” eta model. The changes are 1) an decrease in horizontal grid spacing from 80 to 48 km, 2) incorporation of a cloud prediction scheme, 3) replacement of the original static analysis system with a 12-h intermittent data assimilation system using the eta model, and 4) the use of satellite-sensed total column water data in the eta optimum interpolation analysis. When tested separately, each of the four changes improved model performance. A quantitative and subjective evaluation of the full upgrade package during March and April 1995 indicated that the 48-km eta model was more skillful than the operational 80-km model in predicting the intensity and movement of large-scale weather systems. In addition, the 48-km eta model was more skillful in predicting severe mesoscale precipitation events than either the 80-km eta model, the nested grid model, or the NCEP global spectral model during the March-April 1995 period. The implementation of this new version of the operational early eta system was performed in October 1995.},
	number = {3},
	urldate = {2017-11-01},
	journal = {Weather and Forecasting},
	author = {Rogers, Eric and Black, Thomas L. and Deaven, Dennis G. and DiMego, Geoffrey J. and Zhao, Qingyun and Baldwin, Michael and Junker, Norman W. and Lin, Ying},
	month = sep,
	year = {1996},
	pages = {391--413}
}

@article{rogers_regional_1995,
	title = {The {Regional} {Analysis} {System} for the {Operational} “{Early}” {Eta} {Model}: {Original} 80-km {Configuration} and {Recent} {Changes}},
	volume = {10},
	issn = {0882-8156},
	shorttitle = {The {Regional} {Analysis} {System} for the {Operational} “{Early}” {Eta} {Model}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0434(1995)010%3C0810%3ATRASFT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0434(1995)010<0810:TRASFT>2.0.CO;2},
	abstract = {The analysis component of the National Centers for Environmental Prediction (NCEP) operational “early” 80-km eta model, as implemented in July 1993, is described. This optimum interpolation (OI) analysis is fully multivariate for wind and geopotential height (univariate for specific humidity) and is performed directly on the eta model's vertical coordinate. Although the eta OI analysis and model performance has been generally favorable when compared to the Limited-Area Fine Mesh Model (LFM) and the Nested Grid Model (NGM), deficiencies in the eta OI analysis fields have been observed, especially near the surface. A series of improvements to the eta OI analysis is described. A refinement to the eta model orography, which created a more realistic depiction of the model terrain, is also discussed along with the impact of these changes on analysis and model performance. These changes were implemented in the early eta system in September 1994. The operational configuration of the new mesoscale (29 km) eta model system is introduced, consisting of a mesoscale eta-based data assimilation system (EDAS) and the mesoscalee forecast. An example of an analysis produced by the mesoscale EDAS is presented for comparison with the operational 80-km eta OI analysis. A brief description of more recent changes to the early eta system are also described.},
	number = {4},
	urldate = {2017-11-01},
	journal = {Weather and Forecasting},
	author = {Rogers, Eric and Deaven, Dennis G. and Dimego, Geoffrey S.},
	month = dec,
	year = {1995},
	pages = {810--825}
}

@article{robert_semi-lagrangian_1985,
	title = {A {Semi}-{Lagrangian} and {Semi}-{Implicit} {Numerical} {Integration} {Scheme} for {Multilevel} {Atmospheric} {Models}},
	volume = {113},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1985)113%3C0388:ASLASI%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1985)113<0388:ASLASI>2.0.CO;2},
	abstract = {A complete multilevel atmospheric model of the primitive meteorological equations is integrated at high spatial resolution with a large time step of 90 min. Numerical stability is achieved by associating a semi-Lagrangian technique with the commonly used semi-implicit algorithm. A detailed description of the method is given and some results are presented. From these runs, it seems possible to infer that the time truncation errors remain relatively small. Because of the 1arger time step, the semi-Lagrangian technique contributes to a significant enhancement of the efficiency of the semi-implicit integration scheme.},
	number = {3},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Robert, André and Yee, Tai Loy and Ritchie, Harold},
	month = mar,
	year = {1985},
	pages = {388--394}
}

@article{robert_identification_1986,
	title = {Identification and elimination of an inflow boundary computational solution in limited area model integrations},
	volume = {24},
	issn = {0705-5900},
	url = {http://dx.doi.org/10.1080/07055900.1986.9649258},
	doi = {10.1080/07055900.1986.9649258},
	abstract = {The linearized non‐divergent barotropic vorticity equation in one dimension is used for the study of a problem associated with the specification of lateral boundaries in limited area models. This problem presents itself in the form of a “pillow” that builds up near the inflow boundary of the model. Linear analysis shows that this pillow can easily be eliminated. Linear integrations carried out with a corrector seem to be reasonably accurate. Similar integrations with the linearized shallow water equations in one dimension also produce a pillow and the same corrector gives improved results. Additional runs are performed in order to show that some commonly used nesting strategies do not control this computational problem in a satisfactory manner. It seems that these strategies could be improved with an appropriate corrector.},
	number = {4},
	urldate = {2017-11-01},
	journal = {Atmosphere-Ocean},
	author = {Robert, André and Yakimiw, Evhen},
	month = dec,
	year = {1986},
	pages = {369--385}
}

@article{robert_semi-lagrangian_1982,
	title = {A {Semi}-{Lagrangian} and {Semi}-{Implicit} {Numerical} {Integration} {Scheme} for the {Primitive} {Meteorological} {Equations}},
	volume = {60},
	doi = {10.2151/jmsj1965.60.1_319},
	abstract = {A semi-Lagrangian algorithm is associated with the semi-implicit method in the integration of the shallow water equations on a rotating sphere. The resulting model is unconditionally stable and can be integrated with rather large time steps. Truncation errors remain reasonably small with time steps 25 times as large as those used with explicit integration schemes.An analysis of the proposed method is performed and it indicates that the scheme is stable. Also, the results of a few integrations are presented and from these we conclude that the model is not very sensitive to the size of the time step provided that it does not exceed a value of the order of two or three hours.},
	number = {1},
	journal = {Journal of the Meteorological Society of Japan. Ser. II},
	author = {Robert, André},
	year = {1982},
	pages = {319--325}
}

@misc{noauthor_stable_nodate,
	title = {A stable numerical integration scheme for the primitive meteorological equations: {Atmosphere}-{Ocean}: {Vol} 19, {No} 1},
	url = {http://www.tandfonline.com/doi/abs/10.1080/07055900.1981.9649098},
	urldate = {2017-11-01}
}

@article{robert_semi-implicit_1979,
	title = {The semi-implicit method in numerical methods used in atmospheric models},
	volume = {17},
	journal = {GARP Pubi Ser. Part II},
	author = {Robert, A.},
	year = {1979}
}

@book{dahlquist_numerical_1974,
	title = {Numerical methods},
	publisher = {Prentice-Hall},
	author = {Dahlquist, Germund and Björck, Åke},
	year = {1974}
}

@inproceedings{robert_integration_1969,
	title = {The integration of a spectral model of the atmosphere by the implicit method},
	volume = {7},
	booktitle = {Proc. {WMO}/{IUGG} {Symposium} on {NWP}, {Tokyo}, {Japan} {Meteorological} {Agency}},
	author = {Robert, A.},
	year = {1969},
	pages = {19--24}
}

@article{robert_integration_1966,
	title = {The {Integration} of a {Low} {Order} {Spectral} {Form} of the {Primitive} {Meteorological} {Equations}},
	volume = {44},
	doi = {10.2151/jmsj1965.44.5_237},
	abstract = {The interest for spectral forms of the meteorological equations has grown considerably over the past several years. Integrations in terms of spherical harmonics provide us with an interesting alternative to the grid point method. The results of an extension of the method to the complete meteorological equations will be presented here.A model based on five levels and 15 coefficients is integrated for 200 days starting from an atmosphere at rest and at a uniform temperature. The integration is then continued for another 22 days with 45 coefficients. Cross-sections show a jet stream in each hemisphere and low level easterlies along the equatorial belt. The amplitudes and the phase speeds of the planetary waves in the model compare favourably with their atmospheric equivalents.The results of this integration indicate that spherical harmonics could be used profitably in general circulation models or in the preparation of extended range forecasts.},
	number = {5},
	journal = {Journal of the Meteorological Society of Japan. Ser. II},
	author = {Robert, Andre J.},
	year = {1966},
	pages = {237--245}
}

@article{rivest_spurious_1994,
	title = {Spurious {Resonant} {Response} of {Semi}-{Lagrangian} {Discretizations} to {Orographic} {Forcing}: {Diagnosis} and {Solution}},
	volume = {122},
	issn = {0027-0644},
	shorttitle = {Spurious {Resonant} {Response} of {Semi}-{Lagrangian} {Discretizations} to {Orographic} {Forcing}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1994)122%3C0366%3ASRROSL%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1994)122<0366:SRROSL>2.0.CO;2},
	abstract = {Semi-Lagrangian semi-implicit techniques are now well established and used by an increasing number of meteorological centers. However, it is demonstrated by both analysis and numerical integration that there is a serious problem incorporating orographic forcing into semi-Lagrangian models, since spurious resonance can develop in mountainous regions for Courant numbers larger than unity. A solution, consisting of two classes of schemes, is proposed, analyzed, and then evaluated using a global shallow-water model. Simply off-centering the semi-implicit scheme eliminates the spurious resonances. Although this can be achieved with a first-order scheme, it is at the expense of decreased accuracy, and therefore a second-order scheme is recommended.},
	number = {2},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Rivest, Chantal and Staniforth, Andrew and Robert, André},
	month = feb,
	year = {1994},
	pages = {366--376}
}

@article{lorenc_analysis_1986,
	title = {Analysis methods for numerical weather prediction},
	volume = {112},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49711247414/abstract},
	doi = {10.1002/qj.49711247414},
	abstract = {Bayesian probabilistic arguments are used to derive idealized equations for finding the best analysis for numerical weather prediction. These equations are compared with those from other published methods in the light of the physical characteristics of the NWP analysis problem; namely the predetermined nature of the basis for the analysis, the need for approximation because of large-order systems, the underdeterminacy of the problem when using observations alone, and the availability of prior relationships to resolve the underdeterminacy. Prior relationships result from (1) knowledge of the time evolution of the model (which together with the use of a time distribution of observations constitutes four-dimensional data assimilation); (2) knowledge that the atmosphere varies slowly (leading to balance relationships); (3) other nonlinear relationships coupling parameters and scales in the atmosphere. Methods discussed include variational techniques, smoothing splines, Kriging, optimal interpolation, successive corrections, constrained initialization, the Kalman-Bucy filter, and adjoint model data assimilation. They are all shown to relate to the idealized analysis, and hence to each other. Opinions are given on when particular methods might be more appropriate. By comparison with the idealized method some insight is gained into appropriate choices of parameters in the practical methods.},
	language = {en},
	number = {474},
	urldate = {2017-11-01},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Lorenc, A. C.},
	month = oct,
	year = {1986},
	pages = {1177--1194}
}

@article{ritchie_implementation_1995,
	title = {Implementation of the {Semi}-{Lagrangian} {Method} in a {High}-{Resolution} {Version} of the {ECMWF} {Forecast} {Model}},
	volume = {123},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1995)123%3C0489:IOTSLM%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1995)123<0489:IOTSLM>2.0.CO;2},
	abstract = {In this article the implementation of the semi-Lagrangian method in a high-resolution version of the ECMWF forecast model is examined. Novel aspects include the application of the semi-Lagrangian scheme to a global model using the ECMWF hybrid coordinate in the vertical and its use in a baroclinic spectral model in conjunction with a reduced Gaussian grid in the horizontal. The former Eulerian vorticity-divergence formulation is first converted into a momentum-equation formulation that is considerably more economical, thanks in part to the incorporation of Legendre transform efficiencies that were previously demonstrated for the shallow-water equations. The semi-Lagrangian formulation is presented in detail, together with a discussion of computational aspects that are relevant for executing the high-resolution model efficiently on a modestly parallel supercomputer. The impact of formulation changes is assessed via numerical experiments on a set of 12 independent cases. In particular it is shown that, by virtue of using a larger time step, the semi-Lagrangian version is several times more efficient than the Eulerian scheme, that the hybrid-coordinate configuration maintains its design advantage over the sigma-coordinate version in the stratosphere, that the “vertically noninterpolating” scheme performs better than the “fully interpolating” method, and that the increase in horizontal resolution from T106 to T213 (enabled in part by the gains in model efficiency) has a significant positive impact.},
	number = {2},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Ritchie, Harold and Temperton, Clive and Simmons, Adrian and Hortal, Mariano and Davies, Terry and Dent, David and Hamrud, Mats},
	month = feb,
	year = {1995},
	pages = {489--514}
}

@book{bengtsson_4-dimensional_1975,
	title = {4-{Dimensional} assimilation of meteorological observations},
	language = {English},
	publisher = {International Council of Scientific Unions},
	author = {Bengtsson, Lennart},
	year = {1975}
}

@article{ritchie_semi-lagrangian_1987,
	title = {Semi-{Lagrangian} {Advection} on a {Gaussian} {Grid}},
	volume = {115},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1987)115%3C0608%3ASLAOAG%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1987)115<0608:SLAOAG>2.0.CO;2},
	abstract = {The treatment of advection is related to the stability, accuracy and efficiency of models used in numerical weather prediction. In order to remain stable, conventional Eulerian advection schemes must respect a Courant-Friedrichs-Lewy (CFL) criterion, which limits the size of the time step that can be used in conjunction with a given spatial resolution. In recent years, tests with gridpoint models have shown that semi-Lagrangian schemes permit the use of large time steps (roughly three to six times those permitted by the CFL criterion for the corresponding Eulerian models), without reducing the accuracy of the forecasts. This leads to improved model efficiency, since fewer steps are needed to complete the forecast. Can similar results be achieved in spectral models? This paper examines the semi-Lagrangian treatment of advection on the Gaussian grid used in spectral models. Interpolating and noninterpolating versions of the semi-Lagrangian scheme are applied to the problem of solid body rotation on the globe, and their performance is compared with that of an Eulerian spectral treatment. It is shown that the semi-Lagrangian models produce stable, accurate integrations using time steps that far exceed the CFL limit for the Eulerian spectral model.},
	number = {2},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Ritchie, Harold},
	month = feb,
	year = {1987},
	pages = {608--619}
}

@article{lorenc_global_1981,
	title = {A {Global} {Three}-{Dimensional} {Multivariate} {Statistical} {Interpolation} {Scheme}},
	volume = {109},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1981)109%3C0701:AGTDMS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1981)109<0701:AGTDMS>2.0.CO;2},
	abstract = {A three-dimensional statistical interpolation method, multivariate in geopotential height, thickness and wind, is described. The method has been implemented in the ECMWF operational global data-assimilation scheme, used for routine forecasting and for producing FGGE level III-b analyses. It is distinguished by the large number of data used simultaneously, enabling full exploitation of the potential of the three-dimensional multivariate technique, and by the incorporation of a statistical quality control check on each datum using the analysis itself. Some simple examples illustrating the properties of the method are presented, and a detailed study is made of the effect of various analysis parameters on one practical example.},
	number = {4},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Lorenc, A. C.},
	month = apr,
	year = {1981},
	pages = {701--721}
}

@article{purser_efficient_1991,
	title = {An {Efficient} {Interpolation} {Procedure} for {High}-{Order} {Three}-{Dimensional} {Semi}-{Lagrangian} {Models}},
	volume = {119},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281991%29119%3C2492%3AAEIPFH%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1991)119<2492:AEIPFH>2.0.CO;2},
	abstract = {An efficient method is proposed for performing the grid interpolations required at each advective time step of a multilevel, limited-area semi-Lagrangian model. The distinctive feature of the method is that it is composed of a cascade of one-dimensional interpolations of entire fields of data through a sequence of intermediate grids. These intermediate grids are formed as hybrid combinations of the standard model grid coordinates, which, together with the Lagrangian coordinates, are delineated by the origins of the trajectories that characterize the semi-Lagrangian method. When applied at Nth-order accuracy, the cascade method requires only O(N) operations compared with O(N3) for the conventional three-dimensional interpolation methods, making the adoption of high-order schemes attractive. The technique was tested on a large number (100) of 48-h forecasts and was found to be as accurate as the conventional interpolation procedures based on point-by-point Cartesian products of one-dimensional inter-polators. However, the cascade interpolation technique was 2.9, 6.1, and 10.2 times as fast as the conventional interpolation scheme for fourth-, sixth-, and eighth-order, respectively. We observe that the cascade method is equally applicable to the problem of interpolation from the grid of termini of forward trajectories to the standard model grid, for which there is no obvious counterpart in the Cartesian product method. Our technique therefore opens the way to a whole new class of high-order accurate semi-Lagrangian methods that incorporate the use of forward trajectories as part of the time-stepping process.},
	number = {10},
	urldate = {2017-11-14},
	journal = {Monthly Weather Review},
	author = {Purser, R. J. and Leslie, L. M.},
	month = oct,
	year = {1991},
	pages = {2492--2498}
}

@inproceedings{purser_new_1984,
	address = {Clearwater, FL},
	title = {A new approach to optimal assimilation of meteorological data by iterative {Bayesian} analysis},
	author = {Purser, R},
	month = jun,
	year = {1984}
}

@article{puri_scheme_1982,
	title = {A {Scheme} to {Retain} the {Hadley} {Circulation} {During} {Nonlinear} {Normal} {Mode} {Initialization}},
	volume = {110},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281982%29110%3C0327%3AASTRTH%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1982)110<0327:ASTRTH>2.0.CO;2},
	abstract = {A modified nonlinear normal mode initialization scheme is proposed which provides a possible solution to a major problem associated with nonlinear normal mode initialization. The modified scheme retains the Hadley circulation in the model and at the same time eliminates the gravity wave oscillations. The main feature of the modified scheme is that it isolates model normal modes which are significantly affected by convective processes and excludes these from the initialization by the application of a low-frequency cut-off. The modified scheme has obvious application to four-dimensional assimilation of data.},
	number = {5},
	urldate = {2017-11-14},
	journal = {Monthly Weather Review},
	author = {Puri, K. and Bourke, W.},
	month = may,
	year = {1982},
	pages = {327--335}
}

@article{puri_experiments_1987,
	title = {Some {Experiments} on the {Use} of {Tropical} {Diabatic} {Heating} {Information} for {Initial} {State} {Specification}},
	volume = {115},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281987%29115%3C1394%3ASEOTUO%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1987)115<1394:SEOTUO>2.0.CO;2},
	abstract = {The local response to tropical diabatic heating is studied by using diabatic normal mode initialization procedures. It is shown that diabatic initialization is able to produce a well-balanced state in regions of heating provided the appropriate vertical modes are initialized. However, the persistence of balance during model integrations is strongly dependent on the compatibility between the specified heating during initialization and the heating during the model integration. Finally, a procedure is developed in which cloud-top temperature data is used to identify regions of deep convection where heating rates are specified during initialization. Although the procedure provides a means of combining the analysis of the divergent wind field and initialization, a number of problems remain, namely the specification of the intensity and vertical profiles of the heating rates.},
	number = {7},
	urldate = {2017-11-14},
	journal = {Monthly Weather Review},
	author = {Puri, Kamal},
	month = jul,
	year = {1987},
	pages = {1394--1406}
}

@article{puri_local_1981,
	title = {Local {Geostrophic} {Wind} {Correction} in the {Assimilation} of {Height} {Data} and its {Relationships} to the {Slow} {Manifold}},
	volume = {109},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281981%29109%3C0052%3ALGWCIT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1981)109<0052:LGWCIT>2.0.CO;2},
	abstract = {Experiments with insertion of height data in a free surface spectral model were conducted to explain the effectiveness of local geostrophic correction of the wind field in accelerating the assimilation of the height data by the model. It is shown that the local geostrophic correction projects most of the inserted data on to the slow manifold of the model.},
	number = {1},
	urldate = {2017-11-14},
	journal = {Monthly Weather Review},
	author = {Puri, Kamal},
	month = jan,
	year = {1981},
	pages = {52--55}
}

@article{pu_forecast_1998,
	title = {Forecast sensitivity with dropwindsonde data and targeted observations},
	volume = {50},
	issn = {null},
	url = {http://dx.doi.org/10.3402/tellusa.v50i4.14536},
	doi = {10.3402/tellusa.v50i4.14536},
	abstract = {While forecast models and analysis schemes used in numerical weather prediction have becomegenerally very successful, there is an increasing research interest toward improving forecast skillby adding extra observations either into data sparse areas, or into regions where the verifyingforecast is most sensitive to changes in the initial analysis. The latter approach is referred to as “targeting” observations. In a pioneering experiment of this type, the US Air Force launcheddropwindsondes over the relatively data sparse Northeast Pacific Ocean during 1—10 February1995. The focus of this study is the forecast sensitivity to initial analysis differences, forced bythese observations by using both the adjoint method (ADJM) and quasi-inverse linear method(QILM), which are both useful for determining the targeting area where the observations aremost needed. We discuss several factors that may affect the results, such as the radius of themask for the targeted region, the basic flow and the choice of initial differences at the verificationtime. There are some differences between the adjoint and quasi-inverse linear sensitivitymethods. With both sensitivity methods it is possible to find areas where changes in initialconditions lead to changes in the forecast. We find that these two methods are somewhatcomplementary: the 48-h quasi-inverse linear sensitivity is reliable in pinpointing the region oforigin of a forecast difference. This is particularly useful for cases in which the ensemble forecastspread indicates a region of large uncertainty, or when a specific region requires careful forecasts.This region can be isolated with a mask and forecast differences traced back reliably. Anotherimportant application for the QILM is to trace back observed 48-h forecast errors. The 48-hadjoint sensitivity, on the other hand, is useful in pointing out areas that have maximum impacton the region of interest, but not necessarily the regions that actually led to observed differences, which are indicated more clearly by QILM. At 72 h, the linear assumption made in bothmethods breaks down, nevertheless the backward integrations are still very useful for pinningdown all the areas that would produce changes in the regions of interest (QILM) and the areasthat will produce maximum sensitivity (ADJM). Both methods can be useful for adaptiveobservation systems.},
	number = {4},
	urldate = {2017-11-14},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Pu, Zhao-Xia and Lord, Stephen J. and Kalnay, Eugenia},
	month = jan,
	year = {1998},
	pages = {391--410}
}

@article{pu_sensitivity_1997,
	title = {Sensitivity of {Forecast} {Errors} to {Initial} {Conditions} with a {Quasi}-{Inverse} {Linear} {Method}},
	volume = {125},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281997%29125%3C2479%3ASOFETI%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1997)125<2479:SOFETI>2.0.CO;2},
	abstract = {A quasi-inverse linear method has been developed to study the sensitivity of forecast errors to initial conditions for the National Centers for Environmental Prediction’s (NCEP) global spectral model. The inverse is approximated by running the tangent linear model (TLM) of the nonlinear forecast model with a negative time step, but reversing the sign of friction and diffusion terms, in order to avoid the computational instability that would be associated with these terms if they were run backward. As usually done using the adjoint model integrations, the quasi-inverse TLM is started at the time of the verified forecast error and integrated backward to the corresponding initial time. First, a numerical experiment shows that this quasi-inverse linear estimation is able to trace back the differences between two perturbed forecasts from the NCEP ensemble forecasting system and recover with good accuracy the known difference between the two forecasts at the initial time. This result shows that both the linear estimation and the quasi-inverse linear estimation are quite close to the nonlinear evolution of the perturbation in the nonlinear forecast model, suggesting that it should be possible to apply the method to the study of the sensitivity of forecast errors to initial conditions. The authors then calculate the perturbation field at the initial time (estimate the initial error) by tracing back a 1-day forecast error using the TLM quasi-inverse estimation. As could be expected from the previous experiment, when the estimated error is subtracted from the original analysis, the new initial conditions lead to an almost perfect 1-day forecast. The forecasts beyond the first day are also considerably improved, indicating that the initial conditions have indeed been improved. In the remainder of the paper, this quasi-inverse linear method is compared with the adjoint sensitivity method (Rabier et al., Pu et al.) for medium-range weather forecasting. The authors find that both methods are able to trace back the forecast error to perturbations that improve the initial conditions. However, the forecast improvement obtained by the quasi-inverse linear method is considerably better than that obtained with a single adjoint iteration and similar to the one obtained using five iterations of the adjoint method, even though each adjoint iteration requires at least twice the computer resources of the quasi-inverse TLM estimation. Whereas the adjoint forecast sensitivities are closely related to singular vectors, the quasi-inverse linear perturbations are associated with the bred (Lyapunov) vectors used for ensemble forecasting at NCEP (Toth and Kalnay). The features of the two types of perturbations are also compared in this study. Finally, the possibility of the use of the sensitivity perturbation to improve future forecast skill is discussed, and preliminary experiments encourage further testing of this rather inexpensive method for possible operational use. The model used in this study is the NCEP operational global spectral model at a resolution of T62/L28. The corresponding TLM, and its adjoint, are based on an adiabatic version of the model but include both horizontal and vertical diffusion.},
	number = {10},
	urldate = {2017-11-14},
	journal = {Monthly Weather Review},
	author = {Pu, Zhao-Xia and Kalnay, Eugenia and Sela, Joseph and Szunyogh, Istvan},
	month = oct,
	year = {1997},
	pages = {2479--2503}
}

@article{pu_use_1997,
	title = {The {Use} of {Bred} {Vectors} in the {NCEP} {Global} {3D} {Variational} {Analysis} {System}},
	volume = {12},
	issn = {0882-8156},
	url = {http://journals.ametsoc.org/doi/full/10.1175/1520-0434(1997)012%3C0689:TUOBVI%3E2.0.CO%3B2},
	doi = {10.1175/1520-0434(1997)012<0689:TUOBVI>2.0.CO;2},
	abstract = {The errors in the first-guess (forecast field) of an analysis system vary from day to day, but, as in all current operational data assimilation systems, forecast error covariances are assumed to be constant in time in the NCEP operational three-dimensional variational analysis system (known as a spectral statistical interpolation or SSI). This study focuses on the impact of modifying the error statistics by including effects of the “errors of the day” on the analysis system. An estimate of forecast uncertainty, as defined from the bred growing vectors of the NCEP operational global ensemble forecast, is applied in the NCEP operational SSI analysis system. The growing vectors are used to estimate the spatially and temporally varying degree of uncertainty in the first-guess forecasts used in the analysis. The measure of uncertainty is defined by a ratio of the local amplitude of the growing vectors, relative to a background amplitude measure over a large area. This ratio is used in the SSI system for adjusting the observational error term (giving more weight to observations in regions of larger forecast errors). Preliminary experiments with the low-resolution global system show positive impact of this virtually cost-free method on the quality of the analysis and medium-range weather forecasts, encouraging further tests for operational use. The results of a 45-day parallel run, and a discussion of other methods to take advantage of the knowledge of the day-to-day variation in forecast uncertainties provided by the NCEP ensemble forecast system, are also presented in the paper.},
	number = {3},
	urldate = {2017-11-14},
	journal = {Weather and Forecasting},
	author = {Pu, Zhao-Xia and Kalnay, Eugenia and Parrish, David and Wu, Wanshu and Toth, Zoltan},
	month = sep,
	year = {1997},
	pages = {689--695}
}

@article{platzman_eniac_1979,
	title = {The {ENIAC} {Computations} of 1950—{Gateway} to {Numerical} {Weather} {Prediction}},
	volume = {60},
	issn = {0003-0007},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0477(1979)060%3C0302:TECOTN%3E2.0.CO%3B2},
	doi = {10.1175/1520-0477(1979)060<0302:TECOTN>2.0.CO;2},
	abstract = {The first numerical weather prediction was made on the ENIAC computer in 1950. This lecture gives some of the historical background of that event and a partially narrative account of it.},
	number = {4},
	urldate = {2017-11-14},
	journal = {Bulletin of the American Meteorological Society},
	author = {Platzman, George W.},
	month = apr,
	year = {1979},
	pages = {302--312}
}

@article{platzman_retrospective_1967,
	title = {A retrospective view of {Richardsons} book on weather prediction},
	volume = {48},
	journal = {Bulletin of the American Meteorological Society},
	author = {Platzman, George W.},
	year = {1967},
	pages = {514--550}
}

@article{platzman_spectral_1960,
	title = {The spectral form of the vorticity equation},
	volume = {17},
	issn = {0095-9634},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1960)017%3C0635%3ATSFOTV%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1960)017<0635:TSFOTV>2.0.CO;2},
	abstract = {The nonlinear aspects of the vorticity equation for two-dimensional planetary circulations of the earth's atmosphere may be studied by expansion of the solution in spherical surface harmonics. Some of the main mathematical problems are discussed here that arise in an examination of the “spectral” form of the vorticity equation which results from such an expansion. The truncation of the spectral equations is discussed, and a proof is given of the invariance of mean square velocity and vorticity for truncated spectra. Some comments are made on low-order systems, which are to be followed by a detailed investigation of three-component systems in the second part of this study.},
	number = {6},
	urldate = {2017-11-14},
	journal = {Journal of Meteorology},
	author = {Platzman, George W.},
	month = dec,
	year = {1960},
	pages = {635--644}
}

@misc{noauthor_extending_nodate,
	title = {On extending the limits of variational assimilation in nonlinear chaotic systems - {PIRES} - 1996 - {Tellus} {A} - {Wiley} {Online} {Library}},
	url = {http://onlinelibrary.wiley.com/doi/10.1034/j.1600-0870.1996.00006.x/abstract},
	urldate = {2017-11-14}
}

@article{pielke_comprehensive_1992,
	title = {A comprehensive meteorological modeling system—{RAMS}},
	volume = {49},
	issn = {0177-7971, 1436-5065},
	url = {https://link.springer.com/article/10.1007/BF01025401},
	doi = {10.1007/BF01025401},
	abstract = {SummaryThis paper presents a range of applications of the Regional Atmospheric Modeling System (RAMS), a comprehensive mesoscale meterological modeling system. Applications discussed in this paper include large eddy simulations (LES) and simulations of thunderstorms, cumulus fields, mesoscale convective systems, mid-latitude cirrus clouds, winter storms, mechanically- and thermally-forced mesoscale systems, and mesoscale atmospheric disperision. A summary of current RAMS options is also presented. Improvements to RAMS currently underway include refinements to the cloud radiation, cloud microphysics, cumulus, and surface soil/vegetative parameterization schemes, the parallelization of the code, development of a more versatile visualization capability, and research into meso-α-scale cumulus parameterization.},
	language = {en},
	number = {1-4},
	urldate = {2017-11-14},
	journal = {Meteorology and Atmospheric Physics},
	author = {Pielke, R. A. and Cotton, W. R. and Walko, R. L. and Tremback, C. J. and Lyons, W. A. and Grasso, L. D. and Nicholls, M. E. and Moran, M. D. and Wesley, D. A. and Lee, T. J. and Copeland, J. H.},
	month = mar,
	year = {1992},
	pages = {69--91}
}

@article{phillips_spatial_1986,
	title = {The spatial statistics of random geostrophic modes and first-guess errors},
	volume = {38A},
	issn = {1600-0870},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1600-0870.1986.tb00418.x/abstract},
	doi = {10.1111/j.1600-0870.1986.tb00418.x},
	abstract = {It is hypothesized that a data assimilation system with excellent forecast and analysis components and frequent access to good data should have first-guess errors similar to an ensemble of random slow modes with equipartition of energy. The covariance statistics of such a system on a constant f-plane are calculated and shown to have interesting features. Of these, the overall increase with elevation of wind and geopotential errors, the size of temperature variances for given height variances, the increase with elevation of the horizontal velocity scale, and the sharper correlation in the vertical for wind than geopotential, are also found in the empirical studies of first-guess errors over North America by Hollingsworth and Lönnberg. Two major differences are (a) the presence of a maximum wind and geopotential error at the tropopause in the empirical data, and (b) the empirical horizontal spectra for velocity peak at the largest accessible wave length (5000 km) while the theoretical spectra peak at the shortest wave length (1000 km). If it is assumed that basic conditions of the hypothesis are satisfied, the ECMWF forecast and analysis methods must introduce relatively large errors at long wave lengths. A more believable conclusion is that the assumption of “frequent access to good data” is invalidated by data voids outside of the test network. Other results agree with the Hollingsworth-Lönnberg study in that the separable mathematical models used to represent correlations in operational practice misrepresent some important features. The results also suggest that temperature errors in a forecast of high vertical resolution will be underestimated by evaluation of thickness errors between the standard pressure levels.},
	language = {en},
	number = {4},
	urldate = {2017-11-14},
	journal = {Tellus A},
	author = {Phillips, Norman A.},
	month = aug,
	year = {1986},
	pages = {314--332}
}

@article{phillips_completeness_1982,
	title = {On the {Completeness} of {Multi}-{Variate} {Optimum} {Interpolation} for {Large}-{Scale} {Meteorological} {Analysis}},
	volume = {110},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281982%29110%3C1329%3AOTCOMV%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1982)110<1329:OTCOMV>2.0.CO;2},
	abstract = {The Baer-Tribbia nonlinear modal initialization method implies that large-scale meteorological analyses should focus on analysis of slow mode fields. An idealized multi-variate optimum interpolation analysis is shown to produce grid point results that contain only slow modes. Variational analysis with a slow mode constraint is therefore unnecessary.},
	number = {10},
	urldate = {2017-11-14},
	journal = {Monthly Weather Review},
	author = {Phillips, Norman A.},
	month = oct,
	year = {1982},
	pages = {1329--1334}
}

@article{phillips_variational_1981,
	title = {Variational {Analysis} and the {Slow} {Manifold}},
	volume = {109},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1981)109%3C2415:VAATSM%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1981)109<2415:VAATSM>2.0.CO;2},
	abstract = {The principles of variational analysis are reviewed in a symbolic manner, with emphasis on the error introduced by a failure to use an exact constraint. A technique to approximate a nonlinear exact constraint is suggested, with the object of avoiding error magnification in regions of good data, in the process of analyzing slow mode amplitudes for nonlinear mode initialization. The technique amounts to subtractingall fast modes from the data fields that form the input to the variational analysis. The analysis procedure is then focused on only the analysis of slow mode fields. These general considerations are demonstrated by computations with the vortex model of Tribbia, and show how nonlinear mode techniques can improve initial analyses in a more significant way than the mere elimination of noise. A review of the relative merits and weaknesses of optimum interpolation and variational analysis suggests a logical way to use both techniques in an operational analysis system.},
	number = {12},
	urldate = {2017-11-14},
	journal = {Monthly Weather Review},
	author = {Phillips, Norman A. and Chang, Simon W.},
	month = dec,
	year = {1981},
	pages = {2415--2426}
}

@book{pedlosky_joseph_geophysical_nodate,
	title = {Geophysical {Fluid} {Dynamics}},
	url = {//www.springer.com/us/book/9780387963877},
	abstract = {This second edition of the widely acclaimed Geophysical Fluid Dynamics by Joseph Pedlosky offers the reader a high-level, unified treatment of the theory...},
	urldate = {2017-11-14},
	author = {{Pedlosky, Joseph}}
}

@incollection{phillips_principles_1973,
	title = {Principles of {Large} {Scale} {Numerical} {Weather} {Prediction}},
	isbn = {978-94-010-2601-7 978-94-010-2599-7},
	url = {https://link.springer.com/chapter/10.1007/978-94-010-2599-7_1},
	abstract = {The motion of the atmosphere, when treated from the viewpoint of continuum mechanics, is governed by Newton’s law of motion relating the acceleration to the forces, the thermodynamic law relating the rate of change of internal energy to the rate of heating, the principle of conservation of mass, the thermodynamic state relations, detailed mathematical formulations of the forces and rates of heating, and, finally, appropriate conditions at the boundaries of the particular mathematical model of the atmosphere being considered. Implied in this statement already is a recognition that we limit our attention to an approximate model of the real “atmosphere”. For example, at very high altitudes the mean free path and time interval between molecular collisions becomes large enough that the quasi-equilibrium assumptions of continuum mechanics and thermodynamics break down. As other examples of the limitation of our meteorological viewpoint we may cite on the one hand our neglect of the interaction between the “atmosphere” and its extension to interplanetary space, and on the other hand our ignoring of the exchange of dry air across the air-ground and air-ocean interface, which we shall treat as impervious to the flow of dry air. These somewhat trite examples are cited only to show immediately that we admit to a simplified atmospheric model ; in fact, however, the practical analysis of large-scale atmospheric motions at the present state of hydrodynamical theory forces approximations upon dynamical meteorologists which have a much greater effect on the accuracy of the results than do the somewhat esoteric examples mentioned above.},
	language = {en},
	urldate = {2017-11-14},
	booktitle = {Dynamic {Meteorology}},
	publisher = {Springer, Dordrecht},
	author = {Phillips, N. A.},
	year = {1973},
	doi = {10.1007/978-94-010-2599-7_1},
	pages = {1--96}
}

@article{phillips_equations_1966,
	title = {The {Equations} of {Motion} for a {Shallow} {Rotating} {Atmosphere} and the “{Traditional} {Approximation}”},
	volume = {23},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1966)023%3C0626%3ATEOMFA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1966)023<0626:TEOMFA>2.0.CO;2},
	abstract = {No abstract available.},
	number = {5},
	urldate = {2017-11-14},
	journal = {Journal of the Atmospheric Sciences},
	author = {Phillips, Norman A.},
	month = sep,
	year = {1966},
	pages = {626--628}
}

@article{phillips_coordinate_1957,
	title = {A coordinate system having some special advantages for numerical forecasting},
	volume = {14},
	issn = {0095-9634},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469%281957%29014%3C0184%3AACSHSS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1957)014<0184:ACSHSS>2.0.CO;2},
	abstract = {No Abstract Available.},
	number = {2},
	urldate = {2017-11-14},
	journal = {Journal of Meteorology},
	author = {Phillips, N. A.},
	month = apr,
	year = {1957},
	pages = {184--185}
}

@article{phillips_general_1956,
	title = {The general circulation of the atmosphere: {A} numerical experiment},
	volume = {82},
	issn = {1477-870X},
	shorttitle = {The general circulation of the atmosphere},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49708235202/abstract},
	doi = {10.1002/qj.49708235202},
	abstract = {A long-period numerical forecast is made with a two-level quasi-geostrophic model, starting with an atmosphere in relative rest. Both friction and non-adiabatic effects are included in the equations, the latter as a linear function of latitude. Principal empirical elements in the experiment are the intensity of the heating, the value of the vertical stability, and the type of frictional dissipation. The flow patterns which develop are quite realistic, including a jet and zonal surface westerlies in middle latitudes, and the growth of a large disturbance. The associated energy transformations are investigated, and demonstrate the important role of the disturbance in the development of the zonal currents. The meridional circulation is also studied, together with its contribution to the zonal momentum budgets of the lower and upper halves of the atmosphere. Truncation errors eventually put an end to the forecast by producing a large fictitious increase in energy.},
	language = {en},
	number = {352},
	urldate = {2017-11-14},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Phillips, Norman A.},
	month = apr,
	year = {1956},
	pages = {123--164}
}

@misc{noauthor_nino_nodate,
	title = {El {Nino}, {La} {Nina}, and the {Southern} {Oscillation}, {Volume} 46 - 1st {Edition}},
	url = {https://www.elsevier.com/books/el-nino-la-nina-and-the-southern-oscillation/holton/978-0-12-553235-8},
	urldate = {2017-11-14}
}

@article{perkey_time-dependent_1976,
	title = {A {Time}-{Dependent} {Lateral} {Boundary} {Scheme} for {Limited}-{Area} {Primitive} {Equation} {Models}},
	volume = {104},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281976%29104%3C0744%3AATDLBS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1976)104<0744:ATDLBS>2.0.CO;2},
	abstract = {Before high-resolution numerical models can be of use operationally, they must be restricted to a limited domain, thus necessitating lateral boundary conditions which allow the changes outside the limited domain to influence the results while not contaminating the forecast with spurious boundary-reflected energy. Such a set of time-dependent lateral boundary conditions are presented in this paper. This boundary condition set is investigated using the linear analytic and finite-difference advection equations, the non-linear finite-difference shallow-water equations, and the hydrostatic primitive equations. The results illustrate how the boundary condition transforms long- and medium-length interior advective and gravity waves into short waves which can then be removed by a low pass filter, thereby giving the appearance that the exiting wave simply passed through the boundary. The results also indicate that large-scale advective and gravity waves enter the forecast domain with little degradation. Thus, from the tests performed, the described boundary condition scheme yields a practical solution for prescribing time-dependent lateral boundaries for a limited-area model.},
	number = {6},
	urldate = {2017-11-14},
	journal = {Monthly Weather Review},
	author = {Perkey, Donald J. and Kreitzberg, Carl W.},
	month = jun,
	year = {1976},
	pages = {744--755}
}

@article{patil_local_2001,
	title = {Local low dimensionality of atmospheric dynamics},
	volume = {86},
	issn = {0031-9007},
	doi = {10.1103/PhysRevLett.86.5878},
	abstract = {A statistic, the BV (bred vector) dimension, is introduced to measure the effective local finite-time dimensionality of a spatiotemporally chaotic system. It is shown that the Earth's atmosphere often has low BV dimension, and the implications for improving weather forecasting are discussed.},
	language = {eng},
	number = {26 Pt 1},
	journal = {Physical Review Letters},
	author = {Patil, D. J. and Hunt, B. R. and Kalnay, E. and Yorke, J. A. and Ott, E.},
	month = jun,
	year = {2001},
	pmid = {11415384},
	pages = {5878--5881}
}

@article{pan_simple_1990,
	title = {A {Simple} {Parameterization} {Scheme} of {Evapotranspiration} over {Land} for the {NMC} {Medium}-{Range} {Forecast} {Model}},
	volume = {118},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281990%29118%3C2500%3AASPSOE%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1990)118<2500:ASPSOE>2.0.CO;2},
	abstract = {The use of a simple bucket method to parameterize the evapotranspiration over land has been found to overestimate the latent heat flux in the global spectral model at the National Meteorological Center. A new parameterization package based on the Penman-Monteith potential evapotranspiration concept is reported here. This package has been implemented to reduce the over-moistening problem. Results indicate improvements in the near surface moisture field over land.},
	number = {12},
	urldate = {2017-11-14},
	journal = {Monthly Weather Review},
	author = {Pan, Hua-Lu},
	month = dec,
	year = {1990},
	pages = {2500--2512}
}

@article{pan_interaction_1987,
	title = {Interaction between soil hydrology and boundary-layer development},
	volume = {38},
	issn = {0006-8314, 1573-1472},
	url = {https://link.springer.com/article/10.1007/BF00121563},
	doi = {10.1007/BF00121563},
	abstract = {A two-layer model of soil hydrology and thermodynamics is combined with a one-dimensional model of the planetary boundary layer to study various interactions between evolution of the boundary layer and soil moisture transport. Boundary-layer moistening through surface evaporation reduces the potential and actual surface evaporation as well as the boundary-layer growth. With more advanced stages of soil drying, the restricted surface evaporation allows greater sensible heat flux which enhances boundary-layer growth and entrainment drying.Special individual cases are studied where the wind speed is strong, solar radiation is reduced, transpiration is important, the soil is thin, or the soil is covered with organic debris.},
	language = {en},
	number = {1-2},
	urldate = {2017-11-14},
	journal = {Boundary-Layer Meteorology},
	author = {Pan, H.-L. and Mahrt, L.},
	month = jan,
	year = {1987},
	pages = {185--202}
}

@article{pan_cumulus_1998,
	title = {A cumulus parameterization with a prognostic closure},
	volume = {124},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49712454714/abstract},
	doi = {10.1002/qj.49712454714},
	abstract = {The paper describes the introduction of a prognostic cumulus kinetic energy (CKE) as a replacement for the quasi-equilibrium closure hypothesis of Arakawa and Schubert (AS). In the original version of the AS parameterization, the cloud work function, a measure of the convective available potential energy, is assumed to be maintained at ‘small’ values through a quasi-equilibrium between the cumulus convection and the ‘large-scale forcing’. It is argued here, however, that the distinction between the convective and large-scale processes is ambiguous and subjective. It is demonstrated that the need for such a distinction can be avoided by relaxing the quasi-equilibrium assumption, through the introduction of a prognostic CKE; referred to as prognostic closure. A dimensional parameter, α, is introduced to relate the CKE to the square of the cloud-base convective mass flux. It is shown that ‘adjustment time’ defined by AS is related to α, so that when the adjustment time approaches zero the prognostic closure reduces to quasi-equilibrium closure. A second dimensional parameter, τD, is used to determine the rate at which the CKE is dissipated. In the limit of small α and τD, the convective mass flux is formally independent of both α τD if the environmental sounding is assumed to be given, but in reality the results of a prognostic model do depend on these two parameters because they affect the time-dependent sounding. For simplicity, a single constant value of α is used for all cloud types in tests with a general-circulation model, and this gives reasonably good results. Larger values of α lead to more frequent shallow cumulus convection and a cooler and more humid troposphere, in which stratiform condensation is more active and more large-scale precipitation can reach the surface. A longer dissipation time-scale leads to a warmer tropical troposphere. The interactions between stratiform cloudiness and convection prove to be quite important, leading to the conclusion that the convection parametrization really cannot be evaluated independently of the stratiform cloud parametrization with which it interacts.},
	language = {en},
	number = {547},
	urldate = {2017-11-14},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Pan, Dzong-Ming and Randall, Davi D. A.},
	month = apr,
	year = {1998},
	keywords = {Adjustment time, Convections, Cumulus kinetic energy, Planetary boundary-layer},
	pages = {949--981}
}

@article{palmer_singular_1998,
	title = {Singular {Vectors}, {Metrics}, and {Adaptive} {Observations}},
	volume = {55},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469%281998%29055%3C0633%3ASVMAAO%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1998)055<0633:SVMAAO>2.0.CO;2},
	abstract = {Singular vectors of the linearized equations of motion have been used to study the instability properties of the atmosphere–ocean system and its related predictability. A third use of these singular vectors is proposed here: as part of a strategy to target adaptive observations to “sensitive” parts of the atmosphere. Such observations could be made using unmanned aircraft, though calculations in this paper are motivated by the upstream component of the Fronts and Atlantic Storm-Track Experiment. Oceanic applications are also discussed. In defining this strategy, it is shown that there is, in principle, no freedom in the choice of inner product or metric for the singular vector calculation. However, the correct metric is dependent on the purpose for making the targeted observations (to study precursor developments or to improve forecast initial conditions). It is argued that for predictability studies, where both the dynamical instability properties of the system and the specification of the operational observing network and associated data assimilation system are important, the appropriate metric will differ from that appropriate to a pure geophysical fluid dynamics (GFD) problem. Based on two different sets of calculations, it is argued that for predictability studies (but not for GFD studies), a first-order approximation to the appropriate metric can be based on perturbation energy. The role of observations in data assimilation procedures (constraining large scales more than small scales) is fundamental in understanding reasons for the requirement for different metrics for the two classes of problems. An index-based tensor approach is used to make explicit the role of the metric. The strategy for using singular vectors to target adaptive observations is discussed in the context of other possible approaches, specifically, based on breeding vectors, potential vorticity diagnosis, and sensitivity vectors. The basic premises underlying the use of breeding and singular vectors are discussed. A comparison of the growth rates of breeding and singular vectors is made using a T21 quasigeostrophic model. Singular vectors and subjective potential vorticity (PV) diagnosis are compared for a particular case study. The areas of sensitivity indicated by the two methods only partially agree. Reasons for disagreement hinge around the fact that subjective PV diagnosis emphasizes Lagrangian advection, whereas singular vector analysis emphasizes wave propagation. For the latter, areas of sensitivity may be associated with regions of weak PV gradient, for example, mid to lower troposphere. Amplification of singular vectors propagating from regions of weak PV gradient to regions of strong PV gradient is discussed in terms of pseudomomentum conservation. Evidence is shown that analysis error may be as large in the lower midtroposphere as in the upper troposphere.},
	number = {4},
	urldate = {2017-11-14},
	journal = {Journal of the Atmospheric Sciences},
	author = {Palmer, T. N. and Gelaro, R. and Barkmeijer, J. and Buizza, R.},
	month = feb,
	year = {1998},
	pages = {633--653}
}

@article{palmer_prediction_1988,
	title = {On the {Prediction} of {Forecast} {Skill}},
	volume = {116},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281988%29116%3C2453%3AOTPOFS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1988)116<2453:OTPOFS>2.0.CO;2},
	abstract = {Using 10-day forecast 500 mb height data from the last 7 yr, the potential to predict the skill of numerical weather forecasts is discussed. Four possible predictor sets are described. The first, giving the consistency between adjacent forecasts, is apparently more skillful if the anomaly correlation coefficient, rather than RMS difference, is used as measure of forecast spread and forecast skill. It is concluded that much of this enhanced skill results from the dependence of the anomaly correlation coefficient on the magnitude of the forecast anomaly. It is noted that the spread between “today's” and “yesterday's” forecast is a more reliable estimate of the skill of yesterday's forecast than today's, and the implications of this on lagged-average ensemble forecasts are discussed. The impact of temporal filtering of the data in spread/skill correlations are also described. The second predictor set is derived from a regression analysis between RMS error skill scores and EOF coefficients of the forecast and/or initial 500 mb heights. The predictors themselves are large-scale anomaly patterns, some of which, towards the end of the forecast period, resemble low-frequency teleconnection patterns of the atmosphere. It is shown that forecast EOF coefficients are more skilful predictors than EOF coefficients of the initial conditions, and that when both sets of coefficients are used in the regression there is a danger of overfitting. The dependence of these patterns on the truncation of the EOF expansion and of temporal filtering is discussed. In particular, it is shown that when a severe EOF truncation is made, some of the forecast flow anomaly patterns become less geographically localized, indicating poorer predictive skill. The third predictor is defined as the RMS skill of the day-1 forecast. Both upstream and local correlations are studied. It is shown that with day-1 forecast error leading day-3 RMS error by up to 3 days, there appears to be a propagating signal, in addition to a quasi-stationary one. In general, the latter appears to be dominant. The fourth predictor is defined as the RMS difference between the forecast 500 mb height, and the initial 500 mb height. Use of this latter predictor was motivated by diagnostic studies showing relationships between interannual variability of forecast scores and interannual variability of persistence errors. These studies are partly described here. It is shown that the use of forecast persistence as a predictor gives partial skill, at least towards the end of the forecast period. The skill of the predictors are tested, and the regression coefficients derived, on data from six winters, for both regional and hemispheric skill scores. As an independent test, the predictors are also applied separately to the seventh winter period 1986/87. It is concluded that some aspects of the low-frequency component of forecast skill variability can be satisfactorily predicted, though significant high frequency variability remains unpredicted. In discussing the physical mechanisms that underlie the use of these predictors, three important components of forecast skill variability are discussed: the quality of the initial analysis, the intrinsic instability of the flow, and the role of model systematic errors. It is shown that results from the EOF predictor for the European region towards the end of the forecast period are strongly influenced by model systematic error. On the other hand, over the Pacific/North American region, growth of errors on flows with varying barotropic stability characteristics are an important component of medium-range forecast variability. This is discussed using a barotropic model with basic states defined from the results of the regression analyses for various regions. At shorter range it is suggested that growth of errors by baroclinic processes is probably dominant.},
	number = {12},
	urldate = {2017-11-14},
	journal = {Monthly Weather Review},
	author = {Palmer, T. N. and Tibaldi, S.},
	month = dec,
	year = {1988},
	pages = {2453--2480}
}

@article{palmer_alleviation_1986,
	title = {Alleviation of a systematic westerly bias in general circulation and numerical weather prediction models through an orographic gravity wave drag parametrization},
	volume = {112},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49711247406/abstract},
	doi = {10.1002/qj.49711247406},
	abstract = {Systematic westerly biases in the northern hemisphere wintertime flow of the Meteorological Office 15-layer operational model and 11-layer general circulation model are described. Evidence that the failure to parametrize subgrid-scale orographic gravity wave drag may account for such biases is presented. This evidence is taken from aircraft studies, surface pressure drag measurements, and studies of the zonally averaged momentum budget. A parametrization scheme is described in which the surface stress is proportional to the near-surface wind speed and static stability, and to the variance of subgrid-scale orography. The stress is absorbed in the vertical by considering the influence of such gravity wave activity on static stability and vertical wind shear. A Richardson-number-dependent wave breaking formulation is devised, and the vertical stress profile determined by a saturation hypothesis whereby the breaking waves are maintained at marginal stability. It is shown that wave breaking preferentially occurs in the boundary layer and in the lower stratosphere. Results from a simple zonally symmetric model show how the adjustment to thermal wind balance with a wave drag in the stratosphere, warms polar regions by adiabatic descent, and decelerates the mean westerlies in the troposphere. The influence of the parametrization scheme on integrations of the 11-layer model is described, and found to be generally beneficial. In a discussion of the reasons why this problem has only recently emerged, it is suggested that the satisfactory northern hemisphere winter circulations of previous, coarser general circulation models were due to a compensation implied by underestimating both the surface drag, and the horizontal flux of momentum by explicitly resolved large-scale eddies.},
	language = {en},
	number = {474},
	urldate = {2017-11-14},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Palmer, T. N. and Shutts, G. J. and Swinbank, R.},
	month = oct,
	year = {1986},
	pages = {1001--1039}
}

@article{paegle_atmospheric_1987,
	title = {Atmospheric {Response} to {Tropical} {Thermal} {Forcing} in {Real} {Data} {Integrations}},
	volume = {115},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281987%29115%3C2975%3AARTTTF%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1987)115<2975:ARTTTF>2.0.CO;2},
	abstract = {Evidence is presented for a highly regular seasonal rearrangement of the long-wave pattern over North America from the winter to the spring. The change involves a reversal of the trough-ridge pattern between the two seasons wherein the anticyclone observed in the winter climatology over and west of the Rocky Mountains reverses to a spring trough, and the winter lee cyclone changes to a spring ridge over the eastern United States. These changes, which represent a westward shift of the long-wave pattern from winter to spring, are accompanied by westward shifts of the subtropical jet core from the east to the west coast, and of the tropical rain maxima from the Amazon Basin to the tropical East Pacific Ocean. We investigate the possibility that these westward displacements are dynamically related in a series of ten-day integrations of a general circulation model over four separate ensembles, each consisting of ten cases, during the winter and spring. The data for these ensembles is taken from the Global Weather Experiment, and is used to initialize the NCAR general circulation model. This model maintains the winter-spring patterns observed in the western hemisphere when run in a control mode. The tropical precipitation distribution around the Eastern Pacific and the Amazon Basin is then modified to produce a winterlike rainfall pattern for the spring ensemble. The resulting extratropical changes in the forecast wind and height field resemble the observed winter pattern, rather than the spring distribution of the control. When the tropical precipitation of the winter cases is modified to simulate the distribution observed in spring, the resulting experiments produce forecast changes that resemble the extratropical pattern of spring, although the apparent response is not as great as the observed seasonal changes. The statistical reliability of the winter experiments appears to be higher than that of the spring experiments.},
	number = {12},
	urldate = {2017-11-14},
	journal = {Monthly Weather Review},
	author = {Paegle, Jan and Zhang, Chi-Dong and Baumhefner, David P.},
	month = dec,
	year = {1987},
	pages = {2975--2995}
}

@article{baker_influence_1983,
	title = {The {Influence} of the {Tropics} on the {Prediction} of {Ultralong} {Waves}. {Part} {I}: {Tropical} {Wind} {Field}},
	volume = {111},
	issn = {0027-0644},
	shorttitle = {The {Influence} of the {Tropics} on the {Prediction} of {Ultralong} {Waves}. {Part} {I}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281983%29111%3C1341%3ATIOTTO%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1983)111<1341:TIOTTO>2.0.CO;2},
	abstract = {The influence of tropical wind data on the numerical prediction of ultralong waves is examined. Two data assimilation experiments are performed using the GLAS fourth-order general circulation model. The two experiments are identical except that one utilizes tropical wind data while the other does not. Six forecasts are generated from the initial conditions provided by each experiment. After two days, a reduction in the extratropical wind error is found in the assimilation experiment with tropical wind data. For the six pairs of forecasts examined, the effect of tropical wind data on the 72 h planetary wave prediction is positive in four cases and negative in two cases over the western half of the Northern Hemisphere. Also, the 72 h planetary wave error appears in a predominantly barotropic mode. A detailed examination of the 0000 GMT 15 January 1979 case reveals that the planetary waves are more strongly affected by the wind data in the Northern Hemisphere than in the Southern Hemisphere. Examination of the velocity potential suggests the presence of stronger heating gradients in the no-tropical-wind forecast. The differences present in the initial divergent wind field remain largely restricted to the tropics after 72 h whereas significant differences may be seen in the rotational wind component at all latitudes after 72 h.},
	number = {7},
	urldate = {2017-11-14},
	journal = {Monthly Weather Review},
	author = {Baker, Wayman E. and Paegle, Jan},
	month = jul,
	year = {1983},
	pages = {1341--1355}
}

@article{paegle_geopotential_1976,
	title = {On {Geopotential} {Data} and {Ellipticity} of the {Balance} {Equation}: {A} {Data} {Study}},
	volume = {104},
	issn = {0027-0644},
	shorttitle = {On {Geopotential} {Data} and {Ellipticity} of the {Balance} {Equation}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281976%29104%3C1279%3AOGDAEO%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1976)104<1279:OGDAEO>2.0.CO;2},
	abstract = {One year of geopotential data obtained from the National Meteorological Center and the National Center for Atmospheric Research are diagnosed for the occurrence of non-elliptic regions with respect to the balance equation. The highest frequencies of such occurrences appear at 200 mb over the subtropical oceans where there are few radiosonde observations. Substantial 200 mb frequencies are also found over the United States in the summer season above a reliable data net. A diagnosis of flow divergence implied for the non-elliptic data by a theoretical analysis of Paegle and Paegle (1974) produces values greatly in excess of. typical observations. This suggests that the gridding of the data by objective analysis may not have been adequate and/or that the aforementioned theory overestimates flow divergence in these regions. It is likely that non-elliptic data are important for initialization of primitive equation forecast models. It may be inferred that greater data accuracy, as well as better initialization techniques within non-elliptic regions, are required.},
	number = {10},
	urldate = {2017-11-14},
	journal = {Monthly Weather Review},
	author = {Paegle, Jan and Paegle, Julia N.},
	month = oct,
	year = {1976},
	pages = {1279--1288}
}

@book{ott_coping_1994,
	title = {Coping with chaos. {Analysis} of chaotic data and the exploitation of chaotic systems},
	url = {http://adsabs.harvard.edu/abs/1994cwca.book.....O},
	abstract = {Not Available},
	urldate = {2017-11-14},
	publisher = {J. Wiley},
	author = {Ott, Edward and Sauer, Tim and Yorke, James A.},
	year = {1994},
	keywords = {CHAOS, DATA ANALYSIS, NONLINEARITY}
}

@article{orszag_elimination_1971,
	title = {On the {Elimination} of {Aliasing} in {Finite}-{Difference} {Schemes} by {Filtering} {High}-{Wavenumber} {Components}},
	volume = {28},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469%281971%29028%3C1074%3AOTEOAI%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1971)028<1074:OTEOAI>2.0.CO;2},
	abstract = {No abstract available.},
	number = {6},
	urldate = {2017-11-14},
	journal = {Journal of the Atmospheric Sciences},
	author = {Orszag, Steven A.},
	month = sep,
	year = {1971},
	pages = {1074--1074}
}

@article{a._orszag_transform_1970,
	title = {Transform {Method} for the {Calculation} of {Vector}-{Coupled} {Sums}: {Application} to the {Spectral} {Form} of the {Vorticity} {Equation}},
	volume = {27},
	shorttitle = {Transform {Method} for the {Calculation} of {Vector}-{Coupled} {Sums}},
	doi = {10.1175/1520-0469(1970)027<0890:TMFTCO>2.0.CO;2},
	abstract = {A transform method is developed for the fast calculation of vector-coupled sums appearing in the spectrally truncated vorticity equation. The method involves a kind of finite convolution theorem for expansions in surface harmonics. The method succeeds because it turns out to be much faster to transform the spectral representation to physical space, multiply the physical-space functions, and then inverse transform back to the spectral representation, than to evaluate the vector-coupled sums directly in spectral form. Direct evaluation of the sums requires order N5 operations when the spectral
representation is truncated at surface harmonies of degree N, while the transform method requires about 10N3+40N2
log2N real operations per time step. Direct evaluation of the
sums also requires storage of order N5, while the transform
method requires storage of roughly 3N3 real words. An
explanation is also given how to specialize the transform method to the `hemispheric' models of Baer and Platzman with a savings of nearly a factor of 8 in speed. For the hemispheric model with N = 19, the
transform method requires at least three times fewer calculations than are required by direct evaluation. The transform method is comparable in speed with direct evaluation of the vector-coupled sums when N = 10 (N = 15 for the hemispheric models), with the transform method improving its advantage over direct evaluation as N2. These new methods
suggest that spectral representations with a large number of retained modes may be in a not too unfavorable competitive position with
finite-difference jury methods (which require at least order
N2 log2N operations per time step) for the
solution of the equations of incompressible spherical hydrodynamics.},
	journal = {Journal of Atmospheric Sciences},
	author = {A. Orszag, Steven},
	month = aug,
	year = {1970},
	pages = {890--895}
}

@article{orlanski_simple_1976,
	title = {A simple boundary condition for unbounded hyperbolic flows},
	volume = {21},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/0021999176900231},
	doi = {10.1016/0021-9991(76)90023-1},
	abstract = {A Sommerfeld radiation condition (2.2) is proposed for problems requiring a prescribed open boundary. The equations must be hyperbolic in nature (although the author believes that they may also be good for some elliptic and parabolic problems). It is proven that the proposed condition was shown to be free of reflection for single wave propagation. Two severe tests were used to demonstrate the applicability of the open boundary condition: (i) the collapsing bubble, a dynamic event which excites many different internal gravity waves. The results show minimum distortion. (ii) The spatially growing K-H instability. This test differs from the previous one in that the only waves excited are those corresponding to the maximum unstable wavelengths. In this case, the maximum amplitude is reached at the open boundary. As it has been shown, the open boundary condition (2.2) produces minimum distortion.},
	number = {3},
	urldate = {2017-11-14},
	journal = {Journal of Computational Physics},
	author = {Orlanski, I},
	month = jul,
	year = {1976},
	pages = {251--269}
}

@article{orlanski_rational_1975,
	title = {A rational subdivision of scales for atmospheric processes},
	volume = {56},
	journal = {Bulletin of the American Meteorological Society},
	author = {Orlanski, I},
	year = {1975},
	pages = {527--530}
}

@article{ooyama_theory_1971,
	title = {A {Theory} on {Parameterization} of {Cumulus} {Convection}},
	volume = {49A},
	doi = {10.2151/jmsj1965.49A.0_744},
	abstract = {On the assumption that cumulus clouds can be represented by independent buoyant elements, a general theory is developed for parameterization of cumulus convection illlarge-scale weather systems. No specific method ready for application is yet proposed, except for a simple application to tropical disturbances. The main purpose of this study is to propose a basic theoretical structure of parameterization, so that further investigations, both observational and analytical, can be integrated to produce better practical methods.},
	journal = {Journal of the Meteorological Society of Japan. Ser. II},
	author = {Ooyama, Katsuyuki},
	year = {1971},
	pages = {744--756}
}

@article{oortwijn_perturbations_1995,
	title = {Perturbations {That} {Optimally} {Trigger} {Weather} {Regimes}},
	volume = {52},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469%281995%29052%3C3932%3APTOTWR%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1995)052<3932:PTOTWR>2.0.CO;2},
	abstract = {The sensitivity of the onset of two weather regimes with respect to initial conditions is studied. The weather regimes are a Euro–Atlantic blocking regime and a Euro–Atlantic strong zonal flow regime. Both regimes are characterized by the same anomaly pattern but with opposite sign. Using a three-level quasigeostrophic T21 model and its tangent linear and adjoint versions, initial perturbations are computed that have the largest projection on this anomaly pattern at a prescribed forecast time. The tangent linear and adjoint techniques can be used only to describe linear error growth. However, with an iterative procedure, nonlinear error growth can be taken into account. In this way perturbations can be computed that trigger the onset of a weather regime in the linear range (even optimally) as well as in the nonlinear range. It is shown that moderate initial perturbations occasionally trigger a transition from a blocking regime to a zonal flow regime, or vice versa, within 3 days. For an optimization time of 6 days the iteratively computed perturbations generate such transitions for almost all investigated cases. The perturbations are compared with regional singular vectors, which are the linearly fastest-growing perturbations in the Euro-Atlantic area. In the linear range the perturbations project mainly onto the leading regional singular vectors. In the nonlinear range the projection onto 1inearly slower-growing regional singular vector is stronger. The method can easily be generalized to study the sensitivity for a transition to any weather regime or anomaly pattern. This approach can be useful in generating specific initial conditions for ensemble forecasting.},
	number = {22},
	urldate = {2017-11-14},
	journal = {Journal of the Atmospheric Sciences},
	author = {Oortwijn, Jeroen and Barkmeijer, Jan},
	month = nov,
	year = {1995},
	pages = {3932--3944}
}

@article{oliger_theoretical_1978,
	title = {Theoretical and {Practical} {Aspects} of {Some} {Initial} {Boundary} {Value} {Problems} in {Fluid} {Dynamics}},
	volume = {35},
	issn = {0036-1399},
	url = {http://epubs.siam.org/doi/abs/10.1137/0135035},
	doi = {10.1137/0135035},
	abstract = {Initial-boundary value problems for several systems of partial differential equations from fluid dynamics are discussed. Both rigid wall and open boundary problems are treated. Boundary conditions are formulated and shown to yield well-posed problems for the Eulerian equations for gas dynamics, the shallow-water equations, and linearized constant coefficient versions of the incompressible, anelastic equations. The “primitive” hydrostatic meteorological equations are shown to be ill-posed with any specification of local, pointwise boundary conditions. Analysis of simplified versions of this system illustrates the mechanism responsible for ill-posedness.},
	number = {3},
	urldate = {2017-11-14},
	journal = {SIAM Journal on Applied Mathematics},
	author = {Oliger, J. and Sundström, A.},
	month = nov,
	year = {1978},
	pages = {419--446}
}

@article{ogura_scale_1962,
	title = {Scale {Analysis} of {Deep} and {Shallow} {Convection} in the {Atmosphere}},
	volume = {19},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469%281962%29019%3C0173%3ASAODAS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1962)019<0173:SAODAS>2.0.CO;2},
	abstract = {The approximate equations of motion derived by Batchelor in 1953 are derived by a formal scale analysis, with the assumption that the percentage range in potential temperature is small and that the time scale is set by the Brunt-Väisälä frequency. Acoustic waves are then absent. If the vertical scale is small compared to the depth of an adiabatic atmosphere, the system reduces to the (non-viscous) Boussinesq equations. The computation of the saturation vapor pressure for deep convection is complicated by the important effect of the dynamic pressure on the temperature. For shallow convection this effect is not important, and a simple set of reversible equations is derived.},
	number = {2},
	urldate = {2017-11-14},
	journal = {Journal of the Atmospheric Sciences},
	author = {Ogura, Yoshimitsu and Phillips, Norman A.},
	month = mar,
	year = {1962},
	pages = {173--179}
}

@article{obrien_alternative_1970,
	title = {Alternative {Solutions} to the {Classical} {Vertical} {Velocity} {Problem}},
	volume = {9},
	issn = {0021-8952},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0450%281970%29009%3C0197%3AASTTCV%3E2.0.CO%3B2},
	doi = {10.1175/1520-0450(1970)009<0197:ASTTCV>2.0.CO;2},
	abstract = {The kinematic method for determining vertical velocity ω in pressure coordinates is reviewed. Alternative objective procedures are derived for obtaining ω, and an analytical solution to the pressure-differentiated continuity equation is found. A variational formulation leads to a generalized objective adjustment for divergence estimates which yields improved, physically realistic estimates of ω. Case studies for intense mesoscale convection demonstrate the utility of an adjustment scheme based on the simplest hypothesis, namely, that the errors in divergence estimates are a linear function of pressure.},
	number = {2},
	urldate = {2017-11-14},
	journal = {Journal of Applied Meteorology},
	author = {O'Brien, James J.},
	month = apr,
	year = {1970},
	pages = {197--203}
}

@article{nitta_technique_1969,
	title = {A technique of objective analysis and initialization for the primitive forecast equations},
	volume = {97},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281969%29097%3C0652%3AATOOAA%3E2.3.CO%3B2},
	doi = {10.1175/1520-0493(1969)097<0652:ATOOAA>2.3.CO;2},
	abstract = {A technique of initialization for the primitive forecast equations is presented. The method consists of a marching prediction scheme performed in such a manner that the large-scale solution remains approximately steady, and high-frequency modes created in the adjustment process are damped selectively by time differencing with the Euler-backward method. The scheme places no restriction on the wind divergence field and ensures truncation error consistency between initialization and forecast equations.},
	number = {9},
	urldate = {2017-11-14},
	journal = {Monthly Weather Review},
	author = {Nitta, Takashi and Hovermale, John B.},
	month = sep,
	year = {1969},
	pages = {652--658}
}

@article{murphy_experimental_1986,
	title = {{EXPERIMENTAL} {MONTHLY} {LONG}-{RANGE} {FORECASTS} {FOR} {THE} {UNITED}-{KINGDOM} .2. {A} {REAL}-{TIME} {LONG}-{RANGE} {FORECAST} {BY} {AN} {ENSEMBLE} {OF} {NUMERICAL} {INTEGRATIONS}},
	volume = {115},
	issn = {0026-1149},
	url = {https://ora.ox.ac.uk/objects/uuid:bb4d3287-4f39-4427-8327-71e3bc263612},
	abstract = {The use of an ensemble of integrations for long-range prediction has been studied with a hemispheric version of the Meteorological Office 5-level general circulation model. Some results, showing the potential of the technique, are described. The method is now being used with the global 11-level model to produce real-time long- range forecasts for the long-range forecasting conference in the Synoptic Climatology Branch of the Meteorological Office. Results from the first of these real-time ensemble forecasts are discussed. -Authors},
	language = {eng},
	number = {1372},
	urldate = {2017-11-14},
	journal = {METEOROLOGICAL MAGAZINE},
	author = {Murphy, J. and Palmer, T.},
	month = nov,
	year = {1986},
	pages = {337--349}
}

@article{miller_m._j._non-hydrostatic_1984,
	title = {On the non-hydrostatic equations in pressure and sigma coordinates},
	volume = {110},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49711046413/full},
	number = {464},
	urldate = {2017-10-18},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {{Miller, M. J.} and {White, A. A.}},
	year = {1984},
	pages = {515--533}
}

@incollection{dickinson_land_1992,
	title = {Land {Surface}},
	booktitle = {Climate {System} {Modeling}},
	publisher = {Cambridge University Press},
	author = {Dickinson, R. E.},
	collaborator = {{Kevin E. Trenberth}},
	year = {1992},
	pages = {788}
}

@techreport{dimego_g._data_1985,
	address = {Washington, DC, USA},
	title = {Data processing and quality control for optimum interpolation analyses at the {National} {Meteorological} {Center}},
	url = {http://www.lib.ncep.noaa.gov/ncepofficenotes/files/01408489.pdf},
	number = {Office Note 306.},
	institution = {Washington, D.C. U.S. Dept. of Commerce, National Oceanic and Atmospheric Administration, National Weather Service.},
	author = {{DiMego, G.} and {Phoebus, P. A} and {McDonell, J. E.}},
	year = {1985}
}

@book{stull_introduction_1988,
	title = {An {Introduction} to {Boundary} {Layer} {Meteorology} {\textbar} {Roland} {B}. {Stull} {\textbar} {Springer}},
	isbn = {978-94-009-3027-8},
	url = {//www.springer.com/us/book/9789027727688},
	abstract = {Part of the excitement in boundary-layer meteorology is the challenge associated with turbulent flow - one of the unsolved problems in classical physics....},
	urldate = {2017-11-08},
	author = {Stull, Roland B},
	year = {1988}
}

@article{tsuyuki_prediction_1990,
	title = {Prediction of the 30-60 {Day} {Oscillation} with the {JMA} {Global} {Model} and {Its} {Impact} on {Extended}-range {Forecasts}},
	volume = {68},
	doi = {10.2151/jmsj1965.68.2_183},
	abstract = {Operational 15-day forecasts with the global prediction model of the Japan Meteorological Agency (JMA) are utilized to investigate the relationship between the eastward-propagating 30-60 day modes in the tropics and the predictability of the northern hemisphere extratropical circulation for the period from March 1988 to February 1989.It is found that the global model successfully predicts the eastward-propagating 30-60 day modes both in amplitude and phase when they are significant in the observation. There is a tendency that the forecast skill of the 10-day mean 500 mb geopotential height north of 20°N for days 6-15 becomes relatively high in such cases during the warm season (May-October). In these skilful forecasts, wavelike height anomaly patterns are found in middle latitudes in 500 mb maps of the analysis and the forecast, and wave propagations from low latitudes are seen along these wave-like patterns.The above results indicate that when the tropical 30-60 day oscillation is well predicted the skill of extended-range forecast for the northern hemisphere tends to increase due to a successful prediction of the influence of the 30-60 day modes on the extratropical circulation.},
	number = {2},
	journal = {Journal of the Meteorological Society of Japan. Ser. II},
	author = {Tsuyuki, Tadashi},
	year = {1990},
	pages = {183--201}
}

@article{tripoli_nonhydrostatic_1992,
	title = {A {Nonhydrostatic} {Mesoscale} {Model} {Designed} to {Simulate} {Scale} {Interaction}},
	volume = {120},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281992%29120%3C1342%3AANMMDT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1992)120<1342:ANMMDT>2.0.CO;2},
	abstract = {A three-dimensional nonhydrostatic mesoscale model is presented that is designed to optimally represent the scale-interaction process among inertially balanced and unbalanced modes occurring within convective weather systems. Because scale-interaction simulations are long-term integrations that emphasize the evolution of the three-dimensional kinetic energy spectrum, the model is built to conserve enstrophy, as well as kinetic energy against numerical sources and sinks in three dimensions. A non-Boussinesq and quasi-compressible framework is employed to maintain applicability on meso-α and larger scales as well as for situations of relatively large local density variation. Sample integrations in two and three dimensions are presented that show enstrophy conservation to be effective in improving the prediction of nonlinear evolution as truncation errors act to force anomalous bifurcations from the physical solution.},
	number = {7},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Tripoli, Gregory J.},
	month = jul,
	year = {1992},
	pages = {1342--1359}
}

@article{tripoli_numerical_1979,
	title = {A {Numerical} {Investigation} of {Several} {Factors} {Contributing} to the {Observed} {Variable} {Intensity} of {Deep} {Convection} over {South} {Florida}},
	volume = {19},
	issn = {0021-8952},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0450%281980%29019%3C1037%3AANIOSF%3E2.0.CO%3B2},
	doi = {10.1175/1520-0450(1980)019<1037:ANIOSF>2.0.CO;2},
	abstract = {This study employs a revised version of the Colorado State University three-dimensional numerical cloud scale model to investigate the observed behavior of deep convection over South Florida on 17 July 1973. A brief description of recent model improvements is made. A combined balance and dynamics initialization procedure designed to introduce variable magnitudes and distributions of low-level wind convergence to the initial fields is described. Using radiosonde and PIBAL data collected by the NOAA/ERL Florida Area Cumulus Experiment (FACE) and the National Weather Service at Miami on 17 July 1973, composite wind, temperature, pressure and moisture profiles were constructed to depict the state of the atmosphere at the time of deep convection. Mesoscale convergence was estimated from results of a mesoscale model simulation of low-level sea breeze convergence made by Pielke (personal communication) for the same case study day. Several numerical simulations were performed using the sounding data as a basic state. The initial magnitude and distribution of low-level convergence was varied and the sensitivity of the model to some micro-physical parameters was examined. The results of the numerical experiments show that (i) the magnitude of surface convergence over a finite area has a pronounced influence on the simulated storm circulation, the eddy kinetic energy of the storm and the total rainfall of the storm system; (ii) the horizontal distribution of convergence has a relatively large effect on the rates of entrainment into the updraft below 5 km MSL resulting in significant modulations in predicted precipitation, but only moderate changes in storm kinetic energy; (iii) variations in terminal velocity of precipitation associated with the introduction of the ice phase has only a minor effect on precipitation and total kinetic energy of the storm; and (iv) increased rain evaporation rates result in a moderate increase in the kinetic energy of the simulated storm, but at the expense of surface precipitation. Pressure forces are also shown to play an important role in initiating downdrafts and in biasing the direction of downdraft-associated outflow. Implications of these results to the modification of convective clouds are discussed.},
	number = {9},
	urldate = {2017-11-08},
	journal = {Journal of Applied Meteorology},
	author = {Tripoli, Gregory J. and Cotton, William R.},
	month = sep,
	year = {1979},
	pages = {1037--1063}
}

@article{tribbia_simple_1984,
	title = {A {Simple} {Scheme} for {High}-{Order} {Nonlinear} {Normal} {Mode} {Initialization}},
	volume = {112},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1984)112%3C0278%3AASSFHO%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1984)112<0278:ASSFHO>2.0.CO;2},
	abstract = {An algorithm for obtaining high-order mode initialization of the type first proposed by Baer and Tribbia is developed which is free from the major difficulty of previous methods—the necessity of calculating Frechet derivatives of the nonlinear terms. This new method is shown to be a logical extension of the technique proposed by Machenhauer; thus the asymptotic equivalence of the Machenhauer and Baer-Tribbia initialization methods is accomplished. A comparison between the new algorithm and the older method of calculating second-order initialization demonstrates the accuracy and ease of implementation of the new technique.},
	number = {2},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Tribbia, Joseph J.},
	month = feb,
	year = {1984},
	pages = {278--284}
}

@article{tribbia_nonlinear_1981,
	title = {Nonlinear {Normal}-{Mode} {Balancing} and the {Ellipticity} {Condition}},
	volume = {109},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281981%29109%3C1751%3ANNMBAT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1981)109<1751:NNMBAT>2.0.CO;2},
	abstract = {Using a low-order, spectral, shallow-water model on an f-plane, the conditions under which height-constrained nonlinear normal mode initialization fails and the existence of realizable balancing wind fields are examined. The relationship of this nonrealizability condition and the ellipticity condition for the standard nonlinear balance equation is also examined. A conclusion from this analysis is that non-elliptic geopotential regions must be accompanied by transient gravity wave motion if there is no forcing mechanism. The low-order results are extended through the use of a global shallow-water model. The relationship between the local f-plane results and the global results is analyzed and a strong correlation between the appearance of non-elliptic geopotential regions and the breakdown of the iteration scheme used in non-linear normal mode balancing is noted. It is concluded that moderately weak anticyclonic disturbances in equatorial areas may act as regions of energy exchange between rotational and gravitational modes. Also, the climatological existence of these regions implies the necessity forcing to maintain them in the atmosphere and numerical forecast models.},
	number = {8},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Tribbia, Joseph J.},
	month = aug,
	year = {1981},
	pages = {1751--1761}
}

@article{trevisan_transient_1995,
	title = {Transient error growth and local predictability: a study in the {Lorenz} system},
	volume = {47},
	issn = {1600-0870},
	shorttitle = {Transient error growth and local predictability},
	url = {http://onlinelibrary.wiley.com/doi/10.1034/j.1600-0870.1995.00006.x/abstract},
	doi = {10.1034/j.1600-0870.1995.00006.x},
	abstract = {Lorenz's three-variable convective model is used as a prototypical chaotic system in order to develop concepts related to finite time local predictability. Local predictability measures can be represented by global measures only if the instability properties of the attractor are homogeneous in phase space. More precisely, there are two sources of variability of predictability in chaotic attractors. The first depends on the direction of the initial error vector, and its dependence is limited to an initial transient period. If the attractor has homogeneous predictability properties, this is the only source of variability of error growth rate and, after the transient has elapsed, all initial perturbations grow at the same rate, given by the first (global) Lyapunov exponent. The second is related to the local instability properties in phase space. If the predictability properties of the attractor are not homogeneous, this additional source of variability affects both the transient and post-transient phases of error growth. After the transient phase all initial perturbations of a particular initial condition grow at the same rate, given in this case by the first local Lyapunov exponent. We consider various currently used indexes to quantify finite time local predictability. The probability distributions of the different indexes are examined during and after the transient phase. By comparing their statistics it is possible to discriminate the relative importance of the two sources of variability of predictability and to determine the most appropriate measure of predictability for a given forecast time. It is found that a necessary premise for choosing a relevant local predictability index for a specific system is the study of the characteristics of its transient. The consequences for the problem of forecasting forecast skill in operational models are discussed.},
	language = {en},
	number = {1},
	urldate = {2017-11-08},
	journal = {Tellus A},
	author = {Trevisan, Anna and Legnani, Roberto},
	month = jan,
	year = {1995},
	pages = {103--117}
}

@article{trevisan_periodic_1998,
	title = {Periodic {Orbits}, {Lyapunov} {Vectors}, and {Singular} {Vectors} in the {Lorenz} {System}},
	volume = {55},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469%281998%29055%3C0390%3APOLVAS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1998)055<0390:POLVAS>2.0.CO;2},
	abstract = {Some theoretical issues related to the problem of quantifying local predictability of atmospheric flow and the generation of perturbations for ensemble forecasts are investigated in the Lorenz system. A periodic orbit analysis and the study of the properties of the associated tangent linear equations are performed. In this study a set of vectors are found that satisfy Oseledec theorem and reduce to Floquet eigenvectors in the particular case of a periodic orbit. These vectors, called Lyapunov vectors, can be considered the generalization to aperiodic orbits of the normal modes of the instability problem and are not necessarily mutually orthogonal. The relation between singular vectors and Lyapunov vectors is clarified, and transient or asymptotic error growth properties are investigated. The mechanism responsible for super-Lyapunov growth is shown to be related to the nonorthogonality of Lyapunov vectors. The leading Lyapunov vectors, as defined here, as well as the asymptotic final singular vectors, are tangent to the attractor, while the leading initial singular vectors, in general, point away from it. Perturbations that are on the attractor and maximize growth should be considered in meteorological applications such as ensemble forecasting and adaptive observations. These perturbations can be found in the subspace of the leading Lyapunov vectors.},
	number = {3},
	urldate = {2017-11-08},
	journal = {Journal of the Atmospheric Sciences},
	author = {Trevisan, Anna and Pancotti, Francesco},
	month = feb,
	year = {1998},
	pages = {390--398}
}

@article{trenberth_evaluation_1988,
	title = {An {Evaluation} and {Intercomparison} of {Global} {Analyses} from the {National} {Meteorological} {Center} and the {European} {Centre} for {Medium} {Range} {Weather} {Forecasts}},
	volume = {69},
	issn = {0003-0007},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0477%281988%29069%3C1047%3AAEAIOG%3E2.0.CO%3B2},
	doi = {10.1175/1520-0477(1988)069<1047:AEAIOG>2.0.CO;2},
	abstract = {In order to help establish a global climate record data sets of global analyses from the U.S. National Meteorological Center (NMC) and the European Centre for Medium Range Weather Forecasts (ECMWF) have been comprehensively evaluated. A detailed chronology of the changes in the analysis-forecast system at NMC and ECMWF has been compiled and the main impacts on the analyses have been identified. Discontinuities have been found in certain characteristics of the analyses when major changes occur. Ale main quantities so affected are the divergent wind component and associated vertical motion fields, and the moisture fields. A detailed intercomparison of the two data sets and statistical results show fairly widespread agreement between the analyses from the two centers over the Northern Hemisphere extratropics. In general, the quality of the analyses is much lower in the tropics and Southern Hemisphere. This is reflected in much greater differences in wind fields south of 20°N, with root-mean-square differences in the north-south and east-west components often exceeding 5 m s−1 above ∼500 mb throughout most of this region. Much greater differences in geopotential height south of ∼3°S exist. Major problems at NMC prior to May 1986 occur south of ∼50°S. ECMWF has also experienced difficulties over and around Antarctica, especially prior to 1982. In the tropics, there are major disagreements between the analyses of the divergent wind field and associated vertical motions which have become more intense and more realistic with time, but still appear to be poorly known. The relative humility field is the poorest known and has undergone major changes with time at both centers. Possible reasons for these results am discussed and some implications and recommendations are given.},
	number = {9},
	urldate = {2017-11-08},
	journal = {Bulletin of the American Meteorological Society},
	author = {Trenberth, Kevin E. and Olson, Jerry G.},
	month = sep,
	year = {1988},
	pages = {1047--1057}
}

@article{trefethen_group_1983,
	title = {Group velocity interpretation of the stability theory of {Gustafsson}, {Kreiss}, and {Sundström}},
	volume = {49},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/0021999183901237},
	doi = {10.1016/0021-9991(83)90123-7},
	abstract = {The existing stability theory for finite difference models of hyperbolic initial boundary value problems, due to Gustafsson, Kreiss, and Sundstrom, is difficult to understand in its original algebraic formulation. Here it is shown that the GKS stability criterion has a physical interpretation in terms of group velocity: if the finite difference model together with its boundary conditions can support a set of waves at the boundary with group velocities pointing into the field, then it is unstable. This interpretation is valid for both dissipative and nondissipative difference models. A simple argument explains why such a set of waves is unstable, and yields a new theorem on what kind of unstable growth to expect. Examples are given in one and two space dimensions.},
	number = {2},
	urldate = {2017-11-08},
	journal = {Journal of Computational Physics},
	author = {Trefethen, Lloyd N},
	month = feb,
	year = {1983},
	pages = {199--217}
}

@article{toth_synoptic_1997,
	title = {A {Synoptic} {Evaluation} of the {NCEP} {Ensemble}},
	volume = {12},
	issn = {0882-8156},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0434%281997%29012%3C0140%3AASEOTN%3E2.0.CO%3B2},
	doi = {10.1175/1520-0434(1997)012<0140:ASEOTN>2.0.CO;2},
	abstract = {Ensemble forecasting has been operational at NCEP (formerly the National Meteorological Center) since December 1992. In March 1994, more ensemble forecast members were added. In the new configuration, 17 forecasts with the NCEP global model are run every day, out to 16-day lead time. Beyond the 3 control forecasts (a T126 and a T62 resolution control at 0000 UTC and a T126 control at 1200 UTC), 14 perturbed forecasts are made at the reduced T62 resolution. Global products from the ensemble forecasts are available from NCEP via anonymous FTP. The initial perturbation vectors are derived from seven independent breeding cycles, where the fast-growing nonlinear perturbations grow freely, apart from the periodic rescaling that keeps their magnitude compatible with the estimated uncertainty within the control analysis. The breeding process is an integral part of the extended-range forecasts, and the generation of the initial perturbations for the ensemble is done at no computational cost beyond that of running the forecasts. A number of graphical forecast products derived from the ensemble are available to the users, including forecasters at the Hydrometeorological Prediction Center and the Climate Prediction Center of NCEP. The products include the ensemble and cluster means, standard deviations, and probabilities of different events. One of the most widely used products is the “spaghetti” diagram where a single map contains all 17 ensemble forecasts, as depicted by a selected contour level of a field, for example, 5520 m at 500-hPa height or 50 m s−1 windspeed at the jet level. With the aid of the above graphical displays and also by objective verification, the authors have established that the ensemble can provide valuable information for both the short and extended range. In particular, the ensemble can indicate potential problems with the high-resolution control that occurs on rare occasions in the short range. Most of the time, the “cloud” of the ensemble encompasses the verification, thus providing a set of alternate possible scenarios beyond that of the control. Moreover, the ensemble provides a more consistent outlook for the future. While consecutive control forecasts verifying on a particular date may often display large “jumps” from one day to the next, the ensemble changes much less, and its envelope of solutions typically remains unchanged. In addition, the ensemble extends the practical limit of weather forecasting by about a day. For example, significant new weather systems (blocking, extratropical cyclones, etc.) are usually detected by some ensemble members a day earlier than by the high-resolution control. Similarly, the ensemble mean improves forecast skill by a day or more in the medium to extended range, with respect to the skill of the control. The ensemble is also useful in pointing out areas and times where the spread within the ensemble is high and consequently low skill can be expected and, conversely, those cases in which forecasters can make a confident extended-range forecast because the low ensemble spread indicates high predictability. Another possible application of the ensemble is identifying potential model errors. A case of low ensemble spread with all forecasts verifying poorly may be an indication of model bias. The advantage of the ensemble approach is that it can potentially indicate a systematic bias even for a single case, while studies using only a control forecast need to average many cases.},
	number = {1},
	urldate = {2017-11-08},
	journal = {Weather and Forecasting},
	author = {Toth, Zoltan and Kalnay, Eugenia and Tracton, Steven M. and Wobus, Richard and Irwin, Joseph},
	month = mar,
	year = {1997},
	pages = {140--153}
}

@article{toth_ensemble_1997,
	title = {Ensemble {Forecasting} at {NCEP} and the {Breeding} {Method}},
	volume = {125},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281997%29125%3C3297%3AEFANAT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1997)125<3297:EFANAT>2.0.CO;2},
	abstract = {The breeding method has been used to generate perturbations for ensemble forecasting at the National Centers for Environmental Prediction (formerly known as the National Meteorological Center) since December 1992. At that time a single breeding cycle with a pair of bred forecasts was implemented. In March 1994, the ensemble was expanded to seven independent breeding cycles on the Cray C90 supercomputer, and the forecasts were extended to 16 days. This provides 17 independent global forecasts valid for two weeks every day. For efficient ensemble forecasting, the initial perturbations to the control analysis should adequately sample the space of possible analysis errors. It is shown that the analysis cycle is like a breeding cycle: it acts as a nonlinear perturbation model upon the evolution of the real atmosphere. The perturbation (i.e., the analysis error), carried forward in the first-guess forecasts, is “scaled down” at regular intervals by the use of observations. Because of this, growing errors associated with the evolving state of the atmosphere develop within the analysis cycle and dominate subsequent forecast error growth. The breeding method simulates the development of growing errors in the analysis cycle. A difference field between two nonlinear forecasts is carried forward (and scaled down at regular intervals) upon the evolving atmospheric analysis fields. By construction, the bred vectors are superpositions of the leading local (time-dependent) Lyapunov vectors (LLVs) of the atmosphere. An important property is that all random perturbations assume the structure of the leading LLVs after a transient period, which for large-scale atmospheric processes is about 3 days. When several independent breeding cycles are performed, the phases and amplitudes of individual (and regional) leading LLVs are random, which ensures quasi-orthogonality among the global bred vectors from independent breeding cycles. Experimental runs with a 10-member ensemble (five independent breeding cycles) show that the ensemble mean is superior to an optimally smoothed control and to randomly generated ensemble forecasts, and compares favorably with the medium-range double horizontal resolution control. Moreover, a potentially useful relationship between ensemble spread and forecast error is also found both in the spatial and time domain. The improvement in skill of 0.04–0.11 in pattern anomaly correlation for forecasts at and beyond 7 days, together with the potential for estimation of the skill, indicate that this system is a useful operational forecast tool. The two methods used so far to produce operational ensemble forecasts—that is, breeding and the adjoint (or “optimal perturbations”) technique applied at the European Centre for Medium-Range Weather Forecasts—have several significant differences, but they both attempt to estimate the subspace of fast growing perturbations. The bred vectors provide estimates of fastest sustainable growth and thus represent probable growing analysis errors. The optimal perturbations, on the other hand, estimate vectors with fastest transient growth in the future. A practical difference between the two methods for ensemble forecasting is that breeding is simpler and less expensive than the adjoint technique.},
	number = {12},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Toth, Zoltan and Kalnay, Eugenia},
	month = dec,
	year = {1997},
	pages = {3297--3319}
}

@article{toth_ensemble_1993,
	title = {Ensemble {Forecasting} at {NMC}: {The} {Generation} of {Perturbations}},
	volume = {74},
	issn = {0003-0007},
	shorttitle = {Ensemble {Forecasting} at {NMC}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0477%281993%29074%3C2317%3AEFANTG%3E2.0.CO%3B2},
	doi = {10.1175/1520-0477(1993)074<2317:EFANTG>2.0.CO;2},
	abstract = {On 7 December 1992, The National Meteorological Center (NMC) started operational ensemble forecasting. The ensemble forecast configuration implemented provides 14 independent forecasts every day verifying on days 1–10. In this paper we briefly review existing methods for creating perturbations for ensemble forecasting. We point out that a regular analysis cycle is a “breeding ground” for fast-growing modes. Based on this observation, we devise a simple and inexpensive method to generate growing modes of the atmosphere. The new method, “breeding of growing modes”, or BGM, consists of one additional, perturbed short-range forecast, introduced on top of the regular analysis in an analysis cycle. The difference between the control and perturbed six-hour (first guess) forecast is scaled back to the size of the initial perturbation and then reintroduced onto the new atmospheric analysis. Thus, the perturbation evolves along with the time dependent analysis fields, ensuring that after a few days of cycling the perturbation field consists of a superposition of fast-growing modes corresponding to the contemporaneous atmosphere, akin to local Lyapunov vectors. The breeding cycle has been designed to model how the growing errors are “bred” and maintained in a conventional analysis cycle through the successive use of short-range forecasts. The bred modes should thus offer a good estimate of possible growing error fields in the analysis. Results from extensive experiments indicate that ensembles of just two BGM forecasts achieve better results than much larger random Monte Cado or lagged average forecast (LAF) ensembles. Therefore, the operational ensemble configuration at NMC is based on the BGM method to generate efficient initial perturbations. The only two methods explicitly designed to generate perturbations that contain fast-growing modes corresponding to the evolving atmosphere are the BGM and the method of Lorenz, which is based on the singular modes of the linear tangent model. This method has been adopted operationally at The European Centre for Medium-Range Forecasts (ECMWF) for ensemble forecasting. Both the BGM and the ECMWF methods seem promising, but since it has not yet been possible to compare in detail their operational performance we limit ourselves to pointing out some of their similarities and differences.},
	number = {12},
	urldate = {2017-11-08},
	journal = {Bulletin of the American Meteorological Society},
	author = {Toth, Zoltan and Kalnay, Eugenia},
	month = dec,
	year = {1993},
	pages = {2317--2330}
}

@article{todling_tracking_1994,
	title = {Tracking {Atmospheric} {Instabilities} with the {Kalman} {Filter}. {Part} 1: {Methodology} and {One}-{Layer} {Resultst}},
	volume = {122},
	issn = {0027-0644},
	shorttitle = {Tracking {Atmospheric} {Instabilities} with the {Kalman} {Filter}. {Part} 1},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1994)122%3C0183%3ATAIWTK%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1994)122<0183:TAIWTK>2.0.CO;2},
	abstract = {Sequential data assimilation schemes approaching true optimality for sizable atmospheric models are becoming a reality. The behavior of the Kalman filter (KF) under difficult conditions needs therefore to be understood. In this two-part paper we implement a KF for a two-dimensional shallow-water model, with one or two layers. The model is linearized about a basic flow that depends on latitude; this permits the one-layer (1-L) case to be barotropically unstable. Constant vertical shear in the two-layer (2-L) case induces baroclinic instability. A model-error covariance matrix for the KF simulations is constructed based on the hypothesis that an ensemble of slow modes dominates the errors. In the 1-L case, the system is stable for a meridionally constant basic flow. Assuming equipartition of energy in the construction of the model-error covariance matrix has a deleterious effect on the process of data assimilation in both the stable and unstable cases. Estimation errors are found to be smaller for a model-error spectrum that decays exponentially with wavenumber than an equipartition spectrum. Then the model-error covariance matrix for the 2-L model is also obtained using a decaying-energy spectrum. The barotropically unstable 1-L case is studied for a basic velocity profile that has a cosine-square shape. Given this linear instability, forecast errors grow exponentially when no observations are present. The KF keeps the errors bounded, even when very few observations are available. The best placement of a single observation is determined in this simple situation and shown to be where the instability is strongest. The 2-L case and a comparison with the performance of a currently operational data assimilation scheme will appear in Part II.},
	number = {1},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Todling, Ricardo and Ghil, Michael},
	month = jan,
	year = {1994},
	pages = {183--204}
}

@article{todling_suboptimal_1994,
	title = {Suboptimal {Schemes} for {Atmospheric} {Data} {Assimilation} {Based} on the {Kalman} {Filter}},
	volume = {122},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1994)122%3C2530%3ASSFADA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1994)122<2530:SSFADA>2.0.CO;2},
	abstract = {This work is directed toward approximating the evolution of forecast error covariances for data assimilation. The performance of different algorithms based on simplification of the standard Kalman filter (KF) is studied. These are suboptimal schemes (SOSs) when compared to the KF, which is optimal for linear problems with known statistics. The SOSs considered here are several versions of optimal interpolation (OI), a scheme for height error variance advection, and a simplified KF in which the full height error covariance is advected. To employ a methodology for exact comparison among these schemes, a linear environment is maintained, in which a beta-plane shallow-water model linearized about a constant zonal flow is chosen for the test-bed dynamics. The results show that constructing dynamically balanced forecast error covariances rather than using conventional geostrophically balanced ones is essential for successful performance of any SOS. A posteriori initialization of SOSs to compensate for model-data imbalance sometimes results in poor performance. Instead, properly constructed dynamically balanced forecast error covariances eliminate the need for initialization. When the SOSs studied here make use of dynamically balanced forecast error covariances, the difference among their performances progresses naturally from conventional OI to the KF. In fact, the results suggest that even modest enhancements of OI, such as including an approximate dynamical equation for height error variances while leaving height error correlation structure homogeneous, go a long way toward achieving the performance of the KF, provided that dynamically balanced cross-covariances are constructed and that model errors are accounted for properly. The results indicate that such enhancements are necessary if unconventional data are to have a positive impact.},
	number = {11},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Todling, Ricardo and Cohn, Stephen E.},
	month = nov,
	year = {1994},
	pages = {2530--2557}
}

@article{thuburn_pv-based_1997,
	title = {A {PV}-{Based} {Shallow}-{Water} {Model} on a {Hexagonal}–{Icosahedral} {Grid}},
	volume = {125},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281997%29125%3C2328%3AAPBSWM%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1997)125<2328:APBSWM>2.0.CO;2},
	abstract = {A new global shallow-water model has been developed. It uses a hexagonal–icosahedral grid, potential vorticity as a prognostic variable, and a conservative, shape-preserving scheme for advection of mass, potential vorticity, and tracers. A semi-implicit time scheme is used so that the maximum time step for stable integrations is limited by the advection speed rather than the gravity wave phase speed. This combination of numerical methods avoids some of the major problems of more traditional numerical methods, such as pole problems, and spurious oscillations and negatives in advected quantities. Sample results from a standard set of test cases are presented to illustrate the model’s performance. In a pure advection test case the model’s advection scheme shows good isotropy and phase-speed properties, but it is a little diffusive. In the remaining test cases the model’s overall accuracy is comparable to that of other gridpoint models for which results are available. Two sources of error are noted. One is the dissipation inherent in the advection scheme, which is estimated to be significantly stronger than the dissipation usually imposed in climate models of comparable resolution. The other is the grid structure, which leads to conspicuous symmetry errors in test cases where the true solution is symmetrical. The symmetry errors appear to arise because the hexagonal grid boxes are not perfectly regular but are somewhat distorted, particularly in certain regions of the grid, leading to larger truncation errors in the advection scheme in those regions.},
	number = {9},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Thuburn, John},
	month = sep,
	year = {1997},
	pages = {2328--2347}
}

@article{durran_toward_1993,
	title = {Toward {More} {Accurate} {Wave}-{Permeable} {Boundary} {Conditions}},
	volume = {121},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281993%29121%3C0604%3ATMAWPB%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1993)121<0604:TMAWPB>2.0.CO;2},
	abstract = {This paper investigates several fundamental aspects of wave-permeable, or “radiation,” lateral boundary conditions. Orlanski (1976) proposed that approximate wave-permeable boundary conditions could be constructed by advecting disturbances out of the domain at a phase speed c*, which was to be calculated from the values of the prognostic variable near the boundary. Rigorous justification for this approach is possible for one-dimensional shallow-water flow. It is shown, however, that the floating c* approach gives poor results in the one-dimensional shallow-water problem because all accuracy in the c* calculations is eventually destroyed by the positive feedback between errors in c* and (initially small) errors in the prognostic fields at the boundary. Better results were achieved by using fixed values of c*. In our test cases, an externally specified c* could deviate from the true phase speed U + c by 40\%–60\% and still yield better results than schemes in which c* was calculated at the boundary. In order to examine the effects of wave dispersion on the question of whether c* should be fixed or calculated, tests were conducted with a two-level shallow-water model. Once again, the simulations with fixed c* were distinctly superior to those in which c* was calculated at the boundary. A reasonable, though nonoptimal, value for the fixed c* was the phase speed of the fastest wave. Wave dispersion is, however, not the only factor that makes it difficult to specify wave-permeable boundary conditions. Two-dimensional shallow-water waves are nondispersive, but their trace velocities along the x and y axes are functions of wavenumber. As a consequence, the simple radiation boundary condition appropriate for one-dimensional shallow-water flow is just an approximation for two-dimensional flow. Engquist and Majda ( 1977) developed improved boundary conditions for the two-dimensional problem by constructing approximate “one-way equations.” In this paper, the approach of Engquist and Majda is used to construct second-order one-way wave equations for situations with nonzero mean flow. The new boundary condition is tested against several alternative schemes and found to give the best results. The new boundary condition is particularly recommended for situations where waves strike the boundary at nonnormal angles of incidence.},
	number = {2},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Durran, Dale R. and Yang, Ming-Jen and Slinn, Donald N. and Brown, Randy G.},
	month = feb,
	year = {1993},
	pages = {604--620}
}

@article{durran_third-order_1990,
	title = {The {Third}-{Order} {Adams}-{Bashforth} {Method}: {An} {Attractive} {Alternative} to {Leapfrog} {Time} {Differencing}},
	volume = {119},
	issn = {0027-0644},
	shorttitle = {The {Third}-{Order} {Adams}-{Bashforth} {Method}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281991%29119%3C0702%3ATTOABM%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1991)119<0702:TTOABM>2.0.CO;2},
	abstract = {The third-order Adams–Bashforth method is compared with the leapfrog scheme. Like the leapfrog scheme, the third-order Adams–Bashforth method is an explicit technique that requires just one function evaluation per time step. Yet the third-order Adams–Bashforth method is not subject to time splitting instability and it is more accurate than the leapfrog scheme. In particular, the O[(Δt)4] amplitude error of the third-order Adams–Bashforth method can be a marked improvement over the O[(Δt)2] amplitude error generated by the Asselin-filtered leapfrog scheme—even when the filter factor is very small. The O[(Δt)4] phase-speed errors associated with third-order Adams–Bashforth time differencing can also be significantly less than the O[(Δt)2] errors produced by the leapfrog method. The third-order Adams–Bashforth method does use more storage than the leapfrog method, but its storage requirements are not particularly burdensome. Several numerical examples are provided illustrating the superiority of third-order Adams–Bashforth time differencing. Other higher-order alternatives to the Adams–Bashforth method are also surveyed. A discussion is presented describing the general relationship between the truncation error of an ordinary differential solver and the amplitude and phase-speed errors that develop when the scheme is used to integrate oscillatory systems.},
	number = {3},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Durran, Dale R.},
	month = mar,
	year = {1990},
	pages = {702--720}
}

@article{durran_improving_1988,
	title = {Improving the {Anelastic} {Approximation}},
	volume = {46},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469%281989%29046%3C1453%3AITAA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1989)046<1453:ITAA>2.0.CO;2},
	abstract = {A new diagnostic equation is presented which exhibits many advantages over the conventional forms of the anelastic continuity equation. Scale analysis suggests that use of this “pseudo-incompressible equation” is justified if the Lagrangian time scale of the disturbance is large compared with the time scale for sound wave propagation and the perturbation pressure is small compared to the vertically varying mean-state pressure. No assumption about the magnitude of the perturbation potential temperature or the strength of the mean-state stratification is required. In the various anelastic approximations, the influence of the perturbation density field on the mass balance is entirely neglected. In contrast, the mass-balance in the “pseudo-incompressible approximation” accounts for those density perturbations associated (through the equation of state) with perturbations in the temperature field. Density fluctuations associated with perturbations in the pressure field are neglected. The pseudo-incompressible equation is identical to the anelastic continuity equation when the mean stratification is adiabatic. As the stability increases, the pseudo-incompressible approximation gives a more accurate result. The pseudo-incompressible equation, together with the unapproximated momentum and thermodynamic equations, forms a closed system of governing equations that filters sound waves. The pseudo-incompressible system conserves an energy form that is directly analogous to the total energy conserved by the complete compressible system. The pseudo-incompressible approximation yields a system of equations suitable for use in nonhydrostatic numerical models. The pseudo-incompressible equation also permits the diagnostic calculation of the vertical velocity in adiabatic flow. The pseudo-incompressible equation might also be used to compute the net heating rate in a diabatic flow from extremely accurate observations of the three-dimensional velocity field and very coarse resolution (single sounding) thermodynamic data.},
	number = {11},
	urldate = {2017-11-08},
	journal = {Journal of the Atmospheric Sciences},
	author = {Durran, Dale R.},
	month = jun,
	year = {1988},
	pages = {1453--1461}
}

@article{durran_compressible_1983,
	title = {A {Compressible} {Model} for the {Simulation} of {Moist} {Mountain} {Waves}},
	volume = {111},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281983%29111%3C2341%3AACMFTS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1983)111<2341:ACMFTS>2.0.CO;2},
	abstract = {A two-dimensional, nonlinear, nonhydrostatic model is described which allows the calculation of moist airflow in mountainous terrain. The model is compressible, uses a terrain-following coordinate system, and employs lateral and upper boundary conditions which minimize wave reflections. The model's accuracy and sensitivity are examined. These tests suggest that in numerical simulations of vertically propagating, highly nonlinear mountain waves, a wave absorbing layer does not accurately mimic the effects of wave breakdown and dissipation at high levels in the atmosphere. In order to obtain a correct simulation, the region in which the waves are physically absorbed must generally be included in the computational domain (a nonreflective upper boundary condition should be used as well). The utility of the model is demonstrated in two examples (linear waves in a uniform atmosphere and the 11 January 1972 Boulder windstorm) which illustrate how the presence of moisture can influence propagating waves. In both cases, the addition of moisture to the upstream flow greatly reduces the wave response.},
	number = {12},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Durran, Dale R. and Klemp, Joseph B.},
	month = dec,
	year = {1983},
	pages = {2341--2361}
}

@article{dudhia_nonhydrostatic_1993,
	title = {A {Nonhydrostatic} {Version} of the {Penn} {State}–{NCAR} {Mesoscale} {Model}: {Validation} {Tests} and {Simulation} of an {Atlantic} {Cyclone} and {Cold} {Front}},
	volume = {121},
	issn = {0027-0644},
	shorttitle = {A {Nonhydrostatic} {Version} of the {Penn} {State}–{NCAR} {Mesoscale} {Model}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281993%29121%3C1493%3AANVOTP%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1993)121<1493:ANVOTP>2.0.CO;2},
	abstract = {A nonhydrostatic extension to the Pennsylvania State University-NCAR Mesoscale Model is presented. This new version employs reference pressure as the basis for a terrain-following vertical coordinate and the fully compressible system of equations. In combination with the existing initialization techniques and physics of the current hydrostatic model, this provides a model capable of real-data simulations on any scale, limited only by data resolution and quality and by computer resources. The model uses pressure perturbation and temperature as prognostic variables as well as a B-grid staggering in contrast to most current nonhydrostatic models. The compressible equations are solved with a split-time- step approach where sound waves are treated semi-implicitly on the shorter step. Numerical techniques and finite differencing are described. Two-dimensional tests of flow over a bell-shaped hill on a range of scales were carded out with the hydrostatic and nonhydrostatic models to contrast the two and to verify the dynamics of the new version. Several three-dimensional real-data simulations show the potential use of grid-nesting applications whereby the model is initialized from a coarser hydrostatic or nonhydrostatic model output by interpolation to a smaller grid area of typically between two and four times finer resolution. This approach is illustrated by a simulation of a cold front within a developing midlatitude cyclone, and a comparison of the front to observations of similar features. The cold-frontal boundary was sharply defined at low levels and consisted of narrow linear updraft cores. At 2–4-km altitude this structure gave way to a more diffuse boundary with apparent mixing. Mechanisms are presented to explain these features in terms of inertial and shearing instability. Convection embedded in the frontal band formed a prefrontal line at later stages. Finally, sensitivity studies showed that the frontal band owed its narrowness to the concentrating effect of latent heating. The frontal ascending branch was supplied by a strong easterly ageostrophic flow in the warm sector.},
	number = {5},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Dudhia, Jimy},
	month = may,
	year = {1993},
	pages = {1493--1513}
}

@article{duchon_lanczos_1979,
	title = {Lanczos {Filtering} in {One} and {Two} {Dimensions}},
	volume = {18},
	issn = {0021-8952},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0450%281979%29018%3C1016%3ALFIOAT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0450(1979)018<1016:LFIOAT>2.0.CO;2},
	abstract = {A Fourier method of filtering digital data called Lanczos filtering is described. Its principal feature is the use of “sigma factors” which significantly reduce the amplitude of the Gibbs oscillation. A pair of graphs is developed that can be used to determine filter response quality given the number of weights and the value of the cutoff frequency, the only two inputs required by the method. Examples of response functions in one and two dimensions are given and comparisons are made with response functions from other filters. The simplicity of calculating the weights and the adequate response make Lanczos filtering an attractive filtering method.},
	number = {8},
	urldate = {2017-11-08},
	journal = {Journal of Applied Meteorology},
	author = {Duchon, Claude E.},
	month = aug,
	year = {1979},
	pages = {1016--1022}
}

@article{droegemeier_influence_1993,
	title = {The {Influence} of {Helicity} on {Numerically} {Simulated} {Convective} {Storms}},
	volume = {121},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281993%29121%3C2005%3ATIOHON%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1993)121<2005:TIOHON>2.0.CO;2},
	abstract = {A three-dimensional numerical cloud model is used to investigate the influence of storm-relative environmental helicity (SREH) on convective storm structure and evolution, with a particular emphasis on the identification of ambient shear profiles that are conducive to the development of long-lived, strongly rotating storms. Eleven numerical simulations are made in which the depth and turning angle of the ambient vertical shear vector are varied systematically while maintaining a constant magnitude of the shear in the shear layer. In this manner, an attempt is made to isolate the effects of different environmental Felicities on storm morphology and show that the SREH and bulk Richardson number, rather than the mean shear in the low levels, determine the rotational characteristics and morphology of deep convection. The results demonstrate that storms forming in environments characterized by large SREH are longer-lived than those in less helical surroundings. Further, it appears that the storm-relative winds in the layer 0–3 km must, on average, exceed 10 m s−1 over most of the lifetime of a convective event to obtain supercell storms. The correlation coefficient between vertical vorticityζ and vertical velocity w, which (according to linear theory of dry convection) should be proportional to the product of the normalized helicity density, NHD (i.e., relative helicity), and a function involving the storm-relative wind speed, has the largest peak values (in time) in those simulated storms exhibiting large SREH and strong storm-relative winds in the low levels. Even when the vorticity is predominantly streamwise in the storm-relative framework, giving a normalized helicity density near unity (as is the case in many of these simulations), significant updraft rotation and large w–ζcorrelation coefficients do not develop and persist unless the storm-relative winds are sufficiently strong. The correlation coefficient between w and ζ based on linear theory is found to be a significantly better predictor of net updraft rotation than the bulk Richardson number (BRN) or the BRN shear, and slightly better than the 0-3-km SREH. Both the theoretical correlation coefficient and the SREH are based on the motion of the initial storm after its initially rapid growth. Linear theory also predicts correctly the relative locations of the buoyancy, vertical velocity, and vertical vorticity extrema within the storms after allowance is made for the effects of vertical advection. In predicting the maximum vertical vorticity both above and below 1.14 km, rather than the actual w and ζcorrelation, the 0–3-km SREH performs slightly worse than the BRN. The correlation coefficient, SREH, and BRN all do a credible job of predicting storm type. Thus, it is recommended that operational forecasters use the BRN to predict storm type because it is independent of storm motion, and the SREH to characterize the rotational properties of storms once their motions can be established. Finally, the ability of the NHD to characterize storm type and rotational properties is examined. Computed using the storm-relative winds, the NHD shows little ability to predict storm rotation (i.e., maximum w-ζcorrelation and maximum vertical vorticity), because it neglects the magnitudes of the vorticity and storm-relative wind vectors. Histograms of the disturbance NHD show a distinct bias toward positive values near unity for supercell storms, indicating an extraction of helicity from the mean flow by the disturbance, and only a slight bias for multicell storms.},
	number = {7},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Droegemeier, Kelvin K. and Lazarus, Steven M. and Davies-Jones, Robert},
	month = jul,
	year = {1993},
	pages = {2005--2029}
}

@book{dormand_numerical_1996,
	address = {Boca Raton},
	edition = {1 edition},
	title = {Numerical {Methods} for {Differential} {Equations}: {A} {Computational} {Approach}},
	isbn = {978-0-8493-9433-1},
	shorttitle = {Numerical {Methods} for {Differential} {Equations}},
	abstract = {With emphasis on modern techniques, Numerical Methods for Differential Equations: A Computational Approach covers the development and application of methods for the numerical solution of ordinary differential equations. Some of the methods are extended to cover partial differential equations. All techniques covered in the text are on a program disk included with the book, and are written in Fortran 90. These programs are ideal for students, researchers, and practitioners because they allow for straightforward application of the numerical methods described in the text. The code is easily modified to solve new systems of equations. Numerical Methods for Differential Equations: A Computational Approach also contains a reliable and inexpensive global error code for those interested in global error estimation. This is a valuable text for students, who will find the derivations of the numerical methods extremely helpful and the programs themselves easy to use. It is also an excellent reference and source of software for researchers and practitioners who need computer solutions to differential equations.},
	language = {English},
	publisher = {CRC Press},
	author = {Dormand, J. R.},
	month = feb,
	year = {1996}
}

@article{thompson_dynamical_1961,
	title = {A {Dynamical} {Method} of {Analyzing} {Meteorological} {Data}},
	volume = {13},
	issn = {2153-3490},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.2153-3490.1961.tb00094.x/abstract},
	doi = {10.1111/j.2153-3490.1961.tb00094.x},
	abstract = {This paper deals with the problem of reconstructing meteorological conditions in “holes””— i.e., large regions from which no data are received, but which are surrounded by regions in which the frequency and density of observations are fairly high. The method proposed here is a combination of numerical procedures of analysis and prediction, by which one can generate a series of increasingly exact analyses in a hole. It is shown that the error of this method approaches a definite lower limit which depends on: 
* 1). The size and shape of a hole
* 2). The average time required for individual particles to travel across the hole.
* 3). The average absolute rate of flow across the boundary of the hole, and
* 4). A statistical measure of the inaccuracies inherent in the prediction system. Numerical estimates of the accuracy attainable by this method indicate that dynamical methods are significantly better than conventional methods based on pure interpolation and smoothing. Finally, some aspects of the problem of network design are reviewed in the light of our present results.},
	language = {en},
	number = {3},
	urldate = {2017-11-08},
	journal = {Tellus},
	author = {Thompson, Philip Duncan},
	month = aug,
	year = {1961},
	pages = {334--349}
}

@article{donner_initialization_1988,
	title = {An {Initialization} for {Cumulus} {Convection} in {Numerical} {Weather} {Prediction} {Models}},
	volume = {116},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281988%29116%3C0377%3AAIFCCI%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1988)116<0377:AIFCCI>2.0.CO;2},
	abstract = {A procedure for initializing parameterizations for cumulus convection in numerical weather prediction models is described. The initialization adjust the temperature and humidity fields such that a simplified version of the Kuo cumulus parameterization will yield diagnosed convective precipitation and vertical heating profiles, if a specified velocity field can support them. In an unfavorable velocity field, the initialization will yield the closest approach to diagnosed convective precipitation possible. The initialization minimizes changes in the humidity and temperature fields while satisfying constraints imposed by the cumulus parameterization. Slight adjustments in the temperature field and relatively larger adjustments in the humidity field can modify the large scale from a state which does not support cumulus convection to a state whose convective heating, as parameterized by the simplified version of the Kuo scheme, agrees to the extent possible for an imposed velocity field. Use of more complicated versions of the Kuo cumulus parameterization with the initialized temperature and humidity profiles yields heating rates agreeing reasonably with diagnosed beating. If used in conjunction with an initialization for the velocity field, cumulus initialization may ameliorate problems associated with spinup of physical processes in numerical weather prediction.},
	number = {2},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Donner, Leo J.},
	month = feb,
	year = {1988},
	pages = {377--385}
}

@article{dimego_changes_1992,
	title = {Changes to {NMC}'s {Regional} {Analysis} and {Forecast} {System}},
	volume = {7},
	issn = {0882-8156},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0434%281992%29007%3C0185%3ACTNRAA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0434(1992)007<0185:CTNRAA>2.0.CO;2},
	abstract = {The recent implementation of changes to the National Meteorological Center's (NMC's) Regional Analysis and Forecast System (RAFS) is described. The changes include an expansion of the innermost grids of the nested-grid model (NGM) and the implementation of the Regional Data Assimilation System (RDAS). The new version of the forecast model and a 3-hourly RDAS analysis system were implemented on 7 August 1991. Some results from tests of the revised forecast model and the combined RDAS/NGM system are presented.},
	number = {1},
	urldate = {2017-11-08},
	journal = {Weather and Forecasting},
	author = {DiMego, Geoffrey J. and Mitchell, Kenneth E. and Petersen, Ralph A. and Hoke, James E. and Gerrity, Joseph P. and Tuccillo, James J. and Wobus, Richard L. and Juang, Hann-Ming H.},
	month = mar,
	year = {1992},
	pages = {185--198}
}

@article{dimego_national_1988,
	title = {The {National} {Meteorological} {Center} {Regional} {Analysis} {System}},
	volume = {116},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281988%29116%3C0977%3ATNMCRA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1988)116<0977:TNMCRA>2.0.CO;2},
	abstract = {The National Meteorological Center (NMC) Regional Optimum-Interpolation (ROI) analysis is described. The ROI is the analysis component of the Regional Analysis and Forecast System (RAFS) and is specially designed to provide initial conditions for the Nested Grid Model (NGM), the forecast component of the RAFS. The ROI is an attempt to overcome weaknesses in the Limited-area Fine Mesh (LFM) and Global Optimum-Interpolation (GOI) analysis systems, to provide the NGM with more detailed and balanced analyses and to do so in a three-dimensional and dynamically consistent manner. Among the unique aspects are its hemispheric domain with regional-scale (150–200 km) horizontal resolution and improved vertical resolution (16 levels with the first 12 below 250 mb). The analysis is geostrophically coupled and is multivariate in geopotential and wind; it utilizes the same sigma coordinate as the NGM prediction model. All significant-level radiosonde data are now used, as well as many more of the surface observations. The first-guess fields are adjusted to an improved terrain representation and treated directly in the sigma coordinate. Single-level observations are combined in a simple “super observation” technique which averages nearby reports. The first-guess error correlation functions are more peaked in response to the increased resolution of the analysis. The observation error standard deviations have also been reduced to account for decreased errors of representativeness. The degree of geostrophic coupling, the relative error levels of mass versus wind data and the scale of the horizontal correlation function are varied during the analysis at the uppermost levels and at the levels nearest the surface. The observed surface temperature is now used in the analysis of heights. Finally, in all stages of the analysis, there is an increased dependence on observation quality codes. Verifications versus North American radiosonde data indicate a somewhat looser fit to the data than that of the LFM analyses, but the fit is tighter than the GOI. The fit of moisture data is better than either the LFM or the GOI analyses. Examples of analyses are shown with comparisons to the LFM analyses and first-guess fields. Although the regional analyses tend to underestimate wind speeds at 250 mb, they exhibit increased detail in the moisture and vorticity fields.},
	number = {5},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {DiMego, Geoffrey J.},
	month = may,
	year = {1988},
	pages = {977--1000}
}

@book{thompson_numerical_1961,
	title = {Numerical weather analysis and prediction},
	url = {http://archive.org/details/numericalweather00thom},
	language = {eng},
	urldate = {2017-11-08},
	publisher = {New York : Macmillan},
	author = {Thompson, Philip D.},
	collaborator = {{Internet Archive}},
	year = {1961}
}

@book{thiebaux_spatial_1987,
	title = {Spatial objective analysis : with applications in atmospheric science},
	isbn = {978-0-12-686930-9},
	shorttitle = {Spatial objective analysis},
	url = {http://trove.nla.gov.au/version/21852782},
	abstract = {In 6 libraries. xi, 299 p. : ill. ; 24 cm. Spatial analysis (Statistics) Meteorology -- Methodology. Atmospheric physics -- Statistical methods. Numerical weather forecasting. Stochastic processes.},
	language = {English},
	urldate = {2017-11-08},
	publisher = {London ; Orlando : Academic Press},
	author = {Thiébaux, H. J and Pedder, M. A},
	year = {1987},
	annote = { Includes index }
}

@article{thiebaux_horizontal_1986,
	title = {Horizontal {Structure} of {Hemispheric} {Forecast} {Error} {Correlations} for {Geopotential} and {Temperature}},
	volume = {114},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281986%29114%3C1048%3AHSOHFE%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1986)114<1048:HSOHFE>2.0.CO;2},
	abstract = {A detailed study of hemispheric forecast-error (f.e.) statistics for the operational Canadian large-scale forecast model was made in preparation for reparameterization of the correlation function used in the data assimilation step of the forecast cycle. The choice of an appropriate function type for geopotential height and temperature f.e. lag-correlation representations was a major concern. A number of possible functional representations, both isotropic and anisotropic, were considered, and the goodness-of-fit of the various candidate functions to correlations computed from observed f.e. data were compared. The following special form of the second-order autoregressive function was adopted as the function of choice: (1 + c{\textbar}s{\textbar})e−c{\textbar}s{\textbar}, where {\textbar}s{\textbar} is geographic location separation. An examination of f.e. correlation structure on a regional basis revealed large differences from region to region. Latitudinal, pressure-level, and seasonal dependencies of the statistical structure of constant pressure-surface height and temperature f.e. were also examined. Temperature f.e. correlations were found to have significantly narrower structure than the corresponding height f.e. correlations. In general, the width of the structure functions for both height and temperature f.e. was found to decrease with increasing latitude and with decreasing pressure. The extrapolated height correlations at zero separation were found to decrease significantly with pressure, indicating that the ratio of height prediction error to height observation error also decreases with pressure. An examination of the seasonal dependence of the f.e. correlation structure at 500 mb indicated that it was relatively small. Implications for operational forecasting with periodic adjustment of the objective analysis scheme are discussed.},
	number = {6},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Thiébaux, H. Jean and Mitchell, Herschel L. and Shantz, Donald W.},
	month = jun,
	year = {1986},
	pages = {1048--1066}
}

@article{thiebaux_approximations_1985,
	title = {On approximations to geopotential and wind-field correlation structures},
	volume = {37},
	issn = {null},
	url = {http://dx.doi.org/10.3402/tellusa.v37i2.11660},
	doi = {10.3402/tellusa.v37i2.11660},
	abstract = {The purpose of this note is to show that a correlation structure model which is rigorously derived from simple stochastic assumptions for geopotential anomalies, automatically satisfies the essential properties of correlation representations as they are used in multivariate optimal interpolation and diagnostic studies. The parameters of the illustrations are derived from observed covariances, with location-specific local-time-average values defining the anomalies of the covariance (correlation) computations. For this reference field, it is shown that the two-dimensional model in (Δφ, Δλ) arguments reproduces pronounced anisotropy in correlation structure of height and geostrophic-wind field anomalies. Comparisons are made with model-implicit isotropic correlation arrays which are similar to those computed directly from observed statistical arrays and(similarly) fail to provide accurate representation of true ensemble field relationships.},
	number = {2},
	urldate = {2017-11-08},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Thiébaux, H. Jean},
	month = jan,
	year = {1985},
	pages = {126--131}
}

@inproceedings{benjamin_40-km_1996,
	address = {Norfolk},
	title = {The 40-km 40-level version of {MAPS}/{RUC}},
	publisher = {AMS},
	author = {Benjamin, S. G. and Brown, J. M. and Brundage, K. J. and Devenyi, D and Schwartz, B. and Smimova, T. G. and Smith, T. L. and Wang, F. J.},
	year = {1996},
	pages = {161--163}
}

@article{thiebaux_anisotropic_1976,
	title = {Anisotropic {Correlation} {Functions} for {Objective} {Analysis}},
	volume = {104},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281976%29104%3C0994%3AACFFOA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1976)104<0994:ACFFOA>2.0.CO;2},
	abstract = {Covariance models used in the data assimilation step of operational forecasting generally assume isotropy of height field correlations on constant pressure levels. Because of the evidence that this assumption is a significant source of forecast error, especially In regions of low density data, a two-dimensional anisotropic correlation model has been derived. Using a simple autoregressive scheme, cumbersome extension of the modeling problem has been avoided and much of the direction-dependent variability of observed statistics is resolved. Compared to deviations of observed correlation values around the best fitting isotropic model, the residual variance has been reduced by 56\&\%.},
	number = {8},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Thiebaux, H. Jean},
	month = aug,
	year = {1976},
	pages = {994--1002}
}

@article{thepaut_interactions_1993,
	title = {Interactions of {Dynamics} and {Observations} in a {Four}-{Dimensional} {Variational} {Assimilation}},
	volume = {121},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281993%29121%3C3393%3AIODAOI%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1993)121<3393:IODAOI>2.0.CO;2},
	abstract = {A four-dimensional (4D) variational assimilation (4DVAR) seeks an optimal balance between observations scattered in time and space over a finite 4D analysis volume and a priori information. In some cases, 4DVAR is able to closely fit both observations and the a priori initial estimate by making very small changes to the initial conditions that correspond to those rapidly growing perturbations that have large amplitude at the observation locations and times. Some observations may occur at locations and times for which the amplitudes of rapidly growing perturbations are not large. To fit such data, larger changes to the initial conditions are necessary. Such cases may result in amplification of the analysis increments away from the observation locations. This situation occurs generally for surface data, because of the damping effect of surface exchange processes. These interactions are seen in experiments using single observations. To further explore the impact of surface data in 4DVAR, experiments were conducted with and without ERS-1 C-band measurements of backscatter. As expected and in contrast to conventional approaches, the impact is not confined to the lower troposphere and the analysis increments are balanced. The study focuses on the case of a small intense North Atlantic storm that struck the coast of Norway on New Year's Day 1992. The scatterometer data have a significant, apparently positive, impact on the 4DVAR analysis in this case. The example using scatterometer data also demonstrates the ease with which 4DVAR assimilates nonstandard data, which have a complex, highly nonlinear relationship with the model variables.},
	number = {12},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Thépaut, Jean-Noël and Hoffman, Ross N. and Courtier, Philippe},
	month = dec,
	year = {1993},
	pages = {3393--3414}
}

@inproceedings{benjamin_rapid_1995,
	address = {Tokyo, Japan},
	title = {The {Rapid} {Update} {Cycle}: {A} new mesoscale assimilation system in hybrid theta-sigma coordinates at the {National} {Meteorological} {Center}},
	booktitle = {Second {International} {Symposium} on {Assimilation} of {Observations} in {Meteorology} and {Oceanography}},
	author = {Benjamin, S. G. and Kim, D and Schlatter, T. W.},
	year = {1995},
	pages = {337--342}
}

@article{amezcua_effects_2011,
	title = {The {Effects} of the {RAW} {Filter} on the {Climatology} and {Forecast} {Skill} of the {SPEEDY} {Model}},
	volume = {139},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/2010MWR3530.1},
	doi = {10.1175/2010MWR3530.1},
	abstract = {In a recent study, Williams introduced a simple modification to the widely used Robert–Asselin (RA) filter for numerical integration. The main purpose of the Robert–Asselin–Williams (RAW) filter is to avoid the undesired numerical damping of the RA filter and to increase the accuracy. In the present paper, the effects of the modification are comprehensively evaluated in the Simplified Parameterizations, Primitive Equation Dynamics (SPEEDY) atmospheric general circulation model. First, the authors search for significant changes in the monthly climatology due to the introduction of the new filter. After testing both at the local level and at the field level, no significant changes are found, which is advantageous in the sense that the new scheme does not require a retuning of the parameterized model physics. Second, the authors examine whether the new filter improves the skill of short- and medium-term forecasts. January 1982 data from the NCEP–NCAR reanalysis are used to evaluate the forecast skill. Improvements are found in all the model variables (except the relative humidity, which is hardly changed). The improvements increase with lead time and are especially evident in medium-range forecasts (96–144 h). For example, in tropical surface pressure predictions, 5-day forecasts made using the RAW filter have approximately the same skill as 4-day forecasts made using the RA filter. The results of this work are encouraging for the implementation of the RAW filter in other models currently using the RA filter.},
	number = {2},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Amezcua, Javier and Kalnay, Eugenia and Williams, Paul D.},
	year = {2011},
	pages = {608--619}
}

@article{williams_proposed_2009,
	title = {A {Proposed} {Modification} to the {Robert}–{Asselin} {Time} {Filter}},
	volume = {137},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/2009MWR2724.1},
	doi = {10.1175/2009MWR2724.1},
	abstract = {The Robert–Asselin time filter is widely used in numerical models of weather and climate. It successfully suppresses the spurious computational mode associated with the leapfrog time-stepping scheme. Unfortunately, it also weakly suppresses the physical mode and severely degrades the numerical accuracy. These two concomitant problems are shown to occur because the filter does not conserve the mean state, averaged over the three time slices on which it operates. The author proposes a simple modification to the Robert–Asselin filter, which does conserve the three-time-level mean state. When used in conjunction with the leapfrog scheme, the modification vastly reduces the impacts on the physical mode and increases the numerical accuracy for amplitude errors by two orders, yielding third-order accuracy. The modified filter could easily be incorporated into existing general circulation models of the atmosphere and ocean. In principle, it should deliver more faithful simulations at almost no additional computational expense. Alternatively, it may permit the use of longer time steps with no loss of accuracy, reducing the computational expense of a given simulation.},
	number = {8},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Williams, Paul D.},
	month = aug,
	year = {2009},
	pages = {2538--2546}
}

@article{dickinson_biosphere-atmosphere_1993,
	title = {Biosphere-atmosphere {Transfer} {Scheme} ({BATS}) {Version} 1e as {Coupled} to the {NCAR} {Community} {Climate} {Model}},
	url = {https://opensky.ucar.edu:/islandora/object/technotes%3A154/},
	doi = {10.5065/D67W6959},
	urldate = {2017-11-08},
	author = {Dickinson, E. and Henderson-Sellers, A. and Kennedy, J.},
	year = {1993},
	pages = {69}
}

@article{temperton_implicit_1989,
	title = {Implicit {Normal} {Mode} {Initialization} for {Spectral} {Models}},
	volume = {117},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1989)117%3C0436%3AINMIFS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1989)117<0436:INMIFS>2.0.CO;2},
	abstract = {Implicit nonlinear normal mode initialization schemes enable nonlinear NMI to be performed in models whose normal modes cannot readily be computed. Such schemes are algebraically equivalent to conventional (“explicit”) NMI based on the normal modes of a set of linearized equations which is slightly different from the usual choice. In this paper we apply implicit NMI to a barotropic spectral model whose normal modes are easily found, thus permitting a direct comparison to be made between conventional and implicit NMI schemes. Both first-order (Machenhauer) and second-order (Tribbia) variants of implicit nonlinear NMI are formulated for a spectral model and compared with their explicit counterparts. Experimental results show that the differences between explicit and implicit nonlinear NMI am insignificant except at the very largest horizontal scales. Besides validating the concept of implicit nonlinear NMI, this study suggests a practical approach to initializing very high resolution spectral models for which the normal modes require an inconveniently large amount of storage.},
	number = {2},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Temperton, Clive},
	month = feb,
	year = {1989},
	pages = {436--451}
}

@article{temperton_implicit_1988,
	title = {Implicit {Normal} {Mode} {Initialization}},
	volume = {116},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281988%29116%3C1013%3AINMI%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1988)116<1013:INMI>2.0.CO;2},
	abstract = {It is shown that nonlinear normal mode initialization (NMI) can be implemented without knowing the normal modes of a model. The implicit form of nonlinear NMI is particularly useful for models whose normal modes cannot readily be found; for example, if the underlying linear equations are nonseparable. An implicit nonlinear NMI scheme is formulated for the shallow-water equations on a polar stereographic projection. The linear equations which define the implicit normal modes include most of the beta terms as well as variable Coriolis parameter and map scale factor. Even in this nonseparable case, the equivalence between implicit and conventional nonlinear NMI is shown to be exact. The scheme is implemented in a regional model on a quasi-hemispheric domain, which uses a finite-element discretization on a nonuniform grid. The well-posed lateral boundary conditions of this model lead to consistent boundary conditions for the initialization. Results are presented not only for the implicit form of Machenhauer's nonlinear NMI technique, but also for the implicit form of Tribbia's corresponding second-order scheme which results in an even better initial balance.},
	number = {5},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Temperton, Clive},
	month = may,
	year = {1988},
	pages = {1013--1031}
}

@article{temperton_variational_1984,
	title = {Variational {Normal} {Mode} {Initialization} for a {Multilevel} {Model}},
	volume = {112},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281984%29112%3C2303%3AVNMIFA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1984)112<2303:VNMIFA>2.0.CO;2},
	abstract = {The application of variational normal mode initialization to the ECMWF multilevel grid-point model is described. The technique involves minimizing a variational integral of the changes made by the initialization to the analyzed mass and wind fields, suitably weighted with a view to exerting some control over the relative magnitudes of the adjustments to these fields. We show how to construct an appropriate three-dimensional integral, and describe an efficient procedure for solving the minimization problem in the simple case where the weights depend only on latitude. Experimental results are presented to demonstrate that, in comparison with unconstrained initialization, the changes made to the analyzed mass field can be considerably reduced without undue damage to the wind field, and without compromising the benefits of initialization in providing a forecast free of high-frequency oscillations. In the case studied here, the use of constrained normal mode initialization has no significant impact on the results of a subsequent 5-day forecast.},
	number = {11},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Temperton, Clive},
	month = nov,
	year = {1984},
	pages = {2303--2316}
}

@article{temperton_dynamic_1976,
	title = {Dynamic initialization for barotropic and multi-level models},
	volume = {102},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49710243203/abstract},
	doi = {10.1002/qj.49710243203},
	abstract = {The use of dynamic initialization is examined first for the case of a linearized barotropic model in which both the meteorological and gravity-wave modes have non-zero frequencies, and all variables are allowed to adjust mutually. It is shown that the gravity-wave mode is rapidly damped, leaving the meteorological mode almost intact with appropriate values of divergence as well as balanced mass and vorticity fields. There are some problems associated with the slower rate of convergence at large scales; it is suggested how these might be overcome using spectral rather than finite-difference methods. Mutual adjustment of the variables is shown to be generally more appropriate than forced adjustment. The arguments are extended to a multi-level model by diagonalizing it into its vertical normal modes. The analysis indicates that the external gravity-wave mode should be rapidly damped by dynamic initialization, giving appropriate values of the vertically-meaned divergence, while low-frequency internal modes will be relatively unaffected by the initialization procedure. A series of experiments is performed using a 5-level hemispheric model, and the predictions of the linearized theory are confirmed. In particular it is found that the amount of computation required to reduce the amplitude of the external gravity-wave mode to small levels is equivalent to that required for only 2–3 hours of forward integration. However, the quality of the forecast appears to be surprisingly insensitive to the presence or absence of gravity waves, and the need for such an initialization procedure is not conclusively demonstrated.},
	language = {en},
	number = {432},
	urldate = {2017-11-08},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Temperton, C.},
	month = apr,
	year = {1976},
	pages = {297--311}
}

@inproceedings{benjamin_next_1995,
	address = {Dallas},
	title = {The next version of the {Rapid} {Update} {Cycle} -{RUC} {II}},
	publisher = {AMS},
	author = {Benjamin, S. G. and Grell, G. A. and Brundage, K. J. and Smith, T. L. and Brown, J. M. and Smimova, T. G. and Yang, Z},
	year = {1995},
	pages = {57--61}
}

@article{taylor_spectral_1997,
	title = {The {Spectral} {Element} {Method} for the {Shallow} {Water} {Equations} on the {Sphere}},
	volume = {130},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999196955540},
	doi = {10.1006/jcph.1996.5554},
	abstract = {The spectral element method is implemented for the shallow water equations in spherical geometry and its performance is compared with other models. This is the first step in evaluating the suitability of spectral elements for climate modeling. The potential advantages and disadvantages of spectral elements over more conventional models used for climate studies are discussed. The method requires that the sphere be tiled with rectangles, for which we make use of the gnomonic projection to map the sphere onto the cube. To measure the performance of the method relative to other models, results are presented from a standard suite of shallow water test cases for the sphere. These results confirm the spectral accuracy of the method.},
	number = {1},
	urldate = {2017-11-08},
	journal = {Journal of Computational Physics},
	author = {Taylor, Mark and Tribbia, Joseph and Iskandarani, Mohamed},
	month = jan,
	year = {1997},
	pages = {92--108}
}

@article{tatsumi_spectral_1986,
	title = {A {Spectral} {Limited}-area {Model} with {Time}-dependent {Lateral} {Boundary} {Conditions} and {Its} {Application} to a {Multi}-level {Primitive} {Equation} {Model}},
	volume = {64},
	doi = {10.2151/jmsj1965.64.5_637},
	abstract = {A spectral limited-area primitive-equation model with a time-dependent lateral boundary condition is described.The model is nested in one way to a low resolution model.A spectral representation of the horizontal fields of prognostic variables is performed by introducing a modified double Fourier series.This series is composed of the usual orthogonal double Fourier series, that is suitable for prediction in the limited-area with a free-slip wall boundary condition, and a few additional bases by which the boundary condition which does not belong to the wall condition will be satisfied.Fluxes of mass, momentum, energy, etc.across the boundary can be specified using the additional bases.The proposed spectral method prescribes the amplitude of the additional bases, using the historical data from a coarse-mesh model forecast.The model predicts the amplitude of only the orthogonal bases that satisfy the wall boundary condition.A boundary relaxation technique is incorporated in order to reduce the amplitude of a spurious solution near the boundary due to ill-posed lateral boundary condition.A one-dimensional, linear advection equation is integrated by the present spectral method and by a grid-point method.The comparison of these two methods reveals that the spectral method give far better results than those of the grid point method.This is mainly due to the improved accuracy in estimating horizontal derivatives in the spectral method i.e., the computational dispersion and the systematic phase error that are unavoidable in the grid-point method are completely excluded in the spectral method.The spectral formulation of a limited-area model is applied to the Japan Meteorological Agency (JMA) operational grid-point 12-level fine-mesh limited-area model (12L-FLM; March, 1983 -) and the forecasts of the two 12L-FLMs are compared.The spectral 12L-FLM almost perfectly duplicates the forecast of the grid-point 12L-FLM for relatively large-scale disturbances, within the resolution limit of the latter.However, the forecast of the spectral 12L-FLM is superior to the grid-point model for relatively small-scale disturbances.The compared case includes a well-organized intense typhoon in the initial field.The horizontal scale of the typhoon is almost marginal to be resolved by the grid-point 12L-FLM.The predicted typhoon by the spectral model is more realistically intense and symmetric than that by the grid-point model.The amount of computation required by the spectral 12L-FLM, whose transform grid is the same as that of the grid-point model, is 20∼30 per cent larger than the amount required by the grid-point 12L-FLM.We conclude from this that the computational economy of the spectral 12L-FLM is practically superior to the grid-point 12L-FLM, since the effective resolution of the spectral model is about 1.5times better than the grid-point model.We plan to apply the spectral method to the next operational limited-area model in JMA.},
	number = {5},
	journal = {Journal of the Meteorological Society of Japan. Ser. II},
	author = {Tatsumi, Yasuo},
	year = {1986},
	pages = {637--664}
}

@book{tarantola_inverse_1987,
	edition = {1},
	title = {Inverse {Problem} {Theory}},
	isbn = {978-0-444-59967-4},
	url = {https://www.elsevier.com/books/inverse-problem-theory/tarantola/978-0-444-42765-6},
	urldate = {2017-11-08},
	publisher = {Elsevier},
	author = {Tarantola, A.},
	year = {1987}
}

@incollection{merilees_pseudospectral_1979,
	address = {Geneva, Switzerland},
	series = {{GARP} {Publication} {Series} {No}. 17},
	title = {The pseudospectral method},
	volume = {II},
	booktitle = {Numerical {Methods} {Used} in {Atmospheric} {Models}},
	publisher = {World Meteorological Organization},
	author = {Merilees, Phillip E. and Orszag, S.A},
	year = {1979},
	pages = {276--299}
}

@incollection{dickinson_modeling_1984,
	title = {Modeling {Evapotranspiration} for {Three}-{Dimensional} {Global} {Climate} {Models}},
	copyright = {Copyright 1984 by the American Geophysical Union.},
	isbn = {978-1-118-66603-6},
	url = {http://onlinelibrary.wiley.com/doi/10.1029/GM029p0058/summary},
	abstract = {A parameterization is developed for the calculation of evapotranspiration in three-dimensional atmospheric models. It distinguishes separately between evaporation from the ground and evapotranspiration from plant foliage. Soil water is stored in an active layer of 1 m depth and a 10 cm surface layer is separately distinguished. The evaporation from this soil is parameterized using a high resolution multilayer model for comparison. This parameterized evaporation from the soil is defined by either the potential evaporation rate or by the maximum rate at which water can diffuse to the surface, depending on which rate is smaller. The maximum rate is obtained empirically in terms of various soil-hydraulic parameters. The evapotranspiration from plants occurs either as the evaporation of water stored on the surface of the foliage or as the transpiration of water extracted by roots from the soil. The flux of water from the outer surface of foliage to the atmosphere above the canopy is determined by the decrease in water vapor concentration from the foliage surface to the overlying atmosphere and by the resistance of the foliage molecular boundary layers and the bulk aerodynamic resistance of the canopy. Transpired water encounters an additional stomatal resistance in passing from the inside to the outside of leaves. The foliage temperature and saturation vapor pressure are calculated from a model of the plant canopy energy balance. Soil moisture determines the maximum rate at which roots can extract water from the soil, and if the transpiration demand exceeds this maximum rate, stomatal closure occurs until the demand matches the root supply. A parameterization of land evapotranspiration at the level of detail described in this paper may be required to obtain a realistic diurnal cycle of surface temperature and evapotranspiration for use in mesoscale or global climate models. However, application of the developed procedures is made difficult by the extreme complexity and small-scale detail of surface processes, the lack of adequate data sets for surface parameters, and the need for satisfactory parameterizations of other components of. GCMs such as their rainfall and planetary boundary layer treatments. Because of these difficulties, the development of validated models of land surface processes first requires detailed sensitivity studies to establish what further data sets are most urgently required and what model improvement should be given highest priority.},
	language = {en},
	urldate = {2017-11-08},
	booktitle = {Climate {Processes} and {Climate} {Sensitivity}},
	publisher = {American Geophysical Union},
	author = {Dickinson, Robert E.},
	editor = {Hansen, James E. and Takahashi, Taro},
	year = {1984},
	doi = {10.1029/GM029p0058},
	keywords = {Climatology—Congresses, Geophysics—Congresses, Ocean-atmosphere interaction—Congresses},
	pages = {58--72}
}

@article{dickinson_free_1972,
	title = {Free {Oscillations} of a {Discrete} {Stratified} {Fluid} with {Application} to {Numerical} {Weather} {Prediction}},
	volume = {29},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1972)029%3C0623%3AFOOADS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1972)029<0623:FOOADS>2.0.CO;2},
	abstract = {Numerical models for the prediction of atmospheric motions are described by a finite number of coupled ordinary differential equations. We formally solve the initial-value problem for small-amplitude perturbations on some basic state as described by the prediction system. The solution and hence initial conditions are expressed as a sum over the normal modes of oscillation of the perturbation equations. The question as to which modes describe the evolution of meteorologically significant information may be answered for models which are used not only for prediction but also for climate simulation. Those modes which have a much larger amplitude in noisy real data than in climate simulation studies can be filtered from the initial data. The expansion of grid-point data into the normal modes of a model thus allows filtering in a more selective and rational fashion than has been possible using classical initialization procedures. Such an expansion also allows comparison of numerical simulation studies with spectral studies of actual free modes in the atmosphere. As an example of the model expansion procedure, we describe the application of a finite-difference approximation to the dynamics of a two-layer ocean model on a rotating sphere. In the limit of infinitesimal grid interval, the expansion of initial data is given by the Hough functions of tidal theory. For a finite grid interval, it is necessary to consider not only modes related to the Hough modes but also computational modes specific to the finite-difference equations employed. Examples of the eigenfrequencies and eigenfunctions for a basic state at rest are compared with those obtained assuming a basic state with a latitudinally varying zonal wind.},
	number = {4},
	urldate = {2017-11-08},
	journal = {Journal of the Atmospheric Sciences},
	author = {Dickinson, Robert E. and Williamson, David L.},
	month = may,
	year = {1972},
	pages = {623--640}
}

@article{dey_evolution_1985,
	title = {Evolution of the {National} {Meteorological} {Center} {Global} {Data} {Assimilation} {System}: {January} 1982–{December} 1983},
	volume = {113},
	issn = {0027-0644},
	shorttitle = {Evolution of the {National} {Meteorological} {Center} {Global} {Data} {Assimilation} {System}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281985%29113%3C0304%3AEOTNMC%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1985)113<0304:EOTNMC>2.0.CO;2},
	abstract = {A number of changes were made to the National Meteorological Center global data assimilation system (GDAS) during 1982 and 1983. The most significant of these changes was the replacement of the quasi-univariate, sigma-coordinate optimum interpolation analysis procedure by a version that performs a fully multivariate analysis on mandatory pressure surfaces. The new analysis technique is described in some detail. The impact of this and other changes made during 1982 and 1983 on the performance of the GDAS is evaluated.},
	number = {3},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Dey, Clifford H. and Morone, Lauren L.},
	month = mar,
	year = {1985},
	pages = {304--318}
}

@article{derber_use_1998,
	title = {The {Use} of {TOVS} {Cloud}-{Cleared} {Radiances} in the {NCEP} {SSI} {Analysis} {System}},
	volume = {126},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281998%29126%3C2287%3ATUOTCC%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1998)126<2287:TUOTCC>2.0.CO;2},
	abstract = {With improved assimilation techniques, it is now possible to directly assimilate cloud-cleared radiances, rather than temperature and moisture retrievals, in objective analyses. The direct use of the cloud-cleared radiances became the operational technique for using satellite sounding data at the National Centers for Environmental Prediction (NCEP) in October 1995. The methodology for using the data (including bias correction, ozone analysis, skin temperature analysis, and quality control) are described in this paper. The impact of the direct use of the radiances compared to the previously operational use of satellite sounding data shows considerable improvement in NCEP’s forecast skill, especially in the Southern Hemisphere. It is anticipated that additional positive impacts will occur with application of the technique to other remotely sensed data.},
	number = {8},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Derber, John C. and Wu, Wan-Shu},
	month = aug,
	year = {1998},
	pages = {2287--2299}
}

@article{derber_new_1991,
	title = {The {New} {Global} {Operational} {Analysis} {System} at the {National} {Meteorological} {Center}},
	volume = {6},
	issn = {0882-8156},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0434%281991%29006%3C0538%3ATNGOAS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0434(1991)006<0538:TNGOAS>2.0.CO;2},
	abstract = {At the National Meteorological Center (NMC), a new analysis system was implemented into the operational Global Data Assimilation System on 25 June 1991. This analysis system is referred to as Spectral Statistical Interpolation (SSI) because the spectral coefficients used in the NMC spectral model are analyzed directly using the same basic equations as statistical (optimum) interpolation. The major differences between the SSI analysis system and the conventional optimum interpolation (OI) analysis system previously used operationally at NMC are:   –The analysis variables are closely related to the coefficients of the NMC spectral model.   –Temperature observations are used, not heights as in the previous procedure. As a result, aircraft temperatures are being used for the first time at NMC.   –Nonstandard observations, such as satellite estimates of total precipitable water and ocean-surface wind speeds, can be easily included.   –No data selection is necessary. All observations are used simultaneously.   –The dynamical constraint between the wind and mass fields is more realistic and applied globally.   –Model initialization has been eliminated. The analysis is used directly as the forecast model initial condition.   Extensive pre-implementation testing demonstrated that the SSI consistently produced superior analyses and forecasts when compared to the previous OI system. Improvement in skill is shown not only for the 3–5-day forecasts, but also in one-day aviation forecasts.},
	number = {4},
	urldate = {2017-11-08},
	journal = {Weather and Forecasting},
	author = {Derber, John C. and Parrish, David F. and Lord, Stephen J.},
	month = dec,
	year = {1991},
	pages = {538--547}
}

@article{derber_global_1989,
	title = {A {Global} {Oceanic} {Data} {Assimilation} {System}},
	volume = {19},
	issn = {0022-3670},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0485%281989%29019%3C1333%3AAGODAS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0485(1989)019<1333:AGODAS>2.0.CO;2},
	abstract = {A global oceanic four-dimensional data assimilation system has been developed for use in initializing coupled ocean–atmosphere general circulation models and many other applications. The data assimilation system uses a high resolution global ocean model to extrapolate the information forward in time. The data inserted into the model currently consists only of conventional sea surface temperature observations and vertical temperature profiles. The data are inserted continuously into the model by updating the model's temperature solution every timestep. This update is created using a statistical interpolation routine applied to all data in a 30-day window centered on the present timestep. Large scale features in the sea surface temperature analyses are consistent with those from independent analyses. Subsurface fields created from the assimilation are much more realistic than those produced without the insertion of data. Furthermore, information contained in the assimilation field is shown to be retained in the model solution after the assimilation procedure is terminated. The results are encouraging but further improvements can be made.},
	number = {9},
	urldate = {2017-11-08},
	journal = {Journal of Physical Oceanography},
	author = {Derber, John and Rosati, Anthony},
	month = sep,
	year = {1989},
	pages = {1333--1347}
}

@article{derber_variational_1989,
	title = {A {Variational} {Continuous} {Assimilation} {Technique}},
	volume = {117},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1989)117%3C2437%3AAVCAT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1989)117<2437:AVCAT>2.0.CO;2},
	abstract = {A variational assimilation technique is presented which continuously adjusts a model solution by introducing a correction term to the model equations. The technique is essentially a modification of the adjoint technique. The Variational Continuous Assimilation (VCA) technique optimizes the correction to the model equations rather than the initial conditions as is done in the adjoint technique. The VCA-technique characteristics were examined by inserting independent analyses into a simple quasi- geostrophic model using both the VCA technique and the adjoint technique. Because the model equations do not have to be satisfied exactly in the VCA technique, some of the effects of systematic model errors can be removed from the assimilation. Thus, the VCA technique was able to consistently fit the data better than the adjoint technique. Predictions from the results from the assimilation techniques showed that the forecast from the adjoint technique's solution was consistently inferior to those from the VCA technique and those from the Geophysical Fluid Dynamics Laboratory's (GFDL's) First GARP (Global Atmospheric Research Program) Global Experiment (FGGE) IIIb analyses. As a by-product of the VCA technique, an empirical correction for the model's systematic error is produced. Application of this correction during a forecast produced substantially improved simulations.},
	number = {11},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Derber, John C.},
	month = nov,
	year = {1989},
	pages = {2437--2446}
}

@article{derber_variational_1987,
	title = {Variational {Four}-dimensional {Analysis} {Using} {Quasi}-{Geostrophic} {Constraints}},
	volume = {115},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281987%29115%3C0998%3AVFDAUQ%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1987)115<0998:VFDAUQ>2.0.CO;2},
	abstract = {A variational four-dimensional analysis technique using quasi-geostrophic models as constraints is examined using gridded fields as data. The analysis method uses a standard iterative nonlinear minimization technique to find the solution to the constraining forecast model which best fits the data as measured by a predefined functional. The minimization algorithm uses the derivative of the functional with respect to each of the initial condition values. This derivative vector is found by inserting the weighted differences between the model solution and the inserted data into a backwards integrating adjoint model. The four-dimensional analysis system was examined by applying it to fields created from a primitive equations model forecast and to fields created from satellite retrieval. The results show that the technique has several interesting characteristics not found in more traditional four-dimensional assimilation techniques. These features include a close fit of the model solution to the observations throughout the analysis interval and an insensitivity to the frequency of data insertion or the amount of data. The four-dimensional analysis technique is very versatile and can be extended to more complex problems with little theoretical difficulty.},
	number = {5},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Derber, John C.},
	month = may,
	year = {1987},
	pages = {998--1008}
}

@article{dee_maximum-likelihood_1999,
	title = {Maximum-{Likelihood} {Estimation} of {Forecast} and {Observation} {Error} {Covariance} {Parameters}. {Part} {II}: {Applications}},
	volume = {127},
	issn = {0027-0644},
	shorttitle = {Maximum-{Likelihood} {Estimation} of {Forecast} and {Observation} {Error} {Covariance} {Parameters}. {Part} {II}},
	url = {http://journals.ametsoc.org/doi/full/10.1175/1520-0493%281999%29127%3C1835%3AMLEOFA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1999)127<1835:MLEOFA>2.0.CO;2},
	abstract = {Three different applications of maximum-likelihood estimation of error covariance parameters for atmospheric data assimilation are described. Height error standard deviations, vertical correlation coefficients, and isotropic decorrelation length scales are estimated from rawinsonde height observed-minus-forecast residuals. Sea level pressure error standard deviations and decorrelation length scales are obtained from ship reports, and wind observation error standard deviations and forecast error stream function and velocity potential decorrelation length scales are estimated from aircraft data. These applications serve to demonstrate the ability of the method to estimate covariance parameters using multivariate data from moving observers. Estimates of the parameter uncertainty due to sampling error can be obtained as a by-product of the maximum-likelihood estimation. By bounding this source of error, it is found that many statistical parameters that are usually presumed constant in operational data assimilation systems in fact vary significantly with time. This may well reflect the use of overly simplistic covariance models that cannot adequately describe state-dependent error components such as representativeness error. The sensitivity of the parameter estimates to the treatment of bias, and to the choice of the model representing spatial correlations, is examined in detail. Several experiments emulate an online covariance parameter estimation procedure using a sliding window of data, and it is shown that such a procedure is both desirable and computationally feasible.},
	number = {8},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Dee, Dick P. and Gaspari, Greg and Redder, Chris and Rukhovets, Leonid and da Silva, Arlindo M.},
	month = aug,
	year = {1999},
	pages = {1835--1849}
}

@article{dee_using_1986,
	title = {Using {Hough} {Harmonics} to {Validate} and {Assess} {Nonlinear} shallow-{Water} {Models}},
	volume = {114},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281986%29114%3C2191%3AUHHTVA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1986)114<2191:UHHTVA>2.0.CO;2},
	abstract = {The implementation of a technique for locating programming errors in shallow-water codes, establishing the correctness of the code, and assessing the performance of the numerical model under various flow conditions is described. The right-hand side of the differential equations is modified in such a way that the exact solution of the nonlinear initial-value problem is known, so that the truncation error of the numerical scheme can be studied in detail. The exact solution is prescribed to be any linear combination of Hough harmonies which propagate in time according to their natural frequencies.},
	number = {11},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Dee, Dick P. and Da Silva, Arlindo Moraes},
	month = nov,
	year = {1986},
	pages = {2191--2196}
}

@article{deardorff_parameterization_1972,
	title = {Parameterization of the {Planetary} {Boundary} layer for {Use} in {General} {Circulation} {Models}},
	volume = {100},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1972)100%3C0093%3APOTPBL%3E2.3.CO%3B2},
	doi = {10.1175/1520-0493(1972)100<0093:POTPBL>2.3.CO;2},
	abstract = {The surface stress and fluxes of heat and moisture are parameterized for use in numerical models of the general circulation of the atmosphere. The parameterization is designed to be consistent with recent advances in knowledge of both the planetary boundary layer and the surface layer. A key quantity throughout is the height, h, of the planetary boundary layer, which appears in the governing stability parameter, a bulk Richardson number. With upward heat flux, a time-dependent prediction equation is proposed for h that incorporates penetrative convection and vertical motion. Under stable conditions, h is assumed to depart from the neutral value and to become nearly proportional to the Monin-Obukhov length. The roughness length, Zo, is incorporated in the combination h/zo, and the parameterization is consistent with h/zo affecting only the wind component in the direction of the surface velocity. The direction of the surface wind and stress is derived in a manner consistent with the known value of the surface pressure gradient and theoretical studies of the decrease of stress with height. The parameterization has been tested numerically and appears to be efficient enough to use in existing general circulation models.},
	number = {2},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Deardorff, James W.},
	month = feb,
	year = {1972},
	pages = {93--106}
}

@article{davies_limitations_1983,
	title = {Limitations of {Some} {Common} {Lateral} {Boundary} {Schemes} used in {Regional} {NWP} {Models}},
	volume = {111},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281983%29111%3C1002%3ALOSCLB%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1983)111<1002:LOSCLB>2.0.CO;2},
	abstract = {A brief critical assessment is presented of several lateral boundary schemes currently employed in regional weather prediction models. Simple flow models are used to determine the nature and cause of the primary shortcomings of each of the considered schemes. An awareness of these deficiencies can prove helpful in the implementation and further refinement of these schemes, and also in the interpretation of the resulting prediction errors.},
	number = {5},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Davies, Huw C.},
	month = may,
	year = {1983},
	pages = {1002--1012}
}

@article{daley_four-dimensional_1980,
	title = {Four-{Dimensional}, {Data} {Assimilation} and the {Slow} {Manifold}},
	volume = {108},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1980)108%3C0085%3AFDDAAT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1980)108<0085:FDDAAT>2.0.CO;2},
	abstract = {Four-dimensional data assimilation is the analysis technique that has been devised to cope with the large quantities of asynoptic data received from the new remote observing systems. In this analysis method, an atmospheric simulation model is integrated in time with observed data being inserted into the model whenever it becomes available. In the present study, the four-dimensional data assimilation process is analyzed in terms of the normal modes of the assimilating model and the slow manifold concept of Leith (1979). The problem of “data rejection” and the spurious excitation of transient gravity waves can be shown to have a simple geometrical interpretation in the slow manifold methodology. Using these ideas it is possible to define an ideal assimilation technique. Various realizable assimilation techniques which approach this ideal are proposed and tested.},
	number = {1},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Daley, Roger and Puri, Kamal},
	month = jan,
	year = {1980},
	pages = {85--99}
}

@article{daley_linear_1983,
	title = {Linear non-divergent mass-wind laws on the sphere},
	volume = {35},
	issn = {null},
	url = {http://dx.doi.org/10.3402/tellusa.v35i1.11413},
	doi = {10.3402/tellusa.v35i1.11413},
	abstract = {The properties of 3 types of linear non-divergent mass-wind laws on the sphere have been examined: linear-balance equation, spherical harmonic expansions of the linearized primitive equations, and Rossby-Hough expansions. Both the symmetric and antisymmetric non-zonal cases are examined. The results show that all 3 methods are virtually equivalent for the antisymmetric case, but differ considerably for the symmetric case. All 3 methods, whether derived from the primitive equations or from a filtering approximation, appear to be singular at the equator in the symmetric case.},
	number = {1},
	urldate = {2017-11-08},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Daley, Roger},
	month = jan,
	year = {1983},
	pages = {17--27}
}

@article{tatsumi_economical_1983,
	title = {An {Economical} {Explicit} {Time} {Integration} {Scheme} for {A} {Primitive} {Model}},
	volume = {61},
	doi = {10.2151/jmsj1965.61.2_269},
	abstract = {An economical explicit scheme and its application to a primitive equation model is described. In the present scheme, the low-frequency advection terms are integrated by the leap-frog scheme with a time step interval Δta which is decided by a wind speed of meteorological waves, and not by a gravity wave phase speed. In order to get stable numerical solution, the high frequency gravity wave terms are integrated with a shorter time interval Δtb(≅Δta/M). Time integrations are carried out by combining low frequency terms which are assumed constant during 2Δta leap-frog time extrapolation interval with high frequency terms which are calculated at every Δtb interval. The scheme is three-time-level for low frequency terms. The present scheme is different from the splitting technique proposed by Marchuk (1965).The present economical explicit scheme has the advantage of the easiness in programming and the second order accuracy in the integration of low frequency terms.The present scheme has been applied to the 4L-NHM, operational 4-level northern hemispherical model used in 1978-81 in JMA. The results show that the economical explicit version model produces almost the same prediction as the original (explicit scheme) 4L-NHM. The present scheme saved the computation time as much as the semi-implicit version of 4L-NHM developed by Kudoh (1978) did.},
	number = {2},
	journal = {Journal of the Meteorological Society of Japan. Ser. II},
	author = {Tatsumi, Yasuo},
	year = {1983},
	pages = {269--288}
}

@article{daley_variational_1978,
	title = {Variational non-linear normal mode initialization},
	volume = {30},
	issn = {2153-3490},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.2153-3490.1978.tb00836.x/abstract},
	doi = {10.1111/j.2153-3490.1978.tb00836.x},
	abstract = {The non-linear normal mode initialization technique of Machenhauer (1977) and Baer (1977) has shown great potential in removing spurious high frequency gravity modes from primitive equation model integrations. In essence, this procedure orthogonalizes the time tendencies of the original fields to the time tendencies of the high frequency normal modes of the linearized model equations. In the present work this procedure is generalized by casting the problem in a variational framework. Thus a variational integral is minimized subject to strong constraints obtained from the theory of non-linear normal mode initialization. When applied to the shallow water equations, it is found that this variational approach includes most previous barotropic static initialization procedures as special cases. The procedure was tested under various conditions and the results displayed.},
	language = {en},
	number = {3},
	urldate = {2017-11-08},
	journal = {Tellus},
	author = {Daley, Roger},
	month = jun,
	year = {1978},
	pages = {201--218}
}

@article{merilees_linear_1968,
	title = {On the linear balance equation in terms of spherical harmonics},
	volume = {20},
	number = {1},
	journal = {Tellus},
	author = {Merilees, Phillip E.},
	year = {1968},
	pages = {200--202}
}

@article{menard_application_1996,
	title = {The application of {Kalman} smoother theory to the estimation of {4DVAR} error statistics},
	volume = {48},
	number = {2},
	journal = {Tellus A},
	author = {Ménard, Richard and Daley, Roger},
	year = {1996},
	pages = {221--237}
}

@article{mellor_development_1982,
	title = {Development of a turbulence closure model for geophysical fluid problems},
	volume = {20},
	number = {4},
	journal = {Reviews of Geophysics},
	author = {Mellor, George L. and Yamada, Tetsuji},
	year = {1982},
	pages = {851--875}
}

@article{mellor_hierarchy_1974,
	title = {A {Hierarchy} of {Turbulence} {Closure} {Models} for {Planetary} {Boundary} {Layers}},
	volume = {31},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1974)031%3C1791:AHOTCM%3E2.0.CO;2},
	doi = {10.1175/1520-0469(1974)031<1791:AHOTCM>2.0.CO;2},
	abstract = {Turbulence models centered on hypotheses by Rotta and Kolmogoroff are complex. In the present paper we consider systematic simplifications based on the observation that parameters governing the degree of anisotropy are small. Hopefully, we shall discern a level of complexity which is intuitively attractive and which optimizes computational speed and convenience without unduly sacrificing accuracy. Discussion is focused on density stratified flow due to temperature. However, other dependent variables—such as water vapor and droplet density—can be treated in analogous fashion. It is, in fact, the anticipation of additional physical complexity in modeling turbulent flow fields that partially motivates the interest in an organized process of analytical simplification. For the problem of a planetary boundary layer subject to a diurnally varying surface heat flux or surface temperature, three models of varying complexity have been integrated for 10 days. All of the models incorporate identical empirical constants obtained from neutral flow data alone. The most complex of the three models requires simultaneous solution of 10 partial differential equations for turbulence moments in addition to the equations for the mean velocity components and temperature; the least complex eliminates all of the 10 differential equation whereas a “compromise” model retains two differential equations for total turbulent energy and temperature variance. We conclude that all of the models give nearly the same results. We find the two-differential-equation model particularly attractive.},
	number = {7},
	urldate = {2017-11-08},
	journal = {Journal of the Atmospheric Sciences},
	author = {Mellor, George L. and Yamada, Tetsuji},
	month = oct,
	year = {1974},
	pages = {1791--1806}
}

@article{dalcher_error_1987,
	title = {Error growth and predictability in operational {ECMWF} forecasts},
	volume = {39},
	issn = {null},
	url = {http://dx.doi.org/10.3402/tellusa.v39i5.11774},
	doi = {10.3402/tellusa.v39i5.11774},
	abstract = {We study the forecast error growth in the 100-day ECMWF data set of 10-day forecasts previously utilized by Lorenz, separating the square of the error into systematic and random components. The random error variance is approximately equally distributed among all zonal wavenumbers m corresponding to the same total wavenumber n. Therefore, we combine the random error variance for all zonal wavenumbers and study its dependence on total (2-dimensional) wavenumber rather than on zonal wavenumber.We extend the Lorenz model for global r.m.s. error growth by including the effect of errors associated with deficiencies in the forecast model, and apply this new parameterization to the error variance of 10-day ECMWF operational forecasts obtaining an excellent fit. We point out that the commonly used parameter “doubling time of small errors” is not a good measure of error growth because it has to be determined by extrapolation to small errors and it is very sensitive to the method of extrapolation. On the other hand, the error growth at finite times is a better measure because it is well defined by the data. The results of the error fit to each total wavenumber n are the basis for the main conclusions of the paper. In the northern hemisphere winter data set, the error growth rate α increases almost monotonically with wavenumber, from about 0.3 day-1 at long waves to about 0.45 day-1 at medium and short waves. The saturation error variance V∞ is about 30\% larger than the error variance at day 10 for long waves, which have not yet reached saturation. The scaled source of external error S/V∞ (due to model deficiencies) varies from about 3\% day-1 at long waves to about 20\% day-1 at short waves. This increase of relative model error may be due to the second-order finite differences used in the ECMWF model during 1980/1981.Finally, we estimate the theoretical limit of dynamical predictability as a function of total wavenumber n. We define it as the time at which the error variance reaches 95\% of the saturation value. This time decreases monotonically with n. In the winter, waves n ≤ 10 have not reached saturation at 10 days. In a perfect model with error growth similar to the present model, the predictability limit would be extended by about a week. In the summer, error growth rates and model deficiencies are larger than in winter, and the limit of predictability is close to 10 days even for long waves.},
	number = {5},
	urldate = {2017-11-08},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Dalcher, Amnon and Kalnay, Eugenia},
	month = jan,
	year = {1987},
	pages = {474--491}
}

@article{meehl_global_1992,
	title = {Global coupled models: atmosphere, ocean, sea ice},
	shorttitle = {Global coupled models},
	journal = {Climate System Modeling},
	author = {Meehl, Gerald A.},
	year = {1992},
	pages = {555--581}
}

@article{mcpherson_nmc_1979,
	title = {The {NMC} operational global data assimilation system},
	volume = {107},
	number = {11},
	journal = {Monthly Weather Review},
	author = {McPherson, Ronald D. and Bergman, K. H. and Kistler, R. E. and Rasch, G. E. and Gordon, D. S.},
	year = {1979},
	pages = {1445--1461}
}

@article{mcfarlane_effect_1987,
	title = {The effect of orographically excited gravity wave drag on the general circulation of the lower stratosphere and troposphere},
	volume = {44},
	number = {14},
	journal = {Journal of the atmospheric sciences},
	author = {McFarlane, N. A.},
	year = {1987},
	pages = {1775--1800}
}

@article{tanguay_semi-implicit_1990,
	title = {A {Semi}-implicit {Send}-{Lagrangian} {Fully} {Compressible} {Regional} {Forecast} {Model}},
	volume = {118},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281990%29118%3C1970%3AASISLF%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1990)118<1970:ASISLF>2.0.CO;2},
	abstract = {The semi-implicit algorithm, originally developed by Robert for an economical integration of the primitive equations in large-scale models of the atmospheric, is here generalized in order to integrate the fully compressible, nonhydrostatic equations. We show that there is little computational overhead associated with the integration of the full, and hence presumably more correct, set of equations that do not invoke the hydrostatic assumption to exclude the high frequency, vertically propagating acoustic modes.},
	number = {10},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Tanguay, Monique and Robert, André and Laprise, René},
	month = oct,
	year = {1990},
	pages = {1970--1980}
}

@article{mcdonald_semi-lagrangian_1989,
	title = {Semi-{Lagrangian} integration of a gridpoint shallow water model on the sphere},
	volume = {117},
	number = {1},
	journal = {Monthly Weather Review},
	author = {McDonald, A. and Bates, J. R.},
	year = {1989},
	pages = {130--137}
}

@book{mcdonald_lateral_1997,
	title = {Lateral boundary conditions for operational regional forecast models; a review},
	publisher = {HIRLAM 4 Project},
	author = {McDonald, Aidan},
	year = {1997}
}

@article{mcdonald_two-time-level_1992,
	title = {A two-time-level, three-dimensional semi-{Lagrangian}, semi-implicit, limited-area gridpoint model of the primitive equations},
	volume = {120},
	number = {11},
	journal = {Monthly weather review},
	author = {McDonald, A. and Haugen, Janerik},
	year = {1992},
	pages = {2603--2621}
}

@article{mcdonald_accuracy_1984,
	title = {Accuracy of multiply-upstream, semi-{Lagrangian} advective schemes},
	volume = {112},
	number = {6},
	journal = {Monthly Weather Review},
	author = {McDonald, A.},
	year = {1984},
	pages = {1267--1275}
}

@article{talagrand_variational_1987,
	title = {Variational {Assimilation} of {Meteorological} {Observations} {With} the {Adjoint} {Vorticity} {Equation}. {I}: {Theory}},
	volume = {113},
	issn = {1477-870X},
	shorttitle = {Variational {Assimilation} of {Meteorological} {Observations} {With} the {Adjoint} {Vorticity} {Equation}. {I}},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49711347812/abstract},
	doi = {10.1002/qj.49711347812},
	abstract = {The following variational approach is taken to the problem of assimilation of meteorological observations: find the solution of the assimilating model which minimizes a given scalar function measuring the ‘distance’ between a model solution and the available observations. It is shown how the ‘adjoint equations’ of the model can be used to compute explicitly the ‘gradient’ of the distance function with respect to the model's initial conditions. the computation of one gradient requires one forward integration of the full model equations over the time interval on which the observations are available, followed by one backward integration of the adjoint equations. Successive gradients thus computed are introduced into a descent algorithm in order to determine the initial conditions which define the minimizing model solution. The theory is applied to the vorticity equation. Successful numerical experiments performed on a Haurwitz wave are described.},
	language = {en},
	number = {478},
	urldate = {2017-11-08},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Talagrand, Olivier and Courtier, Philippe},
	month = oct,
	year = {1987},
	pages = {1311--1328}
}

@book{mccormick_multilevel_1992,
	title = {Multilevel projection methods for partial differential equations},
	publisher = {SIAM},
	author = {McCormick, Stephen F.},
	year = {1992}
}

@article{matsuno_numerical_1966,
	title = {Numerical integrations of the primitive equations by a simulated backward difference method},
	volume = {44},
	number = {1},
	journal = {Journal of the Meteorological Society of Japan. Ser. II},
	author = {Matsuno, Taroh},
	year = {1966},
	pages = {76--84}
}

@article{talagrand_study_1981,
	title = {A study of the dynamics of four-dimensional data assimilation},
	volume = {33},
	issn = {2153-3490},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.2153-3490.1981.tb01729.x/abstract},
	doi = {10.1111/j.2153-3490.1981.tb01729.x},
	abstract = {The problem of four-dimensional data assimilation is investigated on the inviscid linearized shallow-water equations. The conditions under which an assimilation of mass data, performed according to a simple updating scheme, will reconstruct the complete mass and velocity fields are studied. On the basis of a mathematical result proved elsewhere, it is shown that energy conservation ensures exact convergence towards any given solution, irrespective of geostrophy or lack of geostrophy, under the only condition that the available observations define a unique solution of the model equations. For most values of the relevant parameters, the divergent part of the wind field is reconstructed much more rapidly than the rotational part. The effect of a damping of gravity waves is considered, and shown to accelerate the reconstruction of the wind field only for scales which are large compared to the Rossby radius of deformation. These results are generalized to the inviscid linearized multi-level primitive equations. The case of wind observations is also considered, and shown to lead to reconstitution of the complete mass field. Finally, comparison with numerical results obtained with non-linear equations shows that the main features deduced from the linearized theory are preserved, but also suggests that the non-linear advection can, at least in some cases, accelerate the process of reconstruction.},
	language = {en},
	number = {1},
	urldate = {2017-11-08},
	journal = {Tellus},
	author = {Talagrand, Oliver},
	month = feb,
	year = {1981},
	pages = {43--60}
}

@article{masuda_integration_1986,
	title = {An integration scheme of the primitive equation model with an icosahedral-hexagonal grid system and its application to the shallow water equations},
	volume = {64},
	journal = {Journal of the Meteorological Society of Japan. Ser. II},
	author = {Masuda, Yoshinobu and Ohnishi, Haruo},
	year = {1986},
	pages = {317--326}
}

@article{mass_regional_1998,
	title = {Regional real-time numerical weather prediction: {Current} status and future potential},
	volume = {79},
	shorttitle = {Regional real-time numerical weather prediction},
	number = {2},
	journal = {Bulletin of the American Meteorological Society},
	author = {Mass, Clifford F. and Kuo, Ying-Hwa},
	year = {1998},
	pages = {253--263}
}

@article{marchuk_numerical_1974,
	title = {Numerical solution of the problems of the dynamics of the atmosphere and ocean},
	volume = {303},
	journal = {Gidrometeoizdat, Leningrad},
	author = {Marchuk, G. I.},
	year = {1974}
}

@article{takle_project_1999,
	title = {Project to {Intercompare} {Regional} {Climate} {Simulations} ({PIRCS}): {Description} and initial results},
	volume = {104},
	issn = {2156-2202},
	shorttitle = {Project to {Intercompare} {Regional} {Climate} {Simulations} ({PIRCS})},
	url = {http://onlinelibrary.wiley.com/doi/10.1029/1999JD900352/abstract},
	doi = {10.1029/1999JD900352},
	abstract = {The first simulation experiment and output archives of the Project to Intercompare Regional Climate Simulations (PIRCS) is described. Initial results from simulations of the summer 1988 drought over the central United States indicate that limited-area models forced by large-scale information at the lateral boundaries reproduce bulk temporal and spatial characteristics of meteorological fields. In particular, the 500 hPa height field time average and temporal variability are generally well simulated by all participating models. Model simulations of precipitation episodes vary depending on the scale of the dynamical forcing. Organized synoptic-scale precipitation systems are simulated deterministically in that precipitation occurs at close to the same time and location as observed (although amounts may vary from observations). Episodes of mesoscale and convective precipitation are represented in a more stochastic sense, with less precise agreement in temporal and spatial patterns. Simulated surface energy fluxes show broad similarity with the First International Satellite Land Surface Climatology Project (ISLSCP) Field Experiment (FIFE) observations in their temporal evolution and time average diurnal cycle. Intermodel differences in midday Bowen ratio tend to be closely associated with precipitation differences. Differences in daily maximum temperatures also are linked to Bowen ratio differences, indicating strong local, surface influence on this field. Although some models have bias with respect to FIFE observations, all tend to reproduce the synoptic variability of observed daily maximum and minimum temperatures. Results also reveal the advantage of an intercomparison in exposing common tendencies of models despite their differences in convective and surface parameterizations and different methods of assimilating lateral boundary conditions.},
	language = {en},
	number = {D16},
	urldate = {2017-11-08},
	journal = {Journal of Geophysical Research: Atmospheres},
	author = {Takle, Eugene S. and Gutowski, William J. and Arritt, Raymond W. and Pan, Zaitao and Anderson, Christopher J. and da Silva, Renato Ramos and Caya, Daniel and Chen, Shyh-Chin and Giorgi, F. and Christensen, Jens Hesselbjerg and Hong, Song-You and Juang, Hann-Ming Henry and Katzfey, Jack and Lapenta, William M. and Laprise, Rene and Liston, Glen E. and Lopez, Philippe and McGregor, John and Pielke, Roger A. and Roads, John O.},
	month = aug,
	year = {1999},
	keywords = {3309 Meteorology and Atmospheric Dynamics: Climatology, 3329 Meteorology and Atmospheric Dynamics: Mesoscale meteorology, 3337 Meteorology and Atmospheric Dynamics: Numerical modeling and data assimilation},
	pages = {19443--19461}
}

@article{manabe_simulated_1965,
	title = {Simulated climatology of a general circulation model with a hydrologic cycle},
	volume = {93},
	number = {12},
	journal = {Mon. Wea. Rev},
	author = {Manabe, Syukuro and Smagorinsky, Joseph and Strickler, Robert F.},
	year = {1965},
	pages = {769--798}
}

@article{manabe_climate_1969,
	title = {Climate and the ocean circulation},
	volume = {97},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1969)097%3C0739:CATOC%3E2.3.CO;2},
	doi = {10.1175/1520-0493(1969)097<0739:CATOC>2.3.CO;2},
	abstract = {The effect of the hydrology of the earth's surface is incorporated into a numerical model of the general circulation of the atmosphere developed at the Geophysical Fluid Dynamics Laboratory of the Environmental Science Services Administration (ESSA). The primitive equation of motion is used for this study. The nine levels of the model are distributed so as to resolve the surface boundary layer and stratosphere. The depletion of solar radiation and the transfer of the terrestrial radiation are computed taking into consideration cloud and atmospheric absorbers such as water vapor, carbon dioxide, and ozone. The scheme treating the hydrology of our model involves the prediction of water vapor in the atmosphere and the prediction of soil moisture and snow cover. In order to represent the mositure-holding capacity of soil, the continent is assumed to be covered by boxes, which can store limited amounts of water. The ocean surface is idealized to be a completely wet surface without any heat capacity. The temperature of the earth's surface is determined in such a way that it satisfies the condition of heat balance. To facilitate the analysis and the interpretation of the results, a simple and idealized distribution of the ocean and the continental region is chosen for this study. The numerical integrations are performed for the annual mean distribution of solar insolation. In general, the qualitative features of hydrologic and thermodynamic regimes at the earth's surface are successfully simulated. Particularly, the horizontal distribution of rainfall is in excellent qualitative agreement with the observations. For example, the typical subtropical desert, the break of the subtropical dry belt along the east coast of the continent, and the equatorial rain belt emerged as the result of numerical time integration. Some features of the spatial distributions of heat and water balance components at the earth's surface also agree well with those obtained by Budyko for the actual atmosphere. Owing to the lack of seasonal variation of solar insolation and lack of poleward transport of heat by ocean currents in the model, excessive snow cover develops at higher latitudes. Accordingly, the temperature in the polar region is much lower than the annual mean temperature observed in the actual atmosphere. This investigation constitutes a preliminary study preceding the numerical integration of the general circulation model of joint ocean-atmosphere interaction, in which the transport of heat by ocean currents plays an important role.},
	number = {11},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Manabe, Syukuro},
	month = nov,
	year = {1969},
	pages = {739--774}
}

@article{malanotte-rizzoli_data_1986,
	title = {Data constraints applied to models of the ocean general circulation. {Part} {I}: {The} steady case},
	volume = {16},
	shorttitle = {Data constraints applied to models of the ocean general circulation. {Part} {I}},
	number = {10},
	journal = {Journal of physical oceanography},
	author = {Malanotte-Rizzoli, Paola and Holland, William R.},
	year = {1986},
	pages = {1665--1682}
}

@article{mahfouf_analysis_1991,
	title = {Analysis of soil moisture from near-surface parameters: {A} feasibility study},
	volume = {30},
	shorttitle = {Analysis of soil moisture from near-surface parameters},
	number = {11},
	journal = {Journal of applied meteorology},
	author = {Mahfouf, Jean-François},
	year = {1991},
	pages = {1534--1547}
}

@article{takacs_two-step_1985,
	title = {A {Two}-{Step} {Scheme} for the {Advection} {Equation} with {Minimized} {Dissipation} and {Dispersion} {Errors}},
	volume = {113},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281985%29113%3C1050%3AATSSFT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1985)113<1050:ATSSFT>2.0.CO;2},
	abstract = {A two-step advection scheme of the Lax-Wendroff type is derived which has accuracy and phase characteristics similar to that of a third-order scheme. The scheme is exactly third-order accurate in time and space for uniform flow. The new scheme is compared with other currently used methods, and is shown to simulate well the advection of localized disturbances with steep gradients. The scheme is derived for constant flow and generalized to two-dimensional nonuniform flow.},
	number = {6},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Takacs, Lawrence L.},
	month = jun,
	year = {1985},
	pages = {1050--1065}
}

@article{madden_description_1972,
	title = {Description of global-scale circulation cells in the tropics with a 40–50 day period},
	volume = {29},
	number = {6},
	journal = {Journal of the atmospheric sciences},
	author = {Madden, Roland A. and Julian, Paul R.},
	year = {1972},
	pages = {1109--1123}
}

@article{madden_detection_1971,
	title = {Detection of a 40–50 day oscillation in the zonal wind in the tropical {Pacific}},
	volume = {28},
	number = {5},
	journal = {Journal of the atmospheric sciences},
	author = {Madden, Roland A. and Julian, Paul R.},
	year = {1971},
	pages = {702--708}
}

@article{szunyogh_effect_2000,
	title = {The {Effect} of {Targeted} {Dropsonde} {Observations} during the 1999 {Winter} {Storm} {Reconnaissance} {Program}},
	volume = {128},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%282000%29128%3C3520%3ATEOTDO%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(2000)128<3520:TEOTDO>2.0.CO;2},
	abstract = {In this paper, the effects of targeted dropsonde observations on operational global numerical weather analyses and forecasts made at the National Centers for Environmental Prediction (NCEP) are evaluated. The data were collected during the 1999 Winter Storm Reconnaissance field program at locations that were found optimal by the ensemble transform technique for reducing specific forecast errors over the continental United States and Alaska. Two parallel analysis–forecast cycles are compared; one assimilates all operationally available data including those from the targeted dropsondes, whereas the other is identical except that it excludes all dropsonde data collected during the program. It was found that large analysis errors appear in areas of intense baroclinic energy conversion over the northeast Pacific and are strongly associated with errors in the first-guess field. The “signal,” defined by the difference between analysis–forecast cycles with and without the dropsonde data, propagates at an average speed of 30° per day along the storm track to the east. Hovmöller diagrams and eddy statistics suggest that downstream development plays a significant role in spreading out the effect of the dropsondes in space and time. On average, the largest rms surface pressure errors are reduced by 10\%–20\% associated with the eastward-propagating leading edge of the signal. The dropsonde data seem to be more effective in reducing forecast errors when zonal flow prevails over the eastern Pacific. Results from combined verification statistics (based on surface pressure, tropospheric winds, and precipitation amount) indicate that the dropsonde data improved the forecasts in 18 of the 25 targeted cases, while the impact was negative (neutral) in only 5 (2) cases.},
	number = {10},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Szunyogh, I. and Toth, Z. and Morss, R. E. and Majumdar, S. J. and Etherton, B. J. and Bishop, C. H.},
	month = oct,
	year = {2000},
	pages = {3520--3537}
}

@article{dimet_variational_1986,
	title = {Variational algorithms for analysis and assimilation of meteorological observations: theoretical aspects},
	volume = {38},
	issn = {null},
	shorttitle = {Variational algorithms for analysis and assimilation of meteorological observations},
	url = {http://dx.doi.org/10.3402/tellusa.v38i2.11706},
	doi = {10.3402/tellusa.v38i2.11706},
	abstract = {Two general algorithms for solving constrained minimization problems are presented and discussed in the context of analysis and assimilation of meteorological observations. In both algorithms, the original constrained problem is transformed by appropriate modifications into one unconstrained problem, or into a sequence of unconstrained problems. The main advantage of proceeding in this way is that the new unconstrained problems can be solved by classical descent algorithms, thus avoiding the need of directly solving the Euler-Lagrange equations of the original constrained problem.The first algorithm presented in the augmented lagrangian algorithm. It generalizes the more classical penalty and duality algorithms. The second algorithm, inspired from optimal control techniques, is based on an appropriate use of an adjoint dynamical equation, and seems to be particularly well adapted to the assimilation of observations distributed in time. Simple numerical examples show the ability of these algorithms to solve non-linear minimization problems of the type encountered in meteorology. Their possible use in more complex situations is discussed, in particular in terms of their computational cost.},
	number = {2},
	urldate = {2017-11-01},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Dimet, François-Xavier Le and Talagrand, Olivier},
	month = jan,
	year = {1986},
	pages = {97--110}
}

@article{madden_predicting_1989,
	title = {On predicting probability distributions of time-averaged meteorological data},
	volume = {2},
	number = {8},
	journal = {Journal of Climate},
	author = {Madden, Roland A.},
	year = {1989},
	pages = {922--925}
}

@article{madden_seasonal_1986,
	title = {Seasonal variations of the 40-50 day oscillation in the tropics},
	volume = {43},
	number = {24},
	journal = {Journal of the Atmospheric Sciences},
	author = {Madden, Roland A.},
	year = {1986},
	pages = {3138--3158}
}

@article{szunyogh_comparison_1997,
	title = {A comparison of {Lyapunov} and optimal vectors in a low-resolution {GCM}},
	volume = {49},
	issn = {null},
	url = {http://dx.doi.org/10.3402/tellusa.v49i2.14467},
	doi = {10.3402/tellusa.v49i2.14467},
	abstract = {We compare the first local Lyapunov vector (LLV) and the leading optimal vectors in a T10/18 level truncated version of the National Centers for Environmental Prediction global spectral model. The leading LLV is a vector toward which all other perturbations turn and hence it is characterized by the fastest possible growth over infinitely long time periods, while the optimal vectors are perturbations that maximize growth for a finite time period, with respect to a chosen norm. Linear tangent model breeding experiments without convection at T10 resolution show that arbitrary random perturbations converge within a transition period of 3 to 4 days to a single LLV. We computed optimal vectors with the Lanczos algorithm, using the total energy norm. For optimization periods shorter than the transition period (about 3 days), the horizontal structure of the leading initial optimal vectors differs substantially from that of the leading LLV, which provides maximum sustainable growth. There are also profound differences between the two types of vectors in their vertical structure. While the 24- h optimal vectors rapidly become similar to the LLV in their vertical structure, changes in their horizontal structure are very slow. As a consequence, their amplification factor drops and stays well below that of the LLV for an extended period after the optimization period ends. This may have an adverse effect when optimal vectors with short optimization periods are used as initial perturbations for medium-range ensemble forecasts. The optimal vectors computed for 3 days or longer are different. In these vectors, the fastest growing initial perturbation has a horizontal structure similar to that of the leading LLV, and its major difference from the LLV, in the vertical structure, tends to disappear by the end of the optimization period. Initially, the optimal vectors are highly unbalanced and the rapid changes in their vertical structure are associated with geostrophic adjustment. The kinetic energy of the initial optimal vectors peaks in the lower troposphere, whereas in the LLV the maximum is around the jet level. During the integration the phase of the streamfunction field of the optimal vectors, with respect to their corresponding temperature field, is rapidly shifted 180°. And, due to drastic changes that also take place in the vertical temperature distribution, the maximum baroclinic shear shifts from the lower troposphere to just below the jet level. Just after initial time, when the geostrophic adjustment dominates, the leading optimal vectors exhibit a growth rate significantly higher than that of the LLV. By the end of the period of optimization, however, the growth rate associated with the leading optimal vectors drops to or below the level of the Lyapunov exponent. The transient super-Lyapunov growth associated with the leading optimal vectors is due to a one-time-only rapid rotation of the optimal vectors toward the leading LLVs. The nature of this rapid rotation depends on the length of the optimization period and the norm chosen. We speculate that the initial optimal vectors computed with commonly used norms may not be realizable},
	number = {2},
	urldate = {2017-11-08},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Szunyogh, Istvan and Kalnay, Eugenia and Toth, Zoltan},
	month = jan,
	year = {1997},
	pages = {200--227}
}

@techreport{machenhauer_spectral_nodate,
	address = {Reading, UK},
	title = {Spectral {Methods}},
	url = {https://www.ecmwf.int/sites/default/files/elibrary/1991/10901-spectral-methods.pdf},
	urldate = {2017-11-08},
	institution = {ECMWF},
	author = {Machenhauer, B.}
}

@article{swanson_four-dimensional_1998,
	title = {Four-dimensional variational assimilation and predictability in a quasi-geostrophic model},
	volume = {50},
	issn = {null},
	url = {http://dx.doi.org/10.3402/tellusa.v50i4.14540},
	doi = {10.3402/tellusa.v50i4.14540},
	abstract = {Four-dimensional variational assimilation (4DVAR) of noisy observations in a multi-layerquasi-geostrophic model is studied, in both the perfect and imperfect model settings. Withinthe perfect model setting, the quality of the assimilated state improves significantly when theassimilation period is extended more than one week into the past. Specifically, when observationsare supplied every 6 h, the squared error in the assimilated state at the end of the assimilationtime period (the present) saturates at a value two orders of magnitude smaller than theimposed observational error for an assimilation period of 10 days. Further, this reduction inerror occurs not only in measures explicitly minimized by 4DVAR, but for all standard measuresof error. For realistic levels of observational error, the extension of forecast lead times is large, exceeding 15 days for global forecasts when the assimilation period is 10 days. This holds evenfor weather regime transitions, which are shown to be predictable at lead times of 10 days. Theuse of long assimilation periods extends forecast lead times approximately 5 days over the casewhen assimilation periods are on the order of one day. The structure of the analysis error whenlong assimilation period 4DVAR is applied is examined. This error is primarily concentratedin the midlatitude storm tracks. The reduction in analysis error is increasingly efficient at smallscales as the assimilation period is increased; consequently, for long assimilation periods theanalysis error projects strongly into the subspace of the leading Lyapunov vectors. The performanceof 4DVAR in an imperfect model setting is also examined, and is found to depend uponthe growth rate of the model errors. For rapidly growing model errors, extension of the assimilationperiod beyond about 1–2 days results in a degradation in the quality of the assimilatedstate as well as in the forecast quality. However, for model error growth rates similar to thegrowth rates of the leading Lyapunov vectors of the system, improvements in the assimilatedstate similar to those found for the perfect model are obtained. As such, it is estimated thatassimilation times of 3–5 days for current levels of model error may improve the quality ofassimilated states and forecasts in an operational setting.},
	number = {4},
	urldate = {2017-11-08},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Swanson, Kyle and Vautard, Robert and Pires, Carlos},
	month = jan,
	year = {1998},
	pages = {369--390}
}

@article{sugi_dynamic_1986,
	title = {Dynamic {Normal} {Mode} {Initialization}},
	volume = {64},
	doi = {10.2151/jmsj1965.64.5_623},
	abstract = {A new dynamic initialization scheme for a primitive equation model is proposed. In the proposed scheme, the balanced initial state is obtained by forward-backward integration of the linear part of the model equations. During the integration the nonlinear part is kept constant. After the integration, the nonlinear terms (including physical processes) are updated. The updating of the nonlinear terms'and the linear integration are repeated several times like the iteration procedure of nonlinear normal mode initialization (NMI). The scheme is proved to be equivalent to NMI with a frequency dependent underrelaxation factor, and therefore, it is called dynamic normal mode initialization (DNI). Since only the linear part is integrated during the dynamic integration, unlike the conventional dynamic initialization, the proposed scheme is efficient. The scheme has been successfully applied to the FSU multilevel global spectral model. The scheme is expected to be applicable to limited area models without difficulty.},
	number = {5},
	journal = {Journal of the Meteorological Society of Japan. Ser. II},
	author = {Sugi, Masato},
	year = {1986},
	pages = {623--636}
}

@inproceedings{benjamin_operational_1994,
	address = {Bergen, Norway},
	title = {An operational isentropic/sigma hybrid forecast model and data assimilation system},
	volume = {III},
	booktitle = {The {Life} {Cycles} of {Extratropical} {Cyclones}},
	publisher = {Geophysical Institute, University of Bergen},
	author = {Benjamin, S. G. and Grell, G. A. and Brown, J. M. and Bleck, R. and Brundage, K. J. and Smith, T. L. and Miller, P. A.},
	editor = {Gronas, S. and Shapiro, M. A.},
	year = {1994},
	pages = {268--273}
}

@article{suarez_delayed_1988,
	title = {A {Delayed} {Action} {Oscillator} for {ENSO}},
	volume = {45},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469%281988%29045%3C3283%3AADAOFE%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1988)045<3283:ADAOFE>2.0.CO;2},
	abstract = {A simple nonlinear model is proposed for the El Niño/Southern Oscillation (ENSO) phenomenon. Its key feature is the inclusion of oceanic wave transit effects through a negative, delayed feedback. A linear stability analysis and numerical results are presented to show that the period of the oscillation is typically several times the delay. It is argued such an effect can account for the long time scale of ENSO.},
	number = {21},
	urldate = {2017-11-08},
	journal = {Journal of the Atmospheric Sciences},
	author = {Suarez, Max J. and Schopf, Paul S.},
	month = nov,
	year = {1988},
	pages = {3283--3287}
}

@article{suarez_parameterization_1983,
	title = {The {Parameterization} {Of} the {Planetary} {Boundary} {Layer} in the {UCLA} {General} {Circulation} {Model}: {Formulation} and {Results}},
	volume = {111},
	issn = {0027-0644},
	shorttitle = {The {Parameterization} {Of} the {Planetary} {Boundary} {Layer} in the {UCLA} {General} {Circulation} {Model}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1983)111%3C2224:TPOTPB%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1983)111<2224:TPOTPB>2.0.CO;2},
	abstract = {A planetary boundary layer (PBL) parameterization for general circulation models (GCMs) is presented. It uses a mixed-layer approach in which the PBL is assumed to be capped by discontinuities in the mean profiles. Both clear and cloud-topped boundary layers are parameterized. Particular emphasis is placed on the formulation of the coupling between the PBL and both the free atmosphere and cumulus convection. For this purpose a modified σ-coordinate is introduced in which the PBL top and the lower boundary are both coordinate surfaces. The use of a bulk PBL formulation with this coordinate is extensively discussed. Results are presented from a July simulation produced by the UCLA GCM. PBL-related variables are shown, to illustrate the various regimes the parameterization is capable of simulating.},
	number = {11},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Suarez, Max J. and Arakawa, Akio and Randall, David A.},
	month = nov,
	year = {1983},
	pages = {2224--2243}
}

@article{machenhauer_spectral_1979,
	title = {The spectral method},
	volume = {2},
	number = {17},
	journal = {Numerical methods used in atmospheric models},
	author = {Machenhauer, B.},
	year = {1979},
	pages = {121--275}
}

@misc{strang_analysis_nodate,
	title = {An {Analysis} of the {Finite} {Element} {Method}, {Second} {Edition}},
	url = {http://bookstore.siam.org/wc08/},
	urldate = {2017-11-08},
	journal = {SIAM Bookstore},
	author = {STRANG, GILBERT and FIX, GEORGE}
}

@article{machenhauer_dynamics_1977,
	title = {On the dynamics of gravity oscillations in a shallow water model with applications to normal mode initialization},
	volume = {50},
	journal = {Beitr. Phys. Atmos},
	author = {Machenhauer, Bennert},
	year = {1977},
	pages = {253--271}
}

@techreport{lynch_digital_1999,
	title = {Digital {Filter} {Initialization} for {HIRLAM}},
	abstract = {A digital lter initialization scheme has been introduced into the Hirlam model and  compared to the reference implicit normal mode initialization scheme. This report  presents details of the scheme and the results of extensive tests showing its advantages.  The scheme is shown to be more eective than the reference normal mode initialization  scheme in eliminating spurious high frequency noise from the forecasts. In a parallel run  using FASTEX data, the scores produced by the DFI run were signicantly better than  those of the reference run. The advantages of digital lter initialization demonstrated in  this report should justify the adoption of the digital ltering initialization scheme as a  new reference scheme for Hirlam.  1  2  Digital Filter Initialization for HIRLAM  1. Introduction  The requirement to modify meteorological analyses to avoid spurious high frequency oscillations in numerical forecasts has been known from the beginning of numerical weather prediction. Indeed, i...},
	institution = {Available at SMHI, S-60176 Norrkoping},
	author = {Lynch, Peter and McGrath, Ray and McDonald, Aidan},
	year = {1999}
}

@article{lynch_dolphchebyshev_1997,
	title = {The {Dolph}–{Chebyshev} {Window}: {A} {Simple} {Optimal} {Filter}},
	volume = {125},
	issn = {0027-0644},
	shorttitle = {The {Dolph}–{Chebyshev} {Window}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1997)125%3C0655:TDCWAS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1997)125<0655:TDCWAS>2.0.CO;2},
	abstract = {Analyzed data for numerical prediction can be effectively initialized by means of a digital filter. Computation time is reduced by using an optimal filter. The construction of optimal filters involves the solution of a nonlinear minimization problem using an iterative procedure. In this paper a simple filter based on the Dolph–Chebyshev window, which has properties similar to those of an optimal filter, is described. It is shown to be optimal for an appropriate choice of parameters. It has an explicit analytical expression and is easily implemented. Its effectiveness is demonstrated by application to Richardson’s forecast: the initial pressure tendency is reduced from 145 hPa per 6 h to −0.9 hPa per 6 h. Use of the filter is not restricted to initialization; it may also be applied as a weak constraint in four-dimensional data assimilation.},
	number = {4},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Lynch, Peter},
	month = apr,
	year = {1997},
	pages = {655--660}
}

@article{lynch_diabatic_1994,
	title = {Diabatic initialization using recursive filters},
	volume = {46},
	number = {5},
	journal = {Tellus A},
	author = {Lynch, Peter and HUANG, XIANG-YU},
	year = {1994},
	pages = {583--597}
}

@article{lynch_initialization_1992,
	title = {Initialization of the {HIRLAM} model using a digital filter},
	volume = {120},
	number = {6},
	journal = {Monthly Weather Review},
	author = {Lynch, Peter and Huang, Xiang-Yu},
	year = {1992},
	pages = {1019--1034}
}

@article{louis_parametric_1979,
	title = {A parametric model of vertical eddy fluxes in the atmosphere},
	volume = {17},
	number = {2},
	journal = {Boundary-Layer Meteorology},
	author = {Louis, Jean-Francois},
	year = {1979},
	pages = {187--202}
}

@article{lott_new_1997,
	title = {A new subgrid-scale orographic drag parametrization: {Its} formulation and testing},
	volume = {123},
	shorttitle = {A new subgrid-scale orographic drag parametrization},
	number = {537},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Lott, François and Miller, Martin J.},
	year = {1997},
	pages = {101--127}
}

@article{lorenz_n-cycle_1971,
	title = {An {N}-cycle time-differencing scheme for stepwise numerical integration},
	volume = {99},
	number = {8},
	journal = {Monthly Weather review},
	author = {Lorenz, Edward N.},
	year = {1971},
	pages = {644--648}
}

@inproceedings{lorenz_predictability:_1996,
	title = {Predictability: {A} problem partly solved},
	volume = {1},
	shorttitle = {Predictability},
	booktitle = {Proc. {Seminar} on predictability},
	author = {Lorenz, Edward N.},
	year = {1996}
}

@book{lorenz_essence_1995,
	title = {The essence of chaos},
	publisher = {University of Washington Press},
	author = {Lorenz, Edward N.},
	year = {1995}
}

@article{axelsson_survey_1985,
	title = {A survey of preconditioned iterative methods for linear systems of algebraic equations},
	volume = {25},
	issn = {0006-3835, 1572-9125},
	url = {https://link.springer.com/article/10.1007/BF01934996},
	doi = {10.1007/BF01934996},
	abstract = {We survey preconditioned iterative methods with the emphasis on solving large sparse systems such as arise by discretization of boundary value problems for partial differential equations.We discuss shortly various acceleration methods but the main emphasis is on efficient preconditioning techniques. Numerical simulations on practical problems have indicated that an efficient preconditioner is the most important part of an iterative algorithm. We report in particular on the state of the art of preconditioning methods for vectorizable and/or parallel computers.},
	language = {en},
	number = {1},
	urldate = {2017-11-08},
	journal = {BIT Numerical Mathematics},
	author = {Axelsson, O.},
	month = mar,
	year = {1985},
	pages = {165--187}
}

@article{galerkin_rods_1915,
	title = {Rods and plates. {Series} occurring in various questions concerning the elastic equilibrium of rods and plates},
	volume = {19},
	journal = {Vestn. Inzh. Tekh},
	author = {Galerkin, Boris Grigoryevich},
	year = {1915},
	pages = {897--908}
}

@book{emanuel_representation_1993,
	series = {Meteorological {Monographs}},
	title = {The {Representation} of {Cumulus} {Convection} in {Numerical} {Models}},
	volume = {24},
	isbn = {978-1-935704-13-3},
	abstract = {This book presents descriptions of numerical models for testing cumulus in cloud fields. It is divided into six parts. Part I provides an overview of the problem, including descriptions of cumulus clouds and the effects of ensembles of cumulus clouds on mass, momentum, and vorticity distributions. A review of closure assumptions is also provided. A review of "classical" convection schemes in widespread use is provided in Part II. The special problems associated with the representation of convection in mesoscale models are discussed in Part III, along with descriptions of some of the commonly used mesoscale schemes. Part IV covers some of the problems associated with the representation of convection in climate models, while the parameterization of slantwise convection is the subject of Part V.},
	language = {en},
	publisher = {American Meteorological Society},
	author = {Emanuel, Kerry and Raymond, D.J.},
	year = {1993},
	note = {Google-Books-ID: utC9BwAAQBAJ},
	keywords = {Science / Earth Sciences / Meteorology \& Climatology, Science / Earth Sciences / General, Science / Earth Sciences / Geology}
}

@article{lorenz_atmospheric_1982,
	title = {Atmospheric predictability experiments with a large numerical model},
	volume = {34},
	number = {6},
	journal = {Tellus},
	author = {Lorenz, E. N.},
	year = {1982},
	pages = {505--513}
}

@article{lorenz_existence_1986,
	title = {On the {Existence} of a {Slow} {Manifold}},
	volume = {43},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1986)043%3C1547:OTEOAS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1986)043<1547:OTEOAS>2.0.CO;2},
	abstract = {We identify the slow manifold of a primitive-equation system with the set of all solutions that are completely devoid of gravity-wave activity. We construct a five-variable model describing coupled Rossby waves and gravity waves. Successive-approximation schemes designed to determine the slow manifold fail to converge when applied to the model, although they sometimes appear to converge before finally diverging. A noniterative scheme which demands only that the fast variables be functions of the slow variables yields a “Slowest invariant manifold,” which, however, is not unequivocally slow. We question whether the complete absence of gravity waves can be logically defined, and we note that the existence or nonexistence of a slow manifold does not depend upon the convergence or nonconvergence of a power series or a succession of approximations.},
	number = {15},
	urldate = {2017-11-08},
	journal = {Journal of the Atmospheric Sciences},
	author = {Lorenz, Edward N.},
	month = aug,
	year = {1986},
	pages = {1547--1558}
}

@article{stensrud_using_2000,
	title = {Using {Initial} {Condition} and {Model} {Physics} {Perturbations} in {Short}-{Range} {Ensemble} {Simulations} of {Mesoscale} {Convective} {Systems}},
	volume = {128},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493%282000%29128%3C2077%3AUICAMP%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(2000)128<2077:UICAMP>2.0.CO;2},
	abstract = {Two separate numerical model ensembles are created by using model configurations with different model physical process parameterization schemes and identical initial conditions, and by using different model initial conditions from a Monte Carlo approach and the identical model configuration. Simulations from these two ensembles are investigated for two 48-h periods during which large, long-lived mesoscale convective systems develop. These two periods are chosen because, in some respects, they span the range of convective forecast problems routinely handled by operational forecasters. Calculations of the root-mean-square error, equitable threat score, and ranked probability score from both ensembles indicate that the model physics ensemble is more skillful than the initial-condition ensemble when the large-scale forcing for upward motion is weak. When the large-scale forcing for upward motion is strong, the initial-condition ensemble is more skillful than the model physics ensemble. This result is consistent with the expectation that model physics play a larger role in model simulations when the large-scale signal is weak and the assumptions used within the model parameterization schemes largely determine the evolution of the simulated weather events. The variance from the two ensembles is created at significantly different rates, with the variance in the physics ensemble being produced two to six times faster during the first 12 h than the variance in the initial-condition ensemble. Therefore, within a very brief time period, the variance from the physics ensemble often greatly exceeds that produced by the initial-condition ensemble. These results suggest that varying the model physics is a potentially powerful method to use in creating an ensemble. In essence, by using different model configurations, the systematic errors of the individual ensemble members are different and, hence, this may allow one to determine a probability density function from this ensemble that is more diffuse than can be accomplished using a single model configuration.},
	number = {7},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Stensrud, David J. and Bao, Jian-Wen and Warner, Thomas T.},
	month = jul,
	year = {2000},
	pages = {2077--2107}
}

@article{lorenz_attractor_1980,
	title = {Attractor sets and quasi-geostrophic equilibrium},
	volume = {37},
	number = {8},
	journal = {Journal of the Atmospheric Sciences},
	author = {Lorenz, Edward N.},
	year = {1980},
	pages = {1685--1699}
}

@article{hinkelmann_mechanismus_1951,
	title = {Der mechanismus des meteorologischen {Lärmes}},
	volume = {3},
	number = {4},
	journal = {Tellus},
	author = {Hinkelmann, K.},
	year = {1951},
	pages = {285--296}
}

@book{golub_matrix_1996,
	edition = {3},
	title = {Matrix computations},
	publisher = {The Johns Hopkins University Press, Ltd.},
	author = {Golub, Gene H. and Van Loan, Charles F.},
	year = {1996}
}

@inproceedings{lorenz_statistical_1960,
	title = {The statistical prediction of solutions of dynamic equations},
	booktitle = {Symposium on {Numerical} {Weather} {Prediction} in {Tokyo}},
	author = {Lorenz, Edward N.},
	year = {1960}
}

@article{lorenz_study_1965,
	title = {A study of the predictability of a 28-variable atmospheric model},
	volume = {17},
	number = {3},
	journal = {Tellus},
	author = {Lorenz, Edward N.},
	year = {1965},
	pages = {321--333}
}

@techreport{gibson_ecmwf_1997,
	title = {{ECMWF} reanalysis description},
	number = {1},
	institution = {ECMWF},
	author = {Gibson, J. K. and Kallberg, P. and Uppala, S. and Nomura, A. and Hernandez, A. and Serrano, E.},
	year = {1997},
	pages = {50}
}

@article{lorenz_energy_1960,
	title = {Energy and numerical weather prediction},
	volume = {12},
	number = {4},
	journal = {Tellus},
	author = {Lorenz, Edward N.},
	year = {1960},
	pages = {364--373}
}

@article{lorenz_available_1955,
	title = {Available potential energy and the maintenance of the general circulation},
	volume = {7},
	number = {2},
	journal = {Tellus},
	author = {Lorenz, Edward N.},
	year = {1955},
	pages = {157--167}
}

@article{lorenc_development_1997,
	title = {Development of an {Operational} {Variational} {Assimilation} {Scheme} ({gtSpecial} {IssueltData} {Assimilation} in {Meteology} and {Oceanography}: {Theory} and {Practice})},
	volume = {75},
	shorttitle = {Development of an {Operational} {Variational} {Assimilation} {Scheme} ({gtSpecial} {IssueltData} {Assimilation} in {Meteology} and {Oceanography}},
	number = {1B},
	journal = {Journal of the Meteorological Society of Japan. Ser. II},
	author = {Lorenc, Andrew C.},
	year = {1997},
	pages = {339--346}
}

@techreport{flattery_spectral_1971,
	type = {Tech. {Report}},
	title = {Spectral models for global analysis and forecasting},
	number = {243},
	institution = {Air Weather Service, US Air Force},
	author = {Flattery, Thomas W.},
	year = {1971},
	pages = {42--54}
}

@article{lorenc_objective_1988,
	title = {Objective quality control of observations using {Bayesian} methods. {Theory}, and a practical implementation},
	volume = {114},
	number = {480},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Lorenc, A. C. and Hammon, O.},
	year = {1988},
	pages = {515--543}
}

@article{stensrud_using_1999,
	title = {Using {Ensembles} for {Short}-{Range} {Forecasting}},
	volume = {127},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1999)127%3C0433%3AUEFSRF%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1999)127<0433:UEFSRF>2.0.CO;2},
	abstract = {Numerical forecasts from a pilot program on short-range ensemble forecasting at the National Centers for Environmental Prediction are examined. The ensemble consists of 10 forecasts made using the 80-km Eta Model and 5 forecasts from the regional spectral model. Results indicate that the accuracy of the ensemble mean is comparable to that from the 29-km Meso Eta Model for both mandatory level data and the 36-h forecast cyclone position. Calculations of spread indicate that at 36 and 48 h the spread from initial conditions created using the breeding of growing modes technique is larger than the spread from initial conditions created using different analyses. However, the accuracy of the forecast cyclone position from these two initialization techniques is nearly identical. Results further indicate that using two different numerical models assists in increasing the ensemble spread significantly. There is little correlation between the spread in the ensemble members and the accuracy of the ensemble mean for the prediction of cyclone location. Since information on forecast uncertainty is needed in many applications, and is one of the reasons to use an ensemble approach, the lack of a correlation between spread and forecast uncertainty presents a challenge to the production of short-range ensemble forecasts. Even though the ensemble dispersion is not found to be an indication of forecast uncertainty, significant spread can occur within the forecasts over a relatively short time period. Examples are shown to illustrate how small uncertainties in the model initial conditions can lead to large differences in numerical forecasts from an identical numerical model.},
	number = {4},
	journal = {Monthly Weather Review},
	author = {Stensrud, David J. and Brooks, Harold E. and Du, Jun and Tracton, M. Steven and Rogers, Eric},
	month = apr,
	year = {1999},
	pages = {433--446}
}

@article{lorenc_optimal_1988,
	title = {Optimal nonlinear objective analysis},
	volume = {114},
	number = {479},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Lorenc, Andrew C.},
	year = {1988},
	pages = {205--240}
}

@article{lorenc_practical_1988,
	title = {A {Practical} {Approximation} to {Optimal} {Four}-{Dimensional} {Objective} {Analysis}},
	volume = {116},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1988)116%3C0730:APATOF%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1988)116<0730:APATOF>2.0.CO;2},
	abstract = {An iterative four-dimensional objective analysis scheme is described. The method is derived by approximating a variational algorithm which should give an optimal four-dimensional analysis The complete set of operationally available observations, and operational analysis and forecast codes, are used. In this the scheme differs from most other studies of optimal four-dimensional analysis, which make fewer approximations in the algorithm, but use simplified models and data. The scheme was developed using the optimal interpolation analysis, nonlinear normal-mode initialization, and nested-grid forecast model from the Regional Analysis and Forecast System of NMC. To these were added an approximate adjoint model of the forecast, and a code to implement a simple decent algorithm. Tests used the operational observation database. The scheme was successful in producing a dynamically consistent four-dimensional analysis that fit the observations without totally impractical computer costs. However for the one test case studied, the forecast from the scheme's analysis was slightly worse than that from the operational analysis. The tests highlighted some deficiencies of the current operational analysis, initialization, and forecast codes. They also indicated areas where further development of the scheme is desirable; in the adjoint forecast model and analysis error estimation.},
	number = {3},
	urldate = {2017-11-08},
	journal = {Monthly Weather Review},
	author = {Lorenc, Andrew C.},
	month = mar,
	year = {1988},
	pages = {730--745}
}

@book{emanuel_representation_2015,
	title = {The representation of cumulus convection in numerical models},
	publisher = {Springer},
	author = {Emanuel, Kerry},
	year = {2015}
}

@techreport{eliasen_numerical_1970,
	title = {On a numerical method for integration of the hydrodynamical equations with a spectral representation of the horizontal fields},
	number = {2},
	institution = {Institute for Theoretisk Meteorologi, University of Copenhagen},
	author = {Eliasen, Erik and Machenhauer, Bennert and Rasmussen, Erik},
	year = {1970},
	pages = {35}
}

@article{browning_initialization_1982,
	title = {Initialization of the shallow water equations with open boundaries by the bounded derivative method},
	volume = {34},
	issn = {2153-3490},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.2153-3490.1982.tb01823.x/abstract},
	doi = {10.1111/j.2153-3490.1982.tb01823.x},
	abstract = {The shallow water equations are a symmetric hyperbolic system with two time scales. In meteorological terms, slow and fast scale motions are referred to as Rossby and inertial/gravity waves, respectively. We prove the existence of smooth solutions (solutions with a number of space and time derivatives on the order of the slow time scale) of the open boundary problem for the shallow water equations by the bounded derivative method. The proof requires that a number of initial time derivatives be of the order of the slow time scale and that the boundary data be smooth. If the boundary data are smooth and only have small errors, then we show that the solution of the open boundary problem is smooth and that only small errors are produced in the interior. If the boundary data are smooth but have large errors, then we show that the solution of the open boundary problem is still smooth. Unfortunately the boundary error propagates into the interior at the speed associated with the fast time scale and destroys the solution in a short time. Thus it is necessary to keep the boundary error small if the solution is to be computed correctly. We show that this restriction can be relaxed so that only the large-scale boundary data need be correct. We demonstrate the importance of these conclusions in several numerical experiments.},
	language = {en},
	number = {4},
	urldate = {2017-11-06},
	journal = {Tellus},
	author = {Browning, G. and Kreiss, H.-O.},
	month = aug,
	year = {1982},
	pages = {334--351}
}

@article{brooks_verification_1997,
	title = {Verification of {Public} {Weather} {Forecasts} {Available} via the {Media}},
	volume = {78},
	issn = {0003-0007},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0477%281997%29078%3C2167%3AVOPWFA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0477(1997)078<2167:VOPWFA>2.0.CO;2},
	abstract = {The question of who is the “best” forecaster in a particular media market is one that the public frequently asks. The authors have collected approximately one year's forecasts from the National Weather Service and major media presentations for Oklahoma City. Diagnostic verification procedures indicate that the question of best does not have a clear answer. All of the forecast sources have strengths and weaknesses, and it is possible that a user could take information from a variety of sources to come up with a forecast that has more value than any one individual source provides. The analysis provides numerous examples of the utility of a distributions-oriented approach to verification while also providing insight into the problems the public faces in evaluating the array of forecasts presented to them.},
	number = {10},
	urldate = {2017-11-06},
	journal = {Bulletin of the American Meteorological Society},
	author = {Brooks, Harold E. and Witt, Arthur and Eilts, Michael D.},
	month = oct,
	year = {1997},
	pages = {2167--2177}
}

@article{bretherton_technique_1976,
	title = {A technique for objective analysis and design of oceanographic experiments applied to {MODE}-73},
	volume = {23},
	issn = {0011-7471},
	url = {http://www.sciencedirect.com/science/article/pii/0011747176900012},
	doi = {10.1016/0011-7471(76)90001-2},
	abstract = {A technique for the objective analysis of oceanic data has been developed and used on simulated data. The technique is based on a standard statistical result—the Gauss-Markov Theorem-which gives an expression for the least square error linear estimate of some physical variable (velocity, stream function, temperature, etc.) given measurements at a limited number of data points, the statistics of the field being estimated in the form of space-time spectra, and the measurement errors. An expression for the r.m.s. error expected in this estimate is also derived and illustrated in the form of ‘error maps’. Efficient sampling arrays can be designed through trial-and-error adjustment of array configurations until a suitable balance of mapping coverage and accuracy, as measured by the error maps, is achieved. Examples of the mapping ability of some simple arrays are given. Using statistics inferred from the preliminary Mid Ocean Dynamics Experiments various realizations of likely flow fields were simulated. The 16 element MODE-I array was tested by comparison of the simulated fields and the objective maps based on inferred ‘measurements’ at the array points. The reliability of statistics inferred from observations was estimated by comparing correlations derived from limited observations of the simulated fields with the known statistics. Correlations derived from two realizations differed significantly but most calculations reproduced the known statistics moderately well. An intercomparison of Eulerian measurements (current meters) and Lagrangian measurements (neutrally buoyant drifters) was also carried out using the objective interpolation method.},
	number = {7},
	urldate = {2017-11-06},
	journal = {Deep Sea Research and Oceanographic Abstracts},
	author = {Bretherton, Francis P. and Davis, Russ E. and Fandry, C. B.},
	month = jul,
	year = {1976},
	pages = {559--582}
}

@article{bratseth_statistical_1986,
	title = {Statistical interpolation by means of successive corrections},
	volume = {38A},
	issn = {1600-0870},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1600-0870.1986.tb00476.x/abstract},
	doi = {10.1111/j.1600-0870.1986.tb00476.x},
	abstract = {A theoretical investigation of the successive correction method for objective analysis of meteorological data is presented, and an explicit formula for the interation limit is offered. By means of this result, it is possible to formulate the method so that this limit conforms with statistical optimal interpolation. Simple experiments indicate that desirable properties of statistical interpolations are easily transferred to the successive correction approach. This includes the use of observation error statistics and multivariate analysis.},
	language = {en},
	number = {5},
	urldate = {2017-11-06},
	journal = {Tellus A},
	author = {Bratseth, Arne M.},
	month = oct,
	year = {1986},
	pages = {439--447}
}

@article{bratseth_simple_1982,
	title = {A simple and efficient approach to the initialization of weather prediction models},
	volume = {34},
	issn = {0040-2826},
	url = {http://dx.doi.org/10.3402/tellusa.v34i4.10821},
	doi = {10.3402/tellusa.v34i4.10821},
	abstract = {An iterative method is suggested, by which the gravity modes of a primitive shallow water equation model are damped very efficiently while the meteorological modes are preserved fairly well. The model equations are integrated in a forward/backward cycle. It is shown that information about the normal modes of the model can be used to increase the damping rate even if these modes are not known explicitly. The meteorological modes can be conserved by keeping the relevant terms constant during each iteration cycle. Experiments with a simple one-dimensional model show that this model reaches a balanced state after a couple of iterations.},
	number = {4},
	urldate = {2017-11-06},
	journal = {Tellus},
	author = {Bratseth, Arne M.},
	month = jan,
	year = {1982},
	pages = {352--357}
}

@article{brankovic_seasonal_2000,
	title = {Seasonal skill and predictability of {ECMWF} {PROVOST} ensembles},
	volume = {126},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49712656704/abstract},
	doi = {10.1002/qj.49712656704},
	abstract = {Variations in seasonal-forecasting skill and predictability during the 15 years (1979–93) of the European Centre for Medium-Range Weather Forecasts (ECMWF) re-analysis (ERA), have been studied using 120-day ensemble integrations of the ECMWF model. These integrations form part of the European Union PROVOST (PRediction Of climate Variations On Seasonal to interannual Time-scales) project. Observed sea surface temperatures (SSTs) were updated daily at the model's lower boundary. Two major and three moderate El Niño Southern Oscillation (ENSO) events occurred during the ERA period. Results are interpreted as giving an upper bound on the predictive skill of a coupled ocean-atmosphere system as a function of season, location, and state of ENSO. The model systematic error was found to be comparable with a typical amplitude of interannual variation. When standardized by the corresponding ERA anomaly variance, systematic error appears to be largest in boreal spring in the northern extratropics, and in boreal summer in the tropics. Ensemble-mean skill scores were found to be positive overall. Apart from the northern winter season, the ensemble-mean skill for months 2–4 drops significantly when compared with months 1–3. The interannual variation of skill scores is much larger for the European region than for the hemispheric domain. Over the northern hemisphere, skill is much higher when only ENSO years are considered; for Europe, the enhancement in skill for ENSO years is much weaker. Estimates of intrinsic predictability were made for each year of the dataset. These estimates, defined both by a t-test and variance ratio, indicate generally high predictability in years when ENSO was strong. Apart from northern winter, the predictability estimates also showed a systematic drop between months 1–3 and months 2–4. It is therefore concluded that the fall in skill scores between months 1–3 and 2–4 indicates more a weakening of the impact of initial conditions (ICs) than, say, an increase in the effects of model error. In order to study this further, the relative impacts of SSTs and ICs, including land surface ICs, on interannual variation of precipitation have been examined in an additional set of experiments. Overall, SSTs have a dominant role, though the impact of ICs is not negligible. The predictability of tropical and extratropical precipitation is also discussed. The level of skill for precipitation in the extratropics is generally lower than in the tropics. However, within the tropics there are regions where the precipitation exhibits chaotic behaviour and is correspondingly less predictable.},
	language = {en},
	number = {567},
	urldate = {2017-11-06},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Branković, Čedo and Palmer, T. N.},
	month = jul,
	year = {2000},
	keywords = {Ensemble prediction, El Niño, Seasonal predictability},
	pages = {2035--2067}
}

@article{houtekamer_review_2016,
	title = {Review of the {Ensemble} {Kalman} {Filter} for {Atmospheric} {Data} {Assimilation}},
	volume = {144},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/MWR-D-15-0440.1},
	doi = {10.1175/MWR-D-15-0440.1},
	abstract = {This paper reviews the development of the ensemble Kalman filter (EnKF) for atmospheric data assimilation. Particular attention is devoted to recent advances and current challenges. The distinguishing properties of three well-established variations of the EnKF algorithm are first discussed. Given the limited size of the ensemble and the unavoidable existence of errors whose origin is unknown (i.e., system error), various approaches to localizing the impact of observations and to accounting for these errors have been proposed. However, challenges remain; for example, with regard to localization of multiscale phenomena (both in time and space). For the EnKF in general, but higher-resolution applications in particular, it is desirable to use a short assimilation window. This motivates a focus on approaches for maintaining balance during the EnKF update. Also discussed are limited-area EnKF systems, in particular with regard to the assimilation of radar data and applications to tracking severe storms and tropical cyclones. It seems that relatively less attention has been paid to optimizing EnKF assimilation of satellite radiance observations, the growing volume of which has been instrumental in improving global weather predictions. There is also a tendency at various centers to investigate and implement hybrid systems that take advantage of both the ensemble and the variational data assimilation approaches; this poses additional challenges and it is not clear how it will evolve. It is concluded that, despite more than 10 years of operational experience, there are still many unresolved issues that could benefit from further research.Contents Introduction...4490Popular flavors of the EnKF algorithm...4491 General description...4491Stochastic and deterministic filters...4492 The stochastic filter...4492The deterministic filter...4492Sequential or local filters...4493 Sequential ensemble Kalman filters...4493The local ensemble transform Kalman filter...4494Extended state vector...4494Issues for the development of algorithms...4495Use of small ensembles...4495 Monte Carlo methods...4495Validation of reliability...4497Use of group filters with no inbreeding...4498Sampling error due to limited ensemble size: The rank problem...4498Covariance localization...4499 Localization in the sequential filter...4499Localization in the LETKF...4499Issues with localization...4500Summary...4501Methods to increase ensemble spread...4501 Covariance inflation...4501 Additive inflation...4501Multiplicative inflation...4502Relaxation to prior ensemble information...4502Issues with inflation...4503Diffusion and truncation...4503Error in physical parameterizations...4504 Physical tendency perturbations...4504Multimodel, multiphysics, and multiparameter approaches...4505Future directions...4505Realism of error sources...4506Balance and length of the assimilation window...4506 The need for balancing methods...4506Time-filtering methods...4506Toward shorter assimilation windows...4507Reduction of sources of imbalance...4507Regional data assimilation...4508 Boundary conditions and consistency across multiple domains...4509Initialization of the starting ensemble...4510Preprocessing steps for radar observations...4510Use of radar observations for convective-scale analyses...4511Use of radar observations for tropical cyclone analyses...4511Other issues with respect to LAM data assimilation...4511The assimilation of satellite observations...4512 Covariance localization...4512Data density...4513Bias-correction procedures...4513Impact of covariance cycling...4514Assumptions regarding observational error...4514Recommendations regarding satellite observations...4515Computational aspects...4515 Parameters with an impact on quality...4515Overview of current parallel algorithms...4516Evolution of computer architecture...4516Practical issues...4517Approaching the gray zone...4518Summary...4518Hybrids with variational and EnKF components...4519 Hybrid background error covariances...4519E4DVar with the α control variable...4519Not using linearized models with 4DEnVar...4520The hybrid gain algorithm...4521Open issues and recommendations...4521Summary and discussion...4521 Stochastic or deterministic filters...4522The nature of system error...4522Going beyond the synoptic scales...4522Satellite observations...4523Hybrid systems...4523Future of the EnKF...4523APPENDIX A...4524Types of Filter Divergence...4524 Classical filter divergence...4524Catastrophic filter divergence...4524APPENDIX B...4524Systems Available for Download...4524References...4525},
	number = {12},
	urldate = {2018-07-05},
	journal = {Monthly Weather Review},
	author = {Houtekamer, P. L. and Zhang, Fuqing},
	month = jun,
	year = {2016},
	pages = {4489--4532}
}

@article{ott_local_2004,
	title = {A local ensemble {Kalman} filter for atmospheric data assimilation},
	volume = {56},
	issn = {null},
	url = {https://doi.org/10.3402/tellusa.v56i5.14462},
	doi = {10.3402/tellusa.v56i5.14462},
	abstract = {In this paper, we introduce a new, local formulation of the ensemble Kalman filter approach for atmospheric data assimilation. Our scheme is based on the hypothesis that, when the Earth’s surface is divided up into local regions of moderate size, vectors of the forecast uncertainties in such regions tend to lie in a subspace of much lower dimension than that of the full atmospheric state vector of such a region. Ensemble Kalman filters, in general, take the analysis resulting from the data assimilation to lie in the same subspace as the expected forecast error. Under our hypothesis the dimension of the subspace corresponding to local regions is low. This is used in our scheme to allow operations only on relatively low-dimensional matrices. The data assimilation analysis is performed locally in a manner allowing massively parallel computation to be exploited. The local analyses are then used to construct global states for advancement to the next forecast time. One advantage, which may take on more importance as ever-increasing amounts of remotely-sensed satellite data become available, is the favorable scaling of the computational cost of our method with increasing data size, as compared to other methods that assimilate data sequentially. The method, its potential advantages, properties, and implementation requirements are illustrated by numerical experiments on the Lorenz-96 model. It is found that accurate analysis can be achieved at a cost which is very modest compared to that of a full global ensemble Kalman filter.},
	number = {5},
	urldate = {2018-07-05},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Ott, Edward and Hunt, Brian R. and Szunyogh, Istvan and Zimin, Aleksey V. and Kostelich, Eric J. and Corazza, Matteo and Kalnay, Eugenia and Patil, D. J. and Yorke, James A.},
	month = jan,
	year = {2004},
	pages = {415--428}
}

@article{whitaker_ensemble_2002,
	title = {Ensemble {Data} {Assimilation} without {Perturbed} {Observations}},
	volume = {130},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/1520-0493(2002)130%3C1913:EDAWPO%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(2002)130<1913:EDAWPO>2.0.CO;2},
	abstract = {The ensemble Kalman filter (EnKF) is a data assimilation scheme based on the traditional Kalman filter update equation. An ensemble of forecasts are used to estimate the background-error covariances needed to compute the Kalman gain. It is known that if the same observations and the same gain are used to update each member of the ensemble, the ensemble will systematically underestimate analysis-error covariances. This will cause a degradation of subsequent analyses and may lead to filter divergence. For large ensembles, it is known that this problem can be alleviated by treating the observations as random variables, adding random perturbations to them with the correct statistics. Two important consequences of sampling error in the estimate of analysis-error covariances in the EnKF are discussed here. The first results from the analysis-error covariance being a nonlinear function of the background-error covariance in the Kalman filter. Due to this nonlinearity, analysis-error covariance estimates may be negatively biased, even if the ensemble background-error covariance estimates are unbiased. This problem must be dealt with in any Kalman filter–based ensemble data assimilation scheme. A second consequence of sampling error is particular to schemes like the EnKF that use perturbed observations. While this procedure gives asymptotically correct analysis-error covariance estimates for large ensembles, the addition of perturbed observations adds an additional source of sampling error related to the estimation of the observation-error covariances. In addition to reducing the accuracy of the analysis-error covariance estimate, this extra source of sampling error increases the probability that the analysis-error covariance will be underestimated. Because of this, ensemble data assimilation methods that use perturbed observations are expected to be less accurate than those which do not. Several ensemble filter formulations have recently been proposed that do not require perturbed observations. This study examines a particularly simple implementation called the ensemble square root filter, or EnSRF. The EnSRF uses the traditional Kalman gain for updating the ensemble mean but uses a “reduced” Kalman gain to update deviations from the ensemble mean. There is no additional computational cost incurred by the EnSRF relative to the EnKF when the observations have independent errors and are processed one at a time. Using a hierarchy of perfect model assimilation experiments, it is demonstrated that the elimination of the sampling error associated with the perturbed observations makes the EnSRF more accurate than the EnKF for the same ensemble size.},
	number = {7},
	urldate = {2018-07-05},
	journal = {Monthly Weather Review},
	author = {Whitaker, Jeffrey S. and Hamill, Thomas M.},
	month = jul,
	year = {2002},
	pages = {1913--1924}
}

@article{bishop_adaptive_2001,
	title = {Adaptive {Sampling} with the {Ensemble} {Transform} {Kalman} {Filter}. {Part} {I}: {Theoretical} {Aspects}},
	volume = {129},
	issn = {0027-0644},
	shorttitle = {Adaptive {Sampling} with the {Ensemble} {Transform} {Kalman} {Filter}. {Part} {I}},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/1520-0493(2001)129%3C0420:ASWTET%3E2.0.CO;2},
	doi = {10.1175/1520-0493(2001)129<0420:ASWTET>2.0.CO;2},
	abstract = {A suboptimal Kalman filter called the ensemble transform Kalman filter (ET KF) is introduced. Like other Kalman filters, it provides a framework for assimilating observations and also for estimating the effect of observations on forecast error covariance. It differs from other ensemble Kalman filters in that it uses ensemble transformation and a normalization to rapidly obtain the prediction error covariance matrix associated with a particular deployment of observational resources. This rapidity enables it to quickly assess the ability of a large number of future feasible sequences of observational networks to reduce forecast error variance. The ET KF was used by the National Centers for Environmental Prediction in the Winter Storm Reconnaissance missions of 1999 and 2000 to determine where aircraft should deploy dropwindsondes in order to improve 24–72-h forecasts over the continental United States. The ET KF may be applied to any well-constructed set of ensemble perturbations. The ET KF technique supercedes the ensemble transform (ET) targeting technique of Bishop and Toth. In the ET targeting formulation, the means by which observations reduced forecast error variance was not expressed mathematically. The mathematical representation of this process provided by the ET KF enables such things as the evaluation of the reduction in forecast error variance associated with individual flight tracks and assessments of the value of targeted observations that are distributed over significant time intervals. It also enables a serial targeting methodology whereby one can identify optimal observing sites given the location and error statistics of other observations. This allows the network designer to nonredundantly position targeted observations. Serial targeting can also be used to greatly reduce the computations required to identify optimal target sites. For these theoretical and practical reasons, the ET KF technique is more useful than the ET technique. The methodology is illustrated with observation system simulation experiments involving a barotropic numerical model of tropical cyclonelike vortices. These include preliminary empirical tests of ET KF predictions using ET KF, 3DVAR, and hybrid data assimilation schemes—the results of which look promising. To concisely describe the future feasible sequences of observations considered in adaptive sampling problems, an extension to Ide et al.’s unified notation for data assimilation is suggested.},
	number = {3},
	urldate = {2018-07-05},
	journal = {Monthly Weather Review},
	author = {Bishop, Craig H. and Etherton, Brian J. and Majumdar, Sharanya J.},
	month = mar,
	year = {2001},
	pages = {420--436}
}

@article{tippett_ensemble_2003,
	title = {Ensemble {Square} {Root} {Filters}},
	volume = {131},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/1520-0493(2003)131%3C1485:ESRF%3E2.0.CO;2},
	doi = {10.1175/1520-0493(2003)131<1485:ESRF>2.0.CO;2},
	abstract = {Ensemble data assimilation methods assimilate observations using state-space estimation methods and low-rank representations of forecast and analysis error covariances. A key element of such methods is the transformation of the forecast ensemble into an analysis ensemble with appropriate statistics. This transformation may be performed stochastically by treating observations as random variables, or deterministically by requiring that the updated analysis perturbations satisfy the Kalman filter analysis error covariance equation. Deterministic analysis ensemble updates are implementations of Kalman square root filters. The nonuniqueness of the deterministic transformation used in square root Kalman filters provides a framework to compare three recently proposed ensemble data assimilation methods.},
	number = {7},
	urldate = {2018-07-05},
	journal = {Monthly Weather Review},
	author = {Tippett, Michael K. and Anderson, Jeffrey L. and Bishop, Craig H. and Hamill, Thomas M. and Whitaker, Jeffrey S.},
	month = jul,
	year = {2003},
	pages = {1485--1490}
}

@article{hunt_efficient_2007,
	series = {Data {Assimilation}},
	title = {Efficient data assimilation for spatiotemporal chaos: {A} local ensemble transform {Kalman} filter},
	volume = {230},
	issn = {0167-2789},
	shorttitle = {Efficient data assimilation for spatiotemporal chaos},
	url = {http://www.sciencedirect.com/science/article/pii/S0167278906004647},
	doi = {10.1016/j.physd.2006.11.008},
	abstract = {Data assimilation is an iterative approach to the problem of estimating the state of a dynamical system using both current and past observations of the system together with a model for the system’s time evolution. Rather than solving the problem from scratch each time new observations become available, one uses the model to “forecast” the current state, using a prior state estimate (which incorporates information from past data) as the initial condition, then uses current data to correct the prior forecast to a current state estimate. This Bayesian approach is most effective when the uncertainty in both the observations and in the state estimate, as it evolves over time, are accurately quantified. In this article, we describe a practical method for data assimilation in large, spatiotemporally chaotic systems. The method is a type of “ensemble Kalman filter”, in which the state estimate and its approximate uncertainty are represented at any given time by an ensemble of system states. We discuss both the mathematical basis of this approach and its implementation; our primary emphasis is on ease of use and computational speed rather than improving accuracy over previously published approaches to ensemble Kalman filtering. We include some numerical results demonstrating the efficiency and accuracy of our implementation for assimilating real atmospheric data with the global forecast model used by the US National Weather Service.},
	number = {1},
	urldate = {2018-07-05},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Hunt, Brian R. and Kostelich, Eric J. and Szunyogh, Istvan},
	month = jun,
	year = {2007},
	keywords = {Data assimilation, Ensemble Kalman filtering, Spatiotemporal chaos, State estimation},
	pages = {112--126}
}

@inproceedings{kalnay_removing_1994,
	address = {Portland, OR},
	title = {Removing growing errors in the analysis cycle},
	booktitle = {Proceedings of the 10th conference on {Numerical} {Weather} {Prediction}, 18-22 {July}, 1994, {Portland}, {OR}},
	publisher = {American Meteorological Society},
	author = {Kalnay, Eugenia and Toth, Zoltan},
	year = {1994},
	pages = {212--215}
}

@article{bonavita_evolution_2015,
	title = {The evolution of the {ECMWF} hybrid data assimilation system},
	volume = {142},
	copyright = {© 2015 Royal Meteorological Society},
	issn = {1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/qj.2652},
	doi = {10.1002/qj.2652},
	abstract = {The trend towards using flow-dependent, ensemble-based estimates of background-error covariances has been one of the main themes of atmospheric data assimilation research and development in recent years. In this work it is documented how flow-dependent ensemble information from the ECMWF ensemble of data assimilations (EDA) has gradually been incorporated into the B model which describes the background-error covariance matrix at the start of the ECMWF 4D-Var assimilation window. Starting with background-error variances for the balanced part of the control vector and observation quality control, the current article extends the flow-dependency to background-error variances for the unbalanced part of the control vector and for background-error correlation structures. The correlations are determined either online from previous days or from a hybrid of climatological and current cycle estimates. Each of these changes is shown to improve both the realism of the modelled B and the accuracy of the analysis and forecast fields produced by the 4D-Var assimilation cycle which makes use of the improved B. Finally, increasing the resolution at which the EDA 4D-Vars are run is shown to reduce the underestimation of the EDA-based error estimates.},
	language = {en},
	number = {694},
	urldate = {2018-07-05},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Bonavita, Massimo and Hólm, Elias and Isaksen, Lars and Fisher, Mike},
	month = aug,
	year = {2015},
	keywords = {ensemble data assimilation, flow-dependent background-error covariances, hybrid 4D-Var},
	pages = {287--303}
}

@article{rabier_ecmwf_2000,
	title = {The {ECMWF} operational implementation of four-dimensional variational assimilation. {I}: {Experimental} results with simplified physics},
	volume = {126},
	copyright = {Copyright © 2000 Royal Meteorological Society},
	issn = {1477-870X},
	shorttitle = {The {ECMWF} operational implementation of four-dimensional variational assimilation. {I}},
	url = {https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/qj.49712656415},
	doi = {10.1002/qj.49712656415},
	abstract = {This paper presents results of a comparison between four-dimensional variational assimilation (4D-Var). using a 6-hour assimilation window and simplified physics during the minimization, and three-dimensional variational assimilation (3D-Var). Results have been obtained at ‘operational’ resolution T213L31/T63L31. (T defines the spectral triangular truncation and L the number of levels in the vertical, with the first parameters defining the resolution of the model trajectory, and the second the resolution of the inner-loop.) The sensitivity of the 4D-Var performance to different set-ups is investigated. In particular, the performance of 4D-Var in the Tropics revealed some sensitivity to the way the adiabatic nonlinear normal-mode initialization of the increments was performed. Going from four outer-loops to only one (as in 3D-Var), together with a change to the 1997 formulation of the background constraint and an initialization of only the small scales, helped to improve the 4D-Var performance. Tropical scores then became only marginally worse for 4D-Var than for 3D-Var. Twelve weeks of experimentation with the one outer-loop 4D-Var and the 1997 background formulation have been studied. The averaged scores show a small but consistent improvement in both hemispheres at all ranges. In the short range, each two- to three-week period has been found to be slightly positive throughout the troposphere. The better short-range performance of the 4D-Var system is also shown by the fits of the background fields to the data. More results are presented for the Atlantic Ocean area during FASTEX (the Fronts and Atlantic Storm-Track Experiment), during which 4D-Var is found to perform better. In individual synoptic cases corresponding to interesting Intensive Observing Periods, 4D-Var has a clear advantage over 3D-Var during rapid cyclogeneses. The very short-range forecasts used as backgrounds are much closer to the data over the Atlantic for 4D-Var than for 3D-Var. The 4D-Var analyses also display more day-to-day variability. Some structure functions are illustrated in the 4D-Var case for a height observation inserted at the beginning, in the middle or at the end of the assimilation window. The dynamical processes seem to be relevant, even with a short 6-hour assimilation period, which explains the better overall performance of the 4D-Var system.},
	language = {en},
	urldate = {2018-06-22},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Rabier, F. and Järvinen, H. and Klinker, E. and Mahfouf, J.-F. and Simmons, A.},
	year = {2000},
	keywords = {Adjoint models, Analysis, Variational assimilation},
	pages = {1143--1170}
}

@article{sasaki_objective_1958,
	title = {An {Objective} {Analysis} {Based} on the {Variational} {Method}},
	volume = {36},
	issn = {0026-1165, 2186-9057},
	url = {https://www.jstage.jst.go.jp/article/jmsj1923/36/3/36_3_77/_article},
	doi = {10.2151/jmsj1923.36.3_77},
	abstract = {Based on a simple principle, a method of obtaining an objective analysis is considered. Techniques of the calculus of variations are employed. Using this principle, two cases are studied. Case I is based on the assumption of quasi-geostrophic and thermal wind conditions. Case II is based on conditions defined by non-divergence and the “balance equation” which correspond to an equivalent barotropic flow. The method is demonstrated by three simple examples.},
	language = {en},
	number = {3},
	urldate = {2018-06-22},
	journal = {Journal of the Meteorological Society of Japan. Ser. II},
	author = {Sasaki, Y.},
	year = {1958},
	pages = {77--88}
}

@book{gandin_objective_1963,
	address = {Leningrad},
	title = {Objective analysis of meteorological fields},
	shorttitle = {Objective analysis of meteorological fields},
	publisher = {Gidrometeorologicheskoe Izdatel’stvo (GIMIZ)},
	author = {Gandin, L.},
	year = {1963},
	note = {Translated to English by the Israel Program for Scientific Translations}
}

@article{panofsky_objective_1949,
	title = {Objective weather-map analysis},
	volume = {6},
	issn = {0095-9634},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469%281949%29006%3C0386%3AOWMA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1949)006<0386:OWMA>2.0.CO;2},
	abstract = {Wind and pressure fields are fitted by third-degree polynomials in areas of the order of 106 square miles. Expressions involving derivatives of wind and pressure are computed and the question of computation of geostrophic deviations is re-examined. A method of connecting polynomials in separate areas is investigated. The following conclusions are drawn: 					  Isopleths and streamlines drawn from the polynomials greatly resemble subjective isopleths and streamlines. In all cases studied, the smoothing seems to be adequate.   Horizontal divergence and vertical velocities can be determined as well from the polynomials objectively as by other subjective methods. The errors of observation influence the magnitude of these quantities considerably, but usually do not affect the sign.   On the scale of these measurements, reliable pressure gradients can be obtained objectively; however, the Laplacian of pressure is very much affected by the technique of analysis and by observational errors.   Reliable values of the geostrophic deviations can be obtained only under favorable conditions. Hence any method of integration of the fundamental equations which requires knowledge of the geostrophic deviations is to be avoided.},
	number = {6},
	urldate = {2017-11-14},
	journal = {Journal of Meteorology},
	author = {Panofsky, R. A.},
	month = dec,
	year = {1949},
	pages = {386--392}
}

@book{daley_atmospheric_1991,
	title = {Atmospheric {Data} {Analysis}},
	isbn = {978-0-521-45825-2},
	abstract = {Atmospheric Data Analysis is intended to fill a void in the atmospheric science literature and curricula. The book is self contained, and includes topics important in several other fields outside atmospheric observation, including atmospheric dynamics and statistics. It outlines the physical and mathematical basis of all aspects of atmospheric analysis. The emphasis is on the theoretical foundation of the subject and most of the development is analytic, but many practical considerations and examples are introduced. There are numerous exercises at the end of each chapter to aid the student in comprehending the material.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Daley, Roger},
	year = {1991},
	note = {Google-Books-ID: RHM6pTMRTHwC},
	keywords = {Science / Earth Sciences / Meteorology \& Climatology}
}

@article{persson_early_2005,
	title = {Early operational {Numerical} {Weather} {Prediction} outside the {USA}: an historical {Introduction}. {Part} 1: {Internationalism} and engineering {NWP} in {Sweden}, 1952–69},
	volume = {12},
	copyright = {Copyright © 2005 Royal Meteorological Society},
	issn = {1469-8080},
	shorttitle = {Early operational {Numerical} {Weather} {Prediction} outside the {USA}},
	url = {https://rmets.onlinelibrary.wiley.com/doi/abs/10.1017/S1350482705001593},
	doi = {10.1017/S1350482705001593},
	language = {en},
	number = {2},
	urldate = {2018-06-22},
	journal = {Meteorological Applications},
	author = {Persson, Anders},
	year = {2005},
	pages = {135--159}
}

@article{persson_early_2005-1,
	title = {Early operational {Numerical} {Weather} {Prediction} outside the {USA}: an historical introduction: {Part} {II}: {Twenty} countries around the world},
	volume = {12},
	copyright = {Copyright © 2005 Royal Meteorological Society},
	issn = {1469-8080},
	shorttitle = {Early operational {Numerical} {Weather} {Prediction} outside the {USA}},
	url = {https://rmets.onlinelibrary.wiley.com/doi/abs/10.1017/S1350482705001751},
	doi = {10.1017/S1350482705001751},
	language = {en},
	number = {3},
	urldate = {2018-06-22},
	journal = {Meteorological Applications},
	author = {Persson, Anders},
	year = {2005},
	pages = {269--289}
}

@article{persson_early_2005-2,
	title = {Early operational {Numerical} {Weather} {Prediction} outside the {USA}: {An} historical introduction {Part} {III}: {Endurance} and mathematics - {British} {NWP}, 1948-1965},
	volume = {12},
	shorttitle = {Early operational {Numerical} {Weather} {Prediction} outside the {USA}},
	doi = {10.1017/S1350482705001933},
	abstract = {The Meteorological Office of the United Kingdom (UKMO) began its operational NWP in November 1965. This marked the start of very successful activity that would gradually bring it to the forefront of NWP development, where it stands today.},
	journal = {Meteorological Applications},
	author = {Persson, Anders},
	month = dec,
	year = {2005},
	pages = {381--413}
}

@article{bolin_carl-gustaf_1999-1,
	title = {Carl-{Gustaf} {Rossby} {The} {Stockholm} period 1947–1957},
	volume = {51},
	issn = {null},
	url = {https://doi.org/10.3402/tellusa.v51i1.12285},
	doi = {10.3402/tellusa.v51i1.12285},
	number = {1},
	urldate = {2018-06-22},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Bolin, Bert},
	month = jan,
	year = {1999},
	pages = {4--12}
}

@article{doos_upper-air_1957,
	title = {Upper-{Air} {Analysis} over {Ocean} {Areas1}},
	volume = {9},
	copyright = {1957 Blackwell Munksgaard},
	issn = {2153-3490},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.2153-3490.1957.tb01872.x},
	doi = {10.1111/j.2153-3490.1957.tb01872.x},
	abstract = {From the results of a test of numerical analyses of 500-mb charts over an ocean area it is concluded that the number of ocean station vessels is a minimum and that supplementary upper air data is required to ensure continuously reliable upper air analyses. A method of determining the mean lapse rate by interpolation is presented by means of which heights of upper pressure surfaces can be extrapolated from observed values of surface pressure and temperature. An attempt is made to determine statistically the true mean error in the numerical analysis of upper-air charts.},
	language = {en},
	number = {2},
	urldate = {2018-06-22},
	journal = {Tellus},
	author = {Döös, Bo R. and Eaton, Max A.},
	year = {1957},
	pages = {184--194}
}

@article{lorenz_predictability_1963,
	series = {Section of {Planetary} {Sciences}},
	title = {The {Predictability} of {Hydrodynamic} {Flow}},
	volume = {25},
	copyright = {1963 The New York Academy of Sciences},
	issn = {2164-0947},
	shorttitle = {Section of {Planetary} {Sciences}},
	url = {https://nyaspubs.onlinelibrary.wiley.com/doi/abs/10.1111/j.2164-0947.1963.tb01464.x},
	doi = {10.1111/j.2164-0947.1963.tb01464.x},
	language = {en},
	number = {4 Series II},
	urldate = {2018-06-22},
	journal = {Transactions of the New York Academy of Sciences},
	author = {Lorenz, Edward N.},
	month = feb,
	year = {1963},
	pages = {409--432}
}

@incollection{phillips_emergence_1990,
	address = {Boston, MA},
	title = {The emergence of quasi-geostrophic theory},
	isbn = {1-878220-03-9},
	language = {en},
	booktitle = {The {Atmosphere}---{A} {Challenge}: {The} {Science} of {Jule} {Gregory} {Charney}},
	publisher = {American Meteorological Society},
	author = {Phillips, N. A.},
	editor = {Lindzen, Richard S. and Lorenz, Edward N. and Platzman, George W.},
	year = {1990},
	pages = {177--206}
}

@article{rossby_planetary_1939,
	title = {Planetary flow patterns in the atmosphere},
	volume = {66},
	journal = {Quart. J. Roy. Met. Soc},
	author = {Rossby, C. G.},
	year = {1939},
	pages = {68--87}
}

@article{rossby_relation_1939,
	title = {Relation between variations in the intensity of the zonal circulation of the atmosphere and the displacements of the semi-permanent centers of action},
	volume = {2},
	journal = {Journal of Marine Research},
	author = {Rossby, Carl G.},
	year = {1939},
	pages = {38--55}
}

@article{charney_physical_1949,
	title = {On a physical basis for numerical prediction of large-scale motions in the atmosphere},
	volume = {6},
	issn = {0095-9634},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1949)006%3C0372:OAPBFN%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1949)006<0372:OAPBFN>2.0.CO;2},
	abstract = {The small-scale “noise” disturbances of the atmosphere create difficulties for the numerical integration of the equations of motion. For example, their existence demands that very small time differences be used in the integration of the finite-difference equations. To eliminate the noise, a filtering method is devised which consists essentially in replacing the primitive hydrodynamical equations by combining the geostrophic and hydrostatic equations with the conservation equations for potential temperature and potential vorticity. In this way a single equation in the pressure is obtained for the motion of the large-scale systems. A method is suggested for its numerical integration. The spread of data required for a short-period forecast is discussed in terms of the rate of spread of influences or “signal velocity” in the atmosphere. It is shown that a small disturbance is propagated both horizontally and vertically at a finite rate. Estimates are obtained for the maximum signal-velocity components in order to establish bounds for the influence region. It is found that numerical forecasts for periods of one or perhaps two days are now possible for certain areas of the earth but that forecasts for longer periods require a greater spread of observation stations than is available. A method is given for reducing the three-dimensional forecast problem to a two-dimensional one by construction of an “equivalent-barotropic” atmosphere. The method is applied to the calculation of the 5OO-mb height tendency, and the results are compared with observation. A rule is derived for determining the positions of the isallohyptic centers from the field of the absolute-vorticity advection.},
	number = {6},
	urldate = {2018-06-22},
	journal = {Journal of Meteorology},
	author = {Charney, J. G.},
	month = dec,
	year = {1949},
	pages = {372--385}
}

@article{charney_scale_1948,
	title = {On the scale of atmospheric motions},
	volume = {17},
	language = {en},
	number = {2},
	journal = {Geofysiske Publikasjoner},
	author = {Charney, Jule G.},
	year = {1948},
	pages = {3--17}
}

@article{charney_dynamics_1947,
	title = {The dynamics of long waves in a baroclinic westerly current},
	volume = {4},
	issn = {0095-9634},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1947)004%3C0136:TDOLWI%3E2.0.CO;2},
	doi = {10.1175/1520-0469(1947)004<0136:TDOLWI>2.0.CO;2},
	abstract = {Previous studies of the long-wave perturbations of the free atmosphere have been based on mathematical models which either fail to take properly into account the continuous vertical shear in the zonal current or else neglect the variations of the vertical component of the earth's angular velocity. The present treatment attempts to supply both these elements and thereby to lead to a solution more nearly in accord with the observed behavior of the atmosphere. By eliminating from consideration at the outset the meteorologically unimportant acoustic and shearing-gravitational oscillations, the perturbation equations are reduced to a system whose solution is readily obtained. Exact stability criteria are deduced, and it is shown that the instability increases with shear, lapse rate, and latitude, and decreases with wave length. Application of the criteria to the seasonal averages of zonal wind suggests that the westerlies of middle latitudes are a seat of constant dynamic instability. The unstable waves are similar in many respects to the observed perturbations: The speed of propagation is generally toward the east and is approximately equal to the speed of the surface zonal current. The waves exhibit thermal asymmetry and a westward tilt of the wave pattern with height. In the lower troposphere the maximum positive vertical velocities occur between the trough and the nodal line to the east in the pressure field. The distribution of the horizontal mass divergence is calculated, and it is shown that the notion of a fixed level of nondivergence must be replaced by that of a sloping surface of nondivergence. The Rossby formula for the speed of propagation of the barotropic wave is generalized to a baroclinic atmosphere. It is shown that the barotropic formula holds if the constant value used for the zonal wind is that observed in the neighborhood of 600 mb.},
	number = {5},
	urldate = {2018-06-22},
	journal = {Journal of Meteorology},
	author = {Charney, J. G.},
	month = oct,
	year = {1947},
	pages = {136--162}
}

@book{lynch_emergence_2006,
	title = {The {Emergence} of {Numerical} {Weather} {Prediction}: {Richardson}'s {Dream}},
	isbn = {978-0-521-85729-1},
	shorttitle = {The {Emergence} of {Numerical} {Weather} {Prediction}},
	abstract = {Lewis Fry Richardson dreamt that scientific weather prediction would one day become a practical reality. Before his ideas could bear fruit several advances were needed: better understanding of the dynamics of the atmosphere; stable computational algorithms to integrate the equations; regular observations of the free atmosphere; and powerful automatic computer equipment. By 1950 advances in all these fronts were sufficient to permit the first computer forecast to be made. Over the ensuing fifty years progress in numerical weather prediction has been dramatic. Weather prediction and climate modelling have now reached a high level of sophistication. This book, first published in 2006, tells the story of Richardson's trial forecast, and the fulfilment of his dream of practical numerical weather forecasting. It includes a complete reconstruction of Richardson's forecast, and analyses in detail the causes of his failure. This will appeal to everyone involved in numerical weather forecasting, from researchers and graduate students to professionals.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Lynch, Peter},
	month = nov,
	year = {2006},
	note = {Google-Books-ID: EV5bZqOO7kkC},
	keywords = {Science / Earth Sciences / Meteorology \& Climatology, Science / History}
}

@book{stensrud_parameterization_2007,
	title = {Parameterization {Schemes}: {Keys} to {Understanding} {Numerical} {Weather} {Prediction} {Models}},
	isbn = {978-0-521-86540-1},
	shorttitle = {Parameterization {Schemes}},
	abstract = {Numerical weather prediction models play an increasingly important role in meteorology, both in short- and medium-range forecasting and global climate change studies. The most important components of any numerical weather prediction model are the subgrid-scale parameterization schemes, and the analysis and understanding of these schemes is a key aspect of numerical weather prediction. This book provides in-depth explorations of the most commonly used types of parameterization schemes that influence both short-range weather forecasts and global climate models. Several parameterizations are summarised and compared, followed by a discussion of their limitations. Review questions at the end of each chapter enable readers to monitor their understanding of the topics covered, and solutions are available to instructors at www.cambridge.org/9780521865401. This will be an essential reference for academic researchers, meteorologists, weather forecasters, and graduate students interested in numerical weather prediction and its use in weather forecasting.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Stensrud, David J.},
	month = may,
	year = {2007},
	note = {Google-Books-ID: lMXSpRwKNO8C},
	keywords = {Science / Earth Sciences / Meteorology \& Climatology}
}

@book{durran_numerical_2010,
	title = {Numerical {Methods} for {Fluid} {Dynamics}: {With} {Applications} to {Geophysics}},
	isbn = {978-1-4419-6412-0},
	shorttitle = {Numerical {Methods} for {Fluid} {Dynamics}},
	abstract = {This scholarly text provides an introduction to the numerical methods used to model partial differential equations, with focus on atmospheric and oceanic flows. The book covers both the essentials of building a numerical model and the more sophisticated techniques that are now available. Finite difference methods, spectral methods, finite element method, flux-corrected methods and TVC schemes are all discussed. Throughout, the author keeps to a middle ground between the theorem-proof formalism of a mathematical text and the highly empirical approach found in some engineering publications. The book establishes a concrete link between theory and practice using an extensive range of test problems to illustrate the theoretically derived properties of various methods. From the reviews: "...the books unquestionable advantage is the clarity and simplicity in presenting virtually all basic ideas and methods of numerical analysis currently actively used in geophysical fluid dynamics." Physics of Atmosphere and Ocean},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Durran, Dale R.},
	month = sep,
	year = {2010},
	note = {Google-Books-ID: ThMZrEOTuuUC},
	keywords = {Mathematics / Numerical Analysis, Mathematics / Algebra / General, Mathematics / Number Systems, Science / Physics / Geophysics, Technology \& Engineering / Mechanical, Technology \& Engineering / Civil / General}
}

@article{kasahara_various_1974,
	title = {Various {Vertical} {Coordinate} {Systems} {Used} for {Numerical} {Weather} {Prediction}},
	volume = {102},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1974)102%3C0509:VVCSUF%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1974)102<0509:VVCSUF>2.0.CO;2},
	abstract = {For numerical weather prediction with primitive equations (the Eulerian hydrodynamic equations modified by the assumption of hydrostatic equilibrium), various coordinate systems are used to represent the vertical structure of the atmosphere. In this paper, we review the essential features of prediction equations, satisfying the conservation of mass and total energy, in various vertical coordinate systems. We formulate the equations of horizontal motion, hydrostatic balance, mass continuity, and thermodynamics using a generalized vertical coordinate in which any variable that gives a single-valued monotonic relationship with a geometric height can be used as a vertical coordinate. Conditions to conserve total energy in a generalized vertical coordinate are investigated. Various prediction schemes using pressure, height, and potential temperature as a vertical coordinate are derived from the set of basic equations in the generalized coordinate system. These three coordinate systems are unique in that the features of prediction equations in each system are all distinct. We place special emphasis on handling the earth's orography as the lower boundary condition. As an extension of the original idea of Phillips applied to the pressure-coordinate system, we propose transformed height and isentropic systems. In those systems, both the top of the model atmosphere and the earth's surface are always coordinate surfaces. It is hoped that these new schemes, as in the case of the Phillips' sigma-system, will enable us to handle the effect of the earth's orography in the prediction models without lengthy coding logic.},
	number = {7},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Kasahara, Akira},
	month = jul,
	year = {1974},
	pages = {509--522}
}

@article{koster_variance_2000,
	title = {Variance and {Predictability} of {Precipitation} at {Seasonal}-to-{Interannual} {Timescales}},
	volume = {1},
	issn = {1525-755X},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1525-7541(2000)001%3C0026:VAPOPA%3E2.0.CO%3B2},
	doi = {10.1175/1525-7541(2000)001<0026:VAPOPA>2.0.CO;2},
	abstract = {A series of atmospheric general circulation model simulations, spanning a total of several thousand years, is used to assess the impact of land surface and ocean boundary conditions on the seasonal-to-interannual variability and predictability of precipitation in a coupled modeling system. In the first half of the analysis, which focuses on precipitation variance, the contributions of ocean, atmosphere, and land processes to this variance are characterized, to first order, with a simple linear model. The resulting clean separation of the contributions leads to two results: 1) land and ocean processes have essentially different domains of influence, that is, the amplification of precipitation variance by land–atmosphere feedback is most important outside of the regions (mainly in the Tropics) that are most affected by sea surface temperatures; and 2) the strength of land–atmosphere feedback in a given region is controlled largely by the relative availability of energy and water there. In the second half of the analysis, the potential for seasonal-to-interannual predictability of precipitation is quantified under the assumption that all relevant surface boundary conditions (in the ocean and on land) are themselves perfectly predictable. Although the chaotic nature of the atmospheric circulation imposes fundamental limits on precipitation predictability in many regions, foreknowledge of sea surface temperature contributes significantly to predictability in the Tropics, and foreknowledge of land surface moisture state contributes significantly to predictability in transition zones between dry and humid climates. Thus, soil moisture initialization or assimilation in a seasonal-to-interannual forecasting system would be especially beneficial in these transition zones.},
	number = {1},
	urldate = {2017-11-01},
	journal = {Journal of Hydrometeorology},
	author = {Koster, Randal D. and Suarez, Max J. and Heiser, Mark},
	month = feb,
	year = {2000},
	pages = {26--46}
}

@article{kaas_using_1999,
	title = {Using tendency errors to tune the parameterisation of unresolved dynamical scale interactions in atmospheric general circulation models},
	volume = {51},
	issn = {null},
	url = {http://dx.doi.org/10.3402/tellusa.v51i5.14481},
	doi = {10.3402/tellusa.v51i5.14481},
	abstract = {A parameterisation of non-linear dynamical interactions with unresolved scales is needed inmost atmospheric models to ensure realistic fluxes of energy and enstrophy near and at thetruncation limit. In this paper, a minimisation of tendency errors in low to medium resolutionversions of the ARPEGE/IFS and the ECHAM4 spectral general circulation models is soughtin order to obtain spectral empirical interaction functions (EIFs) to be used in the formulationof horizontal diffusion. The tendency errors are calculated relative to high resolution adiabaticversions of the models themselves, meaning that the EIFs reflect all non-linear adiabatic processes.Different EIFs are obtained for vorticity, divergence and temperature. The most strikingfeature is that the vorticity and temperature EIFs have non-negligible negative values for lowwave numbers in large parts of the troposphere. This implies that these waves are enhanced inamplitude due to non-linear interactions with unresolved scales. For low resolution models thegeneration/dissipation of kinetic energy due to the interactions is not well parameterised byeither the standard horizontal diffusion in the models, or the EIFs computed here. When theEIFs are used in the formulation of horizontal diffusion it is seen that the kinetic energyspectrum is closer to observations than in the original model versions. Furthermore, the largescale systematic model errors are reduced in a medium resolution simulation, while less clearimprovement is seen in a simulation at low resolution. It is argued that the technique used inthis paper is quite general and may be used to develop a more realistic parameterisation ofunresolved dynamical scale interactions. The method should, with some modifications, also beapplicable in semi-Lagrangian spectral models and in grid point models.},
	number = {5},
	urldate = {2017-11-01},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Kaas, Eigil and Guldberg, Annette and May, Wilhelm and Déqué, Michel},
	month = jan,
	year = {1999},
	pages = {612--629}
}

@article{kasahara_use_1988,
	title = {Use of {Satellite} {Radiometric} {Imagery} {Data} for {Improvement} in the {Analysis} of {Divergent} {Wind} in the {Tropics}},
	volume = {116},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1988)116%3C0866:UOSRID%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1988)116<0866:UOSRID>2.0.CO;2},
	abstract = {A scheme is proposed to incorporate satellite radiometric imagery data into the specification of initial conditions for the National Meteorological Center (NMC) operational global prediction model in order to improve the analysis of the divergent wind field in the tropics. The basic assumptions are that outgoing longwave radiation (OLR) data can provide 1) the division between convective (upward motion) and clear sky (downward motion) areas, and 2) the height of convection cells. The intensity of ascending motion in the convective areas is estimated based on OLR data. The intensity of descending motion is evaluated from the thermodynamic energy balance between radiative cooling and adiabatic warming, since the local time change of temperature is small in the tropics. Once the vertical motion field is determined, the horizontal divergence field can be calculated from the mass continuity equation. Then, a divergent wind field is determined. The total wind is the sum of the new divergent wind and the rotational part, which is assumed to be unchanged. The proposed scheme is tested using the NMC analysis dataset of 21 January 1985 with satisfactory results.},
	number = {4},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Kasahara, Akira and Balgovind, Ramesh C. and Katz, B.},
	month = apr,
	year = {1988},
	pages = {866--883}
}

@article{ide_unified_1997,
	title = {Unified {Notation} for {Data} {Assimilation}: {Operational}, {Sequential} and {Variational} ({gtSpecial} {IssueltData} {Assimilation} in {Meteology} and {Oceanography}: {Theory} and {Practice})},
	volume = {75},
	shorttitle = {Unified {Notation} for {Data} {Assimilation}},
	number = {1B},
	journal = {Journal of the Meteorological Society of Japan. Ser. II},
	author = {Ide, Kayo and Courtier, Philippe and Ghil, Michael and Lorenc, Andrew C.},
	year = {1997},
	pages = {181--189}
}

@article{janjic_step-mountain_1994,
	title = {The {Step}-{Mountain} {Eta} {Coordinate} {Model}: {Further} {Developments} of the {Convection}, {Viscous} {Sublayer}, and {Turbulence} {Closure} {Schemes}},
	volume = {122},
	issn = {0027-0644},
	shorttitle = {The {Step}-{Mountain} {Eta} {Coordinate} {Model}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1994)122%3C0927:TSMECM%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1994)122<0927:TSMECM>2.0.CO;2},
	abstract = {The step-mountain eta model has shown a surprising skill in forecasting severe storms. Much of the credit for this should be given to the Betts and Miller (hereafter referred to as BM) convection scheme and the Mellor-Yamada (hereafter referred to as MY) planetary boundary layer (PBL) formulation. However, the eta model was occasionally producing heavy spurious precipitation over warm water, as well as widely spread light precipitation over oceans. In addition, the convective forcing, particularly the shallow one, could lead to negative entropy changes. As the possible causes of the problems, the convection scheme, the processes at the air-water interface, and the MY level 2 and level 2.5 PBL schemes were reexamined. A major revision of the BM scheme was made, a new marine viscous sublayer scheme was designed, and the MY schemes were retuned. The deep convective regimes are postulated to be characterized by a parameter called “cloud efficiency.” The relaxation time is extended for low cloud efficiencies and vice versa. It is also postulated that there is a range of reference equilibrium states. The specific reference state is chosen depending on the cloud efficiency. The treatment of the shallow cloud tops was modified, and the shallow reference humidity profiles are specified requiring that the entropy change be nonnegative. Over the oceans there are two layers: (a) a viscous sublayer with the vertical transports determined by the molecular diffusion, and (b) a layer above it with the vertical transports determined by the turbulence. The viscous sublayer operates in different regimes depending on the roughness Reynolds number. The MY level 2.5 turbulent kinetic energy (TKE) is initialized from above in the PBL, so that excessive TKE is dissipated at most places during the PBL spinup. The method for calculating the MY level 2.5 master length scale was rectified. To demonstrate the effects of the new schemes for the deep convection and the viscous sublayer, tests were made using two summer cases: one with heavy spurious precipitation, and another with a successful 36-h forecast of a tropical storm. The new schemes had dramatic positive impacts on the case with the spurious precipitation. The results were also favorable in the tropical storm case. The developments presented here were incorporated into the eta model in 1990. The details of further research will be reported elsewhere. The eta model became operational at the National Meteorological Center, Washington, D.C., in June 1993.},
	number = {5},
	urldate = {2017-10-19},
	journal = {Monthly Weather Review},
	author = {Janjić, Zaviša I.},
	month = may,
	year = {1994},
	pages = {927--945}
}

@article{klemp_simulation_1978,
	title = {The {Simulation} of {Three}-{Dimensional} {Convective} {Storm} {Dynamics}},
	volume = {35},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1978)035%3C1070:TSOTDC%3E2.0.CO;2},
	doi = {10.1175/1520-0469(1978)035<1070:TSOTDC>2.0.CO;2},
	abstract = {A new three-dimensional cloud model has been developed for investigating the dynamic character of convective storms. This model solves the compressible equations of motion using a splitting procedure which provides numerical efficiency by treating the sound wave modes separately. For the subgrid turbulence processes, a time-dependent turbulence energy equation is solved which depends on local buoyancy, shear and dissipation. First-order closure is applied to nearly conservative variables with eddy coefficients based on the computed turbulence energy. Open lateral boundaries are incorporated in the model that respond to internal forcing and permit gravity waves to propagate out of the integration domain with little apparent reflection. Microphysical processes are included in the model using a Kessler-type parameterization. Simulations conducted for an unsheared environment reveal that the updraft temperatures follow a moist adiabatic lapse rate and that the convection is dissipated by water loading of the updraft. The influence of a one-directional shear on the storm development is also investigated. A simulation with a veering and backing wind profile exhibits interesting features which include a double vortex circulation, cell splitting and, secondary cell formation.},
	number = {6},
	urldate = {2017-11-01},
	journal = {Journal of the Atmospheric Sciences},
	author = {Klemp, Joseph B. and Wilhelmson, Robert B.},
	month = jun,
	year = {1978},
	pages = {1070--1096}
}

@article{lorenz_predictability_1969,
	title = {The predictability of a flow which possesses many scales of motion},
	volume = {21},
	number = {3},
	journal = {Tellus},
	author = {Lorenz, Edward N.},
	year = {1969},
	pages = {289--307}
}

@article{juang_nmc_1994,
	title = {The {NMC} nested regional spectral model},
	volume = {122},
	number = {1},
	journal = {Monthly Weather Review},
	author = {Juang, Hann-Ming Henry and Kanamitsu, Masao},
	year = {1994},
	pages = {3--26}
}

@article{kalnay_ncep/ncar_1996,
	title = {The {NCEP}/{NCAR} 40-{Year} {Reanalysis} {Project}},
	volume = {77},
	issn = {0003-0007},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0477(1996)077%3C0437:TNYRP%3E2.0.CO;2},
	doi = {10.1175/1520-0477(1996)077<0437:TNYRP>2.0.CO;2},
	abstract = {The NCEP and NCAR are cooperating in a project (denoted “reanalysis”) to produce a 40-year record of global analyses of atmospheric fields in support of the needs of the research and climate monitoring communities. This effort involves the recovery of land surface, ship, rawinsonde, pibal, aircraft, satellite, and other data; quality controlling and assimilating these data with a data assimilation system that is kept unchanged over the reanalysis period 1957–96. This eliminates perceived climate jumps associated with changes in the data assimilation system. The NCEP/NCAR 40-yr reanalysis uses a frozen state-of-the-art global data assimilation system and a database as complete as possible. The data assimilation and the model used are identical to the global system implemented operationally at the NCEP on 11 January 1995, except that the horizontal resolution is T62 (about 210 km). The database has been enhanced with many sources of observations not available in real time for operations, provided by different countries and organizations. The system has been designed with advanced quality control and monitoring components, and can produce 1 mon of reanalysis per day on a Cray YMP/8 supercomputer. Different types of output archives are being created to satisfy different user needs, including a “quick look” CD-ROM (one per year) with six tropospheric and stratospheric fields available twice daily, as well as surface, top-of-the-atmosphere, and isentropic fields. Reanalysis information and selected output is also available on-line via the Internet (http//:nic.fb4.noaa.gov:8000). A special CD-ROM, containing 13 years of selected observed, daily, monthly, and climatological data from the NCEP/NCAR Re-analysis, is included with this issue. Output variables are classified into four classes, depending on the degree to which they are influenced by the observations and/or the model. For example, “C” variables (such as precipitation and surface fluxes) are completely determined by the model during the data assimilation and should be used with caution. Nevertheless, a comparison of these variables with observations and with several climatologies shows that they generally contain considerable useful information. Eight-day forecasts, produced every 5 days, should be useful for predictability studies and for monitoring the quality of the observing systems. The 40 years of reanalysis (1957–96) should be completed in early 1997. A continuation into the future through an identical Climate Data Assimilation System will allow researchers to reliably compare recent anomalies with those in earlier decades. Since changes in the observing systems will inevitably produce perceived changes in the climate, parallel reanalyses (at least 1 year long) will be generated for the periods immediately after the introduction of new observing systems, such as new types of satellite data. NCEP plans currently call for an updated reanalysis using a state-of-the-art system every five years or so. The successive reanalyses will be greatly facilitated by the generation of the comprehensive database in the present reanalysis.},
	number = {3},
	urldate = {2017-10-18},
	journal = {Bulletin of the American Meteorological Society},
	author = {Kalnay, E. and Kanamitsu, M. and Kistler, R. and Collins, W. and Deaven, D. and Gandin, L. and Iredell, M. and Saha, S. and White, G. and Woollen, J. and Zhu, Y. and Leetmaa, A. and Reynolds, R. and Chelliah, M. and Ebisuzaki, W. and Higgins, W. and Janowiak, J. and Mo, K. C. and Ropelewski, C. and Wang, J. and Jenne, Roy and Joseph, Dennis},
	month = mar,
	year = {1996},
	pages = {437--471}
}

@article{juang_ncep_1997,
	title = {The {NCEP} regional spectral model: an update},
	volume = {78},
	shorttitle = {The {NCEP} regional spectral model},
	number = {10},
	journal = {Bulletin of the American Meteorological Society},
	author = {Juang, Hann-Ming Henry and Hong, Song-You and Kanamitsu, Masao},
	year = {1997},
	pages = {2125--2143}
}

@article{rabier_ecmwf_1998,
	title = {The {ECMWF} implementation of three-dimensional variational assimilation ({3D}-{Var}). {II}: {Structure} functions},
	volume = {124},
	issn = {1477-870X},
	shorttitle = {The {ECMWF} implementation of three-dimensional variational assimilation ({3D}-{Var}). {II}},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49712455003/abstract},
	doi = {10.1002/qj.49712455003},
	abstract = {Structure functions for the 3D-Var assimilation scheme of the European Centre for Medium-Range Weather Forecasts are evaluated from statistics of the differences between two forecasts valid at the same time. Results compare satisfactorily with those reported in the existing literature. Non-separability of the correlation functions is a pervasive feature. Accounting for non-separability in 3D-Var is necessary to reproduce geostrophic characteristics of the statistics, such as the increase of length-scale with height for the horizontal correlation of the mass variable, sharper vertical correlations for wind than for mass and shorter horizontal length-scales for temperature than for mass. In our non-separable 3D-Var, the vertical correlations vary with total wave-number and the horizontal correlation functions vary with vertical level.},
	language = {en},
	number = {550},
	urldate = {2017-11-01},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Rabier, F. and McNally, A. and Andersson, E. and Courtier, P. and Undén, P. and Eyre, J. and Hollingsworth, A. and Bouttier, F.},
	month = jul,
	year = {1998},
	keywords = {Data assimilation, Numerical weather prediction, Objective analysis, Structure functions},
	pages = {1809--1829}
}

@article{kalnay-rivas_4th_1977,
	title = {The 4th order {GISS} model of the global atmosphere},
	url = {https://ntrs.nasa.gov/search.jsp?R=19770066699},
	abstract = {The new GISS 4th order model of the global atmosphere is described. It is based on 4th order quadratically conservative differences with the periodic application of a 16th order filter on the sea level pressure and potential temperature equations, a combination which is approximately enstrophy conserving. Several short range forecasts indicate a significant improvement over 2nd order forecasts with the same resolution . However the 4th order forecasts are somewhat inferior to 2nd order forecasts with double resolution. This is probably due to the presence of short waves in the range between 1000 km and 2000 km, which are computed more accurately by the 2nd order high resolution model. An operation count of the schemes indicates that with similar code optimization, the 4th order model will require approximately the same amount of computer time as the 2nd order model with the same resolution. It is estimated that the 4th order model with a grid size of 200 km provides enough accuracy to make horizontal truncation errors negligible over a period of a week for all synoptic scales .},
	urldate = {2017-11-01},
	author = {Kalnay-Rivas, E. Bayliss},
	month = jan,
	year = {1977},
	keywords = {mathematical models, atmospheric models, computerized simulation, finite difference theory, global atmospheric research program, numerical weather forecasting, synoptic meteorology, truncation errors},
	annote = {Document ID: 19770066699; Accession Number: 77A49551; Subject Category: METEOROLOGY AND CLIMATOLOGY; Publisher Information: Germany; Financial Sponsor: NASA; United States; Organization Source: NASA Goddard Inst. for Space Studies; New York, NY, United StatesMassachusetts Inst. of Tech.; Cambridge, MA, United StatesNASA Langley Research Center; Hampton, VA, United States; Description: 13p; In English; Imprint And Other Notes: Beitraege zur Physik der Atmosphaere, vol. 50, no. 3, 1977, p. 299-311.},
	annote = {Document ID: 19770066699; Accession Number: 77A49551; Subject Category: METEOROLOGY AND CLIMATOLOGY; Publisher Information: Germany; Financial Sponsor: NASA; United States; Organization Source: NASA Goddard Inst. for Space Studies; New York, NY, United StatesMassachusetts Inst. of Tech.; Cambridge, MA, United StatesNASA Langley Research Center; Hampton, VA, United States; Description: 13p; In English; Imprint And Other Notes: Beitraege zur Physik der Atmosphaere, vol. 50, no. 3, 1977, p. 299-311.}
}

@book{jazwinski_stochastic_2007,
	title = {Stochastic {Processes} and {Filtering} {Theory}},
	isbn = {978-0-486-46274-5},
	abstract = {This unified treatment of linear and nonlinear filtering theory presents material previously available only in journals, and in terms accessible to engineering students. Its sole prerequisites are advanced calculus, the theory of ordinary differential equations, and matrix analysis. Although theory is emphasized, the text discusses numerous practical applications as well. Taking the state-space approach to filtering, this text models dynamical systems by finite-dimensional Markov processes, outputs of stochastic difference, and differential equations. Starting with background material on probability theory and stochastic processes, the author introduces and defines the problems of filtering, prediction, and smoothing. He presents the mathematical solutions to nonlinear filtering problems, and he specializes the nonlinear theory to linear problems. The final chapters deal with applications, addressing the development of approximate nonlinear filters, and presenting a critical analysis of their performance.},
	language = {en},
	publisher = {Courier Corporation},
	author = {Jazwinski, Andrew H.},
	year = {2007},
	keywords = {Mathematics / Probability \& Statistics / Bayesian Analysis, Science / Applied Sciences}
}

@article{simmons_stability_1997,
	title = {Stability of a {Two}-{Time}-{Level} {Semi}-{Implicit} {Integration} {Scheme} for {Gravity} {Wave} {Motion}},
	volume = {125},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1997)125%3C0600%3ASOATTL%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1997)125<0600:SOATTL>2.0.CO;2},
	abstract = {A study is made of the computational stability of semi-implicit treatments of gravity wave motion suitable for use with two-time-level advection schemes. The analysis is for horizontally uniform reference values of temperature and surface pressure, and for hybrid pressure-based vertical coordinates. Stability requires the use of reference temperatures that are warmer than those that can be used safely with the corresponding three-time-level scheme. The reference surface pressure should also be higher. When stable, the two-time-level scheme is damping, although the largest scales are damped less than by the three-time-level scheme if the latter uses a typical time filtering. The first-order decentered averaging of gravity wave tendencies used in a number of semi-Lagrangian models reduces the need for a relatively warm reference temperature profile but causes a quite substantial damping of otherwise well-represented low-wavenumber modes. The low-wavenumber damping can be avoided by using an alternative, second-order averaging involving a third (past) time level. For this alternative averaging, an economical spatial discretization is proposed that requires no additional departure point. Phase speeds show little sensitivity to these changes in formulation. All variants of the semi-implicit method substantially reduce the phase speeds of the fastest high-wavenumber modes when use is made of the large time steps possible with semi-Lagrangian advection.},
	number = {4},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Simmons, A. J. and Temperton, C.},
	month = apr,
	year = {1997},
	pages = {600--615}
}

@article{jones_simulation_1995,
	title = {Simulation of climate change over europe using a nested regional-climate model. {I}: {Assessment} of control climate, including sensitivity to location of lateral boundaries},
	volume = {121},
	shorttitle = {Simulation of climate change over europe using a nested regional-climate model. {I}},
	number = {526},
	journal = {Quarterly journal of the Royal meteorological society},
	author = {Jones, R. G. and Murphy, J. M. and Noguer, M.},
	year = {1995},
	keywords = {Atmosphere-ocean model, European climate, Nested models, Regional-climate simulation},
	pages = {1413--1449}
}

@article{staniforth_semi-lagrangian_1990,
	title = {Semi-{Lagrangian} {Integration} {Schemes} for {Atmospheric} {Models}—{A} {Review}},
	volume = {119},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1991)119%3C2206:SLISFA%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1991)119<2206:SLISFA>2.0.CO;2},
	abstract = {The semi-Lagrangian methodology is described for a hierarchy of applications (passive advection, forced advection, and coupled sets of equations) of increasing complexity, in one, two, and three dimensions. Attention is focused on its accuracy, stability, and efficiency properties. Recent developments in applying semi-Lagrangian methods to 2D and 3D atmospheric flows in both Cartesian and spherical geometries are then reviewed. Finally, the current status of development is summarized, followed by a short discussion of future perspectives.},
	number = {9},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Staniforth, Andrew and Côté, Jean},
	month = sep,
	year = {1990},
	pages = {2206--2223}
}

@article{kasahara_significance_1982,
	title = {Significance of {Non}-{Elliptic} {Regions} in {Balanced} {Flows} of the {Tropical} {Atmosphere}},
	volume = {110},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1982)110%3C1956:SONERI%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1982)110<1956:SONERI>2.0.CO;2},
	abstract = {Recently, questions were raised concerning the ellipticity condition of the traditional balance equation, related to the application of nonlinear normal mode initialization for primitive equation prediction models. We investigate, in this paper, the occurrence of non-elliptic regions, using the FWE level IIIb analyses of the European Centre for Medium Range Weather Forecasts. We found that non-elliptic regions are ubiquitous in the tropics. For the traditional balance equation, non-elliptic regions are not realizable in the sense that balanced flows are not physically possible. To reconcile this dilemma, we postulate that the traditional balance equation lacks an additional term due, for example, to the effects of subgrid-scale motions. We evaluated this additional term as the residual by computing each term in the balance equation. This additional term modifies the ellipticity criterion of the balance equation. We call the modified ellipticity condition the realizability condition. This study concludes that the non-elliptic regions found in the tropics satisfy the realizability condition when this additional term in the balance equation is considered. This suggests that the apparent dilemma may be resolved by taking into account presently lacking physical processes in achieving the dynamical balance between the mass and wind fields, if the FGGE level IIIb analyses are supposed to be correct.},
	number = {12},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Kasahara, Akira},
	month = dec,
	year = {1982},
	pages = {1956--1967}
}

@article{krishnamurti_reduction_1988,
	title = {Reduction of the {Spinup} {Time} for {Evaporation} and {Precipitation} in a {Spectral} {Model}},
	volume = {116},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1988)116%3C0907:ROTSTF%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1988)116<0907:ROTSTF>2.0.CO;2},
	abstract = {A dynamic relaxation technique is examined to update a spectral model. The technique consists of constraining selected time dependent model variables towards their predetermined space–time estimates, while the remaining variables evolve unconstrained. The scheme involves gradual assimilation of data and thus is essentially free from data insertion shocks generally associated with data assimilation schemes. The scheme can also be used to update the model variables consistent with the observed estimates of diabatic forcings. The spectral formulation is particularly suited to relax the current estimates of model variables towards their observed estimates scale-by-scale. The scheme has been applied to initialize model variables by relaxing vorticity, divergence and total mass (surface pressure) fields through one to three observation periods using an 11-layer model with T-42 spectral resolution. In addition, the moisture field and diabatic heating rates have been relaxed consistent with the observed estimates of precipitation rates. The explicit two-day Newtonian relaxation of the streamfunction, velocity potential (consistent with rainfall estimates) and the surface pressure and an implicit treatment of the humidity (again consistent with rainfall estimates) results in a realistic initialization. Tropical rainfall, humidity analysis and the divergence field show considerable consistency and improvement. The study addresses the model initialization by this scheme and its impact on medium range forecasts using FGGE IIIb data. The reduction of the spinup time is accomplished by this procedure at the initial time. Globally averaged evaporation and precipitation exhibit an equilibration by this procedure. A major result of this study is the ability to initialize an observed rainfall field from the use of a reverse Kuo algorithm, the Newtonian relaxation and the overall physical initialization within this model.},
	number = {4},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Krishnamurti, T. N. and Bedi, H. S. and Heckley, William and Ingles, Kevin},
	month = apr,
	year = {1988},
	pages = {907--920}
}

@article{kobayashi_seasonal_2000,
	title = {Seasonal predictability in winter over eastern {Asia} using the {JMA} global model},
	volume = {126},
	number = {567},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Kobayashi, Chiaki and Takano, Kiyoharu and Kusunoki, Shoji and Sugi, Masato and Kitoh, Akio},
	year = {2000},
	keywords = {Numerical weather prediction, Ensemble forecasting, General circulation model},
	pages = {2111--2123}
}

@article{kanamitsu_recent_1991,
	title = {Recent {Changes} {Implemented} into the {Global} {Forecast} {System} at {NMC}},
	volume = {6},
	issn = {0882-8156},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0434(1991)006%3C0425:RCIITG%3E2.0.CO%3B2},
	doi = {10.1175/1520-0434(1991)006<0425:RCIITG>2.0.CO;2},
	abstract = {A number of improvements were implemented on 6 March 1991 into the National Meteorological Center's global model, which is used in the global data assimilation system (GDAS), the aviation (AVN) forecast, and the medium-range forecast (MRF): 					  The horizontal resolution of the forecast model was increased from triangular truncation T80 to T126, which corresponds to an equivalent increase in grid resolution from 160 km to 105 km.   The use of enhanced orography has been discontinued and replaced by mean orography.   A new marine-stratus parameterization was introduced.   A new mass-conservation constraint was implemented.   The horizontal diffusion in the medium scales was reduced by adopting the Leith formulation.   A new, more accurate sea-surface temperature analysis is now used.    In this note, we discuss each of the changes and briefly review the new model performance.},
	number = {3},
	urldate = {2017-11-01},
	journal = {Weather and Forecasting},
	author = {Kanamitsu, M. and Alpert, J.c. and Campana, K.a. and Caplan, P.m. and Deaven, D.g. and Iredell, M. and Katz, B. and Pan, H.-L. and Sela, J. and White, G.h.},
	month = sep,
	year = {1991},
	pages = {425--435}
}

@article{julian_properties_1975,
	title = {On {Some} {Properties} of {Correlation} {Functions} {Used} in {Optimum} {Interpolation} {Schemes}},
	volume = {103},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1975)103%3C0605:OSPOCF%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1975)103<0605:OSPOCF>2.0.CO;2},
	abstract = {Objective analyses using the so-called method of optimum interpolation incorporates statistical information on the variable(s) by means of the covariance or correlation functions. The concern in this contribution is with some properties of the analytic forms of the correlation functions that are used to model the statistical structure. First, some attention is directed to the question of fitting the various analytic forms (containing adjustable constants) to samples of actual correlations. All but one of the candidate forms were indistinguishable on the basis of the residuals of the statistical fitting procedure. Second, the criterion of positive-definiteness of the correlation function is extended to stipulate that the transform (or spectrum) of the function should possess some features of the spectra of actual variables—the most important one being the spectral decay rate at high wavenumber. Again, all but one of the candidate forms (the same one as above) had transforms that were acceptable. Third, the degree of isotropy of the correlation fields is examined, both for scalar variables (geopotential, temperature) and for the wind field. Finally, the imposition of geostrophy requires some special considerations on the form of the correlation function. For all of these properties a variety of suggested analytic forms are compared and conclusions drawn.},
	number = {7},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Julian, Paul R. and Thiebaux, H. Jean},
	month = jul,
	year = {1975},
	pages = {605--616}
}

@article{janjic_pressure_1989,
	title = {On the pressure gradient force error in σ-coordinate spectral models},
	volume = {117},
	number = {10},
	journal = {Monthly Weather Review},
	author = {Janjić, Zavis̆a I.},
	year = {1989},
	pages = {2285--2292}
}

@article{klein_objective_1959,
	title = {Objective prediction of five-day mean temperatures during winter},
	volume = {16},
	issn = {0095-9634},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1959)016%3C0672:OPOFDM%3E2.0.CO;2},
	doi = {10.1175/1520-0469(1959)016<0672:OPOFDM>2.0.CO;2},
	abstract = {A statistical screening procedure is used to derive linear multiple-regression equations which express 5-day mean surface temperature as a function of 5-day mean 700-mb heights centered 2 days earlier. Application of these equations to heights obtained from barotropic prognoses would have produced temperature predictions of positive skill during the test winter of 1957–58. The forecasts can be considerably improved by including as a predictor the local value of 5-day mean surface temperature for a period 4 days earlier than the forecast period. When this term was combined with the barotropically-estimated heights, objective temperature predictions comparable in accuracy to conventional forecasts were made by multiple-regression equations. Further work is in progress to obtain additional improvement by screening the entire field of surface temperature.},
	number = {6},
	urldate = {2017-11-01},
	journal = {Journal of Meteorology},
	author = {Klein, William H. and Lewis, Billy M. and Enger, Isadore},
	month = dec,
	year = {1959},
	pages = {672--682}
}

@book{mesinger_numerical_1976,
	title = {Numerical methods used in atmospheric models},
	volume = {1},
	publisher = {World Meteorological Organization, International Council of Scientific Unions},
	author = {Mesinger, Fedor and Arakawa, Akio and Sundqvist, Hilding},
	year = {1976}
}

@article{julian_objective_1984,
	title = {Objective {Analysis} in the {Tropics}: {A} {Proposed} {Scheme}},
	volume = {112},
	issn = {0027-0644},
	shorttitle = {Objective {Analysis} in the {Tropics}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1984)112%3C1752%3AOAITTA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1984)112<1752:OAITTA>2.0.CO;2},
	abstract = {The tropical wind field presents some unique problems to an assimilation scheme designed for extratropical latitudes. Foremost among these is the relative increased importance of the divergent component of the upper and lower troposphere. Examination of tropical wind field analyses from conventional assimilation schemes points to some unsatisfactory results. Because of these problems an algorithm is proposed which is intended to handle the rotational and divergent components separately. The divergent component is estimated by transforming satellite-observed outgoing longwave radiation to a velocity potential field. The full analysis is then obtained by statistical optimum interpolation (OI) using a guess field which is an addition of a rotational forecast field with the divergent field estimated above. The scheme is tested against a conventional (single-level) OI scheme for a number of cases selected from the FGGE year. The proposed scheme is shown to perform comparably to the conventional OI scheme in regions of dense conventional observed data and, by induction, to be superior in areas of insufficient data.},
	number = {9},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Julian, Paul R.},
	month = sep,
	year = {1984},
	pages = {1752--1767}
}

@article{kasahara_normal_1976,
	title = {Normal {Modes} of {Ultralong} {Waves} in the {Atmosphere}},
	volume = {104},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1976)104%3C0669:NMOUWI%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1976)104<0669:NMOUWI>2.0.CO;2},
	abstract = {Spherical harmonics have been used to analyze global meteorological data, and because they are the solutions of a linearized nondivergent vorticity equation, it is appropriate to use them as orthogonal basis functions for analysis and prediction. However, for ultralong waves—geostrophic motions of the second type—horizontal divergence plays as essential a role as the vertical component of vorticity. Hence, it will be advantageous to use the solutions of linearized primitive equations over a sphere as basis functions. This will also permit identification of the characteristics of wave motions for the initialization of primitive equation models. Such solutions have been investigated in the past in conjunction with atmospheric tidal theories and the basic mathematical tools already available piecewise in the literature. This paper reviews the mathematical development behind the construction of the eigensolutions (referred to as normal modes) of linearized primitive equations over a sphere. The basic state has no motion and the temperature is a function of height only. The solutions of both the vertical and horizontal structure equations are discussed. The horizontal parts of such normal modes are called Hough harmonics Θsl exp (isλ), where s is zonal wavenumber, λ longitude and l meridional mode index. Hough vector functions Θsl consist of three components—zonal velocity Û, meridional velocity V̂ and geopotential height Ẑ, all of which are functions of latitude. There are three modes with distinct frequencies: eastward and westward propagating gravity waves, and westward propagating rotational waves of the Rossby/Haurwitz type. Hough harmonics are orthogonal and are conveniently used to decompose wind and mass fields simultaneously. Some examples are presented of global data decomposition in terms of Hough harmonics for studying ultralong waves in the atmosphere.},
	number = {6},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Kasahara, Akira},
	month = jun,
	year = {1976},
	pages = {669--690}
}

@article{kitade_nonlinear_1983,
	title = {Nonlinear {Normal} {Mode} {Initialization} with {Physics}},
	volume = {111},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1983)111%3C2194:NNMIWP%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1983)111<2194:NNMIWP>2.0.CO;2},
	abstract = {The nonlinear normal mode initialization with physics was applied for analyses in FGGE IIIb data of the European Center for Medium Range Weather Forecasting (ECMWF). A convergence of the iteration in the initialization was attained by modifying the correction increment for gravity modes in the Machenhauer scheme. The initialized field with physics contains reasonable magnitude of divergence wind as compared with the analysis. The difference of the initialized fields with and without physics is Described in some detail. The impact of initialization on the force is examined for some tropical disturbances. It has been found that the initialization affects the evolution of tropical disturbances through the change of convective heating in the forecast.},
	number = {11},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Kitade, Takeo},
	month = nov,
	year = {1983},
	pages = {2194--2213}
}

@article{janjic_nonlinear_1984,
	title = {Nonlinear {Advection} {Schemes} and {Energy} {Cascade} on {Semi}-{Staggered} {Grids}},
	volume = {112},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1984)112%3C1234:NASAEC%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1984)112<1234:NASAEC>2.0.CO;2},
	abstract = {A common problem with nonlinear advection schemes is the false accumulation of energy at the smallest resolvable scales. To keep this process under control, following Arakawa (1966), a number of energy and enstrophy conserving schemes for staggered and semi-staggered grids have been designed. In this paper, it is demonstrated that, in contrast to the staggered grid, the conservation of energy and enstrophy on the semi-staggered gods does not guarantee that the erroneous transport of energy from large to small scales will be effectively restricted. Using a new approach to the application of the Arakawa Jacobian, a scheme for a semi-staggered grid which exactly reflects the Arakawa theory for nondivergent flow is obtained for the first time. This is achieved by conservation of energy and enstrophy as defined on the staggered grid. These two quantities are of higher accuracy and cannot be calculated directly from the dependent variables on the semi-staggered grid. It is further demonstrated that the amount of energy which can be transported toward smaller scales is more restricted than for any other scheme of this type on both staggered and semi-staggered grid. Experiments performed with the proposed scheme and a scheme which conserves energy and enstrophy as defined on the semi-staggered grid reveal visible differences in long-term integrations which are in agreement with the theory and demonstrate the advantages of the new scheme.},
	number = {6},
	urldate = {2017-10-19},
	journal = {Monthly Weather Review},
	author = {Janjić, Zavisa I.},
	month = jun,
	year = {1984},
	pages = {1234--1245}
}

@article{kalman_new_1961,
	title = {New results in linear filtering and prediction theory},
	volume = {83},
	number = {1},
	journal = {Journal of basic engineering},
	author = {Kalman, Rudolph E. and Bucy, Richard S.},
	year = {1961},
	pages = {95--108}
}

@article{bergman_multivariate_1979,
	title = {Multivariate {Analysis} of {Temperatures} and {Winds} {Using} {Optimum} {Interpolation}},
	volume = {107},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1979)107%3C1423%3AMAOTAW%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1979)107<1423:MAOTAW>2.0.CO;2},
	abstract = {The design of a statistical “optimum interpolation” analysis system for multivariate analysis of temperature and wind fields is described. The scheme uses three-dimensional correlation functions, defined as products of quasi-horizontal and vertical correlations. A numerical prediction is used to provide background fields, and corrections to them are obtained using optimum interpolation. Observations are assigned rms error levels, and for some observational types the errors are assumed to be vertically or laterally correlated. A procedure for using oceanic surface data in the upper air analysis is included. Some special design features, including data selection and error-checking procedures, are discussed. The mechanics of the analysis system are illustrated with a step-by-step example analysis. Several experimental analyses are compared in order to illustrate sensitivity of the analysis scheme to changes in design features and governing parameters.},
	number = {11},
	urldate = {2017-11-06},
	journal = {Monthly Weather Review},
	author = {Bergman, Kenneth H.},
	month = nov,
	year = {1979},
	pages = {1423--1444}
}

@article{kirtman_multiseasonal_1997,
	title = {Multiseasonal {Predictions} with a {Coupled} {Tropical} {Ocean}–{Global} {Atmosphere} {System}},
	volume = {125},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1997)125%3C0789%3AMPWACT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1997)125<0789:MPWACT>2.0.CO;2},
	abstract = {The Center for Ocean–Land–Atmosphere Studies anomaly coupled prediction system, using a sophisticated dynamical model of the tropical Pacific Ocean and the global atmosphere, is described. The resolution of the component models is moderate, with the atmospheric spectral model truncated at triangular total wavenumber 30 and 18 vertical levels. The ocean model is a Pacific Basin model with 0.5° latitude and 1.5° longitude resolution in the waveguide and 20 vertical levels. The performance of the uncoupled component models motivates the anomaly coupling strategy and has led to the development of a simple empirical technique for converting the 850-mb zonal wind into a zonal surface stress that is used in the prediction experiments described here. In developing ocean initial conditions, an iterative procedure that assimilates the zonal wind stress based on the simulated sea surface temperature anomaly error is applied. Based on a sample of 78 18-month hindcasts, the predictions have useful skill in the Nino-3 region for at least 12 months. The systematic error of the predictions is shown to be relatively small because the ocean initial conditions are in reasonable equilibrium with the ocean model. Finally, composites of the hindcast warm El Niño–Southern Oscillation (ENSO) events indicate that the model simulates the basic features of ENSO, but there are errors in the horizontal structure of the sea surface temperature anomaly that potentially limit the predictability of the model.},
	number = {5},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Kirtman, Ben P. and Shukla, J. and Huang, Bohua and Zhu, Zhengxin and Schneider, Edwin K.},
	month = may,
	year = {1997},
	pages = {789--808}
}

@book{kreiss_methods_1973,
	title = {Methods for the approximate solution of time dependent problems},
	number = {10},
	publisher = {International Council of Scientific Unions, World Meteorological Organization},
	author = {Kreiss, Heinz and Kreiss, Heinz-Otto and Oliger, Joseph},
	year = {1973},
	keywords = {Weather forecasting, mathematical models, Numerical analysis, numerical weather forecasting, Atmospheric thermodynamics, Differential equations, Differential equations, Hyperbolic, Fluid dynamics, Meteorologiese navorsing, Nets (Mathematics), Numeriese weervoorspelling}
}

@article{kalnay_maturity_1998,
	title = {Maturity of {Operational} {Numerical} {Weather} {Prediction}: {Medium} {Range}},
	volume = {79},
	issn = {0003-0007},
	shorttitle = {Maturity of {Operational} {Numerical} {Weather} {Prediction}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0477(1998)079%3C2753%3AMOONWP%3E2.0.CO%3B2},
	doi = {10.1175/1520-0477(1998)079<2753:MOONWP>2.0.CO;2},
	abstract = {In 1939 Rossby demonstrated the usefulness of the linearized perturbation of the equations of motion for weather prediction and thus made possible the first successful numerical forecasts of the weather by Charney et al. In 1951 Charney wrote a paper on the science of numerical weather prediction (NWP), where he predicted with remarkable vision how NWP would evolve until the present. In the 1960's Lorenz discovered that the chaotic nature of the atmosphere imposes a finite limit of about two weeks to weather predictability. At that time this fundamental discovery was “only of academic interest” and not really relevant to operational weather forecasting, since at that time the accuracy of even a 2-day forecast was rather poor. Since then, however, computer-based forecasts have improved so much that Lorenz's limit of predictability is starting to become attainable in practice, especially with ensemble forecasting, and the predictabilty of longer-lasting phenomena such as El Niño is beginning to be successfully exploited. The skill of operational weather forecasts has at least doubled over the last two decades. This improvement has taken place relatively steadily, driven by a large number of scientific and computational developments, especially in the area of NWP. It has taken place in all the operational NWP centers, as friendly competition and information sharing make scientific improvements take place faster than they would in a single center. Because the improvements have occurred steadily, rather than suddenly, the overall increase in forecast skill due to NWP has not been clearly recognized by the media and the public despite the impact that improved forecasts have on the national economy and on the lives of every American. In this paper the authors review several measures of operational forecast skill that quantify improvements in NWP at the National Centers for Environmental Prediction (NCEP, formerly the National Meteorological Center) of the National Weather Service, although they are representative of improvements in all major NWP operational centers. The authors point out that there are three major requirements for improved numerical weather prediction: better atmospheric models, better observational data, and better methods for data assimilation. These improvements are generally very computer intensive and can only be made operational with the availability of more powerful supercomputers. Operational forecasts are compared with “reforecasts” from the NCEP–NCAR 40-Year Reanalysis, showing that, if the present-day NWP systems had been available many decades ago, skillful 5-day forecasts would have been possible in the Northern Hemisphere with the upper-air network of the late 1950s. The authors discuss new approaches in the use of observations (variational assimilation of remote observations) and of numerical weather prediction guidance (ensemble forecasting) that have allowed the recent extension of operational predictions into longer ranges and the possibility of adaptive observing systems. The extension of operational forecast skill into seasonal predictions of the El Niño–Southern Oscillation phenomena using coupled ocean–atmosphere models is also discussed. In the last section the authors attempt to "forecast" the future of NWP.},
	number = {12},
	urldate = {2017-11-01},
	journal = {Bulletin of the American Meteorological Society},
	author = {Kalnay, Eugenia and Lord, Stephen J. and McPherson, Ronald D.},
	month = dec,
	year = {1998},
	pages = {2753--2769}
}

@book{james_introduction_1994,
	address = {NY, USA},
	title = {Introduction to circulating atmospheres},
	publisher = {Cambridge University Press},
	author = {James, Ian N.},
	year = {1994},
	keywords = {Science / Earth Sciences / Meteorology \& Climatology, Nature / Weather}
}

@article{kim_improvement_1995,
	title = {Improvement of {Orographic} {Gravity} {Wave} {Parameterization} {Using} a {Mesoscale} {Gravity} {Wave} {Model}},
	volume = {52},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1995)052%3C1875%3AIOOGWP%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1995)052<1875:IOOGWP>2.0.CO;2},
	abstract = {Parameterization of gravity waves due to subgrid-scale orography is now included in most existing large-scale models of the atmosphere. Parameterization schemes, however, have so far been evaluated mainly in view of the overall performance of the large-scale models. This may lead to an inappropriate assessment of the schemes since errors from various sources may interact with one another. To avoid this situation, an approach is taken in which a numerical model that explicitly resolves gravity waves is used to evaluate the performance of the schemes. For this purpose, a mesoscale two-dimensional nonlinear anelastic nonhydrostatic model is developed and used to numerically simulate gravity waves for a variety of orographic conditions. Regarding a subdomain of the mesoseale model as the horizontal grid interval of a large-scale model, two vertical profiles of gravity wave drag are compared–one for the subdomain-averaged values of the drag simulated by the mesoseale model and the other for the drag calculated by a parameterization scheme applied to the subdomain-averaged variables. A test parameterization scheme is constructed by adopting the essential features of the existing schemes. An extensive evaluation of the test parameterization scheme with the aid of the dataset obtained from the mountain wave simulations shows that the scheme does not properly treat the enhancement of drag due to low-level wave breaking through the resonant amplification of nonhydrostatic waves. The authors show that the standard deviation of orography and the tuning coefficient in the scheme alone are not sufficient for properly representing this effect. The authors discuss the approach taken to overcome this deficiency by including additional statistical information on subgrid-scale orography in the input to the parameterization. A revised parameterization scheme constructed following this approach is presented.},
	number = {11},
	urldate = {2017-11-01},
	journal = {Journal of the Atmospheric Sciences},
	author = {Kim, Young-Joon and Arakawa, Akio},
	month = jun,
	year = {1995},
	pages = {1875--1902}
}

@article{ji_impact_1997,
	title = {Impact of data assimilation on ocean initialization and {El} {Nino} prediction},
	volume = {125},
	number = {5},
	journal = {Monthly Weather Review},
	author = {Ji, Ming and Leetmaa, Ants},
	year = {1997},
	pages = {742--753}
}

@article{huang_diabatic_1993,
	title = {Diabatic {Digital}-{Filtering} {Initialization}: {Application} to the {HIRLAM} {Model}},
	volume = {121},
	issn = {0027-0644},
	shorttitle = {Diabatic {Digital}-{Filtering} {Initialization}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1993)121%3C0589:DDFIAT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1993)121<0589:DDFIAT>2.0.CO;2},
	abstract = {A digital-filtering initialization scheme, which includes the effects of diabatic processes, has been formulated. This scheme gives a lower noise level in the forecast and a better organized initial pressure-tendency field than for the corresponding adiabatic initialization. The implementation of the scheme is very easy, requiring only the calculation of the filter coefficients and minor adjustments to the model code. The computational expense of the digital-filtering initialization is directly proportional to the length of the time span over which the filter is applied. By a careful choice of filter weights, based on optimal filter theory, the span of the filter can be reduced by a factor of 2 or 3, with a corresponding increase in efficiency.},
	number = {2},
	urldate = {2017-10-19},
	journal = {Monthly Weather Review},
	author = {Huang, Xiang-Yu and Lynch, Peter},
	month = feb,
	year = {1993},
	pages = {589--603}
}

@article{kalnay_forecasting_1987,
	title = {Forecasting {Forecast} {Skill}},
	volume = {115},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1987)115%3C0349%3AFFS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1987)115<0349:FFS>2.0.CO;2},
	abstract = {We have shown that it is possible to predict the skill of numerical weather forecasts—a quantity which is variable from day to day and region to region. This has been accomplished using as predictor the dispersion (measured by the average correlation) between members of an ensemble of forecasts started from five different analyses. The analyses had been previously derived for satellite data impact studies and included, in the Northern Hemisphere, moderate perturbations associated with the use of different observing systems. When the Northern Hemisphere was used as a verification region, the prediction of skill was rather poor. This is due to the fact that such large area usually contains regions with excellent forecasts as well as regions with poor forecasts, and does not allow for discrimination between them. However, when we used regional verifications, the ensemble forecast dispersion provided a very good prediction of the quality of the individual forecasts. Although the period covered in this study is only one month long, it includes cases with wide variation of skill in each of the four regions considered. The method could be tested in an operational context using ensembles of lagged forecasts and longer time periods in order to test its applicability to different arms and weather regimes.},
	number = {2},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Kalnay, Eugenia and Dalcher, Amnon},
	month = feb,
	year = {1987},
	pages = {349--356}
}

@article{lorenz_deterministic_1963,
	title = {Deterministic {Nonperiodic} {Flow}},
	volume = {20},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1963)020%3C0130:DNF%3E2.0.CO;2},
	doi = {10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2},
	abstract = {Finite systems of deterministic ordinary nonlinear differential equations may be designed to represent forced dissipative hydrodynamic flow. Solutions of these equations can be identified with trajectories in phase space. For those systems with bounded solutions, it is found that nonperiodic solutions are ordinarily unstable with respect to small modifications, so that slightly differing initial states can evolve into considerably different states. Systems with bounded solutions are shown to possess bounded numerical solutions. A simple system representing cellular convection is solved numerically. All of the solutions are found to be unstable, and almost all of them are nonperiodic. The feasibility of very-long-range weather prediction is examined in the light of these results.},
	number = {2},
	urldate = {2017-11-08},
	journal = {Journal of the Atmospheric Sciences},
	author = {Lorenz, Edward N.},
	month = mar,
	year = {1963},
	pages = {130--141}
}

@article{konor_design_1997,
	title = {Design of an {Atmospheric} {Model} {Based} on a {Generalized} {Vertical} {Coordinate}},
	volume = {125},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1997)125%3C1649:DOAAMB%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1997)125<1649:DOAAMB>2.0.CO;2},
	abstract = {Although there are important advantages in the use of an isentropic vertical coordinate in atmospheric models, it requires overcoming computational difficulties associated with intersections of coordinate surfaces with the earth’s surface. In this paper, the authors present a model based on the generalized vertical coordinate, ζ = F(θ, p, pS), in which an isentropic coordinate can be combined with a terrain-following σ coordinate near the surface with a smooth transition between the two. One of the key issues in developing such a model is to satisfy consistency between the predictions of the pressure and the potential temperature. In the model presented in this paper, consistency is maintained by the use of an equation that determines the vertical mass flux. A procedure to properly choose ζ = F(θ, p, pS) is also presented, which guarantees that ζ is a monotonic function of height even when unstable stratification occurs. In the vertical discretization, the Charney–Phillips grid is used since, with this grid, it is straightforward to satisfy the thermodynamic equation when ζ = θ. In the generalized vertical coordinate, determining the pressure gradient force requires both the Montgomery potential and the geopotential at the same levels. The discrete hydrostatic equation is designed to maintain consistency between the two. The vertically discrete equations also satisfy two important integral constraints. With these features, the model becomes identical to the isentropic coordinate model developed by Hsu and Arakawa when ζ = θ. To demonstrate the performance of the model, the simulated nonlinear evolution of a midlatitude disturbance starting from random disturbances is presented. In the simulation, physical processes are represented by simple thermal forcing in the form of Newtonian heating and friction in the form of Rayleigh damping. During the evolution of the disturbance, the model generates sharp fronts both at the surface and in the upper and middle troposphere. No serious computational difficulties are found in this simulation.},
	number = {7},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Konor, Celal S. and Arakawa, Akio},
	month = jul,
	year = {1997},
	pages = {1649--1673}
}

@article{kanamitsu_description_1989,
	title = {Description of the {NMC} {Global} {Data} {Assimilation} and {Forecast} {System}},
	volume = {4},
	issn = {0882-8156},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0434(1989)004%3C0335:DOTNGD%3E2.0.CO%3B2},
	doi = {10.1175/1520-0434(1989)004<0335:DOTNGD>2.0.CO;2},
	abstract = {The National Meteorological Center's (NMC) Global Data Assimilation and Forecast System is described in some detail. The system consists of 1) preprocessing of the initial guess, 2) optimum interpolation objective analysis, 3) update of the initial guess, 4) initialization, 5) forecast, and 6) postprocessing of the forecast. The assimilation and forecast system are continually evolving; the version described here was implemented on 30 November 1988.},
	number = {3},
	urldate = {2017-11-01},
	journal = {Weather and Forecasting},
	author = {Kanamitsu, Masao},
	month = sep,
	year = {1989},
	pages = {335--342}
}

@article{houtekamer_data_1998,
	title = {Data {Assimilation} {Using} an {Ensemble} {Kalman} {Filter} {Technique}},
	volume = {126},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1998)126%3C0796:DAUAEK%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1998)126<0796:DAUAEK>2.0.CO;2},
	abstract = {The possibility of performing data assimilation using the flow-dependent statistics calculated from an ensemble of short-range forecasts (a technique referred to as ensemble Kalman filtering) is examined in an idealized environment. Using a three-level, quasigeostrophic, T21 model and simulated observations, experiments are performed in a perfect-model context. By using forward interpolation operators from the model state to the observations, the ensemble Kalman filter is able to utilize nonconventional observations. In order to maintain a representative spread between the ensemble members and avoid a problem of inbreeding, a pair of ensemble Kalman filters is configured so that the assimilation of data using one ensemble of short-range forecasts as background fields employs the weights calculated from the other ensemble of short-range forecasts. This configuration is found to work well: the spread between the ensemble members resembles the difference between the ensemble mean and the true state, except in the case of the smallest ensembles. A series of 30-day data assimilation cycles is performed using ensembles of different sizes. The results indicate that (i) as the size of the ensembles increases, correlations are estimated more accurately and the root-mean-square analysis error decreases, as expected, and (ii) ensembles having on the order of 100 members are sufficient to accurately describe local anisotropic, baroclinic correlation structures. Due to the difficulty of accurately estimating the small correlations associated with remote observations, a cutoff radius beyond which observations are not used, is implemented. It is found that (a) for a given ensemble size there is an optimal value of this cutoff radius, and (b) the optimal cutoff radius increases as the ensemble size increases.},
	number = {3},
	urldate = {2017-10-19},
	journal = {Monthly Weather Review},
	author = {Houtekamer, P. L. and Mitchell, Herschel L.},
	month = mar,
	year = {1998},
	pages = {796--811}
}

@techreport{kiehl_description_1996,
	title = {Description of the {Ncar} {Community} {Climate} {Model} (ccm3). {Technical} {Note}},
	url = {https://www.osti.gov/scitech/biblio/442361},
	language = {English},
	number = {PB--97-131528/XAB; NCAR/TN--420-STR},
	urldate = {2017-11-01},
	institution = {National Center for Atmospheric Research, Boulder, CO (United States). Climate and Global Dynamics Div.},
	author = {Kiehl, J. T. and Hack, J. J. and Bonan, G. B. and Boville, B. A. and Briegleb, B. P.},
	month = sep,
	year = {1996},
	keywords = {mathematics, environmental sciences, atmospheric circulation, climate models, computer program documentation, computers, general circulation models, information science, law, management, miscellaneous, thermodynamics}
}

@article{kalnay_data_1997,
	title = {Data {Assimilation} in the {Ocean} and in the {Atmosphere}: {What} {Should} be {Next}?},
	shorttitle = {Data {Assimilation} in the {Ocean} and in the {Atmosphere}},
	url = {http://ntrs.nasa.gov/search.jsp?R=20000037959},
	abstract = {As part of the International Symposium on Assimilation of Observation in Meteorology and Oceanography, a panel discussion was held on the evening of 15 March 1995.},
	language = {en},
	urldate = {2017-11-01},
	author = {Kalnay, Eugenia and Anderson, David L. T. and Bennett, Andrew F. and Busalacchi, Antonio J. and Cohn, Stephen E. and Courtier, Philippe and Derber, John and Lorenc, Andrew C. and Parrish, David and Schlatter, Thomas},
	month = jan,
	year = {1997}
}

@article{ji_coupled_1996,
	title = {Coupled {Model} {Predictions} of {ENSO} during the 1980s and the 1990sat the {National} {Centers} for {Environmental} {Prediction}},
	volume = {9},
	number = {12},
	journal = {Journal of Climate},
	author = {Ji, Ming and Leetmaa, Ants and Kousky, Vernon E.},
	year = {1996},
	pages = {3105--3120}
}

@article{ingleby_bayesian_1993,
	title = {Bayesian quality control using multivariate normal distributions},
	volume = {119},
	number = {513},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Ingleby, N. Bruce and Lorenc, Andrew C.},
	year = {1993},
	pages = {1195--1225}
}

@article{klemp_upper_1983,
	title = {An {Upper} {Boundary} {Condition} {Permitting} {Internal} {Gravity} {Wave} {Radiation} in {Numerical} {Mesoscale} {Models}},
	volume = {111},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1983)111%3C0430:AUBCPI%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1983)111<0430:AUBCPI>2.0.CO;2},
	abstract = {A radiative upper boundary condition is proposed for numerical mesoscale models which allows vertically propagating internal gravity waves to pass out of the computational domain with minimal reflection. In this formulation, the pressure along the upper boundary is determined from the Fourier transform of the vertical velocity at that boundary. This boundary condition can easily be incorporated in a wide variety of models and requires little additional computation. The radiation boundary condition is derived from the linear, hydrostatic, Boussinesq equations of motion, neglecting Coriolis effects. However, tests of this radiation boundary condition in the presence of nonhydrostatic, Coriolis, nonlinear and non-Boussinesq effects suggest that it would be effective in many mesoscale modeling applications.},
	number = {3},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Klemp, Joseph B. and Durran, Dale R.},
	month = mar,
	year = {1983},
	pages = {430--444}
}

@article{kalnay_application_2000,
	title = {Application of the {Quasi}-{Inverse} {Method} to {Data} {Assimilation}},
	volume = {128},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(2000)128%3C0864%3AAOTQIM%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(2000)128<0864:AOTQIM>2.0.CO;2},
	abstract = {Four-dimensional variational data assimilation (4D-Var) seeks to find an optimal initial field that minimizes a cost function defined as the squared distance between model solutions and observations within an assimilation window. For a perfect linear model, Lorenc showed that the 4D-Var forecast at the end of the window coincides with a Kalman filter analysis if two conditions are fulfilled: (a) addition to the cost function of a term that measures the distance to the background at the beginning of the assimilation window, and (b) use of the Kalman filter background error covariance in this term. The standard 4D-Var requires minimization algorithms along with adjoint models to compute gradient information needed for the minimization. In this study, an alternative method is suggested based on the use of the quasi-inverse model that, for certain applications, may help accelerate the solution of problems close to 4D-Var. The quasi-inverse approach for the forecast sensitivity problem is introduced, and then a closely related variational assimilation problem using the quasi-inverse model is formulated (i.e., the model is integrated backward but changing the sign of the dissipation terms). It is shown that if the cost function has no background term, and has a complete set of observations (as assumed in many classical 4D-Var papers), the new method solves the 4D-Var-minimization problem efficiently, and is in fact equivalent to the Newton algorithm but without having to compute a Hessian. If the background term is included but computed at the end of the interval, allowing the use of observations that are not complete, the minimization can still be carried out very efficiently. In this case, however, the method is much closer to a 3D-Var formulation in which the analysis is attained through a model integration. For this reason, the method is called “inverse 3D-Var” (I3D-Var). The I3D-Var method was applied to simple models (viscous Burgers’ equation and Lorenz model), and it was found that when the background term is ignored and complete fields of noisy observations are available at multiple times, the inverse 3D-Var method minimizes the same cost function as 4D-Var but converges much faster. Tests with the Advanced Regional Prediction System (ARPS) indicate that I3D-Var is about twice as fast as the adjoint Newton method and many times faster than the quasi-Newton LBFGS algorithm, which uses the adjoint model. Potential problems (including the growth of random errors during the integration back in time) and possible applications to preconditioning, and to problems such as storm-scale data assimilation and reanalysis are also discussed.},
	number = {3},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {Kalnay, Eugenia and Park, Seon Ki and Pu, Zhao-Xia and Gao, Jidong},
	month = mar,
	year = {2000},
	pages = {864--875}
}

@article{koch_interactive_1983,
	title = {An {Interactive} {Barnes} {Objective} {Map} {Analysis} {Scheme} for {Use} with {Satellite} and {Conventional} {Data}},
	volume = {22},
	issn = {0733-3021},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0450(1983)022%3C1487:AIBOMA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0450(1983)022<1487:AIBOMA>2.0.CO;2},
	abstract = {An objective analysis scheme based on the Barnes technique and designed for use on an interactive computer is described. In order to meet the specific needs of the research meteorologist, the interactive Barnes scheme allows real-time assessments both of the quality of the resulting analyses and of the impact of satellite-derived data upon various meteorological data sets. Display of a number of statistical and mapped analysis quality control indicators aid the impact assessments. Simple means for taking account of the spatially clustered nature typical of satellite data are included in the internal computations of the relative weights of data at grid point locations. An analyst is allowed the capability of modifying values of certain input parameters to the interactive Barnes scheme within internally set limits. These constraints were objectively determined and tested in a number of different situations prior to implementation. The following constraints are employed: 1) calculation of the weights as a function of a data spacing representative of the data distribution; 2) automatic elimination of detail at wavelengths smaller than twice the representative data spacing; 3) placement of bounds upon the grid spacing by the data spacing; and 4) setting of a fixed limit on the number of passes through the data to achieve rapid and sufficient convergence of the analyzed values to the observed ones. A mathematical analysis of the convergence properties of the Barnes technique is presented to support the validity of the latter constraint. Despite these constraints, the interactive Barnes scheme remains versatile because it accepts limited inputs to the data and grid display areas, to the data and grid spacings, and to the rate of convergence of the analysis to the observations. Input parameter values are entered through a series of questions displayed on a computer video terminal and by manipulation of display function devices. The analyst immediately sees a plot of the data, the contoured grid values, superimposed in various colors if desired, and the effects of choice of analysis options. Examples of both meteorological and satellite data analyses are presented to demonstrate the objectivity, versatility and practicality of the interactive Barnes scheme.},
	number = {9},
	urldate = {2017-11-01},
	journal = {Journal of Climate and Applied Meteorology},
	author = {Koch, Steven E. and desJardins, Mary and Kocin, Paul J.},
	month = sep,
	year = {1983},
	pages = {1487--1503}
}

@article{ji_experimental_1994,
	title = {An experimental coupled forecast system at the {National} {Meteorological} {Center}},
	volume = {46},
	number = {4},
	journal = {Tellus A},
	author = {Ji, Ming and Kumar, Arun and Leetmaa, Ants},
	year = {1994},
	pages = {398--418}
}

@article{janjic_alternative_2001,
	title = {An alternative approach to nonhydrostatic modeling},
	volume = {129},
	number = {5},
	journal = {Monthly Weather Review},
	author = {Janjic, Zavisa I. and Gerrity Jr, J. P. and Nickovic, S.},
	year = {2001},
	pages = {1164--1178}
}

@article{janjic_stable_1974,
	title = {A stable centered difference scheme free of two-grid-interval noise},
	volume = {102},
	number = {4},
	journal = {Monthly Weather Review},
	author = {Janjić, Zaviša I.},
	year = {1974},
	pages = {319--323}
}

@article{juang_spectral_1992,
	title = {A spectral fully compressible nonhydrostatic mesoscale model in hydrostatic sigma coordinates: {Formulation} and preliminary results},
	volume = {50},
	shorttitle = {A spectral fully compressible nonhydrostatic mesoscale model in hydrostatic sigma coordinates},
	number = {1-3},
	journal = {Meteorology and Atmospheric Physics},
	author = {Juang, Hann-Ming H.},
	year = {1992},
	pages = {75--88}
}

@article{kalnay-rivas_simple_1981,
	title = {A simple mechanism for blocking},
	volume = {38},
	number = {10},
	journal = {Journal of the Atmospheric Sciences},
	author = {Kalnay-Rivas, Eugenia and Merkine, Lee-Or},
	year = {1981},
	pages = {2077--2091}
}

@article{falkovich_new_2000-1,
	title = {A {New} {Method} of {Observed} {Rainfall} {Assimilation} in {Forecast} {Models}},
	volume = {39},
	issn = {0894-8763},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0450(2000)039%3C1282:ANMOOR%3E2.0.CO%3B2},
	doi = {10.1175/1520-0450(2000)039<1282:ANMOOR>2.0.CO;2},
	abstract = {A method to assimilate observed rain rates in the Tropics for improving initial fields in forecast models is proposed. It consists of a 6-h integration of a numerical forecast model; the specific humidity at every time step at each grid point is modified (nudged) in such a way that the total model precipitation accumulated during this integration becomes very close to that observed. An increase in the model precipitation is achieved by moistening the lower troposphere above a grid point with prescribed supersaturation; a decrease in the model rainfall is brought about by decreasing the specific humidity in the lower troposphere in proportion to the difference between the model and reference specific humidity profiles. The modified values depend on the difference between the model and target precipitation. The depth of the atmospheric column in which the humidity is changed is proportional to the target rain rate. Quality criteria of a rain assimilation procedure are proposed. The quality of the assimilation method was verified using a test in which precipitation generated by a forecast model without nudging (“control” experiment) was considered to be “quasi-target” data and the nudging procedure was used for assimilation of the rain produced in the control experiment. The following experiments were performed: control (C)—without nudging, “simulated nudge” (S)—nudging to the 6-h accumulated rainfall from the C experiment, and “satellite nudge”—nudging to the 6-h accumulated satellite-retrieved (observed) rainfall. Each experiment consisted of a 6-h forecast (first guess), analysis, next 6-h forecast (first guess), next analysis, and 24-h forecast. Nudging was applied during the two successive 6-h calculations of the first guess over the tropical belt. Parameters of the nudging procedure were determined in such a way that the assimilation procedure converged quickly and simulated the observed precipitation very closely. The difference in forecast fields between the S and C experiments after a 24-h forecast turned out to be small, indicating high quality of the assimilation procedure. The high sensitivity of forecast fields to the quality of rain retrieval is demonstrated.},
	number = {8},
	urldate = {2017-11-01},
	journal = {Journal of Applied Meteorology},
	author = {Falkovich, Aleksandr and Kalnay, Eugenia and Lord, Stephen and Mathur, Mukut B.},
	month = aug,
	year = {2000},
	pages = {1282--1298}
}

@article{johnson_generalized_1980,
	title = {A generalized transport equation for use with meteorological coordinate systems},
	volume = {108},
	number = {6},
	journal = {Monthly Weather Review},
	author = {Johnson, Donald R.},
	year = {1980},
	pages = {733--745}
}

@article{du_vachat_general_1986,
	title = {A {General} {Formulation} of {Normal} {Modes} for {Limited}-{Area} {Models}: {Application} to {Initialization}},
	volume = {114},
	issn = {0027-0644},
	shorttitle = {A {General} {Formulation} of {Normal} {Modes} for {Limited}-{Area} {Models}},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1986)114%3C2478:AGFONM%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1986)114<2478:AGFONM>2.0.CO;2},
	abstract = {A formulation of normal modes for a limited-area model is proposed. The case of shallow water equations on a conformal projection is considered. This formulation is a generalization of Brière's proposal. It can handle the full variation of the Coriolis parameter and of the map scale factor; it is written in physical-space variables and does not need a rectangular domain to be applied as in Brière's scheme. It gives rise to stationary Rossby modes and gravity modes fully identified and easily separated on the basis of their frequency. By applying Machenhauer's initialization scheme, we rigorously deduce the vertical mode initialization proposed and demonstrated by Bourke and McGregor for a limited-area model.},
	number = {12},
	urldate = {2017-11-01},
	journal = {Monthly Weather Review},
	author = {du Vachat, Régis Juvanon},
	month = dec,
	year = {1986},
	pages = {2478--2487}
}

@article{johnson_comparison_1993,
	title = {A comparison of simulated precipitation by hybrid isentropic-sigma and sigma models},
	volume = {121},
	number = {7},
	journal = {Monthly weather review},
	author = {Johnson, Donald R. and Zapotocny, Tom H. and Reames, Fred M. and Wolf, Bart J. and Pierce, R. Bradley},
	year = {1993},
	pages = {2088--2114}
}

@article{bednarz_future_2016,
	title = {Future {Arctic} ozone recovery: the importance of chemistry and dynamics},
	volume = {16},
	issn = {1680-7324},
	url = {https://www.atmos-chem-phys.net/16/12159/2016/},
	doi = {10.5194/acp-16-12159-2016},
	number = {18},
	journal = {Atmos. Chem. Phys.},
	author = {Bednarz, E. M. and Maycock, A. C. and Abraham, N. L. and Braesicke, P. and Dessens, O. and Pyle, J. A.},
	month = sep,
	year = {2016},
	pages = {12159--12176}
}

@book{national_research_council_decade--century-scale_1,
	title = {Decade-to-{Century}-{Scale} {Climate} {Variability} and {Change}: {A} {Science} {Strategy}},
	isbn = {978-0-309-06098-1},
	shorttitle = {Decade-to-{Century}-{Scale} {Climate} {Variability} and {Change}},
	url = {https://www.nap.edu/catalog/6129/decade-to-century-scale-climate-variability-and-change-a-science},
	urldate = {2017-11-14},
	author = {National Research Council},
	month = nov,
	year = {1},
	doi = {10.17226/6129}
}

@article{parrish_national_1992,
	title = {The {National} {Meteorological} {Center}'s {Spectral} {Statistical}-{Interpolation} {Analysis} {System}},
	volume = {120},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1992)120%3C1747:TNMCSS%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1992)120<1747:TNMCSS>2.0.CO;2},
	abstract = {At the National Meteorological Center (NMC), a new analysis system is being extensively tested for possible use in the operational global data assimilation system. This analysis system is called the spectral statistical- interpolation (SSI) analysis system because the spectral coefficients used in the NMC spectral model are analyzed directly using the same basic equations as statistical (optimal) interpolation. Results from several months of parallel testing with the NMC spectral model have been very encouraging. Favorable features include smoother analysis increments, greatly reduced changes from initialization, and significant improvement of 1-5-day forecasts. Although the analysis is formulated as a variational problem, the objective function being minimized is formally the same one that forms the basis of all existing optimal interpolation schemes. This objective function is a combination of forecast and observation deviations from the desired analysis, weighted by the invent of the corresponding forecast- and observation-error covariance matrices. There are two principal differences in how the SSI implements the minimization of this functional as compared to the current OI used at NMC. First, the analysis variables are spectral coefficients instead of gridpoint values. Second, all observations are used at once to solve a single global problem. No local approximations are made, and there is no special data selection. Because of these differences, it is straightforward to include unconventional data, such as radiances, in the analysis. Currently temperature, wind, surface pressure, mixing, ratio, and Special Sensor Microwave/lmager (SSM/I) total precipitable water can be used as the observation variables. Soon to be added are the scatterometer surface winds. This paper provides a detailed description of the SSI and presents a few results.},
	number = {8},
	journal = {Monthly Weather Review},
	author = {Parrish, David F. and Derber, John C.},
	month = aug,
	year = {1992},
	pages = {1747--1763}
}

@article{purser_high-order_1997,
	title = {High-{Order} {Generalized} {Lorenz} {N}-{Cycle} {Schemes} for {Semi}-{Lagrangian} {Models} {Employing} {Second} {Derivatives} in {Time}},
	volume = {125},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1997)125%3C1261%3AHOGLNC%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1997)125<1261:HOGLNC>2.0.CO;2},
	abstract = {Having recently demonstrated that significant enhancement of forecast accuracy in a semi-Lagrangian model results from the application of high-order time integration methods to the second-derivative form of the equations governing the trajectories, the authors here extend the range of available methods by introducing a class of what they call “generalized Lorenz” (GL) schemes. These explicit GL schemes, like Lorenz’s “N-cycle” methods, which inspired them, achieve a high formal accuracy in time for linear systems at an economy of storage that is the theoretical optimum. They are shown to possess robustly stable and consistent semi-implicit modifications that allow the deepest (fastest) gravity waves to be treated implicitly, so that integrations can proceed efficiently with time steps considerably longer than would be possible in an Eulerian framework. Tests of the GL methods are conducted using an ensemble of 360 forecast cases over the Australian region at high spatial resolution, verifying at 48 h against a control forecast employing time steps sufficiently short to render time truncation errors negligible. Compared with the performance of the best alternative semi-Lagrangian treatment of equivalent storage economy (a quasi-second-order generalized Adams–Bashforth method), our new GL methods produce significant improvements both in formal accuracy and in actual forecast skill.},
	number = {6},
	urldate = {2017-11-14},
	journal = {Monthly Weather Review},
	author = {Purser, R. J. and Leslie, L. M.},
	month = jun,
	year = {1997},
	pages = {1261--1276}
}

@article{purser_generalized_1996,
	title = {Generalized {Adams}–{Bashforth} time integration schemes for a semi-{Lagrangian} model employing the second-derivative form of the horizontal momentum equations},
	volume = {122},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49712253109/abstract},
	doi = {10.1002/qj.49712253109},
	abstract = {We present a generic class of semi-implicit time-integration methods, the ‘Generalized Adams–Bashforth’ schemes, for the simultaneous treatment in a semi-Lagrangian model of the equations of horizontal momentum and kinematics in a rotating environment. The salient feature of the approach is that it deals directly with Lagrangian parcel momentum in terms of the parcel's second time-derivative of position. The classical Adams–Bashforth methods can be generalized to accommodate equations of second-derivative form and, as we demonstrate, can be formulated in such a way that the further important refinement of a semi-implicit handling of the fastest gravity modes follows in a natural way. The principal advantages expected of this unified approach over the more conventional separate semi-Lagrangian treatment of kinematics and momentum are: (i) greater economy of storage at a given order of accuracy, (ii) smaller truncation errors at a given order of accuracy. Tests were run with a full-physics three-dimensional regional semi-Lagrangian forecast model applied on a daily basis to archived operational data over a period of three months. Verifications based on the 48 hour forecasts confirm that the expected benefits of the new schemes are also realized in practice.},
	language = {en},
	number = {531},
	urldate = {2017-11-14},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Purser, R. James and Leslie, Lance M.},
	month = apr,
	year = {1996},
	keywords = {Numerical techniques, Semi-implicit methods, Semi-Lagrangian model},
	pages = {737--763}
}

@misc{noauthor_worldcat_nodate,
	title = {{WorldCat} {Link} {Resolver}, the {OpenURL} link-server from {OCLC}},
	url = {https://umaryland.on.worldcat.org/atoztitles/link?sid=google&auinit=PK&aulast=Smolarkiewicz&atitle=A+simple+positive+definite+advection+scheme+with+small+implicit+diffusion&id=doi:10.1175/1520-0493(1983)111%3C0479:ASPDAS%3E2.0.CO%3B2&title=Monthly+weather+review&volume=111&issue=3&date=1983&spage=479&issn=0027-0644},
	urldate = {2018-07-13}
}

@incollection{haidvogel_ocean_1992,
	title = {Ocean {General} {Circulation} modeling},
	booktitle = {Climate {System} {Modeling}},
	publisher = {Cambridge University Press Cambridge, UK:},
	author = {Haidvogel, Dale B. and Bryan, Frank O.},
	year = {1992},
	pages = {788}
}

@article{evensen_sequential_1994,
	title = {Sequential data assimilation with a nonlinear quasi-geostrophic model using {Monte} {Carlo} methods to forecast error statistics},
	volume = {99},
	issn = {2156-2202},
	url = {http://onlinelibrary.wiley.com/doi/10.1029/94JC00572/abstract},
	doi = {10.1029/94JC00572},
	abstract = {A new sequential data assimilation method is discussed. It is based on forecasting the error statistics using Monte Carlo methods, a better alternative than solving the traditional and computationally extremely demanding approximate error covariance equation used in the extended Kalman filter. The unbounded error growth found in the extended Kalman filter, which is caused by an overly simplified closure in the error covariance equation, is completely eliminated. Open boundaries can be handled as long as the ocean model is well posed. Well-known numerical instabilities associated with the error covariance equation are avoided because storage and evolution of the error covariance matrix itself are not needed. The results are also better than what is provided by the extended Kalman filter since there is no closure problem and the quality of the forecast error statistics therefore improves. The method should be feasible also for more sophisticated primitive equation models. The computational load for reasonable accuracy is only a fraction of what is required for the extended Kalman filter and is given by the storage of, say, 100 model states for an ensemble size of 100 and thus CPU requirements of the order of the cost of 100 model integrations. The proposed method can therefore be used with realistic nonlinear ocean models on large domains on existing computers, and it is also well suited for parallel computers and clusters of workstations where each processor integrates a few members of the ensemble.},
	language = {en},
	number = {C5},
	urldate = {2017-11-01},
	journal = {Journal of Geophysical Research: Oceans},
	author = {Evensen, Geir},
	month = may,
	year = {1994},
	keywords = {4255 Numerical modeling, 4263 Oceanography: General: Ocean prediction},
	pages = {10143--10162}
}

@article{buizza_forecast_2015,
	title = {The forecast skill horizon},
	volume = {141},
	copyright = {© 2015 Royal Meteorological Society},
	issn = {1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/qj.2619},
	doi = {10.1002/qj.2619},
	abstract = {Numerical weather prediction has seen, in the past 25 years, a shift from a ‘deterministic’ approach, based on single numerical integrations, to a probabilistic one, with ensembles of numerical integrations used to estimate the probability distribution function of forecast states. This shift to a probabilistic approach enabled a better extraction of predictive signals at longer lead times and provided a meaningful framework for extending the forecast length beyond 10 days. In this work, the limit of predictive skill is assessed for ECMWF monthly ensemble forecasts at different spatial and temporal scales. The forecast skill horizon is defined as the lead time when the ensemble ceases to be more skilful than a climatological distribution, using a continuous ranked probability score as metric. Results based on 32-day ensemble forecasts indicate that the forecast skill horizon is sensitive to the spatial and temporal scale of the predicted phenomena, to the variable considered and the area analysed. On average over 1 year of forecasts, the forecast skill horizon for instantaneous, grid-point fields is between 16 and 23 days, while it is considerably longer for time- and spatial-average fields. Forecast skill horizons longer than the 2 weeks that were thought to be the limit are now achievable thanks to major advances in numerical weather prediction. More specifically, they are possible because forecasts are now framed in probabilistic terms, with a probability distribution estimated using ensembles generated using forecast models that include more components (e.g. a dynamical ocean and ocean waves) and more faithfully represent processes. Moreover, the forecasts start from more accurate initial conditions constructed using better data-assimilation methods and more observational data.},
	language = {en},
	number = {693},
	urldate = {2019-07-18},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Buizza, Roberto and Leutbecher, Martin},
	year = {2015},
	keywords = {butterfly effect, ensemble prediction, extended-range prediction, forecast skill horizon, predictability},
	pages = {3366--3382}
}

@article{zhang_what_2019,
	title = {What {Is} the {Predictability} {Limit} of {Midlatitude} {Weather}?},
	volume = {76},
	issn = {0022-4928},
	url = {https://journals.ametsoc.org/doi/full/10.1175/JAS-D-18-0269.1},
	doi = {10.1175/JAS-D-18-0269.1},
	abstract = {Understanding the predictability limit of day-to-day weather phenomena such as midlatitude winter storms and summer monsoonal rainstorms is crucial to numerical weather prediction (NWP). This predictability limit is studied using unprecedented high-resolution global models with ensemble experiments of the European Centre for Medium-Range Weather Forecasts (ECMWF; 9-km operational model) and identical-twin experiments of the U.S. Next-Generation Global Prediction System (NGGPS; 3 km). Results suggest that the predictability limit for midlatitude weather may indeed exist and is intrinsic to the underlying dynamical system and instabilities even if the forecast model and the initial conditions are nearly perfect. Currently, a skillful forecast lead time of midlatitude instantaneous weather is around 10 days, which serves as the practical predictability limit. Reducing the current-day initial-condition uncertainty by an order of magnitude extends the deterministic forecast lead times of day-to-day weather by up to 5 days, with much less scope for improving prediction of small-scale phenomena like thunderstorms. Achieving this additional predictability limit can have enormous socioeconomic benefits but requires coordinated efforts by the entire community to design better numerical weather models, to improve observations, and to make better use of observations with advanced data assimilation and computing techniques.},
	number = {4},
	urldate = {2019-08-22},
	journal = {Journal of the Atmospheric Sciences},
	author = {Zhang, Fuqing and Sun, Y. Qiang and Magnusson, Linus and Buizza, Roberto and Lin, Shian-Jiann and Chen, Jan-Huey and Emanuel, Kerry},
	month = jan,
	year = {2019},
	pages = {1077--1091}
}

@article{pena_separating_2004,
	title = {Separating fast and slow modes in coupled chaotic systems},
	volume = {11},
	doi = {10.5194/npg-11-319-2004},
	abstract = {We test a simple technique based on breeding to separate fast and slow unstable modes in coupled systems with different time scales of evolution and variable amplitudes. The technique takes advantage of the earlier saturation of error growth rate of the fastest mode and of the lower value of the saturation amplitude of perturbation of either the fast or the slow modes. These properties of the coupled system allow a physically-based selection of the rescaling time interval and the amplitude of initial perturbations in the "breeding" of unstable modes (Toth and Kalnay, 1993, 1996, 1997; Aurell et al., 1997; Boffetta et al., 1998) to isolate the desired mode. We perform tests in coupled models composed of fast and slow versions of the Lorenz (1963) model with different strengths of coupling. As examples we present first a coupled system which we denote "weather with convection", with a slow, large amplitude model coupled with a fast, small amplitude model, second an "ENSO" system with a "tropical atmosphere" strongly coupled with a "tropical ocean", and finally a triply coupled system denoted "tropical-extratropical" in which a fast model (representing the "extratropical atmosphere") is loosely coupled to the "ENSO" system. We find that it is always possible to isolate the fast modes by taking the limit of small amplitudes and short rescaling intervals, in which case, as expected, the results are the same as the local Lyapunov growth obtained with the linear tangent model. In contrast, slow modes cannot be isolated with either Lyapunov or Singular vectors, since the linear tangent and adjoint models are dominated by the fast modes. Breeding is successful in isolating slow modes if rescaling intervals and amplitudes are chosen from physically appropriate scales.},
	journal = {Nonlinear Processes in Geophysics},
	author = {Peña, Malaquias and Kalnay, Eugenia},
	month = jul,
	year = {2004}
}

@misc{noauthor_decadal_nodate,
	title = {Decadal {North} {Pacific} {Bred} {Vectors} in a {Coupled} {GCM}: {Journal} of {Climate}: {Vol} 20, {No} 23},
	url = {https://journals.ametsoc.org/doi/full/10.1175/2007JCLI1620.1},
	urldate = {2019-08-22}
}

@article{kistler_ncepncar_2001-1,
	title = {The {NCEP}–{NCAR} 50-{Year} {Reanalysis}: {Monthly} {Means} {CD}-{ROM} and {Documentation}},
	volume = {82},
	issn = {0003-0007},
	shorttitle = {The {NCEP}–{NCAR} 50-{Year} {Reanalysis}},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/1520-0477%282001%29082%3C0247%3ATNNYRM%3E2.3.CO%3B2},
	doi = {10.1175/1520-0477(2001)082<0247:TNNYRM>2.3.CO;2},
	number = {2},
	urldate = {2019-08-22},
	journal = {Bulletin of the American Meteorological Society},
	author = {Kistler, Robert and Kalnay, Eugenia and Collins, William and Saha, Suranjana and White, Glenn and Woollen, John and Chelliah, Muthuvel and Ebisuzaki, Wesley and Kanamitsu, Masao and Kousky, Vernon and van den Dool, Huug and Jenne, Roy and Fiorino, Michael},
	month = feb,
	year = {2001},
	pages = {247--268}
}

@book{ruelle_chaotic_1989,
	title = {Chaotic {Evolution} and {Strange} {Attractors}},
	isbn = {978-0-521-36830-8},
	abstract = {This book, based on lectures given at the Accademia dei Lincei, is an accessible and leisurely account of systems that display a chaotic time evolution. This behaviour, though deterministic, has features more characteristic of stochastic systems. The analysis here is based on a statistical technique known as time series analysis and so avoids complex mathematics, yet provides a good understanding of the fundamentals. Professor Ruelle is one of the world's authorities on chaos and dynamical systems and his account here will be welcomed by scientists in physics, engineering, biology, chemistry and economics who encounter nonlinear systems in their research.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Ruelle, D.},
	month = sep,
	year = {1989},
	note = {Google-Books-ID: PXm43Y5NaJEC},
	keywords = {Mathematics / General, Mathematics / Probability \& Statistics / General, Science / Chaotic Behavior in Systems}
}

@article{hamill_reforecasts:_2006,
	title = {Reforecasts: {An} {Important} {Dataset} for {Improving} {Weather} {Predictions}},
	volume = {87},
	issn = {0003-0007},
	shorttitle = {Reforecasts},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/BAMS-87-1-33},
	doi = {10.1175/BAMS-87-1-33},
	abstract = {A “reforecast” (retrospective forecast) dataset has been developed. This dataset is comprised of a 15-member ensemble run out to a 2-week lead. Forecasts have been run every day from 0000 UTC initial conditions from 1979 to the present. The model is a 1998 version of the National Centers for Environmental Prediction's (NCEP's) Global Forecast System (GFS) at T62 resolution. The 15 initial conditions consist of a reanalysis and seven pairs of bred modes. This dataset facilitates a number of applications that were heretofore impossible. Model errors can be diagnosed from the past forecasts and corrected, thereby dramatically increasing the forecast skill. For example, calibrated precipitation forecasts over the United States based on the 1998 reforecast model are more skillful than precipitation forecasts from the 2002 higher-resolution version of the NCEP GFS. Other applications are also demonstrated, such as the diagnosis of the bias for model development and an identification of the most predictable patterns of week-2 forecasts. It is argued that the benefits of reforecasts are so large that they should become an integral part of the numerical weather prediction process. Methods for integrating reforecast approaches without seriously compromising the pace of model development are discussed. Users wishing to explore their own applications of reforecasts can download them through a Web interface.},
	number = {1},
	urldate = {2019-08-22},
	journal = {Bulletin of the American Meteorological Society},
	author = {Hamill, Thomas M. and Whitaker, Jeffrey S. and Mullen, Steven L.},
	month = jan,
	year = {2006},
	pages = {33--46}
}

@unpublished{noauthor_notitle_nodate
}

@unpublished{noauthor_notitle_nodate-1
}

@unpublished{yury_vikhliaev_decadal_nodate,
	title = {Decadal {North} {Pacific} {Bred} {Vectors} in a {Coupled} {GCM}},
	author = {{YURY VIKHLIAEV}}
}

@unpublished{noauthor_notitle_nodate-2
}

@article{davies_lateral_1976,
	title = {A lateral boundary formulation for multi-level prediction models},
	volume = {102},
	issn = {1477-870X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/qj.49710243210/abstract},
	doi = {10.1002/qj.49710243210},
	abstract = {An expedient method is proposed for the lateral boundary treatment of a limited-area prediction model. The method involves the relaxation of the interior flow in the vicinity of the boundary to the external fully prescribed flow. A systematic study of the method is undertaken with an (x, z), linear, primitive equation model. Analytical considerations of the method for the continuous equations demonstrate the manner in which the method consumes gravity wave energy, error and fine spatial scale potential vorticity near the lateral boundaries. Numerical experiments are also undertaken to assess the usefulness of the method. The results indicate that the method gives an adequate representation of outgoing gravity waves with and without an ambient shear flow, and also allows the substantially undistorted transmission of geostrophically balanced flow out of the interior of the limited domain. On the basis of these results, it is suggested that the method constitutes a promising utilitarian treatment of the lateral boundaries.},
	language = {en},
	number = {432},
	urldate = {2017-11-08},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Davies, H. C.},
	month = apr,
	year = {1976},
	pages = {405--418}
}

@article{garcia-moya_predictability_2011,
	title = {Predictability of short-range forecasting: a multimodel approach},
	volume = {63},
	issn = {null},
	shorttitle = {Predictability of short-range forecasting},
	url = {https://doi.org/10.1111/j.1600-0870.2010.00506.x},
	doi = {10.1111/j.1600-0870.2010.00506.x},
	abstract = {Numerical weather prediction (NWP) models (including mesoscale) have limitations when it comes to dealing with severe weather events because extreme weather is highly unpredictable, even in the short range. A probabilistic forecast based on an ensemble of slightly differentmodel runs may help to address this issue. Among other ensemble techniques, Multimodel ensemble prediction systems (EPSs) are proving to be useful for adding probabilistic value to mesoscale deterministic models. A Multimodel Short Range Ensemble Prediction System (SREPS) focused on forecasting the weather up to 72 h has been developed at the SpanishMeteorological Service (AEMET). The system uses five different limited area models (LAMs), namely HIRLAM (HIRLAM Consortium), HRM (DWD), the UM (UKMO), MM5 (PSU/NCAR) and COSMO (COSMO Consortium). These models run with initial and boundary conditions provided by five different global deterministic models, namely IFS (ECMWF), UM (UKMO), GME (DWD), GFS (NCEP) and CMC (MSC). AEMET-SREPS (AE) validation on the large-scale flow, using ECMWF analysis, shows a consistent and slightly underdispersive system. For surface parameters, the system shows high skill forecasting binary events. 24-h precipitation probabilistic forecasts are verified using an up-scaling grid of observations from European high-resolution precipitation networks, and compared with ECMWF-EPS (EC).},
	number = {3},
	urldate = {2019-07-18},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Garc´Ia-Moya, Jose-Antonio and Callado, Alfons and EscribÀ, Pau and Santos, Carlos and Santos-Mun˜Oz, Daniel and Simarro, Juan},
	month = jan,
	year = {2011},
	pages = {550--563}
}

@article{bowler_benefits_2008,
	title = {The {Benefits} of {Multianalysis} and {Poor} {Man}’s {Ensembles}},
	volume = {136},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/doi/full/10.1175/2008MWR2381.1},
	doi = {10.1175/2008MWR2381.1},
	abstract = {A new approach to probabilistic forecasting is proposed, based on the generation of an ensemble of equally likely analyses of the current state of the atmosphere. The rationale behind this approach is to mimic a poor man’s ensemble, which combines the deterministic forecasts from national meteorological services around the world. The multianalysis ensemble aims to generate a series of forecasts that are both as skillful as each other and the control forecast. This produces an ensemble mean forecast that is superior not only to the ensemble members, but to the control forecast in the short range even for slowly varying parameters, such as 500-hPa height. This is something that it is not possible with traditional ensemble methods, which perturb a central analysis. The results herein show that the multianalysis ensemble is more skillful than the Met Office’s high-resolution forecast by 4.5\% over the first 3 days (on average as measured for RMSE). Similar results are found for different verification scores and various regions of the globe. In contrast, the ensemble mean for the ensemble currently run by the Met Office performs 1.5\% worse than the high-resolution forecast (similar results are found for the ECMWF ensemble). It is argued that the multianalysis approach is therefore superior to current ensemble methods. The multianalysis results were achieved with a two-member ensemble: the forecast from a high-resolution model plus a low-resolution perturbed model. It may be possible to achieve greater improvements with a larger ensemble.},
	number = {11},
	urldate = {2019-07-18},
	journal = {Monthly Weather Review},
	author = {Bowler, Neill E. and Arribas, Alberto and Mylne, Kenneth R.},
	month = nov,
	year = {2008},
	pages = {4113--4129}
}

@article{arribas_test_2005,
	title = {Test of a {Poor} {Man}’s {Ensemble} {Prediction} {System} for {Short}-{Range} {Probability} {Forecasting}},
	volume = {133},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/doi/full/10.1175/MWR2911.1},
	doi = {10.1175/MWR2911.1},
	abstract = {Current operational ensemble prediction systems (EPSs) are designed specifically for medium-range forecasting, but there is also considerable interest in predictability in the short range, particularly for potential severe-weather developments. A possible option is to use a poor man’s ensemble prediction system (PEPS) comprising output from different numerical weather prediction (NWP) centers. By making use of a range of different models and independent analyses, a PEPS provides essentially a random sampling of both the initial condition and model evolution errors. In this paper the authors investigate the ability of a PEPS using up to 14 models from nine operational NWP centers. The ensemble forecasts are verified for a 101-day period and five variables: mean sea level pressure, 500-hPa geopotential height, temperature at 850 hPa, 2-m temperature, and 10-m wind speed. Results are compared with the operational ECMWF EPS, using the ECMWF analysis as the verifying “truth.” It is shown that, despite its smaller size, PEPS is an efficient way of producing ensemble forecasts and can provide competitive performance in the short range. The best relative performance is found to come from hybrid configurations combining output from a small subset of the ECMWF EPS with other different NWP models.},
	number = {7},
	urldate = {2019-07-18},
	journal = {Monthly Weather Review},
	author = {Arribas, A. and Robertson, K. B. and Mylne, K. R.},
	month = jul,
	year = {2005},
	pages = {1825--1839}
}

@article{wobus_three_1995,
	title = {Three {Years} of {Operational} {Prediction} of {Forecast} {Skill} at {NMC}},
	volume = {123},
	issn = {0027-0644},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1995)123%3C2132:TYOOPO%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1995)123<2132:TYOOPO>2.0.CO;2},
	abstract = {In real time since 1990, the National Meteorological Center (NMC) has been running a system to predict the forecast skill of the medium-range forecasts produced by the NMC global spectral model. The predictors used are the agreement of an ensemble consisting of operational forecasts from various centers, the persistence in the forecast, and the amplitude of the anomalies. These predictors are used in a stepwise regression scheme, with the last 60 days used as training period, and the regional anomaly correlation of the 0000 UTC NMC global forecast is predicted from days 1 to 6. By far the most important predictor of skill is the agreement between the NMC global forecast started at 0000 UTC, out to 6 days, and four other 12-h “older” forecasts (Japan Meteorological Agency, United Kingdom Meteorological Office, and the European Centre for Medium-Range Weather Forecasts, as well as the average of the NMC forecast at 0000 UTC with the previous day's forecast). The other predictors have been selected to add to the predictive capability of the agreement alone, and together they quantify the factors that forecasters use subjectively when evaluating the available forecasts. These predictions are available to NMC forecasters on workstations and to outside users through the Internet. The predictive ability of this system compares favorably with recent theoretical and experimental studies. The correlation between predicted and verifying forecast skill seems to be best in regions where forecast skin varies significantly. The seasonal variation in predicting the skill is small expect in the Tropics. The overall performance shows that these predictors include enough information about forecast skill to justify further development of skill predictions based on large forecast ensembles and on more sophisticated statistical techniques.},
	number = {7},
	urldate = {2016-09-27},
	journal = {Monthly Weather Review},
	author = {Wobus, Richard L. and Kalnay, Eugenia},
	month = jul,
	year = {1995},
	pages = {2132--2148}
}

@article{halem_assessment_1982,
	title = {An {Assessment} of the {FGGE} {Satellite} {Observing} {System} during {SOP}-1},
	volume = {63},
	issn = {0003-0007},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/1520-0477-63.4.407},
	doi = {10.1175/1520-0477-63.4.407},
	abstract = {This study investigates the degree to which data from the space-borne FGGE observing systems are able to determine the complete state of the atmosphere when incorporated into a global objective analysis cycle. Three data assimilation experiments are performed with the Goddard Laboratory for Atmospheric Sciences (GLAS) analysis/forecast system, using different combinations of the FGGE level II–b data collected during the first Special Observing Period (SOP-1), 5 January through 5 March 1979. The control experiment is an assimilation cycle with the complete FGGE II–b data. The other two assimilation/forecast experiments consist of i) the conventional system without the satellite data and special FGGE data sets; and ii) the FGGE II–b surface and satellite temperature soundings and cloud-track winds, aircraft data, and special FGGE data sets, but without the conventional rawinsonde/pilot balloon network. From these experiments, we attempt to assess the accuracy of the inferred mass and motion fields over data-sparse regions, by examining their influence on analyses and forecasts over data-rich regions. The sensitivity of the analysis to the FGGE satellite data is shown by comparisons of the 6 h forecast error of the 300 mb geopotential height fields for these three experiments. It is found that large 6 h forecast errors downstream of data-sparse regions are reduced when the satellite observations are incorporated in the analysis. Forecast impact results from the initial states of these assimilation cycles show the geographical influence of the FGGE satellite observing system on short- to medium-range (two to five days) weather forecasting. Over North America and Europe, there is a small improvement in forecast skill from the use of the FGGE II–b data. Over Australia, as expected, the positive impact of satellite data is much larger. The number of skillful four- and five-day forecasts over North America and Europe has been increased substantially by the addition of the FGGE II–b data. Examples of useful eight-day forecasts, which occurred in periods of atmospheric blocking situations also are presented.},
	number = {4},
	urldate = {2019-07-18},
	journal = {Bulletin of the American Meteorological Society},
	author = {Halem, M. and Kalnay, E. and Baker, W. E. and Atlas, R.},
	month = apr,
	year = {1982},
	pages = {407--426}
}

@inproceedings{tennekes_forecasting_1986,
	address = {Shinfield Park, Reading},
	title = {Forecasting forecast skill},
	booktitle = {Proceedings of the {ECMWF} {Workshop} on {Predictability} in the {Medium} and {Extended} {Range}},
	publisher = {ECMWF},
	author = {Tennekes, H. and Baede, A. P. M. and Opsteegh, J. D.},
	year = {1986},
	pages = {277--302}
}

@techreport{gronas_pilot_1985,
	address = {Shinfield Park, Reading},
	title = {A pilot study on the prediction of medium range forecast quality},
	url = {https://www.ecmwf.int/en/elibrary/9665-pilot-study-prediction-medium-range-forecast-quality},
	institution = {European Centre for Medium-Range Weather Forecasts},
	author = {Grönås, S.},
	year = {1985}
}

@article{dalcher_medium_1988,
	title = {Medium {Range} {Lagged} {Average} {Forecasts}},
	volume = {116},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1988)116%3C0402:MRLAF%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1988)116<0402:MRLAF>2.0.CO;2},
	abstract = {In this work we report the application of the lagged average forecasting (LAF) technique to operational forecasts of the ECMWF. The ECMWF data consist of two 100-day samples of 10-day forecasts of 500 mb geopotential height for winter 1980/81 and summer 1981. The LAF ensemble includes the latest operational forecast, and also forecasts for the same verification time stated one or more days earlier than the latest one. We focus on the following two issues: 1) Does ensemble averaging improve forecast skill and 2) Is the dispersion of the ensemble useful in predicting forecast skill. We used the LAF technique to produce 3, 5, 7, 8 and 9 day forecasts of the 500 mb height field. The results show the statistically filtered LAF is a marked improvement upon the operational forecast after 5 days. We find that on a global scale forecast skill is weakly correlated with the dispersion of the ensemble, as measured by the rms difference between the operational forecast and the statistically filtered LAF.},
	number = {2},
	urldate = {2019-07-18},
	journal = {Monthly Weather Review},
	author = {Dalcher, Amnon and Kalnay, Eugenia and Hoffman, Ross N.},
	month = feb,
	year = {1988},
	pages = {402--416}
}

@inproceedings{leith_spectral_1974,
	address = {Geneva, Switzerland},
	series = {{GARP} {Working} {Group} on {Numerical} {Experimentation}.},
	title = {Spectral statistical-dynamical forecast experiments},
	volume = {7},
	booktitle = {The {GARP} {Programme} on {Numerical} {Experimentation}},
	publisher = {World Meteorological Organization},
	author = {Leith, C. E.},
	year = {1974},
	pages = {445--467}
}

@inproceedings{ehrendorfer_liouville_2003,
	address = {Shinfield Park, Reading},
	title = {The {Liouville} equation and atmospheric predictability},
	url = {https://www.ecmwf.int/sites/default/files/elibrary/2003/9271-liouville-equation-atmospheric-predictability.pdf},
	booktitle = {Predictability of weather and climate, 9-13 {September} 2002},
	publisher = {ECMWF},
	author = {Ehrendorfer, Martin},
	year = {2003},
	pages = {47--81}
}

@article{li_period_1975,
	title = {Period {Three} {Implies} {Chaos}},
	volume = {82},
	issn = {0002-9890},
	url = {https://doi.org/10.1080/00029890.1975.11994008},
	doi = {10.1080/00029890.1975.11994008},
	number = {10},
	urldate = {2019-07-18},
	journal = {The American Mathematical Monthly},
	author = {Li, Tien-Yien and Yorke, James A.},
	month = dec,
	year = {1975},
	pages = {985--992}
}

@article{molteni_real-time_1990,
	title = {A {Real}-{Time} {Scheme} for the {Prediction} of {Forecast} {Skill}},
	volume = {119},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1991)119%3C1088:ARTSFT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1991)119<1088:ARTSFT>2.0.CO;2},
	abstract = {During the winter of 1988/89, a real-time experimental scheme to predict skill of the ECMWF operational forecast was devised. The scheme was based on statistical relations between skill scores (the predictands) and a number of predictors including consistency between consecutive forecasts, amplitude of very short-range forecast errors, and indices of large-scale regime transitions. The results of the experiment are assessed with particular attention to a period with large variations in the skill of the operational forecast.},
	number = {4},
	urldate = {2019-07-18},
	journal = {Monthly Weather Review},
	author = {Molteni, Franco and Palmer, T. N.},
	month = apr,
	year = {1990},
	pages = {1088--1097}
}

@article{sauer_how_1997,
	title = {How long do numerical chaotic solutions remain valid?},
	journal = {Physical Review Letters},
	author = {Sauer, Tim},
	month = jul,
	year = {1997}
}

@article{wallace_structure_1998,
	title = {On the structure and evolution of {ENSO}-related climate variability in the tropical {Pacific}: {Lessons} from {TOGA}},
	volume = {103},
	issn = {0148-0227},
	shorttitle = {On the structure and evolution of {ENSO}-related climate variability in the tropical {Pacific}},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/97JC02905},
	doi = {10.1029/97JC02905},
	abstract = {Improved observations in the tropical Pacific during the Tropical Ocean-Global Atmosphere (TOGA) program have served to corroborate preexisting notions concerning the seasonally dependent relationships between sea surface temperature, sea level pressure, wind stress, rainfall, upper tropospheric circulation, and ocean thermal structure anomalies in the El Niño-Southern Oscillation (ENSO) phenomenon. However, the paradigm of a quasiperiodic ?ENSO cycle,? phase locked with the annual march, does not capture the complexity of the evolution of the anomalies. The inadequacy of this model was particularly apparent during the second half of TOGA when the variability was highly aperiodic. Also, a single modal structure or empirical orthogonal function does not appear to be capable of representing the range of spatial patterns of ocean-atmosphere interaction in the tropical Pacific. These results suggest the need for a more inclusive phenomenological description of ENSO. Data collected during TOGA serve to confirm the influence of tropical Atlantic sea surface temperature anomalies upon rainfall in northeast Brazil.},
	number = {C7},
	urldate = {2018-11-14},
	journal = {Journal of Geophysical Research: Oceans},
	author = {Wallace, J. M. and Rasmusson, E. M. and Mitchell, T. P. and Kousky, V. E. and Sarachik, E. S. and Storch, H.},
	month = jun,
	year = {1998},
	pages = {14241--14259}
}

@article{penny_local_2013,
	title = {The local ensemble transform {Kalman} filter and the running-in-place algorithm applied to a global ocean general circulation model},
	volume = {20},
	issn = {1607-7946},
	url = {https://www.nonlin-processes-geophys.net/20/1031/2013/},
	doi = {10.5194/npg-20-1031-2013},
	abstract = {The most widely used methods of data assimilation in large-scale oceanography, such as the Simple Ocean Data Assimilation (SODA) algorithm, specify the background error covariances and thus are unable to refine the weights in the assimilation as the circulation changes. In contrast, the more computationally expensive Ensemble Kalman Filters (EnKF) such as the Local Ensemble Transform Kalman Filter (LETKF) use an ensemble of model forecasts to predict changes in the background error covariances and thus should produce more accurate analyses. The EnKFs are based on the approximation that ensemble members reflect a Gaussian probability distribution that is transformed linearly during the forecast and analysis cycle. In the presence of nonlinearity, EnKFs can gain from replacing each analysis increment by a sequence of smaller increments obtained by recursively applying the forecast model and data assimilation procedure over a single analysis cycle. This has led to the development of the "running in place" (RIP) algorithm by Kalnay and Yang (2010) and Yang et al. (2012a,b) in which the weights computed at the end of each analysis cycle are used recursively to refine the ensemble at the beginning of the analysis cycle. To date, no studies have been carried out with RIP in a global domain with real observations.  This paper provides a comparison of the aforementioned assimilation methods in a set of experiments spanning seven years (1997–2003) using identical forecast models, initial conditions, and observation data. While the emphasis is on understanding the similarities and differences between the assimilation methods, comparisons are also made to independent ocean station temperature, salinity, and velocity time series, as well as ocean transports, providing information about the absolute error of each. Comparisons to independent observations are similar for the assimilation methods but the observation-minus-background temperature differences are distinctly lower for LETKF and RIP. The results support the potential for LETKF to improve the quality of ocean analyses on the space and timescales of interest for seasonal prediction and for RIP to accelerate the spin up of the system.},
	number = {6},
	urldate = {2018-11-14},
	journal = {Nonlin. Processes Geophys.},
	author = {Penny, S. G. and Kalnay, E. and Carton, J. A. and Hunt, B. R. and Ide, K. and Miyoshi, T. and Chepurin, G. A.},
	month = nov,
	year = {2013},
	pages = {1031--1046}
}

@article{yang_improving_2013,
	title = {Improving the spin-up of regional {EnKF} for typhoon assimilation and forecasting with {Typhoon} {Sinlaku} (2008)},
	volume = {65},
	issn = {null},
	url = {https://doi.org/10.3402/tellusa.v65i0.20804},
	doi = {10.3402/tellusa.v65i0.20804},
	abstract = {The Running-In-Place (RIP) method is implemented in the framework of the Local Ensemble Transform Kalman Filter (LETKF) coupled with the Weather Research and Forecasting (WRF) model. RIP aims at accelerating the spin-up of the regional LETKF system when the WRF ensemble is initialised from a global analysis, which is obtained at a coarser resolution and lacks features related to the underlying mesoscale evolution. The RIP method is further proposed as an outer-loop scheme to improve the nonlinear evolution of the ensemble when the characteristics of the error statistics change rapidly owing to strong nonlinear dynamics. The impact of using RIP as an outer-loop for the WRF-LETKF system is evaluated for typhoon assimilation and prediction with Typhoon Sinlaku (2008) as a case study. For forecasts beyond one day, the typhoon track prediction is significantly improved after RIP is applied, especially during the spin-up period of the LETKF assimilation when Sinlaku is developing rapidly from a severe tropical storm to a typhoon. The impact of the dropsondes is significantly increased by RIP at early assimilation cycles. Results suggest that these improvements are because of the positive impact on the environmental condition of the typhoon. Results also suggest that using the RIP scheme adaptively allows RIP to be used as an outer-loop for the WRF-LETKF with further improvements.},
	number = {1},
	urldate = {2018-11-14},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Yang, Shu-Chih and Lin, Kuan-Jen and Miyoshi, Takemasa and Kalnay, Eugenia},
	month = dec,
	year = {2013},
	keywords = {observation impact, ensemble Kalman Filter (EnKF), nonlinearity, regional data assimilation, typhoon prediction},
	pages = {20804}
}

@article{wang_iterative_2013,
	title = {An iterative ensemble square root filter and tests with simulated radar data for storm-scale data assimilation},
	volume = {139},
	copyright = {© 2013 Royal Meteorological Society},
	issn = {1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/qj.2077},
	doi = {10.1002/qj.2077},
	abstract = {An iterative procedure is designed to accelerate the ‘spin-up’ of ensemble square-root filter (EnSRF) data-assimilation cycles when starting from a poor initial ensemble. Referred to as the iterative EnSRF (iEnSRF), this iterative procedure follows the ‘running in place’ (RIP) concept developed for the local ensemble transform Kalman filter (LETKF) but because of algorithm differences is implemented differently. The iEnSRF is a three-step procedure: first, a backward EnSRF analysis is performed that updates the ensemble model states at an earlier time. Second, an ensemble of forecasts is run from these updated model states to the analysis time. These two steps are then repeated a prespecified number of times. The backward analysis is performed via an asynchronous ensemble Kalman filter (EnKF), which is capable of assimilating observations collected at times different than the analysis time. Like RIP, the iEnSRF uses the same observations repeatedly during the initial assimilation cycles, allowing for the extraction of additional information from observations when estimated ensemble mean state and ensemble covariance are poor. The iEnSRF algorithm is tested using simulated radar data for an idealized supercell storm. In experiments with a perfect model and the correct storm environment, as well as in the presence of model and environmental errors, the iEnSRF reduces the analysis error in the first few cycles more quickly than the regular EnSRF, leading to improved subsequent short-range forecasts. After the first few analysis cycles, continued use of iterations does not lead to further improvement. The better performance of the iEnSRF appears to be the result of improved background error covariance estimation as well as improved state estimation in the first few cycles, especially for correlations between observed and unobserved variables. Through iterations, the iEnSRF is also able to reach a steady level of state estimation error more quickly than the corresponding non-iterated version.},
	language = {en},
	number = {676},
	urldate = {2018-11-14},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Wang, Shizhang and Xue, Ming and Schenkman, Alexander D. and Min, Jinzhong},
	month = oct,
	year = {2013},
	keywords = {ensemble Kalman filter, iterative procedure, radar data assimilation},
	pages = {1888--1903}
}

@article{atlas_effect_1993,
	title = {The {Effect} of {SST} and {Soil} {Moisture} {Anomalies} on {GLA} {Model} {Simulations} of the 1988 {U}.{S}. {Summer} {Drought}},
	volume = {6},
	issn = {0894-8755},
	url = {https://journals.ametsoc.org/doi/10.1175/1520-0442%281993%29006%3C2034%3ATEOSAS%3E2.0.CO%3B2},
	doi = {10.1175/1520-0442(1993)006<2034:TEOSAS>2.0.CO;2},
	abstract = {A series of simulations of the late spring and early summer of 1988 were conducted in order to study the relative importance of different boundary forcings to the Goddard Laboratory for Atmospheres model's simulation of the heat wave and drought over the Great Plains of the United States during this time period. Separate 60- day simulations were generated from 10, 20, and 30 May 1988 with a variety of boundary condition datasets. For the control experiment, climatological boundary conditions were used. This was followed by experiments in which either the observed 1988 sea surface temperatures (SST) or derived 1988 soil moisture values, or both, were used in place of the climatological fields. Additional experiments were conducted in which only tropical or midlatitude SST anomalies were used. The impact of the different boundary forcings was evaluated relative to the control simulations of the precipitation and surface air temperature over the Great Plains. It was found that the tropical SST anomalies had a significant effect in reducing precipitation in this area, while the midlatitude anomalies did not. Due to the prescribed climatological soil moistures for the SST experiments, a significant increase in surface temperature did not occur in these simulations. In contrast, the simulations with the anomalous 1988 soil moistures produced both a larger reduction of precipitation and a significant increase in surface temperature over the Great Plains. The simulations with both anomalous SST and soil moisture showed only a slight augmentation of the heat wave and drought relative to the experiments with anomalous soil moisture alone.},
	number = {11},
	urldate = {2018-11-14},
	journal = {Journal of Climate},
	author = {Atlas, R. and Wolfson, N. and Terry, J.},
	month = nov,
	year = {1993},
	pages = {2034--2048}
}

@article{kalnay_accelerating_2010,
	title = {Accelerating the spin-up of {Ensemble} {Kalman} {Filtering}},
	volume = {136},
	copyright = {Copyright © 2010 Royal Meteorological Society},
	issn = {1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/qj.652},
	doi = {10.1002/qj.652},
	abstract = {Ensemble Kalman Filter (EnKF) may have a longer spin-up time to reach its asymptotic level of accuracy than the corresponding spin-up time in variational methods (3D-Var or 4D-Var). During the spin-up EnKF has to fulfill two independent requirements, namely that the ensemble mean be close to the true state, and that the ensemble perturbations represent the ‘errors of the day’. As a result, there are cases, such as radar observations of a severe storm, or regional forecast of a hurricane, where EnKF may spin-up too slowly to be useful. A heuristic scheme is proposed to accelerate the spin-up of EnKF by applying a no-cost Ensemble Kalman Smoother, and using the observations more than once in each assimilation window during spin-up in order to maximize the initial extraction of information. The performance of this scheme is tested with the Local Ensemble Transform Kalman Filter (LETKF) implemented in a quasi-geostrophic model, which requires a very long spin-up time when initialized from random initial perturbations from a uniform distribution. Results show that with the new ‘running in place’ (RIP) scheme the LETKF spins up and converges to the optimal level of error faster than 3D-Var or 4D-Var, even in the absence of any prior information. Additional computations (2 to 12 iterations for each assimilation window) are only required during the initial spin-up, since the scheme naturally returns to the original LETKF after spin-up is achieved. RIP also accelerates spin-up when the initial perturbations are drawn from a well-tuned 3D-Var background-error covariance, rather than being uniform noise, and fewer iterations and RIP cycles are required than in the case without such prior information. Copyright © 2010 Royal Meteorological Society},
	language = {en},
	number = {651},
	urldate = {2018-11-14},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Kalnay, Eugenia and Yang, Shu-Chih},
	month = jul,
	year = {2010},
	keywords = {LETKF, 3D-Var 4D-Var, EnKF, RIP scheme},
	pages = {1644--1651}
}

@article{sakov_iterative_2012,
	title = {An {Iterative} {EnKF} for {Strongly} {Nonlinear} {Systems}},
	volume = {140},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/doi/10.1175/MWR-D-11-00176.1},
	doi = {10.1175/MWR-D-11-00176.1},
	abstract = {The study considers an iterative formulation of the ensemble Kalman filter (EnKF) for strongly nonlinear systems in the perfect-model framework. In the first part, a scheme is introduced that is similar to the ensemble randomized maximal likelihood (EnRML) filter by Gu and Oliver. The two new elements in the scheme are the use of the ensemble square root filter instead of the traditional (perturbed observations) EnKF and rescaling of the ensemble anomalies with the ensemble transform matrix from the previous iteration instead of estimating sensitivities between the ensemble observations and ensemble anomalies at the start of the assimilation cycle by linear regression. A simple modification turns the scheme into an ensemble formulation of the iterative extended Kalman filter. The two versions of the algorithm are referred to as the iterative EnKF (IEnKF) and the iterative extended Kalman filter (IEKF).In the second part, the performance of the IEnKF and IEKF is tested in five numerical experiments: two with the 3-element Lorenz model and three with the 40-element Lorenz model. Both the IEnKF and IEKF show a considerable advantage over the EnKF in strongly nonlinear systems when the quality or density of observations are sufficient to constrain the model to the regime of mainly linear propagation of the ensemble anomalies as well as constraining the fast-growing modes, with a much smaller advantage otherwise.The IEnKF and IEKF can potentially be used with large-scale models, and can represent a robust and scalable alternative to particle filter (PF) and hybrid PF–EnKF schemes in strongly nonlinear systems.},
	number = {6},
	urldate = {2018-11-14},
	journal = {Monthly Weather Review},
	author = {Sakov, Pavel and Oliver, Dean S. and Bertino, Laurent},
	month = feb,
	year = {2012},
	pages = {1988--2004}
}

@article{van_leeuwen_nonlinear_2010,
	title = {Nonlinear data assimilation in geosciences: an extremely efficient particle filter},
	volume = {136},
	copyright = {Copyright © 2010 Royal Meteorological Society},
	issn = {1477-870X},
	shorttitle = {Nonlinear data assimilation in geosciences},
	url = {https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/qj.699},
	doi = {10.1002/qj.699},
	abstract = {Almost all research fields in geosciences use numerical models and observations and combine these using data-assimilation techniques. With ever-increasing resolution and complexity, the numerical models tend to be highly nonlinear and also observations become more complicated and their relation to the models more nonlinear. Standard data-assimilation techniques like (ensemble) Kalman filters and variational methods like 4D-Var rely on linearizations and are likely to fail in one way or another. Nonlinear data-assimilation techniques are available, but are only efficient for small-dimensional problems, hampered by the so-called ‘curse of dimensionality’. Here we present a fully nonlinear particle filter that can be applied to higher dimensional problems by exploiting the freedom of the proposal density inherent in particle filtering. The method is illustrated for the three-dimensional Lorenz model using three particles and the much more complex 40-dimensional Lorenz model using 20 particles. By also applying the method to the 1000-dimensional Lorenz model, again using only 20 particles, we demonstrate the strong scale-invariance of the method, leading to the optimistic conjecture that the method is applicable to realistic geophysical problems. Copyright © 2010 Royal Meteorological Society},
	language = {en},
	number = {653},
	urldate = {2018-11-14},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {van Leeuwen, P. J.},
	month = oct,
	year = {2010},
	keywords = {data assimilation, particle filtering},
	pages = {1991--1999}
}

@article{van_leeuwen_particle_2009,
	title = {Particle {Filtering} in {Geophysical} {Systems}},
	volume = {137},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/doi/10.1175/2009MWR2835.1},
	doi = {10.1175/2009MWR2835.1},
	abstract = {The application of particle filters in geophysical systems is reviewed. Some background on Bayesian filtering is provided, and the existing methods are discussed. The emphasis is on the methodology, and not so much on the applications themselves. It is shown that direct application of the basic particle filter (i.e., importance sampling using the prior as the importance density) does not work in high-dimensional systems, but several variants are shown to have potential. Approximations to the full problem that try to keep some aspects of the particle filter beyond the Gaussian approximation are also presented and discussed.},
	number = {12},
	urldate = {2018-11-14},
	journal = {Monthly Weather Review},
	author = {van Leeuwen, Peter Jan},
	month = dec,
	year = {2009},
	pages = {4089--4114}
}

@article{snyder_obstacles_2008,
	title = {Obstacles to {High}-{Dimensional} {Particle} {Filtering}},
	volume = {136},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/doi/10.1175/2008MWR2529.1},
	doi = {10.1175/2008MWR2529.1},
	abstract = {Particle filters are ensemble-based assimilation schemes that, unlike the ensemble Kalman filter, employ a fully nonlinear and non-Gaussian analysis step to compute the probability distribution function (pdf) of a system’s state conditioned on a set of observations. Evidence is provided that the ensemble size required for a successful particle filter scales exponentially with the problem size. For the simple example in which each component of the state vector is independent, Gaussian, and of unit variance and the observations are of each state component separately with independent, Gaussian errors, simulations indicate that the required ensemble size scales exponentially with the state dimension. In this example, the particle filter requires at least 1011 members when applied to a 200-dimensional state. Asymptotic results, following the work of Bengtsson, Bickel, and collaborators, are provided for two cases: one in which each prior state component is independent and identically distributed, and one in which both the prior pdf and the observation errors are Gaussian. The asymptotic theory reveals that, in both cases, the required ensemble size scales exponentially with the variance of the observation log likelihood rather than with the state dimension per se.},
	number = {12},
	urldate = {2018-11-14},
	journal = {Monthly Weather Review},
	author = {Snyder, Chris and Bengtsson, Thomas and Bickel, Peter and Anderson, Jeff},
	month = dec,
	year = {2008},
	pages = {4629--4640}
}

@article{lorenz_statistical_1960-1,
	title = {The statistical prediction of solutions of dynamic equations.},
	journal = {Symposium on Numerical Weather Prediction in Tokyo},
	author = {Lorenz, Edward N.},
	year = {1960},
	pages = {647,629--635}
}

@article{bocquet_combining_2012,
	title = {Combining inflation-free and iterative ensemble {Kalman} filters   for strongly nonlinear systems},
	volume = {19},
	issn = {1607-7946},
	url = {https://www.nonlin-processes-geophys.net/19/383/2012/},
	doi = {10.5194/npg-19-383-2012},
	abstract = {The finite-size ensemble Kalman filter (EnKF-N) is an ensemble Kalman filter (EnKF) which, in perfect model condition, does not require inflation because it partially accounts for the ensemble sampling errors. For the Lorenz '63 and '95 toy-models, it was so far shown to perform as well or better than the EnKF with an optimally tuned inflation. The iterative ensemble Kalman filter (IEnKF) is an EnKF which was shown to perform much better than the EnKF in strongly nonlinear conditions, such as with the Lorenz '63 and '95 models, at the cost of iteratively updating the trajectories of the ensemble members. This article aims at further exploring the two filters and at combining both into an EnKF that does not require inflation in perfect model condition, and which is as efficient as the IEnKF in very nonlinear conditions.  In this study, EnKF-N is first introduced and a new implementation is developed. It decomposes EnKF-N into a cheap two-step algorithm that amounts to computing an optimal inflation factor. This offers a justification of the use of the inflation technique in the traditional EnKF and why it can often be efficient. Secondly, the IEnKF is introduced following a new implementation based on the Levenberg-Marquardt optimisation algorithm. Then, the two approaches are combined to obtain the finite-size iterative ensemble Kalman filter (IEnKF-N). Several numerical experiments are performed on IEnKF-N with the Lorenz '95 model. These experiments demonstrate its numerical efficiency as well as its performance that offer, at least, the best of both filters. We have also selected a demanding case based on the Lorenz '63 model that points to ways to improve the finite-size ensemble Kalman filters. Eventually, IEnKF-N could be seen as the first brick of an efficient ensemble Kalman smoother for strongly nonlinear systems.},
	number = {3},
	urldate = {2018-11-14},
	journal = {Nonlin. Processes Geophys.},
	author = {Bocquet, M. and Sakov, P.},
	month = jun,
	year = {2012},
	pages = {383--399}
}

@article{yang_handling_2012,
	title = {Handling {Nonlinearity} in an {Ensemble} {Kalman} {Filter}: {Experiments} with the {Three}-{Variable} {Lorenz} {Model}},
	volume = {140},
	issn = {0027-0644},
	shorttitle = {Handling {Nonlinearity} in an {Ensemble} {Kalman} {Filter}},
	url = {https://journals.ametsoc.org/doi/10.1175/MWR-D-11-00313.1},
	doi = {10.1175/MWR-D-11-00313.1},
	abstract = {An ensemble Kalman filter (EnKF) is optimal only for linear models because it assumes Gaussian distributions. A new type of outer loop, different from the one used in 3D and 4D variational data assimilation (Var), is proposed for EnKF to improve its ability to handle nonlinear dynamics, especially for long assimilation windows. The idea of the “running in place” (RIP) algorithm is to increase the observation influence by reusing observations when there is strong nonlinear error growth, and thus improve the ensemble mean and perturbations within the local ensemble transform Kalman filter (LETKF) framework. The “quasi-outer-loop” (QOL) algorithm, proposed here as a simplified version of RIP, aims to improve the ensemble mean so that ensemble perturbations are centered at a more accurate state.The performances of LETKF–RIP and LETKF–QOL in the presence of nonlinearities are tested with the three-variable Lorenz model. Results show that RIP and QOL allow LETKF to use longer assimilation windows with significant improvement of the analysis accuracy during periods of high nonlinear growth. For low-frequency observations (every 25 time steps, leading to long assimilation windows), and using the optimal inflation, the standard LETKF RMS error is 0.68, whereas for QOL and RIP the RMS errors are 0.47 and 0.35, respectively. This can be compared to the best 4D-Var analysis error of 0.53, obtained by using both the optimal long assimilation windows (75 time steps) and quasi-static variational analysis.},
	number = {8},
	urldate = {2018-11-14},
	journal = {Monthly Weather Review},
	author = {Yang, Shu-Chih and Kalnay, Eugenia and Hunt, Brian},
	month = mar,
	year = {2012},
	pages = {2628--2646}
}

@book{lorenz_essence_1993,
	address = {Seattle},
	series = {The {Jessie} and {John} {Danz} lectures},
	title = {The essence of chaos},
	isbn = {978-0-295-97270-1 978-1-85728-454-6 978-1-85728-187-3},
	url = {http://www.gbv.de/dms/bowker/toc/9781857284546.pdf},
	language = {English},
	urldate = {2018-11-14},
	publisher = {University of Washington Press},
	author = {Lorenz, Edward N.},
	year = {1993}
}

@article{carrassi_data_2018,
	title = {Data assimilation in the geosciences: {An} overview of methods, issues, and perspectives},
	volume = {9},
	copyright = {© 2018 Wiley Periodicals, Inc.},
	issn = {1757-7799},
	shorttitle = {Data assimilation in the geosciences},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wcc.535},
	doi = {10.1002/wcc.535},
	abstract = {We commonly refer to state estimation theory in geosciences as data assimilation (DA). This term encompasses the entire sequence of operations that, starting from the observations of a system, and from additional statistical and dynamical information (such as a dynamical evolution model), provides an estimate of its state. DA is standard practice in numerical weather prediction, but its application is becoming widespread in many other areas of climate, atmosphere, ocean, and environment modeling; in all circumstances where one intends to estimate the state of a large dynamical system based on limited information. While the complexity of DA, and of the methods thereof, stands on its interdisciplinary nature across statistics, dynamical systems, and numerical optimization, when applied to geosciences, an additional difficulty arises by the continually increasing sophistication of the environmental models. Thus, in spite of DA being nowadays ubiquitous in geosciences, it has so far remained a topic mostly reserved to experts. We aim this overview article at geoscientists with a background in mathematical and physical modeling, who are interested in the rapid development of DA and its growing domains of application in environmental science, but so far have not delved into its conceptual and methodological complexities. This article is categorized under: Climate Models and Modeling {\textgreater} Knowledge Generation with Models},
	language = {en},
	number = {5},
	urldate = {2018-11-14},
	journal = {Wiley Interdisciplinary Reviews: Climate Change},
	author = {Carrassi, Alberto and Bocquet, Marc and Bertino, Laurent and Evensen, Geir},
	month = sep,
	year = {2018},
	keywords = {data assimilation, Bayesian methods, ensemble methods, environmental prediction},
	pages = {e535}
}

@techreport{bouttier_operational_1997,
	type = {{ECMWF} {Newsletter}},
	title = {The operational implementation of {4D}-{Var}},
	number = {78},
	institution = {ECMWF},
	author = {Bouttier, F. and Rabier, F.},
	year = {1997},
	pages = {2--5}
}

@techreport{bouttier_1997_1997,
	type = {Tech. {Memo}., 238},
	title = {The 1997 revision of the {Jb} term in {3D}/{4D}-{Var}},
	institution = {ECMWF},
	author = {Bouttier, F. and Derber, J. C. and Fisher, M.},
	year = {1997}
}

@article{zupanski_regional_1993,
	title = {Regional {Four}-{Dimensional} {Variational} {Data} {Assimilation} in a {Quasi}-{Operational} {Forecasting} {Environment}},
	volume = {121},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1993)121%3C2396:RFDVDA%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1993)121<2396:RFDVDA>2.0.CO;2},
	abstract = {Four-dimensional variational data assimilation is applied to a regional forecast model as part of the development of a new data assimilation system at the National Meteorological Center (NMC). The assimilation employs an operational version of the NMC's new regional forecast model defined in eta vertical coordinates, and data used are operationally produced optimal interpolation (OI) analyses (using the first guess from the NMC's global spectral model), available every 3 h. Humidity and parameterized processes are not included in the adjoint model integration. The calculation of gradients by the adjoint model is approximate since the forecast model is used in its full-physics operational form. All experiments are over a 12-h assimilation period with subsequent 48-h forecast. Three different types of assimilation experiments are performed:   adjustment of initial conditions only (standard “adjoint” approach),   adjustment of a correction to the model equations only (variational continuous assimilation), and   simultaneous or sequential adjustment of both initial conditions and the correction term.   Results indicate significantly better results when the correction term is included in the assimilation. It is shown, for a single case, that the new technique [experiment (c)] is able to produce a forecast better than the current conventional OI assimilation. It is very important to note that these results are obtained with an approximate gradient, calculated from a simplified adjoint model. Thus, it may be possible to perform an operational four-dimensional variational data assimilation of realistic forecast models, even before more complex adjoint models are developed. Also, our results suggest that it may be possible to reduce the large computational cost of assimilation by using only a few iterations of the minimization algorithm. This fast convergence is encouraging from the prospective of operational use.},
	number = {8},
	urldate = {2018-10-26},
	journal = {Monthly Weather Review},
	author = {Zupanski, Milija},
	month = aug,
	year = {1993},
	pages = {2396--2408}
}

@techreport{dimego_data_1985,
	address = {Washington, D.C.},
	title = {Data processing, and quality control for optimum interpolation analyses at the {National} {Meteorological} {Center}},
	url = {https://repository.library.noaa.gov/view/noaa/11502},
	number = {Office Note 306},
	urldate = {2018-10-26},
	institution = {U.S. Dept. of Commerce, National Oceanic and Atmospheric Administration, National Weather Service.},
	author = {DiMego, Geoffrey J. and Phoebus, Patricia A. and McDonell, James E.},
	year = {1985}
}

@article{dee_maximum-likelihood_1999-1,
	title = {Maximum-{Likelihood} {Estimation} of {Forecast} and {Observation} {Error} {Covariance} {Parameters}. {Part} {I}: {Methodology}},
	volume = {127},
	issn = {0027-0644},
	shorttitle = {Maximum-{Likelihood} {Estimation} of {Forecast} and {Observation} {Error} {Covariance} {Parameters}. {Part} {I}},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1999)127%3C1822:MLEOFA%3E2.0.CO;2},
	doi = {10.1175/1520-0493(1999)127<1822:MLEOFA>2.0.CO;2},
	abstract = {The maximum-likelihood method for estimating observation and forecast error covariance parameters is described. The method is presented in general terms but with particular emphasis on practical aspects of implementation. Issues such as bias estimation and correction, parameter identifiability, estimation accuracy, and robustness of the method, are discussed in detail. The relationship between the maximum-likelihood method and generalized cross-validation is briefly addressed. The method can be regarded as a generalization of the traditional procedure for estimating covariance parameters from station data. It does not involve any restrictions on the covariance models and can be used with data from moving observers, provided the parameters to be estimated are identifiable. Any available a priori information about the observation and forecast error distributions can be incorporated into the estimation procedure. Estimates of parameter accuracy due to sampling error are obtained as a by-product.},
	number = {8},
	urldate = {2018-10-26},
	journal = {Monthly Weather Review},
	author = {Dee, Dick P. and da Silva, Arlindo M.},
	month = aug,
	year = {1999},
	pages = {1822--1834}
}

@article{zou_optimal_1992,
	title = {An {Optimal} {Nudging} {Data} {Assimilation} {Scheme} {Using} {Parameter} {Estimation}},
	volume = {118},
	copyright = {Copyright © 1992 Royal Meteorological Society},
	issn = {1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/qj.49711850808},
	doi = {10.1002/qj.49711850808},
	abstract = {A new optimal nudging dynamical relaxation technique is tested in the framework of 4-dimensional variational data assimilation, applied to an adiabatic T40 version of the National Meteorological Center (NMC) spectral model with 18 vertical layers. Several experiments are performed using the NMC operationally analysed data. the variational data assimilation algorithm is also employed in a parameter-estimation mode to determine the vector of optimal nudging coefficients. Results of data-assimilation experiments involving estimated nudging, optimal nudging and variational data assimilation are compared. Issues are addressed related to the dependence of the assimilation on the length of the assimilation period as well as to the ability of retrieving high-quality model initial conditions. The study outlines the ability to obtain optimal nudging coefficients, which can vary in space, in the framework of a parameter-estimation approach using variational data assimilation. Based on our preliminary results the optimal nudging seems to be a most promising data-assimilation scheme.},
	language = {en},
	number = {508},
	urldate = {2018-10-26},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Zou, X. and Navon, I. M. and Ledimet, F. X.},
	month = oct,
	year = {1992},
	pages = {1163--1186}
}

@book{jazwinski_stochastic_1970,
	title = {Stochastic {Processes} and {Filtering} {Theory}},
	publisher = {Academic Press},
	author = {Jazwinski, A. H.},
	year = {1970}
}

@article{talagrand_assimilation_1997,
	title = {Assimilation of {Observations}, an {Introduction} ({Special} {Issue} {Data} {Assimilation} in {Meteorology} and {Oceanography}: {Theory} and {Practice})},
	volume = {75},
	shorttitle = {Assimilation of {Observations}, an {Introduction} ({gtSpecial} {IssueltData} {Assimilation} in {Meteology} and {Oceanography}},
	doi = {10.2151/jmsj1965.75.1B_191},
	abstract = {Assimilation of meteorological or oceanographical observations can be described as the process through which all the available information is used in order to estimate as accurately as possible the state of the atmospheric or oceanic flow. The available information essentially consists of the observations proper, and of the Physical laws which govern the evolution of the flow. The latter are available in practice under the form of a numerical model. The existing assimilation algorithms can be described as either sequential or variational. The links between these algorithms and the theory of statistical estimation are discussed. The performances of present algorithms, and the perspectives for future development, are also briefly discussed.},
	number = {1B},
	journal = {Journal of the Meteorological Society of Japan. Ser. II},
	author = {Talagrand, Olivier},
	year = {1997},
	pages = {191--209}
}

@article{leith_theoretical_1974,
	title = {Theoretical {Skill} of {Monte} {Carlo} {Forecasts}},
	volume = {102},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/doi/10.1175/1520-0493%281974%29102%3C0409%3ATSOMCF%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1974)102<0409:TSOMCF>2.0.CO;2},
	abstract = {The theoretical skill of Monte Carlo approximations to the stochastic dynamic forecasting technique proposed by Epstein is examined by means of an extension of earlier atmospheric predictability studies that used the test-field model of two-dimensional turbulence. The fundamental statistical hydrodynamical concept of an ensemble of phase paths evolving in a dynamical phase space is reviewed and used to define the statistical properties of a finite Monte Carlo sample. The application of a linear regression step to arrive at a final best estimate of the state of the atmosphere is also discussed. The resulting forecasts approach the climatological mean at forecast times so late that all skill has been lost. For an ideal case with an observing resolution, hopefully achievable in the 1980s with satellite-based sensors, it is found that the. Monte Carlo procedure leads to the greatest improvement in mean-square vector wind forecast skill in the 6- to 10-day range. For another case corresponding roughly to present operational resolution the wind forecast skill is improved considerably in the 2- to 5-day range. Much of the improvement in mean-square skill is a consequence of the optimal filtering nature of the procedure which damps erroneous small scale structure in favor of the more predictable large scales.},
	number = {6},
	urldate = {2018-07-20},
	journal = {Monthly Weather Review},
	author = {Leith, C. E.},
	month = jun,
	year = {1974},
	pages = {409--418}
}

@article{woolard_l._1922,
	title = {L. f. richardson on weather prediction by numerical process},
	volume = {50},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281922%2950%3C72%3ALFROWP%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1922)50<72:LFROWP>2.0.CO;2},
	abstract = {No Abstract Available.},
	number = {2},
	urldate = {2018-07-19},
	journal = {Monthly Weather Review},
	author = {Woolard, Edgar W.},
	month = feb,
	year = {1922},
	pages = {72--74}
}

@article{robert_stable_1981,
	title = {A stable numerical integration scheme for the primitive meteorological equations},
	volume = {19},
	issn = {0705-5900},
	url = {https://doi.org/10.1080/07055900.1981.9649098},
	doi = {10.1080/07055900.1981.9649098},
	abstract = {A stable numerical integration scheme is applied to the non‐divergent barotropic vorticity equation. Integrations are performed with time steps ranging from 15 min to 4 h. The root‐mean‐square differences between the forecasts are calculated in order to measure the sensitivity of the predictions to the size of the time step. These experiments show that the truncation errors remain reasonably small with time steps as large as two hours. This scheme is then associated with the semi‐implicit algorithm in the integration of the shallow water equations. Integrations are carried out with large time steps and the resulting predictions are presented in order to demonstrate that the scheme is perfectly stable.},
	number = {1},
	urldate = {2018-07-16},
	journal = {Atmosphere-Ocean},
	author = {Robert, André},
	month = mar,
	year = {1981},
	pages = {35--46}
}

@article{gadd_split_1978,
	title = {A split explicit integration scheme for numerical weather prediction},
	volume = {104},
	copyright = {Copyright © 1978 Royal Meteorological Society},
	issn = {1477-870X},
	url = {https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/qj.49710444103},
	doi = {10.1002/qj.49710444103},
	abstract = {An economical explicit integration scheme for numerical weather prediction models is described. A splitting technique is used, in which the horizontal advection terms in the governing equations are integrated with a timestep limited by the wind speed, whilst the terms which describe gravity-inertia oscillations are integrated in a succession of shorter steps. A two-level numerical scheme with small phase speed errors is used for the advection stage and a forward-backward method for the gravity-inertia terms. The split explicit scheme has been applied to the Meteorological Office operational 10-level model, and to a similar sigma coordinate model, to compute forecasts for periods up to six days ahead. The quality of the numerical forecasts obtained is not reduced when the timesteps used are close to the limits set by linear computational stability criteria. The use of such timesteps leads to a substantial computational economy relative to previously available integration schemes. For the northern hemisphere version of the 10-level model the computing time required is one-third of that for a split semi-implicit scheme and one-sixth of that for the original explicit Lax-Wendroff scheme. Verification statistics for split explicit forecasts indicate improved accuracy when compared with those for earlier operational models.},
	language = {en},
	number = {441},
	urldate = {2018-07-16},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Gadd, A. J.},
	year = {1978},
	pages = {569--582}
}

@article{janjic_nonhydrostatic_2003,
	title = {A nonhydrostatic model based on a new approach},
	volume = {82},
	issn = {0177-7971, 1436-5065},
	url = {https://link.springer.com/article/10.1007/s00703-001-0587-6},
	doi = {10.1007/s00703-001-0587-6},
	abstract = {Summary¶The nonhydrostatic Meso model developed at NCEP (Janjic et al, 2001) is based on a new approach. Namely, a hydrostatic NWP model using mass based vertical coordinate has been extended to include the nonhydrostatic motions. In this way favorable features of the hydrostatic formulation have been preserved. This procedure did not require any linearization or approximation.The nonhydrostatic dynamics has been introduced through an add-on module. The nonhydrostatic module can be turned on and off, so that easy comparison can be made of hydrostatic and nonhydrostatic solutions.Here, the basic philosophy behind the discretization methods applied in the model, and not covered by Janjic et al (2001), is discussed, and the latest developments are reviewed. The forecast examples shown indicate that significant differences between hydrostatic and nonhydrostatic forecasts may develop even at relatively coarse resolution of 8 km. Possible future developments are considered.},
	language = {en},
	number = {1-4},
	urldate = {2018-07-16},
	journal = {Meteorology and Atmospheric Physics},
	author = {Janjic, Z. I.},
	month = jan,
	year = {2003},
	pages = {271--285}
}

@article{laprise_euler_1992,
	title = {The {Euler} {Equations} of {Motion} with {Hydrostatic} {Pressure} as an {Independent} {Variable}},
	volume = {120},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/1520-0493%281992%29120%3C0197%3ATEEOMW%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1992)120<0197:TEEOMW>2.0.CO;2},
	abstract = {A novel form of the Euler equations is developed through the use of a different vertical coordinate system. It is shown that the use of hydrostatic pressure as an independent variable has the advantage that the Euler equations then take a form that parallels very closely the form of the hydrostatic equations cast in isobaric coordinates. This similarity holds even when topography is incorporated through a further transformation into terrain-following coordinates. This leads us to suggest that hydrostatic-pressure coordinates could be used advantageously in nonhydrostatic atmospheric models based on the fully compressible equations.},
	number = {1},
	urldate = {2018-07-16},
	journal = {Monthly Weather Review},
	author = {Laprise, René},
	month = jan,
	year = {1992},
	pages = {197--207}
}

@misc{noauthor_zotero_nodate,
	title = {Zotero {\textbar} {Your} personal research assistant},
	url = {https://www.zotero.org/},
	urldate = {2018-07-16}
}

@misc{noauthor_advanced_nodate,
	title = {The {Advanced} {Regional} {Prediction} {System} ({ARPS}), storm-scale numerical weather prediction and data assimilation {M} {Xue}, {D} {Wang}, {J} {Gao}, {K} {Brewster}, {KK} {Droegemeier} {Meteorology} and {Atmospheric} {Physics} 82 (1), 139-170 - {Google} {Search}},
	url = {https://www.google.com/search?q=The+Advanced+Regional+Prediction+System+(ARPS)%2C+storm-scale+numerical+weather+prediction+and+data+assimilation+M+Xue%2C+D+Wang%2C+J+Gao%2C+K+Brewster%2C+KK+Droegemeier+Meteorology+and+Atmospheric+Physics+82+(1)%2C+139-170&rlz=1C5CHFA_enUS797US797&oq=The+Advanced+Regional+Prediction+System+(ARPS)%2C+storm-scale+numerical+weather+prediction+and+data+assimilation+M+Xue%2C+D+Wang%2C+J+Gao%2C+K+Brewster%2C+KK+Droegemeier+Meteorology+and+Atmospheric+Physics+82+(1)%2C+139-170&aqs=chrome..69i57.4181j0j7&sourceid=chrome&ie=UTF-8},
	urldate = {2018-07-16}
}

@article{sommeria_three-dimensional_1976,
	title = {Three-{Dimensional} {Simulation} of {Turbulent} {Processes} in an {Undisturbed} {Trade} {Wind} {Boundary} {Layer}},
	volume = {33},
	issn = {0022-4928},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1976)033%3C0216%3ATDSOTP%3E2.0.CO%3B2},
	doi = {10.1175/1520-0469(1976)033<0216:TDSOTP>2.0.CO;2},
	abstract = {The numerical model used by Deardorff (1972) for studying the clear air boundary layer under neutral or unstable conditions has been extended to include most of the physical processes occurring in a moist boundary layer in the absence of precipitation. It now contains a water cycle with cloud formation and a revised treatment of the subgrid-scale turbulence which incorporates effects of thermal stratification; it takes Into account infrared radiative cooling in clear and cloudy conditions and the influence of large-scale vertical motions and horizontal gradients. Section 2 includes a description of the model with emphasis on its new features. Section 3 presents some results obtained in a simulation of the trade wind boundary layer with detailed treatment of cloud dynamics in the absence of precipitation. The simulation shows how the turbulent characteristics evolve with time toward a statistically steady state, with an example being given of the turbulent field in the presence of clouds. The relative importance of the various physical processes in the evolution of the mean field of variables is indicated.},
	number = {2},
	urldate = {2018-07-16},
	journal = {Journal of the Atmospheric Sciences},
	author = {Sommeria, Gilles},
	month = feb,
	year = {1976},
	pages = {216--241}
}

@article{saito_nonhydrostatic_2007,
	title = {Nonhydrostatic {Atmospheric} {Models} and {Operational} {Development} at {JMA}},
	volume = {85B},
	issn = {0026-1165, 2186-9057},
	url = {https://www.jstage.jst.go.jp/article/jmsj/85B/0/85B_0_271/_article},
	doi = {10.2151/jmsj.85B.271},
	abstract = {Japan's largest platform for academic e-journals: J-STAGE is a full text database for reviewed academic papers published by Japanese societies},
	language = {en},
	urldate = {2018-07-16},
	journal = {Journal of the Meteorological Society of Japan. Ser. II},
	author = {Saito, Kazuo and Ishida, Jun-ichi and Aranami, Kohei and Hara, Tabito and Segawa, Tomonori and Narita, Masami and Honda, Yuuki},
	year = {2007},
	pages = {271--304}
}

@article{satoh_non-hydrostatic_2014,
	title = {The {Non}-hydrostatic {Icosahedral} {Atmospheric} {Model}: description and development},
	volume = {1},
	issn = {2197-4284},
	shorttitle = {The {Non}-hydrostatic {Icosahedral} {Atmospheric} {Model}},
	url = {https://doi.org/10.1186/s40645-014-0018-1},
	doi = {10.1186/s40645-014-0018-1},
	abstract = {This article reviews the development of a global non-hydrostatic model, focusing on the pioneering research of the Non-hydrostatic Icosahedral Atmospheric Model (NICAM). Very high resolution global atmospheric circulation simulations with horizontal mesh spacing of approximately O (km) were conducted using recently developed supercomputers. These types of simulations were conducted with a specifically designed atmospheric global model based on a quasi-uniform grid mesh structure and a non-hydrostatic equation system. This review describes the development of each dynamical and physical component of NICAM, the assimilation strategy and its related models, and provides a scientific overview of NICAM studies conducted to date.},
	urldate = {2018-07-16},
	journal = {Progress in Earth and Planetary Science},
	author = {Satoh, Masaki and Tomita, Hirofumi and Yashiro, Hisashi and Miura, Hiroaki and Kodama, Chihiro and Seiki, Tatsuya and Noda, Akira T. and Yamada, Yohei and Goto, Daisuke and Sawada, Masahiro and Miyoshi, Takemasa and Niwa, Yosuke and Hara, Masayuki and Ohno, Tomoki and Iga, Shin-ichi and Arakawa, Takashi and Inoue, Takahiro and Kubokawa, Hiroyasu},
	month = oct,
	year = {2014},
	keywords = {Global cloud-resolving simulations, Global non-hydrostatic model, Icosahedral grid},
	pages = {18},
	annote = {Pages 18 in PDF}
}

@techreport{kalnay_documentation_1983,
	title = {Documentation of the {GLAS} fourth order general circulation model.  {Volume} 2:  {Scalar} code},
	shorttitle = {Documentation of the {GLAS} fourth order general circulation model.  {Volume} 2},
	url = {https://ntrs.nasa.gov/search.jsp?R=19840015981},
	abstract = {Volume 2, of a 3 volume technical memoranda contains a detailed documentation of the GLAS fourth order general circulation model. Volume 2 contains the CYBER 205 scalar and vector codes of the model, list of variables, and cross references. A variable name dictionary for the scalar code, and code listings are outlined.},
	urldate = {2018-07-13},
	author = {Kalnay, E. Balgovind},
	month = dec,
	year = {1983},
	keywords = {mathematical models, weather, computerized simulation, numerical weather forecasting, atmospheric circulation, climatology, digital computers, documentation, reference systems, scalars, tensor analysis, vector dominance model},
	annote = {Document ID: 19840015981; Accession Number: 84N24049; Subject Category: METEOROLOGY AND CLIMATOLOGY; Publisher Information: United States; Financial Sponsor: NASA; United States; Organization Source: NASA Goddard Space Flight Center; Greenbelt, MD, United States; Description: 523p; In English; 3volumes},
	annote = {Report/Patent Number: NASA-TM-86064-VOL-2, NAS 1.15:86064-VOL-2}
}

@article{hotta_semi-implicit_2016,
	title = {A {Semi}-{Implicit} {Modification} to the {Lorenz} {N}-{Cycle} {Scheme} and {Its} {Application} for {Integration} of {Meteorological} {Equations}},
	volume = {144},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/doi/10.1175/MWR-D-15-0330.1},
	doi = {10.1175/MWR-D-15-0330.1},
	abstract = {The Lorenz N-cycle is an economical time integration scheme that requires only one function evaluation per time step and a minimal memory footprint, but yet possesses a high order of accuracy. Despite these advantages, it has remained less commonly used in meteorological applications, partly because of its lack of semi-implicit formulation. In this paper, a novel semi-implicit modification to the Lorenz N-cycle is proposed. The advantage of the proposed new scheme is that it preserves the economical memory use of the original explicit scheme. Unlike the traditional Robert–Asselin (RA) filtered semi-implicit leapfrog scheme whose formal accuracy is only of first order, the new scheme has second-order accuracy if it adopts the Crank–Nicolson scheme for the implicit part. A linear stability analysis based on a univariate split-frequency oscillation equation suggests that the 4-cycle is more stable than other choices of N. Numerical experiments performed using the dynamical core of the Simplified Parameterizations Primitive Equation Dynamics (SPEEDY) atmospheric general circulation model under the framework of the Jablonowski–Williamson baroclinic wave test case confirms that the new scheme in fact has second-order accuracy and is more accurate than the traditional RA-filtered leapfrog scheme. The experiments also give evidence for Lorenz’s claim that the explicit 4-cycle scheme can be improved by running its two “isomeric” versions in alternating sequences. Unlike the explicit scheme, however, the proposed semi-implicit scheme is not improved by alternation of the two versions.},
	number = {6},
	urldate = {2018-07-13},
	journal = {Monthly Weather Review},
	author = {Hotta, Daisuke and Kalnay, Eugenia and Ullrich, Paul},
	month = jan,
	year = {2016},
	pages = {2215--2233}
}

@article{matsuno_quasi-geostrophic_1966,
	title = {Quasi-{Geostrophic} {Motions} in the {Equatorial} {Area}},
	volume = {44},
	issn = {0026-1165, 2186-9057},
	url = {https://www.jstage.jst.go.jp/article/jmsj1965/44/1/44_1_25/_article},
	doi = {10.2151/jmsj1965.44.1_25},
	abstract = {Japan's largest platform for academic e-journals: J-STAGE is a full text database for reviewed academic papers published by Japanese societies},
	language = {en},
	number = {1},
	urldate = {2018-07-09},
	journal = {Journal of the Meteorological Society of Japan. Ser. II},
	author = {Matsuno, Taroh},
	year = {1966},
	pages = {25--43}
}

@article{matsuno_false_1966,
	title = {False {Reflection} of {Waves} at the {Boundary} {Due} to the {Use} of {Finite} {Differences}},
	volume = {44},
	issn = {0026-1165, 2186-9057},
	url = {https://www.jstage.jst.go.jp/article/jmsj1965/44/2/44_2_145/_article},
	doi = {10.2151/jmsj1965.44.2_145},
	abstract = {Japan's largest platform for academic e-journals: J-STAGE is a full text database for reviewed academic papers published by Japanese societies},
	language = {en},
	number = {2},
	urldate = {2018-07-09},
	journal = {Journal of the Meteorological Society of Japan. Ser. II},
	author = {Matsuno, T.},
	year = {1966},
	pages = {145--157}
}

@article{neelin_dynamics_1994,
	title = {Dynamics of {Coupled} {Ocean}-{Atmosphere} {Models}: {The} {Tropical} {Problem}},
	volume = {26},
	issn = {0066-4189},
	shorttitle = {Dynamics of {Coupled} {Ocean}-{Atmosphere} {Models}},
	url = {https://www.annualreviews.org/doi/10.1146/annurev.fl.26.010194.003153},
	doi = {10.1146/annurev.fl.26.010194.003153},
	number = {1},
	urldate = {2018-07-09},
	journal = {Annual Review of Fluid Mechanics},
	author = {Neelin, J D and Latif, M and Jin, F},
	month = jan,
	year = {1994},
	pages = {617--659}
}

@techreport{chassignet_viscosity_2001,
	title = {Viscosity {Parameterization} and the {Gulf} {Stream} {Separation}},
	url = {http://www.dtic.mil/docs/citations/ADP013577},
	abstract = {Recent advances in computer architecture allow for numerical integration of state-of-the-art ocean models at basin scale with a grid resolution of 1/10 degrees or higher. At that resolution, the Gulf Stream's separation at Cape Hatteras is well stimulated, but substantial differences from observations are still observed in its path, strength, and variability. Several high resolution (1/12 degrees) North Atlantic simulations performed with the Miami Isopycnic Coordinate Ocean Model (MICOM) are discussed and the results suggest that, even with such a fine grid spacing, the modeled large scale circulation is still quite sensitive to choices in forcing and viscosity parameterization.},
	language = {en},
	number = {ADP013577},
	urldate = {2018-07-09},
	institution = {MIAMI UNIV FL INST OF MARINE AND ATMOSPHERIC SCIENCES},
	author = {Chassignet, Eric P. and Garraffo, Zulema D.},
	month = jan,
	year = {2001}
}

@article{lin_vertically_2004,
	title = {A “{Vertically} {Lagrangian}” {Finite}-{Volume} {Dynamical} {Core} for {Global} {Models}},
	volume = {132},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/doi/full/10.1175/1520-0493(2004)132%3C2293:AVLFDC%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(2004)132<2293:AVLFDC>2.0.CO;2},
	abstract = {A finite-volume dynamical core with a terrain-following Lagrangian control-volume discretization is described. The vertically Lagrangian discretization reduces the dimensionality of the physical problem from three to two with the resulting dynamical system closely resembling that of the shallow water system. The 2D horizontal-to-Lagrangian-surface transport and dynamical processes are then discretized using the genuinely conservative flux-form semi-Lagrangian algorithm. Time marching is split-explicit, with large time steps for scalar transport, and small fractional steps for the Lagrangian dynamics, which permits the accurate propagation of fast waves. A mass, momentum, and total energy conserving algorithm is developed for remapping the state variables periodically from the floating Lagrangian control-volume to an Eulerian terrain-following coordinate for dealing with “physical parameterizations” and to prevent severe distortion of the Lagrangian surfaces. Deterministic baroclinic wave-growth tests and long-term integrations using the Held–Suarez forcing are presented. Impact of the monotonicity constraint is discussed.},
	number = {10},
	urldate = {2018-07-09},
	journal = {Monthly Weather Review},
	author = {Lin, Shian-Jiann},
	month = oct,
	year = {2004},
	pages = {2293--2307}
}

@article{lin_multidimensional_1996,
	title = {Multidimensional {Flux}-{Form} {Semi}-{Lagrangian} {Transport} {Schemes}},
	volume = {124},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1996)124%3C2046%3AMFFSLT%3E2.0.CO%3B2},
	doi = {10.1175/1520-0493(1996)124<2046:MFFSLT>2.0.CO;2},
	abstract = {An algorithm for extending one-dimensional, forward-in-time, upstream-biased, flux-form transport schemes (e.g., the van Leer scheme and the piecewise parabolic method) to multidimensions is proposed. A method is also proposed to extend the resulting Eulerian multidimensional flux-form scheme to arbitrarily long time steps. Because of similarities to the semi-Lagrangian approach of extending time steps, the scheme is called flux-form semi-Lagrangian (FFSL). The FFSL scheme can be easily and efficiently implemented on the sphere. Idealized tests as well as realistic three-dimensional global transport simulations using winds from data assimilation systems are demonstrated. Stability is analyzed with a von Neuman approach as well as empirically on the 2D Cartesian plane. The resulting algorithm is conservative and upstream biased. In addition, it contains monotonicity constraints and conserves tracer correlations, therefore representing the physical characteristics of constituent transport.},
	number = {9},
	urldate = {2018-07-09},
	journal = {Monthly Weather Review},
	author = {Lin, Shian-Jiann and Rood, Richard B.},
	month = sep,
	year = {1996},
	pages = {2046--2070}
}

@incollection{bjerknes_problem_1999,
	title = {The {Problem} of {Weather} {Forecasting} as a {Problem} in {Mechanics} and {Physics}},
	isbn = {978-1-935704-09-6},
	url = {https://link.springer.com/chapter/10.1007/978-1-935704-09-6_1},
	abstract = {If it is true, as every scientist believes, that subsequent atmospheric states develop from the preceding ones according to physical law, then it is apparent that the necessary and sufficient conditions for the rational solution of forecasting problems are the following: 1. A sufficiently accurate knowledge of the state of the atmosphere at the initial time. 2. A sufficiently accurate knowledge of the laws according to which one state of the atmosphere develops from another.},
	language = {en},
	urldate = {2018-07-09},
	booktitle = {The {Life} {Cycles} of {Extratropical} {Cyclones}},
	publisher = {American Meteorological Society, Boston, MA},
	author = {Bjerknes, Vilhelm},
	year = {1999},
	doi = {10.1007/978-1-935704-09-6_1},
	pages = {1--4}
}

@incollection{wheeler_tropical_2015,
	address = {Oxford},
	title = {{TROPICAL} {METEOROLOGY} {AND} {CLIMATE} {\textbar} {Equatorial} {Waves}},
	isbn = {978-0-12-382225-3},
	url = {http://www.sciencedirect.com/science/article/pii/B978012382225300414X},
	abstract = {Synopsis
Horizontal structures and dispersion relations of observed equatorial waves are analogous to solutions of the shallow water equations on an equatorial β-plane. In the past few decades, the significance of equatorial waves for tropical meteorology has become increasingly apparent. Equatorial waves exist in the atmosphere and ocean and cause perturbations in dynamical and thermodynamical variables large enough to be crucial for many aspects of tropical weather and climate variability. They form the basic building blocks of tropical circulations. Some aspects of their dynamics remain poorly understood.},
	urldate = {2018-07-09},
	booktitle = {Encyclopedia of {Atmospheric} {Sciences} ({Second} {Edition})},
	publisher = {Academic Press},
	author = {Wheeler, M. C. and Nguyen, H.},
	editor = {North, Gerald R. and Pyle, John and Zhang, Fuqing},
	month = jan,
	year = {2015},
	doi = {10.1016/B978-0-12-382225-3.00414-X},
	keywords = {Equivalent depth, Intertio-gravity wave, Kelvin wave, Madden-Julian oscillation, Rossby wave, Shallow water, Tropical meteorology, Wavenumber-frequency, Waves, β-Plane},
	pages = {102--112}
}

@article{valcke_coupling_2012,
	title = {Coupling technologies for {Earth} {System} {Modelling}},
	volume = {5},
	issn = {1991-9603},
	url = {https://www.geosci-model-dev.net/5/1589/2012/},
	doi = {10.5194/gmd-5-1589-2012},
	abstract = {This paper presents a review of the software currently used in climate modelling in general and in CMIP5 in particular to couple the numerical codes representing the different components of the Earth System. The coupling technologies presented show common features, such as the ability to communicate and regrid data, and also offer different functions and implementations. Design characteristics of the different approaches are discussed as well as future challenges arising from the increasing complexity of scientific problems and computing platforms.},
	number = {6},
	urldate = {2018-07-09},
	journal = {Geosci. Model Dev.},
	author = {Valcke, S. and Balaji, V. and Craig, A. and DeLuca, C. and Dunlap, R. and Ford, R. W. and Jacob, R. and Larson, J. and O'Kuinghttons, R. and Riley, G. D. and Vertenstein, M.},
	month = dec,
	year = {2012},
	pages = {1589--1596}
}

@article{jackett_algorithms_2006,
	title = {Algorithms for {Density}, {Potential} {Temperature}, {Conservative} {Temperature}, and the {Freezing} {Temperature} of {Seawater}},
	volume = {23},
	issn = {0739-0572},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/JTECH1946.1},
	doi = {10.1175/JTECH1946.1},
	abstract = {Algorithms are presented for density, potential temperature, conservative temperature, and the freezing temperature of seawater. The algorithms for potential temperature and density (in terms of potential temperature) are updates to routines recently published by McDougall et al., while the algorithms involving conservative temperature and the freezing temperatures of seawater are new. The McDougall et al. algorithms were based on the thermodynamic potential of Feistel and Hagen; the algorithms in this study are all based on the “new extended Gibbs thermodynamic potential of seawater” of Feistel. The algorithm for the computation of density in terms of salinity, pressure, and conservative temperature produces errors in density and in the corresponding thermal expansion coefficient of the same order as errors for the density equation using potential temperature, both being twice as accurate as the International Equation of State when compared with Feistel’s new equation of state. An inverse function relating potential temperature to conservative temperature is also provided. The difference between practical salinity and absolute salinity is discussed, and it is shown that the present practice of essentially ignoring the difference between these two different salinities is unlikely to cause significant errors in ocean models.},
	number = {12},
	urldate = {2018-07-09},
	journal = {Journal of Atmospheric and Oceanic Technology},
	author = {Jackett, David R. and McDougall, Trevor J. and Feistel, Rainer and Wright, Daniel G. and Griffies, Stephen M.},
	month = dec,
	year = {2006},
	pages = {1709--1728}
}

@incollection{griffies_formulating_2013,
	title = {Formulating the {Equations} of {Ocean} {Models}},
	copyright = {Copyright 2008 by the American Geophysical Union.},
	isbn = {978-1-118-66643-2},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/177GM18},
	abstract = {This chapter contains sections titled: Introduction Kinematics Tracer Budget Linear Momentum Budget Density Energetic Budgets Basic Non-Equilibrium Thermodynamics Linear Modes of Motion Approximations Elements of Vertical Coordinates Solution Methods},
	language = {en},
	urldate = {2018-07-09},
	booktitle = {Ocean {Modeling} in an {Eddying} {Regime}},
	publisher = {American Geophysical Union (AGU)},
	author = {Griffies, Stephen M. and Adcroft, Alistair J.},
	year = {2013},
	doi = {10.1029/177GM18},
	keywords = {Ocean circulation—Mathematical models, Oceanography—Mathematical models},
	pages = {281--317}
}

@techreport{isaksen_ensemble_2010,
	address = {Shinfield Park, Reading, Berkshire RG2 9AX, England},
	type = {Technical {Memorandum}},
	title = {Ensemble of data assimilations at {ECMWF}},
	number = {636},
	institution = {European Centre for Medium-Range Weather Forecasts},
	author = {Isaksen, Lars and Bonavita, M. and Buizza, R. and Fisher, M. and Haseler, J. and Leutbecher, M. and Raynaud, Laure},
	month = dec,
	year = {2010}
}

@article{lord_analysis_2016,
	title = {Analysis of an {Observing} {System} {Experiment} for the {Joint} {Polar} {Satellite} {System}},
	volume = {97},
	issn = {0003-0007},
	url = {https://journals.ametsoc.org/doi/10.1175/BAMS-D-14-00207.1},
	doi = {10.1175/BAMS-D-14-00207.1},
	abstract = {The Joint Polar Satellite System (JPSS) is a key contributor to the next-generation operational polar-orbiting satellite observing system. In the JPSS era, the complete polar-orbiting observing system will be composed of two satellites—in the midmorning (mid-AM) and afternoon (PM) orbits—each with thermodynamic sounding capabilities from both microwave and hyperspectral infrared instruments. JPSS will occupy the PM orbit, while the Meteorological Operational (MetOp) system, sponsored by the European Organisation for the Exploitation of Meteorological Satellites (EUMETSAT), will occupy the mid-AM orbit.While the current polar-orbiting satellite system has been thoroughly evaluated, information about its resilience and efficacy in the JPSS era is needed. A 7-month (August 2012–February 2013) observing system experiment (OSE) was run with the National Centers for Environmental Prediction (NCEP) Global Forecast System (GFS). Observations were selected from operational satellite data platforms to be representative of the polar-orbiting data in the JPSS era.Overall, removing data from the PM orbit produced inferior scores, with the impact greater in the Southern Hemisphere (SH) than in either the Northern Hemisphere (NH) or the tropics.For the entire 7 months, the time-mean 500-hPa geopotential height anomaly correlation (Z500AC) decreased by 0.005 and 0.013 in the NH and SH, respectively—both of which are statistically significant at the 95\% level. Additionally, a detailed statistical analysis of the distribution of Z500AC skill scores is presented and compared with historical accuracy data. It was determined that eliminating PM orbit data resulted in a higher probability of producing low scores and a lower probability of producing high scores, counter to the trend in GFS forecast skill over the last 20 years.},
	number = {8},
	urldate = {2018-07-05},
	journal = {Bulletin of the American Meteorological Society},
	author = {Lord, Stephen and Gayno, George and Yang, Fanglin},
	month = aug,
	year = {2016},
	pages = {1409--1425}
}

@misc{gramelsberger_conceiving_2009,
	type = {Text},
	title = {Conceiving {Meteorology} as the exact science of the atmosphere: {Vilhelm} {Bjerknes}'s paper of 1904 as a milestone},
	shorttitle = {Conceiving {Meteorology} as the exact science of the atmosphere},
	url = {https://www.ingentaconnect.com/content/schweiz/mz/2009/00000018/00000006/art00009},
	language = {en},
	urldate = {2018-07-05},
	author = {Gramelsberger, Gabriele},
	month = dec,
	year = {2009}
}

@article{buehner_four-dimensional_2013,
	title = {Four-dimensional ensemble-variational data assimilation for global deterministic weather prediction},
	volume = {20},
	issn = {1607-7946},
	url = {https://www.nonlin-processes-geophys.net/20/669/2013/},
	doi = {10.5194/npg-20-669-2013},
	abstract = {The goal of this study is to evaluate a version of the ensemble-variational data assimilation approach (EnVar) for possible replacement of 4D-Var at Environment Canada for global deterministic weather prediction. This implementation of EnVar relies on 4-D ensemble covariances, obtained from an ensemble Kalman filter, that are combined in a vertically dependent weighted average with simple static covariances. Verification results are presented from a set of data assimilation experiments over two separate 6-week periods that used assimilated observations and model configuration very similar to the currently operational system. To help interpret the comparison of EnVar versus 4D-Var, additional experiments using 3D-Var and a version of EnVar with only 3-D ensemble covariances are also evaluated. To improve the rate of convergence for all approaches evaluated (including EnVar), an estimate of the cost function Hessian generated by the quasi-Newton minimization algorithm is cycled from one analysis to the next.  Analyses from EnVar (with 4-D ensemble covariances) nearly always produce improved, and never degraded, forecasts when compared with 3D-Var. Comparisons with 4D-Var show that forecasts from EnVar analyses have either similar or better scores in the troposphere of the tropics and the winter extra-tropical region. However, in the summer extra-tropical region the medium-range forecasts from EnVar have either similar or worse scores than 4D-Var in the troposphere. In contrast, the 6 h forecasts from EnVar are significantly better than 4D-Var relative to radiosonde observations for both periods and in all regions. The use of 4-D versus 3-D ensemble covariances only results in small improvements in forecast quality. By contrast, the improvements from using 4D-Var versus 3D-Var are much larger. Measurement of the fit of the background and analyzed states to the observations suggests that EnVar and 4D-Var can both make better use of observations distributed over time than 3D-Var. In summary, the results from this study suggest that the EnVar approach is a viable alternative to 4D-Var, especially when the simplicity and computational efficiency of EnVar are considered. Additional research is required to understand the seasonal dependence of the difference in forecast quality between EnVar and 4D-Var in the extra-tropics.},
	number = {5},
	urldate = {2018-07-05},
	journal = {Nonlin. Processes Geophys.},
	author = {Buehner, M. and Morneau, J. and Charette, C.},
	month = sep,
	year = {2013},
	pages = {669--682}
}

@article{penny_hybrid_2014,
	title = {The {Hybrid} {Local} {Ensemble} {Transform} {Kalman} {Filter}},
	volume = {142},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/MWR-D-13-00131.1},
	doi = {10.1175/MWR-D-13-00131.1},
	abstract = {Hybrid data assimilation methods combine elements of ensemble Kalman filters (EnKF) and variational methods. While most approaches have focused on augmenting an operational variational system with dynamic error covariance information from an ensemble, this study takes the opposite perspective of augmenting an operational EnKF with information from a simple 3D variational data assimilation (3D-Var) method. A class of hybrid methods is introduced that combines the gain matrices of the ensemble and variational methods, rather than linearly combining the respective background error covariances. A hybrid local ensemble transform Kalman filter (Hybrid-LETKF) is presented in two forms: 1) a traditionally motivated Hybrid/Covariance-LETKF that combines the background error covariance matrices of LETKF and 3D-Var, and 2) a simple-to-implement algorithm called the Hybrid/Mean-LETKF that falls into the new class of hybrid gain methods. Both forms improve analysis errors when using small ensemble sizes and low observation coverage versus either LETKF or 3D-Var used alone. The results imply that for small ensemble sizes, allowing a solution to be found outside of the space spanned by ensemble members provides robustness in both hybrid methods compared to LETKF alone. Finally, the simplicity of the Hybrid/Mean-LETKF design implies that this algorithm can be applied operationally while requiring only minor modifications to an existing operational 3D-Var system.},
	number = {6},
	urldate = {2018-07-05},
	journal = {Monthly Weather Review},
	author = {Penny, Stephen G.},
	month = may,
	year = {2014},
	pages = {2139--2149}
}

@article{kleist_osse-based_2015,
	title = {An {OSSE}-{Based} {Evaluation} of {Hybrid} {Variational}–{Ensemble} {Data} {Assimilation} for the {NCEP} {GFS}. {Part} {I}: {System} {Description} and {3D}-{Hybrid} {Results}},
	volume = {143},
	issn = {0027-0644},
	shorttitle = {An {OSSE}-{Based} {Evaluation} of {Hybrid} {Variational}–{Ensemble} {Data} {Assimilation} for the {NCEP} {GFS}. {Part} {I}},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/MWR-D-13-00351.1},
	doi = {10.1175/MWR-D-13-00351.1},
	abstract = {An observing system simulation experiment (OSSE) has been carried out to evaluate the impact of a hybrid ensemble–variational data assimilation algorithm for use with the National Centers for Environmental Prediction (NCEP) global data assimilation system. An OSSE provides a controlled framework for evaluating analysis and forecast errors since a truth is known. In this case, the nature run was generated and provided by the European Centre for Medium-Range Weather Forecasts as part of the international Joint OSSE project. The assimilation and forecast impact studies are carried out using a model that is different than the nature run model, thereby accounting for model error and avoiding issues with the so-called identical-twin experiments.It is found that the quality of analysis is improved substantially when going from three-dimensional variational data assimilation (3DVar) to a hybrid 3D ensemble–variational (EnVar)-based algorithm. This is especially true in terms of the analysis error reduction for wind and moisture, most notably in the tropics. Forecast impact experiments show that the hybrid-initialized forecasts improve upon the 3DVar-based forecasts for most metrics, lead times, variables, and levels. An additional experiment that utilizes 3DEnVar (100\% ensemble) demonstrates that the use of a 25\% static error covariance contribution does not alter the quality of hybrid analysis when utilizing the tangent-linear normal mode constraint on the total hybrid increment.},
	number = {2},
	urldate = {2018-07-05},
	journal = {Monthly Weather Review},
	author = {Kleist, Daryl T. and Ide, Kayo},
	month = feb,
	year = {2015},
	pages = {433--451}
}

@article{kleist_osse-based_2015-1,
	title = {An {OSSE}-{Based} {Evaluation} of {Hybrid} {Variational}–{Ensemble} {Data} {Assimilation} for the {NCEP} {GFS}. {Part} {II}: {4DEnVar} and {Hybrid} {Variants}},
	volume = {143},
	issn = {0027-0644},
	shorttitle = {An {OSSE}-{Based} {Evaluation} of {Hybrid} {Variational}–{Ensemble} {Data} {Assimilation} for the {NCEP} {GFS}. {Part} {II}},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/MWR-D-13-00350.1},
	doi = {10.1175/MWR-D-13-00350.1},
	abstract = {This work describes the formulation of a hybrid four-dimensional ensemble--variational (4DEnVar) algorithm and initialization options utilized within the National Centers for Environmental Prediction global data assimilation system. Initialization schemes that are proposed for use are the tangent-linear normal mode constraint, weak constraint digital filter, and a combination thereof.An observing system simulation experiment is carried out to evaluate the impact of utilizing hybrid 4DEnVar with various initialization techniques. The experiments utilize a dual-resolution configuration, where the ensemble is run at roughly half the resolution of the deterministic component. It is found that by going from 3D to 4D, analysis error is reduced for most variables and levels. The inclusion of a time-invariant static covariance when used without a normal mode–based strong constraint is found to have a small, positive impact on the analysis. The experiments show that the weak constraint digital filter degrades the quality of analysis, due to the use of hourly states to prescribe high-frequency noise. It is found that going from 3D to 4D ensemble covariances has a relatively larger impact in the extratropics, whereas the original inclusion of ensemble-based covariances was found to have the largest impact in the tropics. The improvements found in going from 3D to 4D covariances in the hybrid EnVar formulation are not as large as was found in Part I from the original introduction of the hybrid algorithm. The analyses generated by the 4D hybrid scheme are found to yield slightly improved extratropical height and wind forecasts, with smaller impacts on other variables and in general in the tropics.},
	number = {2},
	urldate = {2018-07-05},
	journal = {Monthly Weather Review},
	author = {Kleist, Daryl T. and Ide, Kayo},
	month = feb,
	year = {2015},
	pages = {452--470}
}

@article{wang_gsi_2013,
	title = {{GSI} {3DVar}-{Based} {Ensemble}–{Variational} {Hybrid} {Data} {Assimilation} for {NCEP} {Global} {Forecast} {System}: {Single}-{Resolution} {Experiments}},
	volume = {141},
	issn = {0027-0644},
	shorttitle = {{GSI} {3DVar}-{Based} {Ensemble}–{Variational} {Hybrid} {Data} {Assimilation} for {NCEP} {Global} {Forecast} {System}},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/MWR-D-12-00141.1},
	doi = {10.1175/MWR-D-12-00141.1},
	abstract = {An ensemble Kalman filter–variational hybrid data assimilation system based on the gridpoint statistical interpolation (GSI) three-dimensional variational data assimilation (3DVar) system was developed. The performance of the system was investigated using the National Centers for Environmental Prediction (NCEP) Global Forecast System model. Experiments covered a 6-week Northern Hemisphere winter period. Both the control and ensemble forecasts were run at the same, reduced resolution. Operational conventional and satellite observations along with an 80-member ensemble were used. Various configurations of the system including one- or two-way couplings, with zero or nonzero weights on the static covariance, were intercompared and compared with the GSI 3DVar system. It was found that the hybrid system produced more skillful forecasts than the GSI 3DVar system. The inclusion of a static component in the background-error covariance and recentering the analysis ensemble around the variational analysis did not improve the forecast skill beyond the one-way coupled system with zero weights on the static covariance. The one-way coupled system with zero static covariances produced more skillful wind forecasts averaged over the globe than the EnKF at the 1–5-day lead times and more skillful temperature forecasts than the EnKF at the 5-day lead time. Sensitivity tests indicated that the difference may be due to the use of the tangent linear normal mode constraint in the variational system. For the first outer loop, the hybrid system showed a slightly slower (faster) convergence rate at early (later) iterations than the GSI 3DVar system. For the second outer loop, the hybrid system showed a faster convergence.},
	number = {11},
	urldate = {2018-07-05},
	journal = {Monthly Weather Review},
	author = {Wang, Xuguang and Parrish, David and Kleist, Daryl and Whitaker, Jeffrey},
	month = jun,
	year = {2013},
	pages = {4098--4117}
}

@article{greybush_balance_2011,
	title = {Balance and {Ensemble} {Kalman} {Filter} {Localization} {Techniques}},
	volume = {139},
	issn = {0027-0644},
	url = {https://journals.ametsoc.org/doi/abs/10.1175/2010MWR3328.1},
	doi = {10.1175/2010MWR3328.1},
	abstract = {In ensemble Kalman filter (EnKF) data assimilation, localization modifies the error covariance matrices to suppress the influence of distant observations, removing spurious long-distance correlations. In addition to allowing efficient parallel implementation, this takes advantage of the atmosphere’s lower dimensionality in local regions. There are two primary methods for localization. In B localization, the background error covariance matrix elements are reduced by a Schur product so that correlations between grid points that are far apart are removed. In R localization, the observation error covariance matrix is multiplied by a distance-dependent function, so that far away observations are considered to have infinite error. Successful numerical weather prediction depends upon well-balanced initial conditions to avoid spurious propagation of inertial-gravity waves. Previous studies note that B localization can disrupt the relationship between the height gradient and the wind speed of the analysis increments, resulting in an analysis that can be significantly ageostrophic. This study begins with a comparison of the accuracy and geostrophic balance of EnKF analyses using no localization, B localization, and R localization with simple one-dimensional balanced waves derived from the shallow-water equations, indicating that the optimal length scale for R localization is shorter than for B localization, and that for the same length scale R localization is more balanced. The comparison of localization techniques is then expanded to the Simplified Parameterizations, Primitive Equation Dynamics (SPEEDY) global atmospheric model. Here, natural imbalance of the slow manifold must be contrasted with undesired imbalance introduced by data assimilation. Performance of the two techniques is comparable, also with a shorter optimal localization distance for R localization than for B localization.},
	number = {2},
	urldate = {2018-07-05},
	journal = {Monthly Weather Review},
	author = {Greybush, Steven J. and Kalnay, Eugenia and Miyoshi, Takemasa and Ide, Kayo and Hunt, Brian R.},
	month = feb,
	year = {2011},
	pages = {511--522}
}

@article{millero_international_1981,
	title = {International one-atmosphere equation of state of seawater},
	volume = {28},
	issn = {0198-0149},
	url = {http://www.sciencedirect.com/science/article/pii/0198014981901229},
	doi = {10.1016/0198-0149(81)90122-9},
	abstract = {The density measurements by Millero, Gonzalez and Ward (1976, Journal of Marine Research,34, 61–93) and Poisson, Brunet and Brun-Cottan (1980, Deep-Sea Research, 27, 1013–1028), from 0 to 40°C and 0.5 to 43 salinity, have been used to determine a new 1-atm equation of state for seawater. The equation is of the form (t°C; S; ϱ kg m−3)ρ=ρ0+AS+BS32+CS, where A=8.24493×10−1−4.0899×10−3t+7.6438×10−5t2−8.2467×10−7t3+5.3875×10−9t4B=−5.72466×10−3+1.0227×10−4t−1.6546×10−6t2C=4.8314×10−4 and ϱ0 is the density of water (Bigg, 1967, British Journal of Applied Physics, 8, 521–537). ρ0=999.842594+6.793952×10−2t−9.095290×−3t2+1.001685×10−4t3−1.120083×10−6t4+6.536336×10−9t5. The standard error of the equation is 3.6 × 10−3 kg m−3. This equation will become the new 1-atm equation of state of seawater that has been suggested for use by the UNESCO (United Nations Educational, Scientific and Cultural Organization) joint panel on oceanographic tables and standards.},
	number = {6},
	journal = {Deep Sea Research Part A. Oceanographic Research Papers},
	author = {Millero, Frank J. and Poisson, Alain},
	month = jun,
	year = {1981},
	pages = {625--629}
}

@incollection{griffies_formulating_2008,
	title = {Formulating the {Equations} of {Ocean} {Models}},
	isbn = {978-1-118-66643-2},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/177GM18},
	abstract = {Summary This chapter contains sections titled: Introduction Kinematics Tracer Budget Linear Momentum Budget Density Energetic Budgets Basic Non-Equilibrium Thermodynamics Linear Modes of Motion Approximations Elements of Vertical Coordinates Solution Methods},
	booktitle = {Ocean {Modeling} in an {Eddying} {Regime}},
	publisher = {American Geophysical Union (AGU)},
	author = {Griffies, Stephen M. and Adcroft, Alistair J.},
	year = {2008},
	doi = {10.1029/177GM18},
	note = {\_eprint: https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/177GM18},
	keywords = {Ocean circulation—Mathematical models, Oceanography—Mathematical models},
	pages = {281--317}
}

@article{mcwilliams_modeling_1996,
	title = {Modeling the {Oceanic} {General} {Circulation}},
	volume = {28},
	issn = {0066-4189},
	url = {https://doi.org/10.1146/annurev.fl.28.010196.001243},
	doi = {10.1146/annurev.fl.28.010196.001243},
	number = {1},
	urldate = {2021-01-03},
	journal = {Annual Review of Fluid Mechanics},
	author = {McWilliams, J C},
	month = jan,
	year = {1996},
	note = {Publisher: Annual Reviews},
	pages = {215--248},
	annote = {doi: 10.1146/annurev.fl.28.010196.001243}
}

@article{temperton_normal_1981,
	title = {Normal {Mode} {Initialization} for a {Multilevel} {Grid}-{Point} {Model}. {Part} {I}: {Linear} {Aspects}},
	volume = {109},
	url = {https://journals.ametsoc.org/view/journals/mwre/109/4/1520-0493_1981_109_0729_nmifam_2_0_co_2.xml},
	doi = {10.1175/1520-0493(1981)109<0729:NMIFAM>2.0.CO;2},
	language = {English},
	number = {4},
	journal = {Monthly Weather Review},
	author = {Temperton, Clive and Williamson, David L.},
	month = apr,
	year = {1981},
	note = {Place: Boston MA, USA
Publisher: American Meteorological Society},
	pages = {729--743}
}

@incollection{kiehl_atmospheric_1992,
	title = {Atmospheric general circulation modeling},
	booktitle = {Climate system modeling},
	publisher = {Cambridge University Press Cambridge,, UK},
	author = {Kiehl, Jeffrey T},
	year = {1992},
	pages = {319--370}
}

@article{randall_breaking_2003,
	title = {Breaking the {Cloud} {Parameterization} {Deadlock}},
	volume = {84},
	issn = {0003-0007},
	url = {https://doi.org/10.1175/BAMS-84-11-1547},
	doi = {10.1175/BAMS-84-11-1547},
	abstract = {A key factor limiting the reliability of simulations of anthropogenic climate change is the inability to accurately represent the various effects of clouds on climate. Despite the best efforts of the community, the problem has resisted solution for several decades. The reasons for this are briefly reviewed and it is argued that it will be many more decades before the problem can be solved through the approaches to cloud parameterization that have been used up to now. An alternative approach, called superparameterization, is then outlined, in which high-resolution cloud system-resolving models (CSRMs) are used in place of the conventional cloud parameterizations. Tests performed with the Community Atmosphere Model show that superparameterizations can give more realistic simulations of the current climate, including greatly improved simulations of the Madden–Julian oscillation and other tropical wave disturbances. Superparameterizations increase the cost of climate simulation by a factor of several hundred dollars, but can make efficient use of massively parallel computers. In addition, superparameterizations make it possible for a climate model to converge to a global CSRM as the horizontal grid spacing of the climate model decreases to a few kilometers. No existing global atmospheric model has this convergence property. Superparameterizations have the potential to greatly increase the reliability of climate change simulations.},
	number = {11},
	urldate = {2020-10-13},
	journal = {Bulletin of the American Meteorological Society},
	author = {Randall, David and Khairoutdinov, Marat and Arakawa, Akio and Grabowski, Wojciech},
	month = nov,
	year = {2003},
	pages = {1547--1564}
}

@article{grabowski_crcp_1999,
	title = {{CRCP}: a {Cloud} {Resolving} {Convection} {Parameterization} for modeling the tropical convecting atmosphere},
	volume = {133},
	issn = {0167-2789},
	url = {http://www.sciencedirect.com/science/article/pii/S0167278999001049},
	doi = {10.1016/S0167-2789(99)00104-9},
	abstract = {A new computational approach, CRCP, is proposed in which both the large-scale (LS) tropical dynamics and cloud-scale (CS) dynamics are captured explicitly. The leading idea is to represent subgrid scales of the LS model by imbedding a 2D CS model in each column of the 3D LS model – the approach tailored for distributed memory architectures. The overall philosophy underlying CRCP is the reinvestment of efforts from large-eddy simulation to elaborate yet ‘embarrassingly parallel’ turbulence models. Similar as in the traditional ‘convection parameterization’, the LS model provides ‘ambient forcings’ for the CS model imbedded inside each LS column, and the CS model feeds back a ‘convective response’ for every column of the LS model. Furthermore, availability of the cloud-scale data allows for explicit coupling of moist convection with radiative and surface processes. Following our experience with cloud-resolving modeling of the tropical convection, the CS model is oriented along the E–W direction inside each LS model column. A simple strategy for the coupling the LS and CS models derives from physical understanding of interactions between LS flow and moist tropical convection. Theoretical considerations are illustrated with an example of application to observational data from the Phase III of the Global Atmospheric Research Programme Atlantic Tropical Experiment (GATE).},
	number = {1},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Grabowski, Wojciech W and Smolarkiewicz, Piotr K},
	month = sep,
	year = {1999},
	keywords = {Convection parameterization, Moist convection, Tropical atmospheric dynamics},
	pages = {171--178}
}

@article{grabowski_coupling_2001,
	title = {Coupling {Cloud} {Processes} with the {Large}-{Scale} {Dynamics} {Using} the {Cloud}-{Resolving} {Convection} {Parameterization} ({CRCP})},
	volume = {58},
	issn = {0022-4928},
	url = {https://doi.org/10.1175/1520-0469(2001)058<0978:CCPWTL>2.0.CO;2},
	doi = {10.1175/1520-0469(2001)058<0978:CCPWTL>2.0.CO;2},
	abstract = {A formal approach is presented to couple small-scale processes associated with atmospheric moist convection with the large-scale dynamics. The approach involves applying a two-dimensional cloud-resolving model in each column of a three-dimensional large-scale model. In the spirit of classical convection parameterization, which assumes scale separation between convection and the large-scale flow, the cloud-resolving models from neighboring columns interact only through the large-scale dynamics. This approach is referred to as Cloud-Resolving Convection Parameterization (CRCP). In short, CRCP involves many two-dimensional cloud-resolving models interacting in a manner consistent with the large-scale dynamics.The approach is first applied to the idealized problem of a convective–radiative equilibrium of a two-dimensional nonrotating atmosphere in the presence of SST gradients. This simple dynamical setup allows comparison of CRCP simulations with the cloud-resolving model results. In these tests, the large-scale model has various horizontal grid spacings, from 20 to 500 km, and the CRCP domains change correspondingly. Comparison between CRCP and cloud-resolving simulations shows that the large-scale features, such as the mean temperature and moisture profiles and the large-scale flow, are reasonably well represented in CRCP simulations. However, the interaction between ascending and descending branches through the gravity wave mechanism, as well as organization of convection into mesoscale convective systems, are poorly captured. These results illustrate the limitations of not only CRCP, but also convection parameterization in general.The CRCP approach is also applied to the idealized problem of a rotating constant-SST aquaplanet in convective–radiative equilibrium. The global CRCP simulation features pronounced large-scale organization of convection within the equatorial waveguide. A prominent solitary equatorial “super cloud cluster” develops toward the end of the 80-day long simulation, which bears a strong resemblance to the Madden–Julian oscillation observed in the terrestrial Tropics.},
	number = {9},
	urldate = {2020-10-13},
	journal = {Journal of the Atmospheric Sciences},
	author = {Grabowski, Wojciech W.},
	month = may,
	year = {2001},
	pages = {978--997}
}

@article{charney_growth_1964,
	title = {On the {Growth} of the {Hurricane} {Depression}},
	volume = {21},
	issn = {0022-4928},
	url = {https://doi.org/10.1175/1520-0469(1964)021<0068:OTGOTH>2.0.CO;2},
	doi = {10.1175/1520-0469(1964)021<0068:OTGOTH>2.0.CO;2},
	abstract = {Why do cyclones form in a conditionally unstable tropical atmosphere whose vertical thermal structure is apparently more favorable to small-scale cumulus convection than to convective circulations of tropical cyclone scale? It is proposed that the cyclone develops by a kind of secondary instability in which existing cumulus convection is augmented in regions of low-level horizontal convergence and quenched in regions of low-level divergence. The cumulus- and cyclone-scale motions are thus to be regarded as cooperating rather than as competing–the clouds supplying latent heat energy to the cyclone, and the cyclone supplying the fuel, in the form of moisture, to the clouds.A scale-analysis indicates that it is appropriate to use the balance equations of Eliassen for the macro-motion; in this case the effect of friction in the boundary-layer may be incorporated as a condition on the vertical velocity at the top of the boundary layer. It is argued that the mean humidity in a system of convecting cumulus clouds in statistical equilibrium with the cyclone-scale circulation is appreciably less than its saturation value. The atmosphere is then gravitationally stable for the macro-scale convective process even though it is gravitationally unstable for the micro-scale convective process. The amplification of the disturbance is due to the surface frictionally induced convergence of moisture and liberation of latent heat in the center of the cyclone.},
	number = {1},
	urldate = {2020-10-13},
	journal = {Journal of the Atmospheric Sciences},
	author = {Charney, Jule G. and Eliassen, Arnt},
	month = jan,
	year = {1964},
	pages = {68--75}
}

@article{zeng_terrestrial_2005,
	title = {Terrestrial mechanisms of interannual {CO2} variability},
	volume = {19},
	issn = {0886-6236},
	url = {https://doi.org/10.1029/2004GB002273},
	doi = {10.1029/2004GB002273},
	abstract = {The interannual variability of atmospheric CO2 growth rate shows remarkable correlation with the El Niño Southern Oscillation (ENSO). Here we present results from mechanistically based terrestrial carbon cycle model VEgetation-Global-Atmosphere-Soil (VEGAS), forced by observed climate fields such as precipitation and temperature. Land is found to explain most of the interannual CO2 variability with a magnitude of about 5 PgC yr?1. The simulated land-atmosphere flux has a detrended correlation of 0.53 (0.6 at the 2?7 year ENSO band) with the CO2 growth rate observed at Mauna Loa from 1965 to 2000. We also present the total ocean flux from the Hamburg Ocean Carbon Cycle Model (HAMOCC) which shows ocean-atmosphere flux variation of about 1 PgC yr?1, and it is largely out of phase with land flux. On land, much of the change comes from the tropical regions such as the Amazon and Indonesia where ENSO related climate anomalies are in the same direction across much of the tropics. The subcontinental variations over North America and Eurasia are comparable to the tropics but the total interannual variability is about 1 PgC yr?1 due to the cancellation from the subregions. This has implication for flux measurement network distribution. The tropical dominance also results from a ?conspiracy? between climate and plant/soil physiology, as precipitation and temperature changes drive opposite changes in net primary production (NPP) and heterotrophic respiration (Rh), both contributing to land-atmosphere flux changes in the same direction. However, NPP contributes to about three fourths of the total tropical interannual variation and the rest is from heterotrophic respiration; thus precipitation appears to be a more important factor than temperature on the interannual timescales as tropical wet and dry regimes control vegetation growth. Fire, largely driven by drought, also contributes significantly to the interannual CO2 variability at a rate of about 1 PgC yr?1, and it is not totally in phase with NPP or Rh. The robust variability in tropical fluxes agree well with atmospheric inverse modeling results. Even over North America and Eurasia, where ENSO teleconnection is less robust, the fluxes show general agreement with inversion results, an encouraging sign for fruitful carbon data assimilation.},
	number = {1},
	urldate = {2020-10-13},
	journal = {Global Biogeochemical Cycles},
	author = {Zeng, N. and Mariotti, A. and Wetzel, P.},
	month = mar,
	year = {2005},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {climate, CO2, variability},
	annote = {doi: 10.1029/2004GB002273}
}

@article{zeng_glacial-interglacial_2003,
	title = {Glacial-interglacial atmospheric {CO2} change —{The} glacial burial hypothesis},
	volume = {20},
	issn = {1861-9533},
	url = {https://doi.org/10.1007/BF02915395},
	doi = {10.1007/BF02915395},
	abstract = {Organic carbon buried under the great ice sheets of the Northern Hemisphere is suggested to be the missing link in the atmospheric CO2 change over the glacial-interglacial cycles. At glaciation, the advancement of continental ice sheets buries vegetation and soil carbon accumulated during warmer periods. At deglaciation, this burial carbon is released back into the atmosphere. In a simulation over two glacial-interglacial cycles using a synchronously coupled atmosphere-land-ocean carbon model forced by reconstructed climate change, it is found that there is a 547-Gt terrestrial carbon release from glacial maximum to interglacial, resulting in a 60-Gt (about 30-ppmv) increase in the atmospheric CO2, with the remainder absorbed by the ocean in a scenario in which ocean acts as a passive buffer. This is in contrast to previous estimates of a land uptake at deglaciation. This carbon source originates from glacial burial, continental shelf, and other land areas in response to changes in ice cover, sea level, and climate. The input of light isotope enriched terrestrial carbon causes atmospheric δ13C to drop by about 0.3‰ at deglaciation, followed by a rapid rise towards a high interglacial value in response to oceanic warming and regrowth on land. Together with other ocean based mechanisms such as change in ocean temperature, the glacial burial hypothesis may offer a full explanation of the observed 80–100-ppmv atmospheric CO2 change.},
	number = {5},
	journal = {Advances in Atmospheric Sciences},
	author = {Zeng, Ning},
	month = sep,
	year = {2003},
	pages = {677--693}
}

@article{kucharski_further_2012,
	title = {A further assessment of vegetation feedback on decadal {Sahel} rainfall variability},
	volume = {40},
	issn = {1432-0894},
	url = {https://doi.org/10.1007/s00382-012-1397-x},
	doi = {10.1007/s00382-012-1397-x},
	abstract = {The effect of vegetation feedback on decadal-scale Sahel rainfall variability is analyzed using an ensemble of climate model simulations in which the atmospheric general circulation model ICTPAGCM (“SPEEDY”) is coupled to the dynamic vegetation model VEGAS to represent feedbacks from surface albedo change and evapotranspiration, forced externally by observed sea surface temperature (SST) changes. In the control experiment, where the full vegetation feedback is included, the ensemble is consistent with the observed decadal rainfall variability, with a forced component 60 \% of the observed variability. In a sensitivity experiment where climatological vegetation cover and albedo are prescribed from the control experiment, the ensemble of simulations is not consistent with the observations because of strongly reduced amplitude of decadal rainfall variability, and the forced component drops to 35 \% of the observed variability. The decadal rainfall variability is driven by SST forcing, but significantly enhanced by land-surface feedbacks. Both, local evaporation and moisture flux convergence changes are important for the total rainfall response. Also the internal decadal variability across the ensemble members (not SST-forced) is much stronger in the control experiment compared with the one where vegetation cover and albedo are prescribed. It is further shown that this positive vegetation feedback is physically related to the albedo feedback, supporting the Charney hypothesis.},
	number = {5},
	journal = {Climate Dynamics},
	author = {Kucharski, Fred and Zeng, Ning and Kalnay, Eugenia},
	year = {2012},
	pages = {1453--1466}
}

@article{kroger_sensitivity_2011,
	title = {Sensitivity of {ENSO} characteristics to a new interactive flux correction scheme in a coupled {GCM}},
	volume = {36},
	issn = {1432-0894},
	url = {https://doi.org/10.1007/s00382-010-0759-5},
	doi = {10.1007/s00382-010-0759-5},
	abstract = {A fast coupled global climate model (CGCM) is used to study the sensitivity of El Niño Southern Oscillation (ENSO) characteristics to a new interactive flux correction scheme. With no flux correction applied our CGCM reveals typical bias in the background state: for instance, the cold tongue in the tropical east Pacific becomes too cold, thus degrading atmospheric sensitivity to variations of sea surface temperature (SST). Sufficient atmospheric sensitivity is essential to ENSO. Our adjustment scheme aims to sustain atmospheric sensitivity by counteracting the SST drift in the model. With reduced bias in the forcing of the atmosphere, the CGCM displays ENSO-type variability that otherwise is absent. The adjustment approach employs a one-way anomaly coupling from the ocean to the atmosphere: heat fluxes seen by the ocean are based on full SST, while heat fluxes seen by the atmosphere are based on anomalies of SST. The latter requires knowledge of the model’s climatological SST field, which is accumulated interactively in the spin-up phase (“training”). Applying the flux correction already during the training period (by utilizing the evolving SST climatology) is necessary for efficiently reducing the bias. The combination of corrected fluxes seen by the atmosphere and uncorrected fluxes seen by the ocean implies a restoring mechanism that counteracts the bias and allows for long stable integrations in our CGCM. A suite of sensitivity runs with varying training periods is utilized to study the effect of different levels of bias in the background state on important ENSO properties. Increased duration of training amplifies the coupled sensitivity in our model and leads to stronger amplitudes and longer periods of the Nino3.4 index, increased emphasis of warm events that is reflected in enhanced skewness, and more pronounced teleconnections in the Pacific. Furthermore, with longer training durations we observe a mode switch of ENSO in our model that closely resembles the observed mode switch related to the mid-1970s “climate shift”.},
	number = {1},
	journal = {Climate Dynamics},
	author = {Kröger, Jürgen and Kucharski, Fred},
	month = jan,
	year = {2011},
	pages = {119--137}
}

@article{ruiz-barradas_finding_2017,
	title = {Finding the driver of local ocean–atmosphere coupling in reanalyses and {CMIP5} climate models},
	volume = {48},
	issn = {1432-0894},
	url = {https://doi.org/10.1007/s00382-016-3197-1},
	doi = {10.1007/s00382-016-3197-1},
	abstract = {Identification of the driver of coupled anomalies in the climate system is of great importance for a better understanding of the system and for its use in predictive efforts with climate models. The present analysis examines the robustness of a physical method proposed three decades ago to identify coupled anomalies as of atmospheric or oceanic origin by analyzing 850 mb vorticity and sea surface temperature anomalies. The method is then used as a metric to assess the coupling in climate simulations and a 30-year hindcast from models of the CMIP5 project. Analysis of the frequency of coupled anomalies exceeding one standard deviation from uncoupled NCEP/NCAR and ERA-Interim and partially coupled CFSR reanalyses shows robustness in the main results: anomalies of oceanic origin arise inside the deep tropics and those of atmospheric origin outside of the tropics. Coupled anomalies occupy similar regions in the global oceans independently of the spatiotemporal resolution. Exclusion of phenomena like ENSO, NAO, or AMO has regional effects on the distribution and origin of coupled anomalies; the absence of ENSO decreases anomalies of oceanic origin and favors those of atmospheric origin. Coupled model simulations in general agree with the distribution of anomalies of atmospheric and oceanic origin from reanalyses. However, the lack of the feedback from the atmosphere to the ocean in the AMIP simulations reduces substantially the number of coupled anomalies of atmospheric origin and artificially increases it in the tropics while the number of those of oceanic origin outside the tropics is also augmented. Analysis of a single available 30-year hindcast surprisingly indicates that coupled anomalies are more similar to AMIP than to coupled simulations. Differences in the frequency of coupled anomalies between the AMIP simulations and the uncoupled reanalyses, and similarities between the uncoupled and partially coupled reanalyses, support the notion that the nature of the coupling between the ocean and the atmosphere is transmitted into the reanalyses via the assimilation of observations.},
	number = {7},
	journal = {Climate Dynamics},
	author = {Ruiz-Barradas, Alfredo and Kalnay, Eugenia and Peña, Malaquías and BozorgMagham, Amir E. and Motesharrei, Safa},
	month = apr,
	year = {2017},
	pages = {2153--2172}
}

@article{wallace_reduction_1983,
	title = {Reduction of systematic forecast errors in the {ECMWF} model through the introduction of an envelope orography},
	volume = {109},
	issn = {0035-9009},
	url = {https://doi.org/10.1002/qj.49710946202},
	doi = {10.1002/qj.49710946202},
	abstract = {Abstract Day 1 forecast errors in the ECMWF model geopotential height fields during wintertime show a distinctive and highly reproducible signature with negative biases over the major mountain barriers. These biases are largest on days when the 500mb flow over the mountains is strong and they tend to shift position from day to day so as to remain close to the region where the jet stream crosses the mountain barrier. These systematic errors evolve through the forecast interval until by day 10 they assume an equivalent barotropic structure which strongly resembles the upper-level stationary wave pattern, but has the opposite sign, which indicates that the model does not have sufficient (presumably orographic) forcing to maintain the stationary waves. The time evolution of the systematic error pattern is investigated by means of a series of experiments with a barotropic model, in which the observed mean wintertime 300 mb flow is perturbed by a steady forcing derived from the day 1 forecast error pattern. The day 10 error patterns, as simulated by the barotropic model, bear a strong similarity to the observed ones. The forcing in the vicinity of the northern Rockies makes a particularly large contribution to the simulated day 10 error pattern whereas that in the Himalaya region appears to be relatively less important. The impact of an enhanced orography upon the climate of the ECMWF model is investigated by carrying out a pair of extended integrations out to 50 days. The control run is based on the conventional average-type orography used for operational forecasting; the other run is based on an ?envelope orography? constructed by adding to the conventional, grid-square averaged, orography an increment proportional to the standard deviation of the sub-grid scale variance. Results for this one, rather short pair of integrations suggest that the envelope orography may be capable of yielding a more realistic simulation of the observed wintertime flow pattern, particularly with respect to features in the Pacific and western North American sectors. Certain aspects of the zonally averaged circulation are also more realistic in this envelope simulation. A series of 21 successive ten-day forecast integrations has also been carried out with this envelope orography from February 1982 data. Results indicate that the introduction of the envelope orography results in a slight degradation of the short-range forecasts together with a distinct improvement of the forecast beyond four days. The beneficial impact towards the end of the forecast interval appears to be large enough to increase the forecast usefulness by perhaps as much as half a day.},
	number = {462},
	urldate = {2020-10-13},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Wallace, John M. and Tibaldi, Stefano and Simmons, Adrian J.},
	month = oct,
	year = {1983},
	note = {Publisher: John Wiley \& Sons, Ltd},
	pages = {683--717},
	annote = {doi: 10.1002/qj.49710946202}
}

@article{zhao_prognostic_1997,
	title = {A {Prognostic} {Cloud} {Scheme} for {Operational} {NWP} {Models}},
	volume = {125},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/1520-0493(1997)125<1931:APCSFO>2.0.CO;2},
	doi = {10.1175/1520-0493(1997)125<1931:APCSFO>2.0.CO;2},
	abstract = {An explicit cloud prediction model has been developed and incorporated into the Eta Model at the National Centers for Environmental Prediction. In this scheme, only one predictive variable, cloud mixing ratio, is added to the model’s prognostic equations to represent both cloud liquid water and cloud ice. Precipitation is diagnostically calculated from cloud mixing ratio. Extensive tests have been performed. The statistical results show a significant improvement in the model precipitation forecasts. Diagnostic studies suggest that the inclusion of cloud ice is important in transferring water vapor to precipitation and in the enhancement of latent heat release; the latter subsequently affects the vertical motion field significantly.},
	number = {8},
	urldate = {2020-10-13},
	journal = {Monthly Weather Review},
	author = {Zhao, Qingyun and Carr, Frederick H.},
	month = aug,
	year = {1997},
	pages = {1931--1953}
}

@article{monin_basic_1954,
	title = {Basic laws of turbulent mixing in the atmosphere near the ground},
	volume = {24},
	number = {151},
	journal = {Tr. Geofiz. Inst., Akad. Nauk SSSR},
	author = {Monin, AS and Obukhov, AM},
	year = {1954},
	pages = {163--187}
}

@article{miyakoda_comparative_1977,
	title = {Comparative global prediction experiments on parameterized subgrid-scale vertical eddy transports},
	volume = {50},
	journal = {Control Atmos Phys},
	author = {Miyakoda, K and Sirutis, J},
	year = {1977},
	pages = {445--487}
}

@article{kain_one-dimensional_1990,
	title = {A {One}-{Dimensional} {Entraining}/{Detraining} {Plume} {Model} and {Its} {Application} in {Convective} {Parameterization}},
	volume = {47},
	issn = {0022-4928},
	url = {http://journals.ametsoc.org/doi/abs/10.1175/1520-0469(1990)047%3C2784:AODEPM%3E2.0.CO;2},
	doi = {10.1175/1520-0469(1990)047<2784:AODEPM>2.0.CO;2},
	abstract = {A new one-dimensional cloud model, specifically designed for application in mesoscale convective parameterization schemes (CPSs), is introduced. The model is unique in its representation of environmental entrainment and updraft detrainment rates. In particular, the two-way exchange of mass between clouds and their environment is modulated at each vertical level by a buoyancy sorting mechanism at the interface of clear and cloudy air. The new entrainment/detrainment scheme allows vertical profiles of both updraft moisture detrainment and updraft vertical mass flux to vary in a physically realistic way as a function of the cloud-scale environment. These performance characteristics allow the parameterized vertical distribution of convective heating and drying to be much more responsive to environmental conditions than is possible with a traditional one-dimensional entraining plume model. The sensitivities of the new model to variations in environmental convective available potential energy and vertical moisture distribution in idealized convective environments are demonstrated and its sensitivities to several key control parameters are examined. Finally, the performance of the new model in the Fritsch–Chappell CPS is evaluated. Parameterized heating and drying profiles are elucidated as they relate to the convective environment and to the type of cloud model used in the CPS.},
	number = {23},
	urldate = {2017-11-01},
	journal = {Journal of the Atmospheric Sciences},
	author = {Kain, John S. and Fritsch, J. Michael},
	month = dec,
	year = {1990},
	pages = {2784--2802}
}

@article{arakawa_cumulus_2004,
	title = {The {Cumulus} {Parameterization} {Problem}: {Past}, {Present}, and {Future}},
	volume = {17},
	issn = {0894-8755},
	url = {https://doi.org/10.1175/1520-0442(2004)017<2493:RATCPP>2.0.CO;2},
	doi = {10.1175/1520-0442(2004)017<2493:RATCPP>2.0.CO;2},
	abstract = {A review of the cumulus parameterization problem is presented with an emphasis on its conceptual aspects covering the history of the underlying ideas, major problems existing at present, and possible directions and approaches for future climate models. Since its introduction in the early 1960s, there have been decades of controversies in posing the cumulus parameterization problem. In this paper, it is suggested that confusion between budget and advection considerations is primarily responsible for the controversies. It is also pointed out that the performance of parameterization schemes can be better understood if one is not bound by their authors' justifications. The current trend in posing cumulus parameterization is away from deterministic diagnostic closures, including instantaneous adjustments, toward prognostic or nondeterministic closures, including relaxed and/or triggered adjustments. A number of questions need to be answered, however, for the merit of this trend to be fully utilized.Major practical and conceptual problems in the conventional approach of cumulus parameterization, which include artificial separations of processes and scales, are then discussed. It is rather obvious that for future climate models the scope of the problem must be drastically expanded from “cumulus parameterization” to “unified cloud parameterization,” or even to “unified model physics.” This is an extremely challenging task, both intellectually and computationally, and the use of multiple approaches is crucial even for a moderate success. “Cloud-resolving convective parameterization” or “superparameterization” is a promising new approach that can develop into a multiscale modeling framework (MMF). It is emphasized that the use of such a framework can unify our currently diversified modeling efforts and make verification of climate models against observations much more constructive than it is now.},
	number = {13},
	urldate = {2020-10-13},
	journal = {Journal of Climate},
	author = {Arakawa, Akio},
	month = jul,
	year = {2004},
	pages = {2493--2525}
}

@article{cardinali_influence-matrix_2004,
	title = {Influence-matrix diagnostic of a data assimilation system},
	volume = {130},
	issn = {0035-9009},
	url = {https://doi.org/10.1256/qj.03.205},
	doi = {10.1256/qj.03.205},
	abstract = {Abstract The influence matrix is used in ordinary least-squares applications for monitoring statistical multiple-regression analyses. Concepts related to the influence matrix provide diagnostics on the influence of individual data on the analysis?the analysis change that would occur by leaving one observation out, and the effective information content (degrees of freedom for signal) in any sub-set of the analysed data. In this paper, the corresponding concepts have been derived in the context of linear statistical data assimilation in numerical weather prediction. An approximate method to compute the diagonal elements of the influence matrix (the self-sensitivities) has been developed for a large-dimension variational data assimilation system (the four-dimensional variational system of the European Centre for Medium-Range Weather Forecasts). Results show that, in the boreal spring 2003 operational system, 15\% of the global influence is due to the assimilated observations in any one analysis, and the complementary 85\% is the influence of the prior (background) information, a short-range forecast containing information from earlier assimilated observations. About 25\% of the observational information is currently provided by surface-based observing systems, and 75\% by satellite systems. Low-influence data points usually occur in data-rich areas, while high-influence data points are in data-sparse areas or in dynamically active regions. Background-error correlations also play an important role: high correlation diminishes the observation influence and amplifies the importance of the surrounding real and pseudo observations (prior information in observation space). Incorrect specifications of background and observation-error covariance matrices can be identified, interpreted and better understood by the use of influence-matrix diagnostics for the variety of observation types and observed variables used in the data assimilation system. Copyright ? 2004 Royal Meteorological Society},
	number = {603},
	urldate = {2020-10-11},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Cardinali, Carla and Pezzulli, Sergio and Andersson, Erik},
	month = oct,
	year = {2004},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {Observations, Regression methods},
	pages = {2767--2786},
	annote = {doi: 10.1256/qj.03.205}
}

@article{chen_use_2017,
	title = {Use of {EFSO} for {Online} {Data} {Assimilation} {Quality} {Monitoring} and {Proactive} {Quality} {Control}},
	number = {47},
	journal = {CAS/JSC WGNE Research Activities in Atmospheric and Oceanic Modelling},
	author = {Chen, Tse-Chun and Kalnay, Eugenia and Hotta, Daisuke},
	year = {2017},
	pages = {9}
}

@article{khairoutdinov_simulations_2005,
	title = {Simulations of the {Atmospheric} {General} {Circulation} {Using} a {Cloud}-{Resolving} {Model} as a {Superparameterization} of {Physical} {Processes}},
	volume = {62},
	issn = {0022-4928},
	url = {https://journals.ametsoc.org/jas/article/62/7/2136/26283/Simulations-of-the-Atmospheric-General-Circulation},
	doi = {10.1175/JAS3453.1},
	language = {en},
	number = {7},
	urldate = {2020-10-07},
	journal = {Journal of the Atmospheric Sciences},
	author = {Khairoutdinov, Marat and Randall, David and DeMott, Charlotte},
	month = jul,
	year = {2005},
	note = {Publisher: American Meteorological Society},
	pages = {2136--2154}
}

@article{khairoutdinov_cloud_2001,
	title = {A cloud resolving model as a cloud parameterization in the {NCAR} {Community} {Climate} {System} {Model}: {Preliminary} results},
	volume = {28},
	copyright = {Copyright 2001 by the American Geophysical Union.},
	issn = {1944-8007},
	shorttitle = {A cloud resolving model as a cloud parameterization in the {NCAR} {Community} {Climate} {System} {Model}},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2001GL013552},
	doi = {10.1029/2001GL013552},
	abstract = {Preliminary results of a short climate simulation with a 2-D cloud resolving model (CRM) installed into each grid column of an NCAR Community Climate System Model (CCSM) are presented. The CRM replaces the conventional convective and stratiform cloud parameterizations, and allows for explicit computation of the global cloud fraction distribution for radiation computations. The extreme computational cost of the combined CCSM/CRM model has thus far limited us to a two-month long climate simulation (December-January) using 2.8° × 2.8° resolution. The simulated geographical distributions of the total rainfall, precipitable water, cloud cover, and Earth radiation budget, for the month of January, look very reasonable.},
	language = {en},
	number = {18},
	urldate = {2020-10-07},
	journal = {Geophysical Research Letters},
	author = {Khairoutdinov, Marat F. and Randall, David A.},
	year = {2001},
	note = {\_eprint: https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1029/2001GL013552},
	pages = {3617--3620}
}

@book{walker_world_1928,
	title = {World weather {III}},
	publisher = {Edward Stanford},
	author = {Walker, Sir Gilbert Thomas},
	year = {1928}
}

@book{philander_nino_1990,
	address = {New York},
	title = {El {Nino}, {La} {Nina}, and the {Southern} {Oscillation}},
	url = {https://books.google.com/books?id=9fwrkW_B1YYC},
	publisher = {Academic Press},
	author = {Philander, S.G.},
	year = {1990}
}

@article{van_den_dool_searching_1994,
	title = {Searching for analogues, how long must we wait?},
	volume = {46},
	issn = {null},
	url = {https://doi.org/10.3402/tellusa.v46i3.15481},
	doi = {10.3402/tellusa.v46i3.15481},
	abstract = {A three-way relationship is derived between the size of a library (M years) of historical atmospheric data, the distance between an arbitrarily picked state of the atmosphere and its nearest neighbor (or analogue), and the size of the spatial domain, as measured by the number of spatial degrees of freedom (N). It is found that it would take a library of order 1030 years to find 2 observed flows that match to within current observational error over a large area such as the Northern Hemisphere. Obviously, with only 10—100 years of data, the probability of finding natural analogous is very small, unless one is satisfied with analogy over small areas or in just 2 of 3 degrees of freedom as represented, for instance, by 2 or 3 leading empirical orthogonal modes. We further propose the notion that analogues can be constructed by combining a number of observed flow patterns. We have found at least one application where linearly constructed analogues are conclusively better at specifying US surface weather from concurrent 700 mb geopotential height than natural analogues are.},
	number = {3},
	urldate = {2018-11-14},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Van den Dool, H. M.},
	month = jan,
	year = {1994},
	pages = {314--324}
}

@article{molteni_predictability_1993,
	title = {Predictability and finite-time instability of the northern winter circulation},
	volume = {119},
	issn = {0035-9009},
	url = {https://doi.org/10.1002/qj.49711951004},
	doi = {10.1002/qj.49711951004},
	abstract = {Abstract The finite-time instability and associated predictability of atmospheric of atmospheric circulations are defined in terms of the largest singular values, and associated singular vectors, of the linear evolution operator determined form given equations of motion. These quantities are calculated in both a barotropic and a three-level quasi-geostrophic model, using as basic states realistic large-scale northern wintertime flows that represent the climatological state, regime composites, and specific realizations of these regimes. for time-invariant basic states, the singular vectors are compared with the corresponding normal-mode solutions; it is shown that the perturbations defined (at the initial time) by the singular vectors have much larger growth rates than the normal modes, and possess a more localized spatial structure. The regimes studied have opposite values of the Pacific/North American (PNA) index, and growth rates for the barotropic basis states appear to confirm earlier studies that the barotropic instability of the negative PNA states may be larger than the corresponding positive PNA states. The evolution of the singular-vector perturbations, with emphasis on the vertical structure, is compared for time-evolving and time-invariant baroclinic basis states; the effects of nonlinearity are also discusses. It is shown that, in the baroclinic model, interactions between synoptic-scale eddies in the time-evolving basic state and in the perturbation field are fundamental for studying the predictability of transitions in the large-scale circulation. Consequently results obtained from linear calculations using very smooth basic states cannot properly account for such predictability. These results form the basis of a technique used to initialize ensembles of forecasts made with a primitive-equation model, and are described in the companion paper (Mureau et al. 1993).},
	number = {510},
	urldate = {2020-08-11},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Molteni, Franco and Palmer, T. N.},
	month = jan,
	year = {1993},
	note = {Publisher: John Wiley \& Sons, Ltd},
	pages = {269--298},
	annote = {doi: 10.1002/qj.49711951004}
}

@article{gill_simple_1980,
	title = {Some simple solutions for heat-induced tropical circulation},
	volume = {106},
	issn = {0035-9009},
	url = {https://doi.org/10.1002/qj.49710644905},
	doi = {10.1002/qj.49710644905},
	abstract = {Abstract A simple analytic model is constructed to elucidate some basic features of the response of the tropical atmosphere to diabatic heating. In particular, there is considerable east-west asymmetry which can be illustrated by solutions for heating concentrated in an area of finite extent. This is of more than academic interest because heating in practice tends to be concentrated in specific areas. For instance, a model with heating symmetric about the equator at Indonesian longitudes produces low-level easterly flow over the Pacific through propagation of Kelvin waves into the region. It also produces low-level westerly inflow over the Indian Ocean (but in a smaller region) because planetary waves propagate there. In the heating region itself the low-level flow is away from the equator as required by the vorticity equation. The return flow toward the equator is farther west because of planetary wave propagation, and so cyclonic flow is obtained around lows which form on the western margins of the heating zone. Another model solution with the heating displaced north of the equator provides a flow similar to the monsoon circulation of July and a simple model solution can also be found for heating concentrated along an inter-tropical convergence line.},
	number = {449},
	urldate = {2020-08-11},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Gill, A. E.},
	month = jul,
	year = {1980},
	note = {Publisher: John Wiley \& Sons, Ltd},
	pages = {447--462},
	annote = {doi: 10.1002/qj.49710644905}
}

@article{pena_statistics_2003,
	title = {Statistics of locally coupled ocean and atmosphere intraseasonal anomalies in {Reanalysis} and {AMIP} data},
	volume = {10},
	issn = {1607-7946},
	url = {https://npg.copernicus.org/articles/10/245/2003/},
	doi = {10.5194/npg-10-245-2003},
	number = {3},
	journal = {Nonlin. Processes Geophys.},
	author = {Peña, M. and Kalnay, E. and Cai, M.},
	month = jun,
	year = {2003},
	note = {Publisher: Copernicus Publications},
	pages = {245--251}
}

@article{zebiak_model_1987,
	title = {A {Model} {El} {Ni}\&ntilde–{Southern} {Oscillation}},
	volume = {115},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/1520-0493(1987)115<2262:AMENO>2.0.CO;2},
	doi = {10.1175/1520-0493(1987)115<2262:AMENO>2.0.CO;2},
	abstract = {A coupled atmosphere-ocean model is developed and used to study the ENSO (El Ni\&amp;ntilde/Southern Oscillation) phenomenon. With no anomalous external forcing, the coupled model reproduces certain key features of the observed phenomenon. including the recurrence of warm events at irregular intervals with a preference for three to four years. It is shown that the mean sea surface temperature, wind and ocean current fields determine the characteristic spatial structure of ENSO anomalies. The tendency for phase-locking of anomalies is explained in terms of a variation in coupling strength associated with the annual cycle in the mean fields. Sensitivity studies reveal that both the amplitude and the time of scale of the oscillation are sensitive to several parameters that affect the strength of the atmosphere–ocean coupling. Stronger coupling implies larger oscillations with a longer time scale. A critical element of the model oscilliation is the variability in the equatorial heat content of the upper ocean. Equatorial heat content increases prior to warm events and decreases sharply during the events. A theory for this variability and the associated transitions between the non-El Niño and El Niño states is presented. Implications of the model results for the prediction of El Niño events are discussed.},
	number = {10},
	urldate = {2020-08-11},
	journal = {Monthly Weather Review},
	author = {Zebiak, Stephen E. and Cane, Mark A.},
	month = oct,
	year = {1987},
	pages = {2262--2278}
}

@incollection{charney_predictability_1981,
	address = {Cambridge Eng. ; New York},
	title = {Predictability of monsoons},
	isbn = {978-0-521-22497-0},
	abstract = {This volume presents a survey of our state of knowledge of the physical and dynamical processes involved in the Asian monsoon. Although traditionally the main emphasis has been on the study of the atmospheric component, it has long been known that the oceans play a vitally important part in determining the occurrence of this spectacular seasonal event. A scientific study of this phenomenon involves a detailed investigation of the dynamical processes which occur in both the atmosphere and the ocean, on timescales on up to at least a year and on spatial scales from a few hundred kilometres or so up to that of the global atmospheric and oceanic circulations. The editors present a coherent survey of each of the meteorological, oceanographic and hydrological aspects and of their implications for weather forecasting and flood prediction. Monsoon Dynamics is a timely survey of a dramatic meteorological phenomenon which will interest meteorologists, climatologists and geophysicists.},
	language = {English},
	booktitle = {Monsoon {Dynamics}},
	publisher = {Cambridge University Press},
	author = {Charney, J. G. and Shukla, J.},
	month = apr,
	year = {1981}
}

@article{motesharrei_modeling_2016,
	title = {Modeling sustainability: population, inequality, consumption, and bidirectional coupling of the {Earth} and {Human} {Systems}},
	volume = {3},
	issn = {2095-5138},
	url = {https://doi.org/10.1093/nsr/nww081},
	doi = {10.1093/nsr/nww081},
	abstract = {Over the last two centuries, the impact of the Human System has grown dramatically, becoming strongly dominant within the Earth System in many different ways. Consumption, inequality, and population have increased extremely fast, especially since about 1950, threatening to overwhelm the many critical functions and ecosystems of the Earth System. Changes in the Earth System, in turn, have important feedback effects on the Human System, with costly and potentially serious consequences. However, current models do not incorporate these critical feedbacks. We argue that in order to understand the dynamics of either system, Earth System Models must be coupled with Human System Models through bidirectional couplings representing the positive, negative, and delayed feedbacks that exist in the real systems. In particular, key Human System variables, such as demographics, inequality, economic growth, and migration, are not coupled with the Earth System but are instead driven by exogenous estimates, such as United Nations population projections. This makes current models likely to miss important feedbacks in the real Earth–Human system, especially those that may result in unexpected or counterintuitive outcomes, and thus requiring different policy interventions from current models. The importance and imminence of sustainability challenges, the dominant role of the Human System in the Earth System, and the essential roles the Earth System plays for the Human System, all call for collaboration of natural scientists, social scientists, and engineers in multidisciplinary research and modeling to develop coupled Earth–Human system models for devising effective science-based policies and measures to benefit current and future generations.},
	number = {4},
	urldate = {2020-08-11},
	journal = {National Science Review},
	author = {Motesharrei, Safa and Rivas, Jorge and Kalnay, Eugenia and Asrar, Ghassem R. and Busalacchi, Antonio J. and Cahalan, Robert F. and Cane, Mark A. and Colwell, Rita R. and Feng, Kuishuang and Franklin, Rachel S. and Hubacek, Klaus and Miralles-Wilhelm, Fernando and Miyoshi, Takemasa and Ruth, Matthias and Sagdeev, Roald and Shirmohammadi, Adel and Shukla, Jagadish and Srebric, Jelena and Yakovenko, Victor M. and Zeng, Ning},
	month = dec,
	year = {2016},
	pages = {470--494}
}

@article{mote_novel_2020,
	title = {A {Novel} {Approach} to {Carrying} {Capacity}: {From} a priori {Prescription} to a posteriori {Derivation} {Based} on {Underlying} {Mechanisms} and {Dynamics}},
	volume = {48},
	issn = {0084-6597},
	url = {https://doi.org/10.1146/annurev-earth-053018-060428},
	doi = {10.1146/annurev-earth-053018-060428},
	abstract = {The Human System is within the Earth System. They should be modeled bidirectionally coupled, as they are in reality. The Human System is rapidly expanding, mostly due to consumption of fossil fuels (approximately one million times faster than Nature accumulated them) and fossil water. This threatens not only other planetary subsystems but also the Human System itself. Carrying Capacity is an important tool to measure sustainability, but there is a widespread view that Carrying Capacity is not applicable to humans. Carrying Capacity has generally been prescribed a priori, mostly using the logistic equation. However, the real dynamics of human population and consumption are not represented by this equation or its variants. We argue that Carrying Capacity should not be prescribed but should insteadbe dynamically derived a posteriori from the bidirectional coupling of Earth System submodels with the Human System model. We demonstrate this approach with a minimal model of Human?Nature interaction (HANDY). ?? The Human System is a subsystem of the Earth System, with inputs (resources) from Earth System sources and outputs (waste, emissions) to Earth System sinks. ?? The Human System is growing rapidly due to nonrenewable stocks of fossil fuels and water and threatens the sustainability of the Human System and to overwhelm the Earth System. ?? Carrying Capacity has been prescribed a priori and using the logistic equation, which does not represent the dynamics of the Human System. ?? Our new approach to human Carrying Capacity is derived from dynamically coupled Earth System?Human System models and can be used to estimate the sustainability of the Human System.},
	number = {1},
	urldate = {2020-08-11},
	journal = {Annual Review of Earth and Planetary Sciences},
	author = {Mote, Safa and Rivas, Jorge and Kalnay, Eugenia},
	month = may,
	year = {2020},
	note = {Publisher: Annual Reviews},
	pages = {657--683},
	annote = {doi: 10.1146/annurev-earth-053018-060428}
}

@article{poterjoy_efficient_2016,
	title = {Efficient {Assimilation} of {Simulated} {Observations} in a {High}-{Dimensional} {Geophysical} {System} {Using} a {Localized} {Particle} {Filter}},
	volume = {144},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/MWR-D-15-0322.1},
	doi = {10.1175/MWR-D-15-0322.1},
	abstract = {This study presents the first application of a localized particle filter (PF) for data assimilation in a high-dimensional geophysical model. Particle filters form Monte Carlo approximations of model probability densities conditioned on observations, while making no assumptions about the underlying error distribution. Unlike standard PFs, the local PF uses a localization function to reduce the influence of distant observations on state variables, which significantly decreases the number of particles required to maintain the filter’s stability. Because the local PF operates effectively using small numbers of particles, it provides a possible alternative to Gaussian filters, such as ensemble Kalman filters, for large geophysical models. In the current study, the local PF is compared with stochastic and deterministic ensemble Kalman filters using a simplified atmospheric general circulation model. The local PF is found to provide stable filtering results over yearlong data assimilation experiments using only 25 particles. The local PF also outperforms the Gaussian filters when observation networks include measurements that have non-Gaussian errors or relate nonlinearly to the model state, like remotely sensed data used frequently in atmospheric analyses. Results from this study encourage further testing of the local PF on more complex geophysical systems, such as weather prediction models.},
	number = {5},
	urldate = {2020-08-11},
	journal = {Monthly Weather Review},
	author = {Poterjoy, Jonathan and Anderson, Jeffrey L.},
	month = apr,
	year = {2016},
	pages = {2007--2020}
}

@article{weickmann_intraseasonal_1985,
	title = {Intraseasonal (30–60 {Day}) {Fluctuations} of {Outgoing} {Longwave} {Radiation} and 250 mb {Streamfunction} during {Northern} {Winter}},
	volume = {113},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/1520-0493(1985)113<0941:IDFOOL>2.0.CO;2},
	doi = {10.1175/1520-0493(1985)113<0941:IDFOOL>2.0.CO;2},
	abstract = {Ten years of outgoing longwave radiation (OLR) and 250 mb circulation data are used in a statistical study which concentrates on 28–72 day fluctuations during Northern Hemisphere winter. The results of spectral and cross-spectral analyses show that 28–72 day planetary-scale oscillations of OLR and 250 mb circulation are statistically significant features of the entire 10-year dataset.The strongest OLR fluctuations at 28–72 day periods are located from the equator to 15°S and extend from about 60 to 160°E and in the vicinity of the South Pacific Convergence Zone (SPCZ). The streamfunction variance shows significant 28–72 day fluctuations over the subtropics of both hemispheres and over the extratropical North Atlantic.The OLR anomalies propagate from west to east between 60 and 160°E at about 5 m s−1. There are statistically significant relationships between the regions of (inferred) equatorial cloudiness and planetary-scale circulation features. Fluctuations in the windfield near the exit regions of the east Asian and North American jets are important components of the life cycle of 28–72 day oscillations during northern winter. The life cycle also includes a prominent wavenumber 1 evolution which manifests itself synoptically as an eccentric circumpolar vortex, expanded in regions of enhanced equatorial cloudiness and contracted in regions of suppressed equatorial cloudiness.},
	number = {6},
	urldate = {2020-08-11},
	journal = {Monthly Weather Review},
	author = {Weickmann, Klaus M. and Lussky, Glenn R. and Kutzbach, John E.},
	month = jun,
	year = {1985},
	pages = {941--961}
}

@article{carbone_tropical_2000,
	title = {Tropical {Island} {Convection} in the {Absence} of {Significant} {Topography}. {Part} {I}: {Life} {Cycle} of {Diurnally} {Forced} {Convection}},
	volume = {128},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/1520-0493(2000)128<3459:TICITA>2.0.CO;2},
	doi = {10.1175/1520-0493(2000)128<3459:TICITA>2.0.CO;2},
	abstract = {Diurnally forced convection was observed over the Tiwi Islands, north of the Australian continent, as part of the Maritime Continent Thunderstorm Experiment. Immature peninsula-scale (5–15 km) sea breezes were observed to initiate moist convection early each day, principally through convergence that results from the confluence or collision of peninsula breeze fronts. Convection initiated by peninsula-scale breezes usually fails to organize beyond a small cluster of cells and dissipates as a local event. Mature island-scale (∼100 km) breezes develop by late morning and subsequently play a pivotal role in the forcing and evolution of organized convection.The initiation of mesoscale convective systems (MCSs) is observed to be a direct consequence of breeze front collisions for only ∼20\% of the days on which organized convection develops. This is referred to as “type A” forcing and it occurs when normal convective development is delayed or otherwise suppressed. Type A forcing is nature’s backup mechanism and it is less likely to produce large or strong mesoscale convective systems when compared to the general population of events.On approximately 80\% of days during which organized convection develops, a multiple-stage forcing process evolves through complex interactions between preferred sea breezes and convectively generated cold pools. So-called type B forcing emerges 1–3 h before penetration of the sea-breeze fronts to the interior island. Type B evolution has at least four stages: 1) leeward- or other preferred-coast sea-breeze showers that develop small cold pools, 2) showers that travel inland when their cold pools become denser than the marine boundary layer, 3) westward propagation of squalls that result from a merge or maturation of small cold pools, and 4) interaction between a gust front and a zonally oriented sea-breeze front of island scale (∼100 km). A collision of gust fronts, emanating from separate convective areas over Bathurst and Melville Islands, can excite a fifth stage of development associated with many of the strongest systems.A principal finding of this study is that all MCSs over the Tiwi Islands can be traced backward in time to the initiation of convection by island-scale sea breezes, usually of type B near leeward coasts. Subsequent convective evolution is characteristic of traveling free convection elsewhere in that it organizes according to cold pool, shear balance, and mean flow factors. The presence of a critical level in the lower troposphere is a unique aspect of the theoretical “optimal condition” associated with island convection in a low-level jet regime; however, the data presented here suggest that the effects of surface layer stagnation may be of greater practical importance.Since the aforestated conclusions are based on time series of rather limited duration, the reader is cautioned as to uncertainty associated with the climatological frequency of events as described herein. Furthermore, the authors have not examined external forcings, which may be associated with large-scale circulations.},
	number = {10},
	urldate = {2020-08-11},
	journal = {Monthly Weather Review},
	author = {Carbone, R. E. and Wilson, J. W. and Keenan, T. D. and Hacker, J. M.},
	month = oct,
	year = {2000},
	pages = {3459--3480}
}

@article{droegemeier_numerical_1997,
	title = {The numerical prediction of thunderstorms: {Challenges}. potential benefits and results from real-time operational tests},
	volume = {46},
	number = {4},
	journal = {Bulletin of the World Meteorological Organization},
	author = {Droegemeier, KK},
	year = {1997},
	note = {Publisher: Geneva, Switzerland: The Organization, 1990-},
	pages = {324--335}
}

@article{krishnamurti_multimodel_2000,
	title = {Multimodel {Ensemble} {Forecasts} for {Weather} and {Seasonal} {Climate}},
	volume = {13},
	issn = {0894-8755},
	url = {https://doi.org/10.1175/1520-0442(2000)013<4196:MEFFWA>2.0.CO;2},
	doi = {10.1175/1520-0442(2000)013<4196:MEFFWA>2.0.CO;2},
	abstract = {In this paper the performance of a multimodel ensemble forecast analysis that shows superior forecast skills is illustrated and compared to all individual models used. The model comparisons include global weather, hurricane track and intensity forecasts, and seasonal climate simulations. The performance improvements are completely attributed to the collective information of all models used in the statistical algorithm.The proposed concept is first illustrated for a low-order spectral model from which the multimodels and a “nature run” were constructed. Two hundred time units are divided into a training period (70 time units) and a forecast period (130 time units). The multimodel forecasts and the observed fields (the nature run) during the training period are subjected to a simple linear multiple regression to derive the statistical weights for the member models. The multimodel forecasts, generated for the next 130 forecast units, outperform all the individual models. This procedure was deployed for the multimodel forecasts of global weather, multiseasonal climate simulations, and hurricane track and intensity forecasts. For each type an improvement of the multimodel analysis is demonstrated and compared to the performance of the individual models. Seasonal and multiseasonal simulations demonstrate a major success of this approach for the atmospheric general circulation models where the sea surface temperatures and the sea ice are prescribed. In many instances, a major improvement in skill over the best models is noted.},
	number = {23},
	urldate = {2020-08-11},
	journal = {Journal of Climate},
	author = {Krishnamurti, T. N. and Kishtawal, C. M. and Zhang, Zhan and LaRow, Timothy and Bachiochi, David and Williford, Eric and Gadgil, Sulochana and Surendran, Sajani},
	month = dec,
	year = {2000},
	pages = {4196--4216}
}

@article{buizza_sensitivity_1994,
	title = {Sensitivity of optimal unstable structures},
	volume = {120},
	issn = {0035-9009},
	url = {https://doi.org/10.1002/qj.49712051609},
	doi = {10.1002/qj.49712051609},
	abstract = {Abstract Optimal unstable perturbations, i.e. structures that grow fastest over a finite time interval, can be used in numerical weather prediction to construct the initial conditions of an ensemble of integrations. Optimal perturbations superimposed on a basic state provide a representation of the uncertainty of the initial state of the atmospheric flow. The computation of the fastest-growing perturbations over a finite time interval can be achieved in the linear approximation by using the forward and adjoint tangent version of a full nonlinear model. Previous results, obtained using a version of a primitive-equation model with a reasonable horizontal and vertical resolution, showed that the lack of parametrization of turbulent processes can lead to fast-growing perturbations characterized by ?non-meteorological? structures. The first part of this paper focuses on this problem. Numerical experiments have been performed to study the impact of a simple surface-drag and vertical-diffusion scheme on the most unstable perturbations. It is shown how the very simple parametrization of the turbulent processes implemented inhibits the growth of non-meteorological structures close to the surface. A second very important problem to face when constructing the initial conditions of an ensemble of forecasts, using optimal perturbations, is the definition of the optimization time interval over which the growth of these unstable structures is maximized. This problem will be investigated in the second part of this work, where the impact of the optimization time interval on the definition of the unstable sub-space is studied for time periods up to three days. Results from different cases seem to indicate that unstable sub-spaces computed with an optimization time interval longer than 36 hours are very similar.},
	number = {516},
	urldate = {2020-08-11},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Buizza, Roberto},
	month = jan,
	year = {1994},
	note = {Publisher: John Wiley \& Sons, Ltd},
	pages = {429--451},
	annote = {doi: 10.1002/qj.49712051609}
}

@article{fischer_error_1998,
	title = {Error growth and {Kalman} filtering within an idealized baroclinic flow},
	volume = {50},
	issn = {null},
	url = {https://doi.org/10.3402/tellusa.v50i5.14561},
	doi = {10.3402/tellusa.v50i5.14561},
	abstract = {The dynamics of covariances within a baroclinic flow are presented, as obtained by an explicitcomputation of the forecast error covariance matrix. This is possible since the numerical modelis a low-dimensional, semi-geostrophic, uniform potential vorticity model. In addition, idealizedobservations and observation errors are assimilated with a Kalman filter. This allows for designinga large set of idealized observation system simulations (IOSS) where the impact of extrameasurements in data sparse areas is studied. The results show that maximal error growth isconcentrated along the large-scale frontal strips. When baroclinic interactions are switched off, error growth is enhanced in the upstream parts of the system, and damped in the downstreamregions. This shows that barotropic growth alone significantly departs from the mixed barotropic-baroclinic case, so that the baroclinic effects cannot be neglected. The IOSS indicate thata permanent data supply produces a significant damping of error growth, because the data areinjected continuously in time. The sensitivity studies show that the positions of the pseudoobservationsmust be in the vicinity of the frontal structures, and that both the surface frontand the tropopause jet have to be sampled. When a widespread, non-permanent observationnetwork is considered, objective targeting strategies are worked out, and their impact on the2-day forecast error field is studied. The striking feature is the strong dependency of the forecasterror on the initial error covariance. It is found that the errors are decreased efficiently bytargeted pseudo-observations only if dynamically reshaped correlations are specified, insteadof the conventional isotropic ones.},
	number = {5},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Fischer, Claude and Joly, Alain and Lalaurette, François},
	month = jan,
	year = {1998},
	note = {Publisher: Taylor \& Francis},
	pages = {596--615},
	annote = {doi: 10.3402/tellusa.v50i5.14561}
}

@article{pu_targeting_1999,
	title = {Targeting observations with the quasi-inverse linear and adjoint {NCEP} global models: {Performance} during {FASTEX}},
	volume = {125},
	issn = {0035-9009},
	url = {https://doi.org/10.1002/qj.49712556110},
	doi = {10.1002/qj.49712556110},
	abstract = {Abstract This note gives a brief summary of the targeting results obtained with both adjoint and quasi-inverse linear NCEP global spectral models during the Fronts and Atlantic Storm-Track EXperiment (FASTEX). Questions concerning the feasibility of the methods and related issues about targeting observations are briefly discussed.},
	number = {561},
	urldate = {2020-08-11},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Pu, Zhao-Xia and Kalnay, Eugenia},
	month = oct,
	year = {1999},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {Adjoint, Fronts and Atlantic Storm-Track EXperiment (FASTEX), Quasi-inverse linear, Targeted observations},
	pages = {3329--3337},
	annote = {doi: 10.1002/qj.49712556110}
}

@inproceedings{kalnay_are_2002,
	title = {Are bred vectors the same as {Lyapunov} vectors?},
	author = {Kalnay, Eugenia and Corazza, Matteo and Cai, Ming},
	year = {2002},
	pages = {6820}
}

@article{cai_bred_2003,
	title = {Bred {Vectors} of the {Zebiak}–{Cane} {Model} and {Their} {Potential} {Application} to {ENSO} {Predictions}},
	volume = {16},
	issn = {0894-8755},
	url = {https://doi.org/10.1175/1520-0442(2003)016<0040:BVOTZC>2.0.CO;2},
	doi = {10.1175/1520-0442(2003)016<0040:BVOTZC>2.0.CO;2},
	abstract = {The breeding method is used to obtain the bred vectors (BV) of the Zebiak–Cane (ZC) atmosphere–ocean coupled model. Bred vectors represent a nonlinear, finite-time extension of the leading local Lyapunov vectors of the ZC model. The spatial structure and growth rate of bred vectors are strongly related to the background ENSO evolution of the ZC model. It is equally probable for the BVs to have a positive or negative sign (defined using the Niño-3 index of the BV), though often there is a sign change just before or after an El Niño event. The growth rate (and therefore the spatial coherence) of the BVs peaks several months prior to and after an El Niño event and it is nearly neutral at the mature stage.Potential applications of bred vectors for ENSO predictions are explored in the context of data assimilation and ensemble forecasting under a perfect model scenario. It is shown that when bred vectors are removed from random initial error fields, forecast errors can be reduced by up to 30\%. This suggests that minimizing the projection of the bred vectors on the observation-minus-analysis field may be a beneficial factor to an operational forecast system. The ensemble mean of a pair of forecasts perturbed with positive/negative bred vectors improves the forecast skill, particularly for lead times longer than 6 months, substantially reducing the “spring barrier” for ENSO prediction.},
	number = {1},
	urldate = {2020-08-11},
	journal = {Journal of Climate},
	author = {Cai, Ming and Kalnay, Eugenia and Toth, Zoltan},
	month = jan,
	year = {2003},
	pages = {40--56}
}

@article{tracton_operational_1993,
	title = {Operational {Ensemble} {Prediction} at the {National} {Meteorological} {Center}: {Practical} {Aspects}},
	volume = {8},
	issn = {0882-8156},
	url = {https://doi.org/10.1175/1520-0434(1993)008<0379:OEPATN>2.0.CO;2},
	doi = {10.1175/1520-0434(1993)008<0379:OEPATN>2.0.CO;2},
	abstract = {On 7 December 1992 NMC began operational ensemble prediction. The ensemble configuration provides 14 independent forecasts every day, verifying on days 1 through 10. The ensemble members are generated through a combination of time lagging [Lagged-Average Forecasting] and a new method, Breeding of Growing Modes (Toth and Kalnay). In adopting the ensemble approach, NMC explicitly recognizes that forecasts are stochastic, not deterministic, in nature. There is no single solution, only an array of possibilities, and forecast ensembles provide a rational basis for assessing the range and likelihood of alternative scenarios.Given the near saturation of computer resources at NMC, implementation of ensemble prediction required a trade-off between model resolution and multiple runs. Before 7 December 1992, NMC was producing a single global forecast through 10 days with the highest-resolution (T126) version possible of its medium-range forecast model. Now, based an experiments that showed no adverse impact upon the quality of forecasts, the T126 model run is truncated to T62 resolution beyond day 6. The computer savings are used to generate the balance of the ensemble members at the lower T62 resolution. While these complementary runs are, on the average, somewhat less skillful when considered individually, it is expected that ensemble averaging will increase skill levels. More importantly, we expect that ensemble prediction will enhance the utility of NWP by (a) providing a basis for the estimation of the reliability of forecasts, and (b) creating a quantitative foundation for probabilistic forecasting.A major challenge of ensemble prediction is to condense the large amounts of information provided by ensembles into a user-friendly format that can be easily assimilated and used by forecasters. Some examples of output products relevant to operational forecast applications are illustrated. They include the display of each member of the ensemble, ensemble mean and dispersion fields, “clustering” of similar forecasts, and simple probability estimates.While this implementation of ensemble prediction is relatively modest (ensembles of 14 members for the forecasts encompassing days 1 through 10), it does provide the basis for development of operational experience with ensemble forecasting, and for research directed toward maximizing the utility of NMC's numerical guidance.},
	number = {3},
	urldate = {2020-08-11},
	journal = {Weather and Forecasting},
	author = {Tracton, M. Steven and Kalnay, Eugenia},
	month = sep,
	year = {1993},
	pages = {379--398}
}

@article{morss_idealized_2001,
	title = {Idealized {Adaptive} {Observation} {Strategies} for {Improving} {Numerical} {Weather} {Prediction}},
	volume = {58},
	issn = {0022-4928},
	url = {https://doi.org/10.1175/1520-0469(2001)058<0210:IAOSFI>2.0.CO;2},
	doi = {10.1175/1520-0469(2001)058<0210:IAOSFI>2.0.CO;2},
	abstract = {Adaptive sampling uses information about individual atmospheric situations to identify regions where additional observations are likely to improve weather forecasts of interest. The observation network could be adapted for a wide range of forecasting goals, and it could be adapted either by allocating existing observations differently or by adding observations from programmable platforms to the existing network. In this study, observing strategies are explored in a simulated idealized system with a three-dimensional quasigeostrophic model and a realistic data assimilation scheme. Using simple error norms, idealized adaptive observations are compared to nonadaptive observations for a range of observation densities.The results presented show that in this simulated system, the influence of both adaptive and nonadaptive observations depends strongly on the observation density. For sparse observation networks, the simple adaptive strategies tested are beneficial: adaptive observations can, on average, reduce analysis and forecast errors more than the same number of nonadaptive observations, and they can reduce errors by a given amount using fewer observational resources. In contrast, for dense observation networks it is much more difficult to benefit from adapting observations, at least for the data assimilation method used here. The results suggest that the adaptive strategies tested are most effective when the observations are adapted regularly and frequently, giving the data assimilation system as many opportunities as possible to reduce errors as they evolve. They also indicate that ensemble-based estimates of initial condition errors may be useful for adaptive observations. Further study is needed to understand the extent to which the results from this idealized study apply to more complex, more realistic systems.},
	number = {2},
	urldate = {2020-08-10},
	journal = {Journal of the Atmospheric Sciences},
	author = {Morss, Rebecca E. and Emanuel, Kerry A. and Snyder, Chris},
	month = jan,
	year = {2001},
	pages = {210--232}
}

@inproceedings{toth_ensemble_1996,
	title = {Ensemble forecasting at {NCEP}},
	volume = {2},
	booktitle = {Proc. {Seminar} on {Predictability}},
	author = {Toth, Zoltan and Kalnay, Eugenia},
	year = {1996},
	pages = {39--61}
}

@article{errico_predictability_1987,
	title = {Predictability {Experiments} {Using} a {High}-{Resolution} {Limited}-{Area} {Model}},
	volume = {115},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/1520-0493(1987)115<0488:PEUAHR>2.0.CO;2},
	doi = {10.1175/1520-0493(1987)115<0488:PEUAHR>2.0.CO;2},
	abstract = {Recently reported results indicate that limited-area mesoscale models with prescribed lateral boundaries do not exhibit the same predictability error growth as observed in large-scale (global) models. These results have been reanalyzed in greater detail. New methods of limited-area initialization and spectral analysis have been used. The new analyses indicate that several model properties act to restrict the growth of perturbation. These include: the Projection of initial perturbations onto gravity waves which interact only weakly with other, more significant motions; the “sweeping out” of errors by correct or perfect lateral boundaries; and the reduction of differences by subgrid dissipation. This last property suggests that there is a strong dynamical forcing of small scales by much larger scales, so that this forcing is only weakly affected by typical, small perturbations in this model. New experiments suggest that some quasi-geostrophic components of the forecasts, away from the inflow boundaries, exhibit local error doubling times of approximately one day within active baroclinic regions. Such doubling is not observed in a lower-resolution, global forecast model.},
	number = {2},
	urldate = {2020-08-10},
	journal = {Monthly Weather Review},
	author = {Errico, R. and Baumhefner, D.},
	month = feb,
	year = {1987},
	pages = {488--504}
}

@article{jarvinen_variational_1999,
	title = {Variational assimilation of time sequences of surface observations with serially correlated errors},
	volume = {51},
	issn = {0280-6495},
	url = {https://doi.org/10.1034/j.1600-0870.1999.t01-4-00002.x},
	doi = {10.1034/j.1600-0870.1999.t01-4-00002.x},
	abstract = {ABSTRACT Assimilation of observations from frequently reporting surface stations with a four-dimensional variational assimilation system (4D-Var) is described. A model for the serial observation error correlation is applied to observed time sequences of surface pressure observations, whereby the relative weight of the mean information over the temporal variations is decreased in the assimilation. Variational quality control is performed jointly for each time sequence of observations so as to either keep or reject all observations belonging to a time sequence. The operational practice at ECMWF has previously been to use just one pressure datum from each station within each 6-h assimilation time window. The increase of observational information used in these assimilation experiments results in a small but systematic increase in the short-range forecast accuracy. The r.m.s. of the analysis increments is decreased in the experiments, which means there is an improved consistency between the background and the observations. A study of a rapidly developing small-scale synoptic system (the Irish Christmas Storm in 1997) showed that both the background and the analysis became more accurate when more frequent observations were assimilated. Single-observation experiments showed that a surface pressure timesequence of data from a single surface station can intensify the analysis of a mid-latitude baroclinic system, that was underestimated in the background, when used in a 6-h 4D-Var. The method to assimilate time sequences presented in this paper has been implemented into the ECMWF operational 4D-Var assimilation system.},
	number = {4},
	urldate = {2020-07-25},
	journal = {Tellus A},
	author = {Järvinen, Heikki and Andersson, Erik and Bouttier, François},
	month = aug,
	year = {1999},
	note = {Publisher: John Wiley \& Sons, Ltd},
	pages = {469--488},
	annote = {doi: 10.1034/j.1600-0870.1999.t01-4-00002.x}
}

@incollection{gustafsson_review_1981,
	address = {New York, NY},
	title = {A {Review} of {Methods} for {Objective} {Analysis}},
	isbn = {978-1-4612-5970-1},
	url = {https://doi.org/10.1007/978-1-4612-5970-1_2},
	abstract = {For a given situation, our knowledge about the state of the atmosphere is given by a large number of actual and recent observations, irregularly distributed in space and time. The procedure of combining these observed data to make conclusions about the total variation of the meteorological variables within the area of interest, has generally been called meteorological analysis. The term “objective analysis” has been used for analysis as a numerical procedure by the aid of a computer to distinguish from the manual or “subjective” analysis procedure. In my opinion, the term “objective analysis” is too pretentious, a more relevant terminology is “numerical analysis” versus “manual analysis”.},
	booktitle = {Dynamic {Meteorology}: {Data} {Assimilation} {Methods}},
	publisher = {Springer New York},
	author = {Gustafsson, Nils},
	editor = {Bengtsson, Lennart and Ghil, Michael and Källén, Erland},
	year = {1981},
	doi = {10.1007/978-1-4612-5970-1_2},
	pages = {17--76}
}

@incollection{nichols_mathematical_2010,
	address = {Berlin, Heidelberg},
	title = {Mathematical {Concepts} of {Data} {Assimilation}},
	isbn = {978-3-540-74703-1},
	url = {https://doi.org/10.1007/978-3-540-74703-1_2},
	abstract = {Environmental systems can be realistically described by mathematical and numerical models of the system dynamics. These models can be used to predict the future behaviour of the system, provided that the initial states of the system are known. Complete data defining all of the states of a system at a specific time are, however, rarely available. Moreover, both the models and the available initial data contain inaccuracies and random noise that can lead to significant differences between the predicted states and the actual states of the system. In this case, observations of the system over time can be incorporated into the model equations to derive “improved” estimates of the states and also to provide information about the “uncertainty” in the estimates.},
	booktitle = {Data {Assimilation}: {Making} {Sense} of {Observations}},
	publisher = {Springer Berlin Heidelberg},
	author = {Nichols, N. K.},
	editor = {Lahoz, William and Khattatov, Boris and Menard, Richard},
	year = {2010},
	doi = {10.1007/978-3-540-74703-1_2},
	pages = {13--39}
}

@article{pires_extending_1996,
	title = {On extending the limits of variational assimilation in nonlinear chaotic systems},
	volume = {48},
	issn = {0280-6495},
	url = {https://doi.org/10.1034/j.1600-0870.1996.00006.x},
	doi = {10.1034/j.1600-0870.1996.00006.x},
	abstract = {ABSTRACT A study is made of the limits imposed on variational assimilation of observations by the chaotic character of the atmospheric flow. The primary goal of the study is to determine to which degree, and how, the knowledge of past noisy observations can improve the knowledge of the present state of a chaotic system. The study is made under the hypothesis of a perfect model. Theoretical results are illustrated by numerical experiments performed with the classical three-variable system introduced by Lorenz. Both theoretical and numerical results show that, even in the chaotic regime, appropriate use of past observations improves the accuracy on the estimate of the present state of the flow. However, the resulting estimation error mostly projects onto the unstable modes of the system, and the corresponding gain in predictability is limited. Theoretical considerations provide explicit estimates of the statistics of the assimilation error. The error depends on the state of the flow over the assimilation period. It is largest when there has been a period of strong instability in the very recent past. In the limit of infinitely long assimilation periods, the behaviour of the cost-function of variational assimilation is singular: it tends to fold into deep narrow ?valleys? parallel to the sheets of the unstable manifold of the system. An unbounded number of secondary minima appear, where solutions of minimization algorithms can be trapped. The absolute minimum of the cost-function always lies on the sheet of the unstable manifold containing the exact state of the flow. But the error along the unstable manifold saturates to a finite value, and the absolute minimum of the cost function does not, in general, converge to the exact state of the flow. Even so, the absolute minimum of the cost function is the best estimate that can be obtained of the state of the flow. An algorithm is proposed, the quasi-static variational assimilation, for determining the absolute minimum, based on successive small increments of the assimilation period and quasi-static adjustments of the minimizing solution. Finally, the impact of assimilation on predictability is assessed by forecast experiments with that system. The ability of the present paper lies mainly in the qualitative results it presents. Qualitative estimates relevant for the atmosphere call for further studies.},
	number = {1},
	urldate = {2020-07-11},
	journal = {Tellus A},
	author = {Pires, Carlos and Vautard, Robert and Talagrand, Oliver},
	month = jan,
	year = {1996},
	note = {Publisher: John Wiley \& Sons, Ltd},
	pages = {96--121},
	annote = {doi: 10.1034/j.1600-0870.1996.00006.x}
}

@article{hunt_four-dimensional_2004,
	title = {Four-dimensional ensemble {Kalman} filtering},
	volume = {56},
	issn = {null},
	url = {https://doi.org/10.3402/tellusa.v56i4.14424},
	doi = {10.3402/tellusa.v56i4.14424},
	abstract = {Ensemble Kalman filteringwas developed as away to assimilate observed data to track the current state in a computational model. In this paper we showthat the ensemble approach makes possible an additional benefit: the timing of observations, whether they occur at the assimilation time or at some earlier or later time, can be effectively accounted for at low computational expense. In the case of linear dynamics, the technique is equivalent to instantaneously assimilating data as they are measured. The results of numerical tests of the technique on a simple model problem are shown.},
	number = {4},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Hunt, B.R. and Kalnay, E. and Kostelich, E.J. and Ott, E. and Patil, D.J. and Sauer, T. and Szunyogh, I. and Yorke, J.A. and Zimin, A.V.},
	month = jan,
	year = {2004},
	note = {Publisher: Taylor \& Francis},
	pages = {273--277},
	annote = {doi: 10.3402/tellusa.v56i4.14424}
}

@article{miyoshi_10240-member_2014,
	title = {The 10,240-member ensemble {Kalman} filtering with an intermediate {AGCM}},
	volume = {41},
	issn = {0094-8276},
	url = {https://doi.org/10.1002/2014GL060863},
	doi = {10.1002/2014GL060863},
	abstract = {Abstract The local ensemble transform Kalman filter (LETKF) with an intermediate atmospheric general circulation model (AGCM) is implemented with the Japanese 10 petaflops (floating point operations per second) ?K computer? for large-ensemble simulations of 10,240 members, 2 orders of magnitude greater than the typical ensemble size of about 100. The computational challenge includes the eigenvalue decomposition of 10,240???10,240 dense covariance matrices at each grid point. Using the efficient eigenvalue solver for the K computer, the LETKF computations are accelerated by a factor of 8, allowing a 3?week experiment of 10,240-member LETKF with an intermediate AGCM for the first time. The flow-dependent 10,240-member ensemble revealed meaningful long-range error correlations at continental scales. The surface pressure error correlation shows teleconnection patterns like the Pacific North American pattern. Specific humidity error correlation shows continental scale wave trains. Investigations with different ensemble sizes suggest that at least several hundred members be necessary to capture these continental scale error correlations.},
	number = {14},
	urldate = {2020-07-11},
	journal = {Geophysical Research Letters},
	author = {Miyoshi, Takemasa and Kondo, Keiichi and Imamura, Toshiyuki},
	month = jul,
	year = {2014},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {data assimilation, ensemble Kalman filter, covariance localization, large ensemble},
	pages = {5264--5271},
	annote = {doi: 10.1002/2014GL060863}
}

@article{kondo_impact_2016,
	title = {Impact of {Removing} {Covariance} {Localization} in an {Ensemble} {Kalman} {Filter}: {Experiments} with 10 240 {Members} {Using} an {Intermediate} {AGCM}},
	volume = {144},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/MWR-D-15-0388.1},
	doi = {10.1175/MWR-D-15-0388.1},
	abstract = {The ensemble Kalman filter (EnKF) with high-dimensional geophysical systems usually employs up to 100 ensemble members and requires covariance localization to reduce the sampling error in the forecast error covariance between distant locations. The authors’ previous work pioneered implementation of an EnKF with a large ensemble of up to 10 240 members, but this method required application of a relatively broad covariance localization to avoid memory overflow. This study modified the EnKF code to save memory and enabled for the first time the removal of completely covariance localization with an intermediate AGCM. Using the large sample size, this study aims to investigate the analysis and forecast accuracy, as well as the impact of covariance localization when the sampling error is small. A series of 60-day data assimilation cycle experiments with different localization scales are performed under the perfect model scenario to investigate the pure impact of covariance localization. The results show that the analysis and 7-day forecasts are much improved by removing covariance localization and that the long-range covariance between distant locations plays a key role. The eigenvectors of the background error covariance matrix based on the 10 240 ensemble members are explicitly computed and reveal long-range structures.},
	number = {12},
	urldate = {2020-07-12},
	journal = {Monthly Weather Review},
	author = {Kondo, Keiichi and Miyoshi, Takemasa},
	month = nov,
	year = {2016},
	pages = {4849--4865}
}

@article{derber_reformulation_1999,
	title = {A reformulation of the background error covariance in the {ECMWF} global data assimilation system},
	volume = {51},
	issn = {null},
	url = {https://doi.org/10.3402/tellusa.v51i2.12316},
	doi = {10.3402/tellusa.v51i2.12316},
	abstract = {The background error covariance plays an important role in modern data assimilation andanalysis systems by determining the distribution of the information in the data in space andbetween variables. A new formulation has been developed for use in the ECMWF system. Thenon-separable structure functions depend on the horizontal and vertical scales and a generalizedlinear balance operator to imply multivariate structure functions. The balance operator isincorporated into the definition of the analysis variables to ensure good preconditioning of theproblem. The formulation and structure of the background error covariance are presented, andthe implications for the analysis increments are examined. This reformulation became the operationalECMWF formulation in 3D-Var in May 1997 and in 4D-Var in November 1997.},
	number = {2},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Derber, J. and Bouttier, F.},
	month = jan,
	year = {1999},
	note = {Publisher: Taylor \& Francis},
	pages = {195--221},
	annote = {doi: 10.3402/tellusa.v51i2.12316}
}

@article{lorenc_comparison_2015,
	title = {Comparison of {Hybrid}-{4DEnVar} and {Hybrid}-{4DVar} {Data} {Assimilation} {Methods} for {Global} {NWP}},
	volume = {143},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/MWR-D-14-00195.1},
	doi = {10.1175/MWR-D-14-00195.1},
	abstract = {The Met Office has developed an ensemble-variational data assimilation method (hybrid-4DEnVar) as a potential replacement for the hybrid four-dimensional variational data assimilation (hybrid-4DVar), which is the current operational method for global NWP. Both are four-dimensional variational methods, using a hybrid combination of a fixed climatological model of background error covariances with localized covariances from an ensemble of current forecasts designed to describe the structure of “errors of the day.” The fundamental difference between the methods is their modeling of the time evolution of errors within each data assimilation window: 4DVar uses a linear model and its adjoint and 4DEnVar uses a localized linear combination of nonlinear forecasts. Both hybrid-4DVar and hybrid-4DEnVar beat their three-dimensional versions, which are equivalent, in NWP trials. With settings based on the current operational system, hybrid-4DVar performs better than hybrid-4DEnVar. Idealized experiments designed to compare the time evolution of covariances in the methods are described: the basic 4DEnVar represents the evolution of ensemble errors as well as 4DVar. However, 4DVar also represents the evolution of errors from the climatological covariances, whereas 4DEnVar does not. This difference is the main cause of the superiority of hybrid-4DVar. Another difference is that the authors’ 4DVar explicitly penalizes rapid variations in the analysis increment trajectory, while the authors’ 4DEnVar contains no dynamical constaints on imbalance. The authors describe a four-dimensional incremental analysis update (4DIAU) method that filters out the high-frequency oscillations introduced by the poorly balanced 4DEnVar increments. Possible methods for improving hybrid-4DEnVar are discussed.},
	number = {1},
	urldate = {2020-07-12},
	journal = {Monthly Weather Review},
	author = {Lorenc, Andrew C. and Bowler, Neill E. and Clayton, Adam M. and Pring, Stephen R. and Fairbairn, David},
	month = jan,
	year = {2015},
	pages = {212--229}
}

@article{buehner_implementation_2015,
	title = {Implementation of {Deterministic} {Weather} {Forecasting} {Systems} {Based} on {Ensemble}–{Variational} {Data} {Assimilation} at {Environment} {Canada}. {Part} {I}: {The} {Global} {System}},
	volume = {143},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/MWR-D-14-00354.1},
	doi = {10.1175/MWR-D-14-00354.1},
	abstract = {A major set of changes was made to the Environment Canada global deterministic prediction system during the fall of 2014, including the replacement of four-dimensional variational data assimilation (4DVar) by four-dimensional ensemble–variational data assimilation (4DEnVar). The new system provides improved forecast accuracy relative to the previous system, based on results from two sets of two-month data assimilation and forecast experiments. The improvements are largest at shorter lead times, but significant improvements are maintained in the 120-h forecasts for most regions and vertical levels. The improvements result from the combined impact of numerous changes, in addition to the use of 4DEnVar. These include an improved treatment of radiosonde and aircraft observations, an improved radiance bias correction procedure, the assimilation of ground-based GPS data, a doubling of the number of assimilated channels from hyperspectral infrared sounders, and an improved approach for initializing model forecasts. Because of the replacement of 4DVar with 4DEnVar, the new system is also more computationally efficient and easier to parallelize, facilitating a doubling of the analysis increment horizontal resolution. Replacement of a full-field digital filter with the 4D incremental analysis update approach, and the recycling of several key variables that are not directly analyzed significantly reduced the model spinup during both the data assimilation cycle and in medium-range forecasts.},
	number = {7},
	urldate = {2020-07-12},
	journal = {Monthly Weather Review},
	author = {Buehner, Mark and McTaggart-Cowan, Ron and Beaulne, Alain and Charette, Cécilien and Garand, Louis and Heilliette, Sylvain and Lapalme, Ervig and Laroche, Stéphane and Macpherson, Stephen R. and Morneau, Josée and Zadra, Ayrton},
	month = jul,
	year = {2015},
	pages = {2532--2559}
}

@article{gustafsson_four-dimensional_2014,
	title = {Four-dimensional ensemble variational ({4D}-{En}-{Var}) data assimilation for the {HIgh} {Resolution} {Limited} {Area} {Model} ({HIRLAM})},
	volume = {21},
	url = {https://npg.copernicus.org/articles/21/745/2014/},
	doi = {10.5194/npg-21-745-2014},
	number = {4},
	journal = {Nonlinear Processes in Geophysics},
	author = {Gustafsson, N. and Bojarova, J.},
	year = {2014},
	pages = {745--762}
}

@phdthesis{kleist_evaluation_2012,
	type = {{PhD} {Thesis}},
	title = {An evaluation of hybrid variational-ensemble data assimilation for the {NCEP} {GFS}},
	author = {Kleist, Daryl Timothy},
	year = {2012}
}

@article{de_azevedo_dynamically_2018,
	title = {Dynamically {Weighted} {Hybrid} {Gain} {Data} {Assimilation}: {Perfect} {Model} {Experiments}.},
	volume = {2018},
	journal = {AGUFM},
	author = {de Azevedo, Helena Barbieri and Goncalves, Luis and Kalnay, Eugenia and Wespetal, Matthew},
	year = {2018},
	pages = {IN43C--0913}
}

@article{hamrud_enkf_2014,
	title = {{EnKF} and {Hybrid} {Gain} {Ensemble} {Data} {Assimilation}},
	url = {https://www.ecmwf.int/node/9766},
	abstract = {The wish to do detailed comparisons between variational and more scalable ensemble-based data assimilation systems in a semi-operational environment has led to the development of a state of the art EnKF system at ECMWF. A broad description of the ECMWF EnKF is given in this paper, focusing on highlighting differences compared to standard EnKF practice. In particular, a discussion of the novel algorithm used to control imbalances between the mass and wind fields in the EnKF analysis is given. The scalability and computational properties of the EnKF are reviewed and the implementation choices adopted at ECMWF described. The sensitivity of the ECMWF EnKF to ensemble size, horizontal resolution and representation of model errors is also discussed. The performance of the EnKF system has been compared to a 4DVar of similar resolution. It is found that there is not a major difference between the forecast skill of the two systems. However, like the operational hybrid 4DVar-EDA, a hybrid EnKF-Variational system (which we refer to as Hybrid Gain Ensemble Data Assimilation, HG-EnDA) is capable of significantly out-performing both component systems. The HG-EnDA has been implemented with little effort following Penny (2014). Results of numerical experimentation comparing the HG-EnDA with the hybrid 4DVar-EDA used operationally at ECMWF are presented.},
	journal = {ECMWF Technical Memoranda},
	author = {Hamrud, Mats and Bonavita, Massimo and Isaksen, Lars},
	year = {2014},
	note = {Publisher: ECMWF}
}

@article{lorenc_potential_2003,
	title = {The potential of the ensemble {Kalman} filter for {NWP}—a comparison with {4D}-{Var}},
	volume = {129},
	issn = {0035-9009},
	url = {https://doi.org/10.1256/qj.02.132},
	doi = {10.1256/qj.02.132},
	abstract = {Abstract The ensemble Kalman filter (EnKF) is reviewed for its expected assimilation characteristics and ease of implementation, and compared to the currently more popular four-dimensional variational assimilation (4D-Var). The EnKF is attractive when building a new medium-range ensemble numerical weather prediction (NWP) system. However it is less suitable for NWP systems with uncertainty in a wide range of scales; it may not use high-resolution satellite data as effectively as 4D-Var. For limited-area mesoscale NWP systems a hybrid method is attractive. ? Crown copyright, 2003. Royal Meteorological Society},
	number = {595},
	urldate = {2020-07-11},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Lorenc, Andrew C.},
	month = oct,
	year = {2003},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {Numerical weather prediction, Error covariance modelling},
	pages = {3183--3203},
	annote = {doi: 10.1256/qj.02.132}
}

@article{lorenc_modelling_2003,
	title = {Modelling of error covariances by {4D}-{Var} data assimilation},
	volume = {129},
	issn = {0035-9009},
	url = {https://doi.org/10.1256/qj.02.131},
	doi = {10.1256/qj.02.131},
	abstract = {Abstract The extended Kalman filter is presented as a good approximation to the optimal assimilation of observations into a numerical weather prediction (NWP) model, as long as the evolution of errors stays close to linear. The error probability distributions are approximated by Gaussians, characterized by their mean and covariance. The full nonlinear forecast model is used to propagate the mean, and a linear model (not necessarily tangent to the full model) the covariances. Since it is impossible to determine the covariances in detail, physically based assumptions about their behaviour must be made; for instance, three-dimensional balance relationships are used. The linear model can be thought of as extending the covariance relationships to the time dimension. Incremental four-dimensional variational (4D-Var) is derived as a practical implementation of the extended Kalman filter, optimally using these modelled covariances for a finite time window. It is easy to include a simplified model of forecast errors in the representation. This Kalman filter based paradigm differs from more traditional derivations of 4D-Var in attempting to estimate the mean, rather than the mode, of the posterior probability density function. The latter is difficult for a NWP system representing scales which exhibit chaotic behaviour over the period of interest. The covariance modelling assumptions often result in a null space of error modes with little variance. It is argued that this is as important as the variance and correlation structures usually examined, since the implied constraints allow optimal use of observations giving gradient and tendency information. Difficulties arise in the approach when the NWP system is capable of resolving significant structures (such as convective cells) not always determined by the observations. ? Crown copyright, 2003. Royal Meteorological Society},
	number = {595},
	urldate = {2020-07-11},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Lorenc, Andrew C.},
	month = oct,
	year = {2003},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {Numerical weather prediction, Error covariance modelling, Extended Kalman filter},
	pages = {3167--3182},
	annote = {doi: 10.1256/qj.02.131}
}

@phdthesis{harlim_errors_2006,
	type = {{PhD} {Thesis}},
	title = {Errors in the initial conditions for numerical weather prediction: {A} study of error growth patterns and error reduction with ensemble filtering},
	author = {Harlim, John},
	year = {2006}
}

@article{potthast_localized_2019,
	title = {A {Localized} {Adaptive} {Particle} {Filter} within an {Operational} {NWP} {Framework}},
	volume = {147},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/MWR-D-18-0028.1},
	doi = {10.1175/MWR-D-18-0028.1},
	abstract = {Particle filters are well known in statistics. They have a long tradition in the framework of ensemble data assimilation (EDA) as well as Markov chain Monte Carlo (MCMC) methods. A key challenge today is to employ such methods in a high-dimensional environment, since the naïve application of the classical particle filter usually leads to filter divergence or filter collapse when applied within the very high dimension of many practical assimilation problems (known as the curse of dimensionality). The goal of this work is to develop a localized adaptive particle filter (LAPF), which follows closely the idea of the classical MCMC or bootstrap-type particle filter, but overcomes the problems of collapse and divergence based on localization in the spirit of the local ensemble transform Kalman filter (LETKF) and adaptivity with an adaptive Gaussian resampling or rejuvenation scheme in ensemble space. The particle filter has been implemented in the data assimilation system for the global forecast model ICON at Deutscher Wetterdienst (DWD). We carry out simulations over a period of 1 month with a global horizontal resolution of 52 km and 90 layers. With four variables analyzed per grid point, this leads to 6.6 × 106 degrees of freedom. The LAPF can be run stably and shows a reasonable performance. We compare its scores to the operational setup of the ICON LETKF.},
	number = {1},
	urldate = {2020-07-12},
	journal = {Monthly Weather Review},
	author = {Potthast, Roland and Walter, Anne and Rhodin, Andreas},
	month = jan,
	year = {2019},
	pages = {345--362}
}

@article{yang_weight_2009,
	title = {Weight interpolation for efficient data assimilation with the {Local} {Ensemble} {Transform} {Kalman} {Filter}},
	volume = {135},
	issn = {0035-9009},
	url = {https://doi.org/10.1002/qj.353},
	doi = {10.1002/qj.353},
	abstract = {Abstract We have investigated a method to substantially reduce the analysis computations within the Local Ensemble Transform Kalman Filter (LETKF) framework. Instead of computing the LETKF analysis at every model grid point, we compute the analysis on a coarser grid and interpolate onto a high-resolution grid by interpolating the analysis weights of the ensemble forecast members derived from the LETKF. Because the weights vary on larger scales than the analysis increments, there is little degradation in the quality of the weight-interpolated analyses compared to the analyses derived with the high-resolution grid. The weight-interpolated analyses are more accurate than the ones derived by interpolating the analysis increments. Additional benefit from the weight-interpolation method includes improving the analysis accuracy in the data-void regions, where the standard LEKTF with the high-resolution grid gives no analysis corrections due to a lack of available observations. Copyright ? Royal Meteorological Society and Crown Copyright, 2008},
	number = {638},
	urldate = {2020-07-11},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Yang, Shu-Chih and Kalnay, Eugenia and Hunt, Brian and E. Bowler, Neill},
	month = jan,
	year = {2009},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {LETKF, 3D-, 4D-, Var},
	pages = {251--262},
	annote = {doi: 10.1002/qj.353}
}

@article{vetra-carvalho_state---art_2018,
	title = {State-of-the-art stochastic data assimilation methods for high-dimensional non-{Gaussian} problems},
	volume = {70},
	issn = {null},
	url = {https://doi.org/10.1080/16000870.2018.1445364},
	doi = {10.1080/16000870.2018.1445364},
	abstract = {AbstractThis paper compares several commonly used state-of-the-art ensemble-based data assimilation methods in a coherent mathematical notation. The study encompasses different methods that are applicable to high-dimensional geophysical systems, like ocean and atmosphere and provide an uncertainty estimate. Most variants of Ensemble Kalman Filters, Particle Filters and second-order exact methods are discussed, including Gaussian Mixture Filters, while methods that require an adjoint model or a tangent linear formulation of the model are excluded. The detailed description of all the methods in a mathematically coherent way provides both novices and experienced researchers with a unique overview and new insight in the workings and relative advantages of each method, theoretically and algorithmically, even leading to new filters. Furthermore, the practical implementation details of all ensemble and particle filter methods are discussed to show similarities and differences in the filters aiding the users in what to use when. Finally, pseudo-codes are provided for all of the methods presented in this paper.},
	number = {1},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Vetra-Carvalho, Sanita and van Leeuwen, Peter Jan and Nerger, Lars and Barth, Alexander and Altaf, M. Umer and Brasseur, Pierre and Kirchgessner, Paul and Beckers, Jean-Marie},
	month = jan,
	year = {2018},
	note = {Publisher: Taylor \& Francis},
	pages = {1--43},
	annote = {doi: 10.1080/16000870.2018.1445364}
}

@article{keppenne_initial_2002,
	title = {Initial {Testing} of a {Massively} {Parallel} {Ensemble} {Kalman} {Filter} with the {Poseidon} {Isopycnal} {Ocean} {General} {Circulation} {Model}},
	volume = {130},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/1520-0493(2002)130<2951:ITOAMP>2.0.CO;2},
	doi = {10.1175/1520-0493(2002)130<2951:ITOAMP>2.0.CO;2},
	abstract = {A multivariate ensemble Kalman filter (MvEnKF) implemented on a massively parallel computer architecture has been developed for the Poseidon ocean circulation model and tested with a Pacific basin model configuration. There are about 2 million prognostic state-vector variables. Parallelism for the data assimilation step is achieved by regionalization of the background-error covariances that are calculated from the phase–space distribution of the ensemble. Each processing element (PE) collects elements of a matrix measurement functional from nearby PEs. To avoid the introduction of spurious long-range covariances associated with finite ensemble sizes, the background-error covariances are given compact support by means of a Hadamard (element by element) product with a three-dimensional canonical correlation function.The methodology and the MvEnKF implementation are discussed. To verify the proper functioning of the algorithms, results from an initial experiment with in situ temperature data are presented. Furthermore, it is shown that the regionalization of the background covariances has a negligible impact on the quality of the analyses.Even though the parallel algorithm is very efficient for large numbers of observations, individual PE memory, rather than speed, dictates how large an ensemble can be used in practice on a platform with distributed memory.},
	number = {12},
	urldate = {2020-07-10},
	journal = {Monthly Weather Review},
	author = {Keppenne, Christian L. and Rienecker, Michele M.},
	month = dec,
	year = {2002},
	pages = {2951--2965}
}

@article{kalman_new_1960,
	title = {A new approach to linear filtering and prediction problems},
	author = {Kalman, Rudolph Emil},
	year = {1960}
}

@article{fisher_equivalence_2005,
	title = {On the equivalence between {Kalman} smoothing and weak-constraint four-dimensional variational data assimilation},
	volume = {131},
	issn = {0035-9009},
	url = {https://doi.org/10.1256/qj.04.142},
	doi = {10.1256/qj.04.142},
	abstract = {Abstract The fixed-interval Kalman smoother produces optimal estimates of the state of a system over a time interval, given observations over the interval, together with a prior estimate of the state and its error covariance at the beginning of the interval. At the end of the interval, the Kalman smoother estimate is identical to that produced by a Kalman filter, given the same observations and the same initial state and covariance matrix. For an imperfect model, the model error term in the covariance evolution equation acts to reduce the dependence of the estimate on observations and prior states that are well separated in time. In particular, if the assimilation interval is sufficiently long, the estimate at the end of the interval is effectively independent of the state and covariance matrix specified at the beginning of the interval. In this case, the Kalman smoother provides estimates at the end of the interval that are identical to those of a Kalman filter that has been running indefinitely. For a linear model, weak-constraint four-dimensional variational data assimilation (4D-Var) is equivalent to a fixed-interval Kalman smoother. It follows that, if the assimilation interval is made sufficiently long, the 4D-Var analysis at the end of the assimilation interval will be identical to that produced by a Kalman filter that has been running indefinitely. The equivalence between weak-constraint 4D-Var and a long-running Kalman filter is demonstrated for a simple analogue of the numerical weather-prediction (NWP) problem. For this nonlinear system, 4D-Var analysis with a 10-day assimilation window produces analyses of the same quality as those of an extended Kalman filter. It is demonstrated that the current ECMWF operational 4D-Var system retains a memory of earlier observations and prior states over a period of between four and ten days, suggesting that weak-constraint 4D-Var with an analysis interval in the range of four to ten days may provide a viable algorithm with which to implement an unapproximated Kalman filter. Whereas assimilation intervals of this length are unlikely to be computationally feasible for operational NWP in the near future, the ability to run an unapproximated Kalman filter should prove invaluable for assessing the performance of cheaper, but suboptimal, alternatives. Copyright ? 2005 Royal Meteorological Society},
	number = {613},
	urldate = {2020-07-10},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Fisher, M. and Leutbecher, M. and Kelly, G. A.},
	month = oct,
	year = {2005},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {Numerical weather prediction, Kalman filter, Model error},
	pages = {3235--3246},
	annote = {doi: 10.1256/qj.04.142}
}

@article{evans_rise_2004,
	title = {{RISE} {UNDERGRADUATES} {FIND} {THAT} {REGIME} {CHANGES} {IN} {LORENZ}’{S} {MODEL} {ARE} {PREDICTABLE}},
	volume = {85},
	issn = {00030007, 15200477},
	url = {www.jstor.org/stable/26216961},
	number = {4},
	urldate = {2020-07-10},
	journal = {Bulletin of the American Meteorological Society},
	author = {Evans, Erin and Bhatti, Nadia and Kinney, Jacki and Pann, Lisa and Peña, Malaquias and Yang, Shu-Chih and Kalnay, Eugenia and Hansen, James},
	year = {2004},
	note = {Publisher: American Meteorological Society},
	pages = {520--524}
}

@article{yang_data_2006,
	title = {Data {Assimilation} as {Synchronization} of {Truth} and {Model}: {Experiments} with the {Three}-{Variable} {Lorenz} {System}*},
	volume = {63},
	issn = {0022-4928},
	url = {https://doi.org/10.1175/JAS3739.1},
	doi = {10.1175/JAS3739.1},
	abstract = {The potential use of chaos synchronization techniques in data assimilation for numerical weather prediction models is explored by coupling a Lorenz three-variable system that represents “truth” to another that represents “the model.” By adding realistic “noise” to observations of the master system, an optimal value of the coupling strength was clearly identifiable. Coupling only the y variable yielded the best results for a wide range of higher coupling strengths. Coupling along dynamically chosen directions identified by either singular or bred vectors could improve upon simpler chaos synchronization schemes. Generalized synchronization (with the parameter r of the slave system different from that of the master) could be easily achieved, as indicated by the synchronization of two identical slave systems coupled to the same master, but the slaves only provided partial information about regime changes in the master. A comparison with a standard data assimilation technique, three-dimensional variational analysis (3DVAR), demonstrated that this scheme is slightly more effective in producing an accurate analysis than the simpler synchronization scheme. Higher growth rates of bred vectors from both the master and the slave anticipated the location and size of error spikes in both 3DVAR and synchronization. With less frequent observations, synchronization using time-interpolated observational increments was competitive with 3DVAR. Adaptive synchronization, with a coupling parameter proportional to the bred vector growth rate, was successful in reducing episodes of large error growth. These results suggest that a hybrid chaos synchronization–data assimilation approach may provide an avenue to improve and extend the period for accurate weather prediction.},
	number = {9},
	urldate = {2020-07-10},
	journal = {Journal of the Atmospheric Sciences},
	author = {Yang, Shu-Chih and Baker, Debra and Li, Hong and Cordes, Katy and Huff, Morgan and Nagpal, Geetika and Okereke, Ena and Villafañe, Josue and Kalnay, Eugenia and Duane, Gregory S.},
	month = sep,
	year = {2006},
	pages = {2340--2354}
}

@article{giering_recipes_1998,
	title = {Recipes for {Adjoint} {Code} {Construction}},
	volume = {24},
	issn = {0098-3500},
	url = {https://doi.org/10.1145/293686.293695},
	doi = {10.1145/293686.293695},
	number = {4},
	journal = {ACM Trans. Math. Softw.},
	author = {Giering, Ralf and Kaminski, Thomas},
	month = dec,
	year = {1998},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery},
	keywords = {data assimilation, adjoint model, adjoint operator, automatic differentiation, computational differentiation, differentiation of algorithms, implicit functions, inverse modeling, optimization, reverse mode},
	pages = {437--474}
}

@article{bonavita_use_2012,
	title = {On the use of {EDA} background error variances in the {ECMWF} {4D}-{Var}},
	url = {https://www.ecmwf.int/node/8272},
	abstract = {A hybrid assimilation system which uses sample statistics from an Ensemble of Data Assimilations (EDA) to estimate background error variances has been implemented at ECMWF. We show that the new system is beneficial in terms of deterministic forecast skill provided that random and systematic errors in the estimation of variances are properly accounted for. The mechanisms through which EDA sample variances influence the deterministic analysis are clarified. An interesting aspect is that the use of flow-dependent variances alone is able to introduce a significant degree of flow-dependency in the analysis increments.},
	journal = {ECMWF Technical Memoranda},
	author = {Bonavita, Massimo and Isaksen, Lars and Hólm, Elías},
	year = {2012},
	note = {Publisher: ECMWF}
}

@article{kalnay_response_2007,
	title = {Response to the discussion on “4-{D}-{Var} or {EnKF}?” by {Nils} {Gustafsson}},
	volume = {59},
	issn = {null},
	url = {https://doi.org/10.1111/j.1600-0870.2007.00263.x},
	doi = {10.1111/j.1600-0870.2007.00263.x},
	number = {5},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Kalnay, Eugenia and Li, Hong and Miyoshi, Takemasa and Yang, Shu-Chih and Ballabrera-Poy, Joaquim},
	month = jan,
	year = {2007},
	note = {Publisher: Taylor \& Francis},
	pages = {778--780},
	annote = {doi: 10.1111/j.1600-0870.2007.00263.x}
}

@article{rabier_four-dimensional_1992,
	title = {Four-{Dimensional} {Assimilation} {In} the {Presence} of {Baroclinic} {Instability}},
	volume = {118},
	issn = {0035-9009},
	url = {https://doi.org/10.1002/qj.49711850604},
	doi = {10.1002/qj.49711850604},
	abstract = {Abstract Current operational assimilation methods have revealed deficiencies in cases of strong baroclinic development. Baroclinic conditions are therefore appropriate for evaluating the potential for improvement which could be achieved through the implementation of a fully four-dimensional data assimilation. In this paper the behaviour of a variational scheme is investigated for a typical baroclinic instability problem, where a wave develops and retroacts on to the basic zonal flow. the tangent-linear model is shown to lead to a good approximation of the time evolution of the wave over a range of 48 hours, even at the most intense cyclogenesis period. For the assimilation experiments the twin experiment approach is applied. Only part of the flow evolution is observed, either the zonal component or the eddy component. In either case the method proves successful in reconstructing the unobserved part of the flow, taking advantage of the nonlinear coupling that exists between those components. However, nonlinearities can lead to difficulties when the range of validity of the tangent-linear model is exceeded or when the cost function exhibits multiple minima.},
	number = {506},
	urldate = {2020-07-10},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Rabier, Florence and Courtier, Philippe},
	month = jul,
	year = {1992},
	note = {Publisher: John Wiley \& Sons, Ltd},
	pages = {649--672},
	annote = {doi: 10.1002/qj.49711850604}
}

@article{joiner_efficient_1998,
	title = {Efficient methods to assimilate remotely sensed data based on information content},
	volume = {124},
	issn = {0035-9009},
	url = {https://doi.org/10.1002/qj.49712454915},
	doi = {10.1002/qj.49712454915},
	abstract = {Abstract Two basic approaches have evolved to utilize measurements of radiance (i.e. thermal or scattered solar radiation) by satellite-borne instruments in data assimilation systems: radiances (raw or cloud-corrected) may be assimilated directly, or they may be pre-processed to retrieve geophysical parameters for subsequent assimilation. The retrieval process is often ill-posed, and therefore requires the use of prior information to constrain the solution. For example, temperature and humidity profiles retrieved using radiances from nadir-viewing infrared and microwave sounders often incorporate prior information in the form of climatology or forecasts. The use of prior information presents difficulties when assimilating retrievals. Here we present methods to remove prior information from retrievals in order to achieve a more consistent assimilation of the data. In addition, these methods can be used as a data compression device, which can reduce the amount of computation required by some analysis systems compared with radiance assimilation. The methods are implemented and compared in a one-dimensional assimilation system using simulated data from current and future infrared-temperature profiling instruments.},
	number = {549},
	urldate = {2020-07-10},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Joiner, J. and Da Silva, A. M.},
	month = jul,
	year = {1998},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {Data assimilation, Retrieval techniques, Satellite data},
	pages = {1669--1694},
	annote = {doi: 10.1002/qj.49712454915}
}

@article{el_akkraoui_intercomparison_2008,
	title = {Intercomparison of the primal and dual formulations of variational data assimilation},
	volume = {134},
	issn = {0035-9009},
	url = {https://doi.org/10.1002/qj.257},
	doi = {10.1002/qj.257},
	abstract = {Abstract Two approaches can be used to solve the variational data assimilation problem. The primal form corresponds to the 3D/4D-Var used now in many operational NWP centres. An alternative approach, called dual or 3D/4D-PSAS, consists in solving the problem in the dual of observation space. Both forms use the same basic operators so that once one method is developed, it should be possible to obtain the other easily provided these operators have a modular form. It has been shown that, with proper conditioning of the minimization problem, the two algorithms should have similar convergence rates and computational performances. In the presence of nonlinearities, the incremental form of 3D/4D-Var extends the equivalence to the so-called 3D/4D-PSAS. The first objective of this paper is to present results obtained with the variational data assimilation of the Meteorological Service of Canada to show the equivalence between the 3D-Var and the PSAS systems. This exercise has forced us to have a close look at the modularity of the operational 3D/4D-Var which then makes it possible to obtain the 3D-PSAS scheme. This paper then focuses on these two quadratic problems that show similar convergence rates. However, the minimization of 3D-PSAS is examined more thoroughly as some parameters are shown to be determining elements in the minimization process. Lastly, preconditioning properties are studied and the Hessians of the two problems are shown to be directly related to one another through their singular vectors, which makes it possible to cycle the Hessian of the PSAS form. Copyright ? 2008 Royal Meteorological Society},
	number = {633},
	urldate = {2020-07-10},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {El Akkraoui, Amal and Gauthier, Pierre and Pellerin, Simon and Buis, Samuel},
	month = apr,
	year = {2008},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {3D-Var, 4D-Var, duality, PSAS},
	pages = {1015--1025},
	annote = {doi: 10.1002/qj.257}
}

@article{bergthorsson_numerical_1955,
	title = {Numerical {Weather} {Map} {Analysis1}},
	volume = {7},
	issn = {0040-2826},
	url = {https://doi.org/10.1111/j.2153-3490.1955.tb01170.x},
	doi = {10.1111/j.2153-3490.1955.tb01170.x},
	abstract = {Abstract A method to analyze upper air charts numerically is presented. The analysis is expressed by the height values of the pressure surface in gridpoints. The computed height in a gridpoint is obtained as a weighted mean of height values derived from the surrounding height and wind observations, the forecast height in the point and the corresponding normal height. Nine 500 mb maps are analyzed with the aid of the Swedish computor BESK, six of these consecutive. The size of the grid was 32 ? 41 points. The analyses have been compared with two independent conventional analyses. The mean values of the root mean square of the differences between the numerical and the conventional analyses were 26 m and 24 m respectively and 26 m between the two conventional ones. The root mean square of the differences between the observed and analyzed heights was 22 m in the mean. This is roughly what should be expected judging from the existing knowledge about observation errors. Three barotropic forecasts have been computed from the numerical analyses. They are compared with the corresponding numerical forecasts from conventionally analyzed maps. It was not possible to find any significant difference between the goodness of the forecasts based on the numerical analyses and the conventional analyses.},
	number = {3},
	urldate = {2020-07-10},
	journal = {Tellus},
	author = {Bergthórsson, Páll and Döös, Bo R.},
	month = aug,
	year = {1955},
	note = {Publisher: John Wiley \& Sons, Ltd},
	pages = {329--340},
	annote = {doi: 10.1111/j.2153-3490.1955.tb01170.x}
}

@article{evensen_ensemble_2003,
	title = {The {Ensemble} {Kalman} {Filter}: theoretical formulation and practical implementation},
	volume = {53},
	issn = {1616-7228},
	url = {https://doi.org/10.1007/s10236-003-0036-9},
	doi = {10.1007/s10236-003-0036-9},
	abstract = {The purpose of this paper is to provide a comprehensive presentation and interpretation of the Ensemble Kalman Filter (EnKF) and its numerical implementation. The EnKF has a large user group, and numerous publications have discussed applications and theoretical aspects of it. This paper reviews the important results from these studies and also presents new ideas and alternative interpretations which further explain the success of the EnKF. In addition to providing the theoretical framework needed for using the EnKF, there is also a focus on the algorithmic formulation and optimal numerical implementation. A program listing is given for some of the key subroutines. The paper also touches upon specific issues such as the use of nonlinear measurements, in situ profiles of temperature and salinity, and data which are available with high frequency in time. An ensemble based optimal interpolation (EnOI) scheme is presented as a cost-effective approach which may serve as an alternative to the EnKF in some applications. A fairly extensive discussion is devoted to the use of time correlated model errors and the estimation of model bias.},
	number = {4},
	journal = {Ocean Dynamics},
	author = {Evensen, Geir},
	month = nov,
	year = {2003},
	pages = {343--367}
}

@article{kalnay_4-d-var_2007,
	title = {4-{D}-{Var} or ensemble {Kalman} filter?},
	volume = {59},
	issn = {0280-6495},
	url = {https://doi.org/10.1111/j.1600-0870.2007.00261.x},
	doi = {10.1111/j.1600-0870.2007.00261.x},
	abstract = {ABSTRACT We consider the relative advantages of two advanced data assimilation systems, 4-D-Var and ensemble Kalman filter (EnKF), currently in use or under consideration for operational implementation. With the Lorenz model, we explore the impact of tuning assimilation parameters such as the assimilation window length and background error covariance in 4-D-Var, variance inflation in EnKF, and the effect of model errors and reduced observation coverage. For short assimilation windows EnKF gives more accurate analyses. Both systems reach similar levels of accuracy if long windows are used for 4-D-Var. For infrequent observations, when ensemble perturbations grow non-linearly and become non-Gaussian, 4-D-Var attains lower errors than EnKF. If the model is imperfect, the 4-D-Var with long windows requires weak constraint. Similar results are obtained with a quasi-geostrophic channel model. EnKF experiments made with the primitive equations SPEEDY model provide comparisons with 3-D-Var and guidance on model error and ?observation localization?. Results obtained using operational models and both simulated and real observations indicate that currently EnKF is becoming competitive with 4-D-Var, and that the experience acquired with each of these methods can be used to improve the other. A table summarizes the pros and cons of the two methods.},
	number = {5},
	urldate = {2020-07-09},
	journal = {Tellus A},
	author = {Kalnay, EUGENIA and LI, HONG and MIYOSHI, TAKEMASA and YANG, SHU-CHIH and BALLABRERA-POY, JOAQUIM},
	month = oct,
	year = {2007},
	note = {Publisher: John Wiley \& Sons, Ltd},
	pages = {758--773},
	annote = {doi: 10.1111/j.1600-0870.2007.00261.x}
}

@article{liu_ensemble-based_2008,
	title = {An {Ensemble}-{Based} {Four}-{Dimensional} {Variational} {Data} {Assimilation} {Scheme}. {Part} {I}: {Technical} {Formulation} and {Preliminary} {Test}},
	volume = {136},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/2008MWR2312.1},
	doi = {10.1175/2008MWR2312.1},
	abstract = {Applying a flow-dependent background error covariance (𝗕 matrix) in variational data assimilation has been a topic of interest among researchers in recent years. In this paper, an ensemble-based four-dimensional variational (En4DVAR) algorithm, designed by the authors, is presented that uses a flow-dependent background error covariance matrix constructed by ensemble forecasts and performs 4DVAR optimization to produce a balanced analysis. A great advantage of this En4DVAR design over standard 4DVAR methods is that the tangent linear and adjoint models can be avoided in its formulation and implementation. In addition, it can be easily incorporated into variational data assimilation systems that are already in use at operational centers and among the research community.A one-dimensional shallow water model was used for preliminary tests of the En4DVAR scheme. Compared with standard 4DVAR, the En4DVAR converges well and can produce results that are as good as those with 4DVAR but with far less computation cost in its minimization. In addition, a comparison of the results from En4DVAR with those from other data assimilation schemes [e.g., 3DVAR and ensemble Kalman filter (EnKF)] is made. The results show that the En4DVAR yields an analysis that is comparable to the widely used variational or ensemble data assimilation schemes and can be a promising approach for real-time applications.In addition, experiments were carried out to test the sensitivities of EnKF and En4DVAR, whose background error covariance is estimated from the same ensemble forecasts. The experiments indicated that En4DVAR obtained reasonably sound analysis even with larger observation error, higher observation frequency, and more unbalanced background field.},
	number = {9},
	urldate = {2020-07-10},
	journal = {Monthly Weather Review},
	author = {Liu, Chengsi and Xiao, Qingnong and Wang, Bin},
	month = sep,
	year = {2008},
	pages = {3363--3373}
}

@article{liu_ensemble-based_2009,
	title = {An {Ensemble}-{Based} {Four}-{Dimensional} {Variational} {Data} {Assimilation} {Scheme}. {Part} {II}: {Observing} {System} {Simulation} {Experiments} with {Advanced} {Research} {WRF} ({ARW})},
	volume = {137},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/2008MWR2699.1},
	doi = {10.1175/2008MWR2699.1},
	abstract = {An ensemble-based four-dimensional variational data assimilation (En4DVAR) algorithm and its performance in a low-dimension space with a one-dimensional shallow-water model have been presented in Part I. This algorithm adopts the standard incremental approach and preconditioning in the variational algorithm but avoids the need for a tangent linear model and its adjoint so that it can be easily incorporated into variational assimilation systems. The current study explores techniques for En4DVAR application in real-dimension data assimilation. The EOF decomposed correlation function operator and analysis time tuning are formulated to reduce the impact of sampling errors in En4DVAR upon its analysis. With the Advanced Research Weather Research and Forecasting (ARW-WRF) model, Observing System Simulation Experiments (OSSEs) are designed and their performance in real-dimension data assimilation is examined. It is found that the designed En4DVAR localization techniques can effectively alleviate the impacts of sampling errors upon analysis. Most forecast errors and biases in ARW are reduced by En4DVAR compared to those in a control experiment. En3DVAR cycling experiments are used to compare the ensemble-based sequential algorithm with the ensemble-based retrospective algorithm. These experiments indicate that the ensemble-based retrospective assimilation, En4DVAR, produces an overall better analysis than the ensemble-based sequential algorithm, En3DVAR, cycling approach.},
	number = {5},
	urldate = {2020-07-10},
	journal = {Monthly Weather Review},
	author = {Liu, Chengsi and Xiao, Qingnong and Wang, Bin},
	month = may,
	year = {2009},
	pages = {1687--1704}
}

@article{liu_ensemble-based_2013,
	title = {An {Ensemble}-{Based} {Four}-{Dimensional} {Variational} {Data} {Assimilation} {Scheme}. {Part} {III}: {Antarctic} {Applications} with {Advanced} {Research} {WRF} {Using} {Real} {Data}},
	volume = {141},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/MWR-D-12-00130.1},
	doi = {10.1175/MWR-D-12-00130.1},
	abstract = {A four-dimensional ensemble-based variational data assimilation (4DEnVar) algorithm proposed in Part I of the 4DEnVar series (denoted En4DVar in Part I, but here we refer to it as 4DEnVar according to WMO conference recommendation to differentiate it from En4DVar algorithm using adjoint model) uses a flow-dependent background error covariance calculated from ensemble forecasts and performs 4DVar optimization based on an incremental approach and a preconditioning algorithm. In Part II, the authors evaluated 4DEnVar with observing system simulation experiments (OSSEs) using the Advanced Research Weather Research and Forecasting Model (ARW-WRF, hereafter WRF). The current study extends the 4DEnVar to assimilate real observations for a cyclone in the Antarctic and the Southern Ocean in October 2007. The authors performed an intercomparison of four different WRF variational approaches for the case, including three-dimensional variational data assimilation (3DVar), first guess at the appropriate time (FGAT), and ensemble-based three-dimensional (En3DVar) and four-dimensional (4DEnVar) variational data assimilations. It is found that all data assimilation approaches produce positive impacts in this case. Applying the flow-dependent background error covariance in En3DVar and 4DEnVar yields forecast skills superior to those with the homogeneous and isotropic background error covariance in 3DVar and FGAT. In addition, the authors carried out FGAT and 4DEnVar 3-day cycling and 72-h forecasts. The results show that 4DEnVar produces a better performance in the cyclone prediction. The inflation factor on 4DEnVar can effectively improve the 4DEnVar analysis. The authors also conducted a short period (10-day lifetime of the cyclone in the domain) of analysis/forecast intercomparison experiments using 4DEnVar, FGAT, and 3DVar. The 4DEnVar scheme demonstrates overall superior and robust performance.},
	number = {8},
	urldate = {2020-07-10},
	journal = {Monthly Weather Review},
	author = {Liu, Chengsi and Xiao, Qingnong},
	month = jul,
	year = {2013},
	pages = {2721--2739}
}

@article{zupanski_maximum_2005,
	title = {Maximum {Likelihood} {Ensemble} {Filter}: {Theoretical} {Aspects}},
	volume = {133},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/MWR2946.1},
	doi = {10.1175/MWR2946.1},
	abstract = {A new ensemble-based data assimilation method, named the maximum likelihood ensemble filter (MLEF), is presented. The analysis solution maximizes the likelihood of the posterior probability distribution, obtained by minimization of a cost function that depends on a general nonlinear observation operator. The MLEF belongs to the class of deterministic ensemble filters, since no perturbed observations are employed. As in variational and ensemble data assimilation methods, the cost function is derived using a Gaussian probability density function framework. Like other ensemble data assimilation algorithms, the MLEF produces an estimate of the analysis uncertainty (e.g., analysis error covariance). In addition to the common use of ensembles in calculation of the forecast error covariance, the ensembles in MLEF are exploited to efficiently calculate the Hessian preconditioning and the gradient of the cost function. A sufficient number of iterative minimization steps is 2–3, because of superior Hessian preconditioning. The MLEF method is well suited for use with highly nonlinear observation operators, for a small additional computational cost of minimization. The consistent treatment of nonlinear observation operators through optimization is an advantage of the MLEF over other ensemble data assimilation algorithms. The cost of MLEF is comparable to the cost of existing ensemble Kalman filter algorithms. The method is directly applicable to most complex forecast models and observation operators. In this paper, the MLEF method is applied to data assimilation with the one-dimensional Korteweg–de Vries–Burgers equation. The tested observation operator is quadratic, in order to make the assimilation problem more challenging. The results illustrate the stability of the MLEF performance, as well as the benefit of the cost function minimization. The improvement is noted in terms of the rms error, as well as the analysis error covariance. The statistics of innovation vectors (observation minus forecast) also indicate a stable performance of the MLEF algorithm. Additional experiments suggest the amplified benefit of targeted observations in ensemble data assimilation.},
	number = {6},
	urldate = {2020-07-10},
	journal = {Monthly Weather Review},
	author = {Zupanski, Milija},
	month = jun,
	year = {2005},
	pages = {1710--1726}
}

@article{whitaker_reanalysis_2004,
	title = {Reanalysis without {Radiosondes} {Using} {Ensemble} {Data} {Assimilation}},
	volume = {132},
	issn = {0027-0644},
	url = {https://doi.org/10.1175/1520-0493(2004)132<1190:RWRUED>2.0.CO;2},
	doi = {10.1175/1520-0493(2004)132<1190:RWRUED>2.0.CO;2},
	abstract = {Studies using idealized ensemble data assimilation systems have shown that flow-dependent background-error covariances are most beneficial when the observing network is sparse. The computational cost of recently proposed ensemble data assimilation algorithms is directly proportional to the number of observations being assimilated. Therefore, ensemble-based data assimilation should both be more computationally feasible and provide the greatest benefit over current operational schemes in situations when observations are sparse. Reanalysis before the radiosonde era (pre-1931) is just such a situation.The feasibility of reanalysis before radiosondes using an ensemble square root filter (EnSRF) is examined. Real surface pressure observations for 2001 are used, subsampled to resemble the density of observations we estimate to be available for 1915. Analysis errors are defined relative to a three-dimensional variational data assimilation (3DVAR) analysis using several orders of magnitude more observations, both at the surface and aloft. We find that the EnSRF is computationally tractable and considerably more accurate than other candidate analysis schemes that use static background-error covariance estimates. We conclude that a Northern Hemisphere reanalysis of the middle and lower troposphere during the first half of the twentieth century is feasible using only surface pressure observations. Expected Northern Hemisphere analysis errors at 500 hPa for the 1915 observation network are similar to current 2.5-day forecast errors.},
	number = {5},
	urldate = {2020-07-10},
	journal = {Monthly Weather Review},
	author = {Whitaker, Jeffrey S. and Compo, Gilbert P. and Wei, Xue and Hamill, Thomas M.},
	month = may,
	year = {2004},
	pages = {1190--1200}
}

@article{xue_arps_1995,
	title = {{ARPS} 4.0 user’s guide},
	volume = {380},
	journal = {Center for Advanced Prediction Systems, The University of Oklahoma},
	author = {Xue, M and Droegemeier, KK and Wong, V and Shapiro, A and Brewster, K},
	year = {1995}
}

@article{smolarkiewicz_simple_1983,
	title = {A {Simple} {Positive} {Definite} {Advection} {Scheme} with {Small} {Implicit} {Diffusion}},
	volume = {111},
	url = {https://journals.ametsoc.org/view/journals/mwre/111/3/1520-0493_1983_111_0479_aspdas_2_0_co_2.xml},
	doi = {10.1175/1520-0493(1983)111<0479:ASPDAS>2.0.CO;2},
	language = {English},
	number = {3},
	journal = {Monthly Weather Review},
	author = {Smolarkiewicz, Piotr K.},
	month = mar,
	year = {1983},
	note = {Place: Boston MA, USA
Publisher: American Meteorological Society},
	pages = {479--486}
}

@article{zalesak_fully_1979,
	title = {Fully multidimensional flux-corrected transport algorithms for fluids},
	volume = {31},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/0021999179900512},
	doi = {10.1016/0021-9991(79)90051-2},
	abstract = {The theory of flux-corrected transport (FCT) developed by Boris and Book [J. Comput. Phys. 11 (1973) 38; 18 (1975) 248; 20 (1976) 397] is placed in a simple, generalized format, and a new algorithm for implementing the critical flux limiting stage' in multidimensions without resort to time splitting is presented. The new flux limiting algorithm allows the use of FCT techniques in multidimensional fluid problems for which time splitting would produce unacceptable numerical results, such as those involving incompressible or nearly incompressible flow fields. The “clipping” problem associated with the original one dimensional flux limiter is also eliminated or alleviated. Test results and applications to a two dimensional fluid plasma problem are presented.},
	number = {3},
	journal = {Journal of Computational Physics},
	author = {Zalesak, Steven T},
	month = jun,
	year = {1979},
	pages = {335--362}
}

@article{boris_flux-corrected_1973,
	title = {Flux-corrected transport. {I}. {SHASTA}, a fluid transport algorithm that works},
	volume = {11},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/0021999173901472},
	doi = {10.1016/0021-9991(73)90147-2},
	abstract = {This paper describes a class of explicit, Eulerian finite-difference algorithms for solving the continuity equation which are built around a technique called “flux correction.” These flux-corrected transport algorithms are of indeterminate order but yield realistic, accurate results. In addition to the mass-conserving property of most conventional algorithms, the FCT algorithms strictly maintain the positivity of actual mass densities so steep gradients and inviscid shocks are handled particularly well. This first paper concentrates on a simple one-dimensional version of FCT utilizing SHASTA, a new transport algorithm for the continuity equation, which is described in detail.},
	number = {1},
	journal = {Journal of Computational Physics},
	author = {Boris, Jay P and Book, David L},
	month = jan,
	year = {1973},
	pages = {38--69}
}

@book{saito_documentation_2001,
	title = {Documentation of the meteorological research institute/numerical prediction division unified nonhydrostatic model},
	volume = {42},
	publisher = {Tech. Rep. MRI,},
	author = {Saito, Kazuo and Kato, Teruyuki and Eito, Hisaki and Muroi, Chiashi},
	year = {2001}
}

@article{davies_new_2005,
	title = {A new dynamical core for the {Met} {Office}'s global and regional modelling of the atmosphere},
	volume = {131},
	issn = {0035-9009},
	url = {https://doi.org/10.1256/qj.04.101},
	doi = {10.1256/qj.04.101},
	abstract = {Abstract A computational scheme suitable for numerical weather prediction and climate modelling over a wide range of length scales is described. Its formulation is non-hydrostatic and fully compressible, and shallow atmosphere approximations are not made. Semi-implicit, semi-Lagrangian time-integration methods are used. The scheme forms the dynamical core of the unified model used at the Met Office for all its operational numerical weather prediction and in its climate studies. ? Crown copyright, 2005. Royal Meteorological Society},
	number = {608},
	urldate = {2021-01-26},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Davies, T. and Cullen, M. J. P. and Malcolm, A. J. and Mawson, M. H. and Staniforth, A. and White, A. A. and Wood, N.},
	month = apr,
	year = {2005},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {Climate modelling, Deep atmosphere, Fully compressible, Non-hydrostatic, NWP Predictor–corrector, Semi-implicit, Semi-Lagrangian},
	pages = {1759--1782},
	annote = {https://doi.org/10.1256/qj.04.101}
}

@book{staniforth_unified_2002,
	title = {Unified {Model} {Documentation} {Paper}, 15, {Joy} of {UM} 5.3—{Model} formulation},
	publisher = {UKMO},
	author = {Staniforth, A. and White, A. and Wood, N. and Thuburn, J. and Zerroukat, M. and Cordero, E. and et al.},
	year = {2002}
}

@article{cullen_unified_1993,
	title = {The unified forecast/climate model},
	volume = {122},
	number = {1449},
	journal = {Meteorological Magazine},
	author = {Cullen, MJP},
	year = {1993},
	note = {Publisher: HMSO},
	pages = {81--94}
}

@article{saito_operational_2006,
	title = {The {Operational} {JMA} {Nonhydrostatic} {Mesoscale} {Model}},
	volume = {134},
	url = {https://journals.ametsoc.org/view/journals/mwre/134/4/mwr3120.1.xml},
	doi = {10.1175/MWR3120.1},
	language = {English},
	number = {4},
	journal = {Monthly Weather Review},
	author = {Saito, Kazuo and Fujita, Tsukasa and Yamada, Yoshinori and Ishida, Jun-ichi and Kumagai, Yukihiro and Aranami, Kohei and Ohmori, Shiro and Nagasawa, Ryoji and Kumagai, Saori and Muroi, Chiashi and Kato, Teruyuki and Eito, Hisaki and Yamazaki, Yosuke},
	month = apr,
	year = {2006},
	note = {Place: Boston MA, USA
Publisher: American Meteorological Society},
	pages = {1266--1298}
}

@book{phillips_nested_1979,
	title = {The nested grid model},
	url = {https://www.weather.gov/media/owp/oh/hdsc/docs/TR22.pdf},
	publisher = {NOAA. Tech. Report NWS 22},
	author = {Phillips, Norman A},
	year = {1979}
}

@book{mannik_nonhydrostatic_2001,
	title = {Nonhydrostatic adiabatic kernel for {HIRLAM}: part {II}: anelastic, hybrid-coordinate, explicit-{Eulerian} model},
	volume = {49},
	publisher = {HIRLAM Technical Reports},
	author = {Männik, Aarne and Room, Rein},
	year = {2001}
}

@book{room_nonhydrostatic_2006,
	title = {Nonhydrostatic adiabatic kernel for {HIRLAM} {Part} {IV} {Semi}-implicit semi-{Lagrangian} scheme},
	volume = {65},
	publisher = {HIRLAM Technical Reports},
	author = {Room, R and Mannik, A and Luhamaa, A},
	year = {2006}
}

@book{ikawa_description_1991,
	title = {Description of a nonhydrostatic model developed at the {Forecast} {Research} {Department} of the {MRI}.},
	volume = {28},
	publisher = {Technical Reports of the MRI},
	author = {Ikawa, Motohki},
	year = {1991}
}

@article{skamarock_time-split_2008,
	title = {A time-split nonhydrostatic atmospheric model for weather research and forecasting applications},
	volume = {227},
	issn = {0021-9991},
	url = {http://www.sciencedirect.com/science/article/pii/S0021999107000459},
	doi = {10.1016/j.jcp.2007.01.037},
	abstract = {The sub-grid-scale parameterization of clouds is one of the weakest aspects of weather and climate modeling today, and the explicit simulation of clouds will be one of the next major achievements in numerical weather prediction. Research cloud models have been in development over the last 45 years and they continue to be an important tool for investigating clouds, cloud-systems, and other small-scale atmospheric dynamics. The latest generation are now being used for weather prediction. The Advanced Research WRF (ARW) model, representative of this generation and of a class of models using explicit time-splitting integration techniques to efficiently integrate the Euler equations, is described in this paper. It is the first fully compressible conservative-form nonhydrostatic atmospheric model suitable for both research and weather prediction applications. Results are presented demonstrating its ability to resolve strongly nonlinear small-scale phenomena, clouds, and cloud systems. Kinetic energy spectra and other statistics show that the model is simulating small scales in numerical weather prediction applications, while necessarily removing energy at the gridscale but minimizing artificial dissipation at the resolved scales. Filtering requirements for atmospheric models and filters used in the ARW model are discussed.},
	number = {7},
	journal = {Predicting weather, climate and extreme events},
	author = {Skamarock, William C. and Klemp, Joseph B.},
	month = mar,
	year = {2008},
	keywords = {Numerical weather prediction, Numerical methods, 65M06, 65M12, 76E06, 76R10, 76U05, 86A10, Compressible flow, Time splitting},
	pages = {3465--3485}
}

@article{klemp_conservative_2007,
	title = {Conservative {Split}-{Explicit} {Time} {Integration} {Methods} for the {Compressible} {Nonhydrostatic} {Equations}},
	volume = {135},
	url = {https://journals.ametsoc.org/view/journals/mwre/135/8/mwr3440.1.xml},
	doi = {10.1175/MWR3440.1},
	language = {English},
	number = {8},
	journal = {Monthly Weather Review},
	author = {Klemp, J. B. and Skamarock, W. C. and Dudhia, J.},
	month = aug,
	year = {2007},
	note = {Place: Boston MA, USA
Publisher: American Meteorological Society},
	pages = {2897--2913}
}

@book{skamarock_description_2005,
	series = {{NCAR} {Tech}. {Note}},
	title = {A description of the advanced research {WRF} version 2},
	volume = {468},
	publisher = {National Center For Atmospheric Research Boulder Co Mesoscale and Microscale …},
	author = {Skamarock, William C and Klemp, Joseph B and Dudhia, Jimy and Gill, David O and Barker, Dale M and Wang, Wei and Powers, Jordan G},
	year = {2005}
}

@article{juang_ncep_2000,
	title = {The {NCEP} {Mesoscale} {Spectral} {Model}: {A} {Revised} {Version} of the {Nonhydrostatic} {Regional} {Spectral} {Model}},
	volume = {128},
	url = {https://journals.ametsoc.org/view/journals/mwre/128/7/1520-0493_2000_128_2329_tnmsma_2.0.co_2.xml},
	doi = {10.1175/1520-0493(2000)128<2329:TNMSMA>2.0.CO;2},
	language = {English},
	number = {7},
	journal = {Monthly Weather Review},
	author = {Juang, Hann-Ming Henry},
	month = jul,
	year = {2000},
	note = {Place: Boston MA, USA
Publisher: American Meteorological Society},
	pages = {2329--2362}
}

@article{yeh_cmcmrb_2002,
	title = {The {CMC}–{MRB} {Global} {Environmental} {Multiscale} ({GEM}) {Model}. {Part} {III}: {Nonhydrostatic} {Formulation}},
	volume = {130},
	url = {https://journals.ametsoc.org/view/journals/mwre/130/2/1520-0493_2002_130_0339_tcmgem_2.0.co_2.xml},
	doi = {10.1175/1520-0493(2002)130<0339:TCMGEM>2.0.CO;2},
	language = {English},
	number = {2},
	journal = {Monthly Weather Review},
	author = {Yeh, Kao-San and Côté, Jean and Gravel, Sylvie and Méthot, André and Patoine, Alaine and Roch, Michel and Staniforth, Andrew},
	month = feb,
	year = {2002},
	note = {Place: Boston MA, USA
Publisher: American Meteorological Society},
	pages = {339--356}
}

@article{cote_operational_1998,
	title = {The {Operational} {CMC}–{MRB} {Global} {Environmental} {Multiscale} ({GEM}) {Model}. {Part} {II}: {Results}},
	volume = {126},
	url = {https://journals.ametsoc.org/view/journals/mwre/126/6/1520-0493_1998_126_1397_tocmge_2.0.co_2.xml},
	doi = {10.1175/1520-0493(1998)126<1397:TOCMGE>2.0.CO;2},
	language = {English},
	number = {6},
	journal = {Monthly Weather Review},
	author = {Côté, Jean and Desmarais, Jean-Guy and Gravel, Sylvie and Méthot, André and Patoine, Alain and Roch, Michel and Staniforth, Andrew},
	month = jun,
	year = {1998},
	note = {Place: Boston MA, USA
Publisher: American Meteorological Society},
	pages = {1397--1418}
}

@article{cote_operational_1998-1,
	title = {The {Operational} {CMC}–{MRB} {Global} {Environmental} {Multiscale} ({GEM}) {Model}. {Part} {I}: {Design} {Considerations} and {Formulation}},
	volume = {126},
	url = {https://journals.ametsoc.org/view/journals/mwre/126/6/1520-0493_1998_126_1373_tocmge_2.0.co_2.xml},
	doi = {10.1175/1520-0493(1998)126<1373:TOCMGE>2.0.CO;2},
	language = {English},
	number = {6},
	journal = {Monthly Weather Review},
	author = {Côté, Jean and Gravel, Sylvie and Méthot, André and Patoine, Alain and Roch, Michel and Staniforth, Andrew},
	month = jun,
	year = {1998},
	note = {Place: Boston MA, USA
Publisher: American Meteorological Society},
	pages = {1373--1395}
}

@article{benard_stability_2005,
	title = {Stability of {Leapfrog} {Constant}-{Coefficients} {Semi}-{Implicit} {Schemes} for the {Fully} {Elastic} {System} of {Euler} {Equations}: {Case} with {Orography}},
	volume = {133},
	url = {https://journals.ametsoc.org/view/journals/mwre/133/5/mwr2907.1.xml},
	doi = {10.1175/MWR2907.1},
	language = {English},
	number = {5},
	journal = {Monthly Weather Review},
	author = {Bénard, P. and Mašek, J. and Smolíková, P.},
	month = may,
	year = {2005},
	note = {Place: Boston MA, USA
Publisher: American Meteorological Society},
	pages = {1065--1075}
}

@article{bouttier_arome_2003,
	title = {Arome: a new operational mesoscale {NWP} system for {Meteo}-{France}},
	volume = {33},
	journal = {CAS/JSC WGNE Res. Act. Atmos. Ocea. Modelling},
	author = {Bouttier, F},
	year = {2003},
	pages = {0503--0504}
}

@article{tapp_non-hydrostatic_1976,
	title = {A non-hydrostatic mesoscale model},
	volume = {102},
	issn = {0035-9009},
	url = {https://doi.org/10.1002/qj.49710243202},
	doi = {10.1002/qj.49710243202},
	abstract = {Abstract A 3-dimensional non-hydrostatic compressible model designed for mesoscale studies is discussed. A semi-implicit scheme for integrating the equations has been developed where the terms which involve the horizontal and vertical propagation of sound waves are treated implicitly and all other terms are represented explicitly. In an atmosphere with a neutrally stable lapse rate the sound waves are then unconditionally stable while the stability of advection is governed by a criterion similar to the usual Courant-Freidrichs-Lewy condition. When the atmosphere is stratified the stability criterion for sound waves, which depends on the Brunt-Väisalä frequency but is independent of the grid length, is also sufficient for the stability of gravity waves. Tests conducted to simulate a sea-breeze in Florida agree qualitatively with published results for a hydrostatic model.},
	number = {432},
	urldate = {2021-01-26},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Tapp, M. C. and White, P. W.},
	month = apr,
	year = {1976},
	note = {Publisher: John Wiley \& Sons, Ltd},
	pages = {277--296},
	annote = {https://doi.org/10.1002/qj.49710243202}
}

@article{xue_advanced_2003,
	title = {The {Advanced} {Regional} {Prediction} {System} ({ARPS}), storm-scale numerical weather prediction and data assimilation.},
	volume = {82},
	journal = {Meteorology \& Atmospheric Physics},
	author = {Xue, Ming and Wang, Donghai and Gao, Jidong and Brewster, Keith and Droegemeier, Kelvin K},
	year = {2003}
}

@article{soong_response_1980,
	title = {Response of {Tradewind} {Cumuli} to {Large}-{Scale} {Processes}},
	volume = {37},
	url = {https://journals.ametsoc.org/view/journals/atsc/37/9/1520-0469_1980_037_2035_rotctl_2_0_co_2.xml},
	doi = {10.1175/1520-0469(1980)037<2035:ROTCTL>2.0.CO;2},
	language = {English},
	number = {9},
	journal = {Journal of Atmospheric Sciences},
	author = {Soong, S-T. and Ogura, Y.},
	month = sep,
	year = {1980},
	note = {Place: Boston MA, USA
Publisher: American Meteorological Society},
	pages = {2035--2050}
}

@article{zhang_two-way_1986,
	title = {A {Two}-{Way} {Interactive} {Nesting} {Procedure} with {Variable} {Terrain} {Resolution}},
	volume = {114},
	url = {https://journals.ametsoc.org/view/journals/mwre/114/7/1520-0493_1986_114_1330_atwinp_2_0_co_2.xml},
	doi = {10.1175/1520-0493(1986)114<1330:ATWINP>2.0.CO;2},
	language = {English},
	number = {7},
	journal = {Monthly Weather Review},
	author = {Zhang, Da-Lin and Chang, Hai-Ru and Seaman, Nelson L. and Warner, Thomas T. and Fritsch, J. Michael},
	month = jul,
	year = {1986},
	note = {Place: Boston MA, USA
Publisher: American Meteorological Society},
	pages = {1330--1339}
}

@article{williamson_integration_1968,
	title = {Integration of the barotropic vorticity equation on a spherical geodesic grid},
	volume = {20},
	issn = {0040-2826},
	url = {https://doi.org/10.1111/j.2153-3490.1968.tb00406.x},
	doi = {10.1111/j.2153-3490.1968.tb00406.x},
	abstract = {ABSTRACT A quasi-homogeneous net of points over a sphere for numerical integration is defined. The grid consists of almost equal-area, equilateral spherical triangles covering the sphere. Finite difference approximations for a nondivergent, barotropic model expressed in terms of a streamfunction are proposed for an arbitrary triangular grid. These differences are applied to the spherical geodesic grid. The model is integrated for 12-day periods using analytic initial conditions of wave number six and four. The numerical solution with these special initial conditions follows the analytic solution quite closely, the only difference being a small phase error. Small truncation errors are noticeable in the square of the streamfunction averaged over latitude bands.},
	number = {4},
	urldate = {2021-01-26},
	journal = {Tellus},
	author = {Williamson, David L.},
	month = nov,
	year = {1968},
	note = {Publisher: John Wiley \& Sons, Ltd},
	pages = {642--653},
	annote = {https://doi.org/10.1111/j.2153-3490.1968.tb00406.x}
}

@article{klemp_numerical_1978,
	title = {Numerical {Simulation} of {Hydrostatic} {Mountain} {Waves}},
	volume = {35},
	url = {https://journals.ametsoc.org/view/journals/atsc/35/1/1520-0469_1978_035_0078_nsohmw_2_0_co_2.xml},
	doi = {10.1175/1520-0469(1978)035<0078:NSOHMW>2.0.CO;2},
	language = {English},
	number = {1},
	journal = {Journal of Atmospheric Sciences},
	author = {Klemp, J. B. and Lilly, D. K.},
	month = jan,
	year = {1978},
	note = {Place: Boston MA, USA
Publisher: American Meteorological Society},
	pages = {78--107}
}

@book{briggs_multigrid_1987,
	address = {Philadelphia, PA},
	title = {A multigrid tutorial},
	publisher = {SIAM},
	author = {Briggs, William L},
	year = {1987}
}

@article{buckeridge_robust_2011,
	title = {A robust numerical method for the potential vorticity based control variable transform in variational data assimilation},
	volume = {137},
	issn = {0035-9009},
	url = {https://doi.org/10.1002/qj.826},
	doi = {10.1002/qj.826},
	abstract = {Abstract The potential vorticity based control variable transformation for variational data assimilation, proposed in Cullen (2003), is a promising alternative to the currently more common vorticity based transformation. It leads to a better decorrelation of the control variables, but it involves solving a highly ill-conditioned elliptic partial differential equation (PDE), with a constraint. This PDE has so far been impossible to solve to any reasonable accuracy for realistic grid resolutions in finite difference formulations. Following on from the work in Buckeridge and Scheichl (2010) we propose a numerical method for it based on a Krylov subspace method with a multigrid preconditioner. The problem of interest includes a constraint in the form of two-dimensional elliptic solves embedded within the main three-dimensional problem. Thus the discretised problem cannot be formulated as a simple linear equation system with a sparse system matrix (as usual in elliptic PDEs). Therefore, in order to precondition the system we apply the multigrid method in Buckeridge and Scheichl (2010) to a simplified form of the three-dimensional operator (without the embedded two-dimensional problems) leading to an asymptotically optimal convergence of the preconditioned Krylov subspace method. The solvers used at the Met Office typically take over 100 iterations to converge to a residual tolerance of 0.1 and fail to converge to a tolerance of 10?2. The method proposed in this paper, in contrast, can converge to a tolerance of 10?2 within 15 iterations on all typical grid resolutions used at the Met Office, and is convergent to a tolerance of 10?6. In addition, the method demonstrates almost optimal parallel scalability. Copyright ? 2011 Royal Meteorological Society and British Crown Copyright, the Met Office},
	number = {657},
	urldate = {2021-01-26},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Buckeridge, S. and Cullen, M.J.P. and Scheichl, R. and Wlasak, M.},
	month = apr,
	year = {2011},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {finite volume, multigrid, parallelisation, potential vorticity, preconditioner, solver},
	pages = {1083--1094},
	annote = {https://doi.org/10.1002/qj.826}
}

@book{meurant_computer_1999,
	title = {Computer solution of large linear systems},
	publisher = {Elsevier},
	author = {Meurant, Gerard},
	year = {1999}
}

@book{barrett_templates_1994,
	series = {Other {Titles} in {Applied} {Mathematics}},
	title = {Templates for the {Solution} of {Linear} {Systems}: {Building} {Blocks} for {Iterative} {Methods}},
	isbn = {978-0-89871-328-2},
	url = {https://doi.org/10.1137/1.9781611971538},
	urldate = {2021-01-26},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Barrett, Richard and Berry, Michael and Chan, Tony F. and Demmel, James and Donato, June and Dongarra, Jack and Eijkhout, Victor and Pozo, Roldan and Romine, Charles and van der Vorst, Henk},
	month = jan,
	year = {1994},
	doi = {10.1137/1.9781611971538},
	annote = {doi:10.1137/1.9781611971538}
}

@book{ferziger_computational_2002,
	title = {Computational {Methods} for {Fluid} {Dynamics}},
	volume = {3},
	publisher = {Springer},
	author = {Ferziger, Joel H and Perić, Milovan},
	year = {2002}
}

@book{gustafsson_time_1995,
	title = {Time dependent problems and difference methods},
	volume = {24},
	isbn = {0-471-50734-2},
	publisher = {John Wiley \& Sons},
	author = {Gustafsson, Bertil and Kreiss, Heinz-Otto and Oliger, Joseph},
	year = {1995}
}

@article{lin_explicit_1997,
	title = {An explicit flux-form semi-lagrangian shallow-water model on the sphere},
	volume = {123},
	issn = {0035-9009},
	url = {https://doi.org/10.1002/qj.49712354416},
	doi = {10.1002/qj.49712354416},
	abstract = {Abstract A global shallow-water model based on the flux-form semi-lagrangian scheme is described. the mass-conserving flux-form semi-Lagrangian scheme is a multidimensional semi-Lagrangian extension of the higher order Godunov-type finite-volume schemes (e.g., the piece-wise parabolic method). Unlike the piece-wise parabolic methodology, neither directional splitting nor a Riemann solver is involved. A reverse engineering procedure is introduced to achieve the goal of consistent transport of the absolute vorticity and the mass, and hence, the potential vorticity. Gravity waves are treated explicitly, in a manner that is consistent with the forward-in-time flux-form semi-Lagrangian transport scheme. Due to the finite-volume nature of the flux-form semi-lagrangian scheme and the application of the monotonicity constraint, which can be regarded as a subgrid-scale flux parametrization, essentially noise-free solutions are obtained without additional diffusion. Two selected shallow-water test cases proposed by Williamson et al. (1992) and a stratospheric vortex erosion simulation are presented. Discussions on the accuracy and computational efficiency are given based on the comparisons with a Eulerian spectral model and two advective-form semi-implicit semi-Lagrangian models.},
	number = {544},
	urldate = {2021-01-25},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Lin, Shian-Jiann and Rood, Richard B.},
	month = oct,
	year = {1997},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {Numerical techniques, Computational test cases, Conservative advection},
	pages = {2477--2498},
	annote = {https://doi.org/10.1002/qj.49712354416}
}

@article{williamson_numerical_2000,
	title = {Numerical approximations for global atmospheric general circulation models},
	volume = {127},
	journal = {Numerical Modeling of Global Atmosphere in the Climate System},
	author = {Williamson, David L and Laprise, Rene},
	year = {2000},
	note = {Publisher: Kluwer Academic Publishers},
	pages = {219}
}

@article{kucharski_decadal_2006,
	title = {Decadal interactions between the western tropical {Pacific} and the {North} {Atlantic} {Oscillation}},
	volume = {26},
	issn = {1432-0894},
	url = {https://doi.org/10.1007/s00382-005-0085-5},
	doi = {10.1007/s00382-005-0085-5},
	abstract = {The relationship between interdecadal variations of tropical sea surface temperature (SST) in the last 120 years and circulation anomalies related to the North Atlantic Oscillation (NAO) is investigated in this study. Using an atmospheric general circulation model (AGCM), we confirm observational evidence that variations in the SST gradient in the western tropical Pacific are related to the NAO anomalies on decadal timescale, and may be contributing to the shift towards the positive NAO phase observed in the late 20th century. The role played by the Indian Ocean-NAO teleconnection, advocated in recent studies focused on the last 50 years, is also assessed in the context of the 120-year long record. It is suggested that a positive feedback between the Pacific SST and the hemispheric circulation pattern embedding the decadal NAO signal may act to enhance the internal variability of the coupled ocean–atmosphere system, and justify the stronger teleconnection found in observational data than in SST-forced AGCM experiments.},
	number = {1},
	journal = {Climate Dynamics},
	author = {Kucharski, Fred and Molteni, Franco and Bracco, Annalisa},
	month = jan,
	year = {2006},
	pages = {79--91}
}

@article{tolman_user_2009,
	title = {User manual and system documentation of {WAVEWATCH} {III} {TM} version 3.14},
	volume = {276},
	journal = {Technical note, MMAB Contribution},
	author = {Tolman, Hendrik L},
	year = {2009},
	pages = {220}
}

@article{corazza_implementation_2007,
	title = {An implementation of the {Local} {Ensemble} {Kalman} {Filter} in a quasi geostrophic model and comparison with {3D}-{Var}},
	volume = {14},
	url = {https://npg.copernicus.org/articles/14/89/2007/},
	doi = {10.5194/npg-14-89-2007},
	number = {1},
	journal = {Nonlinear Processes in Geophysics},
	author = {Corazza, M. and Kalnay, E. and Yang, S. C.},
	year = {2007},
	pages = {89--101}
}

@article{dee_data_1998,
	title = {Data assimilation in the presence of forecast bias},
	volume = {124},
	issn = {0035-9009},
	url = {https://doi.org/10.1002/qj.49712454512},
	doi = {10.1002/qj.49712454512},
	abstract = {Abstract Statistical-analysis methods are generally derived under the assumption that forecast errors are strictly random and zero in the mean. If the short-term forecast, used as the background field in the statistical-analysis equation, is in fact biased, so will the resulting analysis be biased. The only way to account properly for bias in a statistical analysis is to do so explicitly, by estimating the forecast bias and then correcting the forecast prior to analysis. We present a rigorous method for estimating forecast bias by means of data assimilation, based on an unbiased subset of the observing system. The result is a sequential bias estimation and correction algorithm, whose implementation involves existing components of operational statistical-analysis systems. The algorithm is designed to perform on-line, in the context of suboptimal data-assimilation methods which are based on approximate information about forecast- and observation-error covariances. The added computational cost of incorporating online bias estimation and correction into an operational system roughly amounts to one additional solution of the statistical-analysis equation, for a limited number of observations. Off-line forecast-bias estimates based on previously produced assimilated-data sets can be produced as well, using an existing analysis system. We show that our sequential bias estimation algorithm fits into a broader theoretical framework provided by the separate-bias estimation approach of estimation theory. In this framework the bias parameters are defined rather generally and can be used to describe systematic model errors and observational bias as well. We illustrate the performance of the algorithm in a simulated data-assimilation experiment with a one-dimensional forced dissipative shallow-water model. A climate error is introduced into the forecast model via topographic forcing. while random errors are generated by stochastic forcing. In this simple setting our algorithm is well able to estimate and correct the forecast bias caused by this systematic error, and the climate error in the assimilated-data set is virtually eliminated as a result.},
	number = {545},
	urldate = {2021-02-26},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Dee, Dick P. and Da Silva, Arlindo M.},
	month = jan,
	year = {1998},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {Bias estimation, Statistical analysis, Systematic errors},
	pages = {269--295},
	annote = {https://doi.org/10.1002/qj.49712454512}
}

@article{hascoet_tapenade_2013,
	title = {The {Tapenade} {Automatic} {Differentiation} tool: {Principles}, {Model}, and {Specification}},
	volume = {39},
	url = {http://dx.doi.org/10.1145/2450153.2450158},
	number = {3},
	journal = {ACM Transactions On Mathematical Software},
	author = {Hascoët, L. and Pascual, V.},
	year = {2013}
}

@article{anderson_local_2003,
	title = {A {Local} {Least} {Squares} {Framework} for {Ensemble} {Filtering}},
	volume = {131},
	url = {https://journals.ametsoc.org/view/journals/mwre/131/4/1520-0493_2003_131_0634_allsff_2.0.co_2.xml},
	doi = {10.1175/1520-0493(2003)131<0634:ALLSFF>2.0.CO;2},
	language = {English},
	number = {4},
	journal = {Monthly Weather Review},
	author = {Anderson, Jeffrey L.},
	month = apr,
	year = {2003},
	note = {Place: Boston MA, USA
Publisher: American Meteorological Society},
	pages = {634--642}
}

@article{zhang_tests_2006,
	title = {Tests of an {Ensemble} {Kalman} {Filter} for {Mesoscale} and {Regional}-{Scale} {Data} {Assimilation}. {Part} {I}: {Perfect} {Model} {Experiments}},
	volume = {134},
	url = {https://journals.ametsoc.org/view/journals/mwre/134/2/mwr3101.1.xml},
	doi = {10.1175/MWR3101.1},
	language = {English},
	number = {2},
	journal = {Monthly Weather Review},
	author = {Zhang, Fuqing and Meng, Zhiyong and Aksoy, Altug},
	month = feb,
	year = {2006},
	note = {Place: Boston MA, USA
Publisher: American Meteorological Society},
	pages = {722--736}
}

@article{torn_boundary_2006,
	title = {Boundary {Conditions} for {Limited}-{Area} {Ensemble} {Kalman} {Filters}},
	volume = {134},
	url = {https://journals.ametsoc.org/view/journals/mwre/134/9/mwr3187.1.xml},
	doi = {10.1175/MWR3187.1},
	language = {English},
	number = {9},
	journal = {Monthly Weather Review},
	author = {Torn, Ryan D. and Hakim, Gregory J. and Snyder, Chris},
	month = sep,
	year = {2006},
	note = {Place: Boston MA, USA
Publisher: American Meteorological Society},
	pages = {2490--2502}
}

@article{hunt_efficient_2005,
	title = {Efficient {Data} {Assimilation} for {Spatiotemporal} {Chaos}: a {Local} {Ensemble} {Transform} {Kalman} {Filter}},
	journal = {https://arxiv.org/abs/physics/0511236v1},
	author = {Hunt, Brian R.},
	year = {2005}
}

@article{ott_exploiting_2002,
	title = {Exploiting {Local} {Low} {Dimensionality} of the {Atmospheric} {Dynamics} for {Efficient} {Ensemble} {Kalman} {Filtering}},
	journal = {https://arxiv.org/abs/physics/0203058v1},
	author = {Ott, Edward and Hunt, Brian R. and Szunyogh, Istvan and Corazza, Matteo and Kalnay, Eugenia and Patil, D. J. and Yorke, James A.},
	year = {2002}
}

@article{chen_proactive_2019,
	title = {Proactive {Quality} {Control}: {Observing} {System} {Simulation} {Experiments} with the {Lorenz} ’96 {Model}},
	volume = {147},
	url = {https://journals.ametsoc.org/view/journals/mwre/147/1/mwr-d-18-0138.1.xml},
	doi = {10.1175/MWR-D-18-0138.1},
	language = {English},
	number = {1},
	journal = {Monthly Weather Review},
	author = {Chen, Tse-Chun and Kalnay, Eugenia},
	month = jan,
	year = {2019},
	note = {Place: Boston MA, USA
Publisher: American Meteorological Society},
	pages = {53--67}
}

@article{gelaro_examination_2009,
	title = {Examination of observation impacts derived from observing system experiments ({OSEs}) and adjoint models},
	volume = {61},
	issn = {0280-6495},
	url = {https://doi.org/10.1111/j.1600-0870.2008.00388.x},
	doi = {10.1111/j.1600-0870.2008.00388.x},
	abstract = {ABSTRACT With the adjoint of a data assimilation system, the impact of any or all assimilated observations on measures of forecast skill can be estimated accurately and efficiently. The approach allows aggregation of results in terms of individual data types, channels or locations, all computed simultaneously. In this study, adjoint-based estimates of observation impact are compared with results from standard observing system experiments (OSEs) using forward and adjoint versions of the NASA GEOS-5 atmospheric data assimilation system. Despite important underlying differences in the way observation impacts are measured in the two approaches, the results show that they provide consistent estimates of the overall impact of most of the major observing systems in reducing a dry total-energy metric of 24-h forecast error over the globe and extratropics and, to a lesser extent, over the tropics. Just as importantly, however, it is argued that the two approaches provide unique, but complementary, information about the impact of observations on numerical weather forecasts. Moreover, when used together, they reveal both redundancies and dependencies between observing system impacts as observations are added or removed from the data assimilation system. Understanding these dependencies appears to pose an important challenge in making optimal use of the global observing system for numerical weather prediction.},
	number = {2},
	urldate = {2021-02-27},
	journal = {Tellus A},
	author = {Gelaro, Ronald and Zhu, Yanqiu},
	month = mar,
	year = {2009},
	note = {Publisher: John Wiley \& Sons, Ltd},
	pages = {179--193},
	annote = {https://doi.org/10.1111/j.1600-0870.2008.00388.x}
}

@article{farchi_review_2018,
	title = {Review article: {Comparison} of local particle filters and new implementations},
	volume = {25},
	url = {https://npg.copernicus.org/articles/25/765/2018/},
	doi = {10.5194/npg-25-765-2018},
	number = {4},
	journal = {Nonlinear Processes in Geophysics},
	author = {Farchi, A. and Bocquet, M.},
	year = {2018},
	pages = {765--807}
}

@article{metropolis_monte_1949,
	title = {The {Monte} {Carlo} {Method}},
	volume = {44},
	issn = {0162-1459},
	url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1949.10483310},
	doi = {10.1080/01621459.1949.10483310},
	number = {247},
	journal = {Journal of the American Statistical Association},
	author = {Metropolis, Nicholas and Ulam, S.},
	month = sep,
	year = {1949},
	note = {Publisher: Taylor \& Francis},
	pages = {335--341},
	annote = {doi: 10.1080/01621459.1949.10483310}
}

@incollection{phillips_example_1959,
	address = {New York},
	title = {An example of non-linear computational instability},
	booktitle = {The {Atmosphere} and the {Sea} in {Motion}},
	publisher = {The Rockefeller Institute Press},
	author = {Phillips, Norman A},
	year = {1959},
	pages = {516}
}

@article{stackpole_nmc_1978,
	series = {Office note ({National} {Meteorological} {Center} ({U}.{S}.)) ; 178},
	title = {The {NMC} 9-{Layer} {Global} {Primitive} {Equation} {Model} on a latitude-longitude grid},
	url = {https://repository.library.noaa.gov/view/noaa/12745},
	abstract = {"In November 1972, the National Meteorological Center (NMC) put into operation a fully global analysis-forecast system employing a Hough function spectral analysis and an 8-layer primitive equation forecast model on a 5° latitude-longitude grid. The analysis forecast set was run twice per day with the 12-hour forecast serving as the first guess for the analysis at the next observation time. The forecast model was described in GARP Publications Series No. 14. Since that time a number of evolutionary changes have taken place in both the analysis system and the forecast model"--Introduction.},
	author = {Stackpole, John D.},
	editor = {{National Meteorological Center (U.S.)}},
	year = {1978},
	keywords = {Long-range weather forecasting, Mathematical models, Numerical weather forecasting}
}

@article{magnusson_factors_2013,
	title = {Factors {Influencing} {Skill} {Improvements} in the {ECMWF} {Forecasting} {System}},
	volume = {141},
	url = {https://journals.ametsoc.org/view/journals/mwre/141/9/mwr-d-12-00318.1.xml},
	doi = {10.1175/MWR-D-12-00318.1},
	language = {English},
	number = {9},
	journal = {Monthly Weather Review},
	author = {Magnusson, Linus and Källén, Erland},
	month = sep,
	year = {2013},
	note = {Place: Boston MA, USA
Publisher: American Meteorological Society},
	pages = {3142--3153}
}

@inproceedings{palmer_ensemble_1993,
	title = {Ensemble prediction},
	volume = {1},
	booktitle = {Proceedings of the {ECMWF} {Seminar} on {Validation} of models over {Europe}},
	author = {Palmer, TN and Molteni, F and Mureau, R and Buizza, R and Chapelet, P and Tribbia, J},
	year = {1993},
	pages = {21--66}
}

@article{zhou_comparison_2016,
	title = {A {Comparison} of {Perturbations} from an {Ensemble} {Transform} and an {Ensemble} {Kalman} {Filter} for the {NCEP} {Global} {Ensemble} {Forecast} {System}},
	volume = {31},
	url = {https://journals.ametsoc.org/view/journals/wefo/31/6/waf-d-16-0109_1.xml},
	doi = {10.1175/WAF-D-16-0109.1},
	language = {English},
	number = {6},
	journal = {Weather and Forecasting},
	author = {Zhou, Xiaqiong and Zhu, Yuejian and Hou, Dingchen and Kleist, Daryl},
	month = dec,
	year = {2016},
	note = {Place: Boston MA, USA
Publisher: American Meteorological Society},
	pages = {2057--2074}
}

@article{hughes_skill_1987,
	series = {Office note ({National} {Centers} for {Environmental} {Prediction} ({U}.{S}.)) ; 326},
	title = {Skill of the medium range forecast group},
	url = {https://repository.library.noaa.gov/view/noaa/11485},
	abstract = {"This paper depicts in a graphical manner the skill of the Medium Range (3-10 day) Forecast Group (MRFG) man and machine (numerical model guidance) forecasts. It will be updated each February in order to present the latest scores for each of the several forecast categories in the MRFG. Only scores with at least a 5-year period of record are presented. This paper contains the standardized and unstandardized mean sea-level pressure and 500 mb correlation; the Gilman, Hughes and experimental precipitation skill; the minimum/maximum absolute temperature error; and the 5-day mean normalized 500 mb correlation, temperature, and precipitation skill scores"--Purpose"},
	author = {Hughes, Francis D.},
	editor = {{National Meteorological Center (U.S.)}},
	year = {1987},
	keywords = {Weather forecasting, Numerical analysis, Long-range weather forecasting, Mathematical models, Numerical weather forecasting}
}

@article{gerrity_efficient_1972,
	title = {On the {Efficient} {Reduction}, of {Truncation} {Error} in {Numerical} {Weather} {Prediction} {Models}},
	volume = {100},
	url = {https://journals.ametsoc.org/view/journals/mwre/100/8/1520-0493_1972_100_0637_oterot_2_3_co_2.xml},
	doi = {10.1175/1520-0493(1972)100<0637:OTEROT>2.3.CO;2},
	language = {English},
	number = {8},
	journal = {Monthly Weather Review},
	author = {Gerrity, Joseph P. and McPherson, Ronald D. and Polger, Paul D.},
	month = aug,
	year = {1972},
	note = {Place: Boston MA, USA
Publisher: American Meteorological Society},
	pages = {637--643}
}

@article{pan_implementing_1995,
	series = {Office note ({National} {Centers} for {Environmental} {Prediction} ({U}.{S}.)) ; 409},
	title = {Implementing a mass flux convection parameterization package for the {NMC} medium-range forecast model},
	url = {https://repository.library.noaa.gov/view/noaa/11429},
	abstract = {On 11 August, 1993, a new convection parameterization package has become operational for the National Meteorological Center (NMC) Medium-Range Forecast (MRF) model replacing a Kuo (1965, 1974) scheme that has been in operation for over ten years. The new scheme is a version of a simplified Arakawa-Schubert (1974) scheme that uses the mass flux concept to adjust the atmospheric temperature and moisture field. The new scheme uses quasi-equilibrium assumption as a closure and includes a downdraft scheme that is analogous to the updraft scheme. Testing of the new scheme in parallel during Northern Hemisphere Spring shows a consistent improvement in the precipitation forecast verified against the observations taken by the high density North America rain gauge network maintained by the National Weather Service. Improvement in the tropical climatology and the tropical cyclone prediction have also been noted.},
	author = {Pan, Hua-Lu and Wu, Wan-Shu},
	editor = {{National Centers for Environmental Prediction (U.S.)}},
	year = {1995},
	keywords = {Weather forecasting, Numerical analysis, Long-range weather forecasting, Mathematical models, Numerical weather forecasting}
}

@article{boyer_noaa_2018,
	title = {{NOAA} {Atlas} {NESDIS} 87, {WORLD} {OCEAN} {DATABASE} 2018 ({Pre}-release)},
	url = {https://www.ncei.noaa.gov/sites/default/files/2020-04/wod_intro.pdf},
	journal = {World Ocean Database},
	author = {Boyer, Tim P and Baranova, Olga K and Coleman, Carla and Garcia, Hernan E and Grodsky, Alexandra and Locarnini, Ricardo A and Mishonov, Alexey V and Paver, Christopher R and Reagan, James R and Seidov, Dan and Smolyar, Igor V. and Weathers, Katharine W. and Zweng, Melissa M.},
	editor = {Mishonov, Alexey V.},
	year = {2018}
}

@article{daley_navdas_2001,
	title = {{NAVDAS}: {Formulation} and {Diagnostics}},
	volume = {129},
	url = {https://journals.ametsoc.org/view/journals/mwre/129/4/1520-0493_2001_129_0869_nfad_2.0.co_2.xml},
	doi = {10.1175/1520-0493(2001)129<0869:NFAD>2.0.CO;2},
	language = {English},
	number = {4},
	journal = {Monthly Weather Review},
	author = {Daley, Roger and Barker, Edward},
	month = apr,
	year = {2001},
	note = {Place: Boston MA, USA
Publisher: American Meteorological Society},
	pages = {869--883}
}

@inproceedings{miyoshi_local_2019,
	address = {San Franciso, CA},
	title = {Local {Particle} {Filter} {Implemented} with {Minor} {Modifications} to the {LETKF} {Code}},
	abstract = {Penny and Miyoshi (2015) developed a Local Particle Filter (LPF) in a form as the ensemble transform matrix of the Local Ensemble Transform Kalman Filter (LETKF). The LETKF has been widely used for various geophysical systems including global and regional numerical weather prediction (NWP) models and Martian atmospheric models. Therefore, implementing consistently with an existing LETKF code is useful. The particle weights of LPF, or equivalently the ensemble transform matrix of LPF, consist of 0 and 1 entries, and the smooth spatial transition of local weights is essential. German Weather Service (DWD) implemented the LETKF for their operational global model ICON based on an icosahedral grid system, where the LETKF weights are computed at a coarser analysis grid and interpolated into a higher-resolution icosahedral model grid. The interpolation brings spatial smoothing similarly to weight interpolation (Yang et al. 2008). The spatial smoothing is beneficial for smooth spatial transition of local weights, particularly for LPF. Potthast et al. (2018) applied the LPF weights in the German LETKF system and reported a stable performance in the operational setup. They called their LPF system LAPF (Local Adaptive Particle Filter). Further, Walter and Potthast (2019) improved their LAPF as a Gaussian mixture filter, what they call the LMCPF (Local Mixture Coefficients Particle Filter). This study aims to sort out the various implementations of LPF consistently with an existing LETKF code. Here we use the LETKF code first developed by Miyoshi (2005) based on an intermediate AGCM known as the SPEEDY model. In this presentation, we would like to focus on the theory and code designs of the LPF and its Gaussian mixture extension, with only minor modifications to the existing LETKF code.},
	booktitle = {{NG13A} - {Advances} in {Data} {Assimilation}, {Predictability}, and {Uncertainty} {Quantification} {I}},
	author = {Miyoshi, Takemasa and Kotsuki, Shunji and Kondo, Keiichi and Potthast, Roland},
	year = {2019}
}

@article{fletcher_mixed_2010,
	title = {Mixed {Gaussian}-lognormal four-dimensional data assimilation},
	volume = {62},
	issn = {null},
	url = {https://www.tandfonline.com/doi/abs/10.1111/j.1600-0870.2009.00439.x},
	doi = {10.1111/j.1600-0870.2009.00439.x},
	number = {3},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Fletcher, S.J.},
	month = jan,
	year = {2010},
	note = {Publisher: Taylor \& Francis},
	pages = {266--287},
	annote = {doi: 10.1111/j.1600-0870.2009.00439.x}
}

@article{ruiz-barradas_finding_2017-1,
	title = {Finding the driver of local ocean–atmosphere coupling in reanalyses and {CMIP5} climate models},
	volume = {48},
	issn = {1432-0894},
	url = {https://doi.org/10.1007/s00382-016-3197-1},
	doi = {10.1007/s00382-016-3197-1},
	abstract = {Identification of the driver of coupled anomalies in the climate system is of great importance for a better understanding of the system and for its use in predictive efforts with climate models. The present analysis examines the robustness of a physical method proposed three decades ago to identify coupled anomalies as of atmospheric or oceanic origin by analyzing 850 mb vorticity and sea surface temperature anomalies. The method is then used as a metric to assess the coupling in climate simulations and a 30-year hindcast from models of the CMIP5 project. Analysis of the frequency of coupled anomalies exceeding one standard deviation from uncoupled NCEP/NCAR and ERA-Interim and partially coupled CFSR reanalyses shows robustness in the main results: anomalies of oceanic origin arise inside the deep tropics and those of atmospheric origin outside of the tropics. Coupled anomalies occupy similar regions in the global oceans independently of the spatiotemporal resolution. Exclusion of phenomena like ENSO, NAO, or AMO has regional effects on the distribution and origin of coupled anomalies; the absence of ENSO decreases anomalies of oceanic origin and favors those of atmospheric origin. Coupled model simulations in general agree with the distribution of anomalies of atmospheric and oceanic origin from reanalyses. However, the lack of the feedback from the atmosphere to the ocean in the AMIP simulations reduces substantially the number of coupled anomalies of atmospheric origin and artificially increases it in the tropics while the number of those of oceanic origin outside the tropics is also augmented. Analysis of a single available 30-year hindcast surprisingly indicates that coupled anomalies are more similar to AMIP than to coupled simulations. Differences in the frequency of coupled anomalies between the AMIP simulations and the uncoupled reanalyses, and similarities between the uncoupled and partially coupled reanalyses, support the notion that the nature of the coupling between the ocean and the atmosphere is transmitted into the reanalyses via the assimilation of observations.},
	number = {7},
	journal = {Climate Dynamics},
	author = {Ruiz-Barradas, Alfredo and Kalnay, Eugenia and Peña, Malaquías and BozorgMagham, Amir E. and Motesharrei, Safa},
	month = apr,
	year = {2017},
	pages = {2153--2172}
}

@article{bach_local_2019,
	title = {Local {Atmosphere}–{Ocean} {Predictability}: {Dynamical} {Origins}, {Lead} {Times}, and {Seasonality}},
	volume = {32},
	url = {https://journals.ametsoc.org/view/journals/clim/32/21/jcli-d-18-0817.1.xml},
	doi = {10.1175/JCLI-D-18-0817.1},
	language = {English},
	number = {21},
	journal = {Journal of Climate},
	author = {Bach, Eviatar and Motesharrei, Safa and Kalnay, Eugenia and Ruiz-Barradas, Alfredo},
	month = nov,
	year = {2019},
	note = {Place: Boston MA, USA
Publisher: American Meteorological Society},
	pages = {7507--7519}
}

@article{persson_early_2005-3,
	title = {Early operational {Numerical} {Weather} {Prediction} outside the {USA}: an historical introduction {Part} {III}: {Endurance} and mathematics – {British} {NWP}, 1948–1965},
	volume = {12},
	issn = {1350-4827},
	url = {https://www.cambridge.org/core/article/early-operational-numerical-weather-prediction-outside-the-usa-an-historical-introduction-part-iii-endurance-and-mathematics-british-nwp-19481965/E47615FC785AFB4A79CF731A17CC103B},
	doi = {10.1017/S1350482705001933},
	abstract = {The Meteorological Office of the United Kingdom (UKMO) began its operational NWP in November 1965. This marked the start of very successful activity that would gradually bring it to the forefront of NWP development, where it stands today.},
	number = {4},
	journal = {Meteorological Applications},
	author = {Persson, Anders},
	year = {2005},
	note = {Edition: 2005/12/16
Publisher: Cambridge University Press},
	pages = {381--413}
}

@article{persson_early_2005-4,
	title = {Early operational {Numerical} {Weather} {Prediction} outside the {USA}: an historical {Introduction}. {Part} 1: {Internationalism} and engineering {NWP} in {Sweden}, 1952–69},
	volume = {12},
	issn = {1350-4827},
	url = {https://www.cambridge.org/core/article/early-operational-numerical-weather-prediction-outside-the-usa-an-historical-introduction-part-1-internationalism-and-engineering-nwp-in-sweden-195269/62B132A2DB529EA0C02AD169EB678938},
	doi = {10.1017/S1350482705001593},
	abstract = {The story of numerical weather prediction (NWP) is a great story. It deals with the first successful attempts to see into the chaotic future, to predict non-period events. It is to a large extent a story of computers, mathematics and numerical schemes. But the development cannot be fully understood unless non-mathematical and non-technological facts are also included. Meteorological understanding, political considerations and human emotions are difficult to quantify, but they make the picture complete and the narrative more interesting for readers outside the ‘NWP community’.},
	number = {2},
	journal = {Meteorological Applications},
	author = {Persson, Anders},
	year = {2005},
	note = {Edition: 2005/07/01
Publisher: Cambridge University Press},
	pages = {135--159}
}

@article{persson_early_2005-5,
	title = {Early operational {Numerical} {Weather} {Prediction} outside the {USA}: an historical introduction: {Part} {II}: {Twenty} countries around the world},
	volume = {12},
	issn = {1350-4827},
	url = {https://www.cambridge.org/core/article/early-operational-numerical-weather-prediction-outside-the-usa-an-historical-introduction-part-ii-twenty-countries-around-the-world/C8DECEBD1420DFEBA63208B1C946FEA1},
	doi = {10.1017/S1350482705001751},
	abstract = {When computers became available in the 1950s meteorologists were among the first to display a keen interest in their use. They also placed the highest demands on their capacity. The earliest NWP initiatives came both from the universities and from the meteorological institutes, especially when the development of computers allowed operational runs.},
	number = {3},
	journal = {Meteorological Applications},
	author = {Persson, Anders},
	year = {2005},
	note = {Edition: 2005/10/07
Publisher: Cambridge University Press},
	pages = {269--289}
}

@article{kalnay_impact_2003,
	title = {Impact of urbanization and land-use change on climate},
	volume = {423},
	issn = {1476-4687},
	url = {https://doi.org/10.1038/nature01675},
	doi = {10.1038/nature01675},
	abstract = {The most important anthropogenic influences on climate are the emission of greenhouse gases1 and changes in land use, such as urbanization and agriculture2. But it has been difficult to separate these two influences because both tend to increase the daily mean surface temperature3,4. The impact of urbanization has been estimated by comparing observations in cities with those in surrounding rural areas, but the results differ significantly depending on whether population data5 or satellite measurements of night light6,7,8 are used to classify urban and rural areas7,8. Here we use the difference between trends in observed surface temperatures in the continental United States and the corresponding trends in a reconstruction of surface temperatures determined from a reanalysis of global weather over the past 50 years, which is insensitive to surface observations, to estimate the impact of land-use changes on surface warming. Our results suggest that half of the observed decrease in diurnal temperature range is due to urban and other land-use changes. Moreover, our estimate of 0.27â€‰Â°C mean surface warming per century due to land-use changes is at least twice as high as previous estimates based on urbanization alone7,8.},
	number = {6939},
	journal = {Nature},
	author = {Kalnay, Eugenia and Cai, Ming},
	month = may,
	year = {2003},
	pages = {528--531}
}

@book{rodgers_inverse_2000,
	series = {Series on {Atmospheric}, {Oceanic} and {Planetary} {Physics}},
	title = {Inverse {Methods} for {Atmospheric} {Sounding}},
	volume = {Volume 2},
	isbn = {978-981-02-2740-1},
	url = {https://doi.org/10.1142/3171},
	number = {Volume 2},
	urldate = {2021-05-06},
	publisher = {WORLD SCIENTIFIC},
	author = {Rodgers, Clive D},
	month = jul,
	year = {2000},
	doi = {10.1142/3171},
	annote = {doi:10.1142/3171}
}

@article{van_leeuwen_consistent_2020,
	title = {A consistent interpretation of the stochastic version of the {Ensemble} {Kalman} {Filter}},
	volume = {146},
	issn = {0035-9009},
	url = {https://doi.org/10.1002/qj.3819},
	doi = {10.1002/qj.3819},
	abstract = {Abstract Ensemble Kalman Filters are used extensively in all geoscience areas. Often a stochastic variant is used, in which each ensemble member is updated via the Kalman Filter equation with an extra perturbation in the innovation. These perturbations are essential for the correct ensemble spread in a stochastic Ensemble Kalman Filter, and are applied either to the observations or to the modelled observations. This paper investigates if there is a preference for either of these two perturbation methods. Both versions lead to the same posterior mean and covariance when the prior and the likelihood are Gaussian in the state. However, ensemble verification methods, Bayes' Theorem and the Best Linear Unbiased Estimate (BLUE) suggest that one should perturb the modelled observations. Furthermore, it is known that in non-Gaussian settings the perturbed modelled observation scheme is preferred, illustrated here for a skewed likelihood. Existing reasons for the perturbed observation scheme are shown to be incorrect, and no new arguments in favour of that scheme have been found. Finally, a new and consistent derivation and interpretation of the stochastic version of the EnKF equations is derived based on perturbing modelled observations. It is argued that these results have direct consequences for (iterative) Ensemble Kalman Filters and Smoothers, including ?perturbed observation? 3D- and 4D-Vars, both in terms of internal consistency and implementation.},
	number = {731},
	urldate = {2021-05-06},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {van Leeuwen, Peter Jan},
	month = jul,
	year = {2020},
	note = {Publisher: John Wiley \& Sons, Ltd},
	keywords = {data assimilation, ensemble, nonlinear, particle filter, synchronisation},
	pages = {2815--2825},
	annote = {https://doi.org/10.1002/qj.3819}
}

@article{lorenc_atmospheric_2003,
	title = {Atmospheric modelling, data assimilation and predictability. {By} {Eugenia} {Kalnay}. {Cambridge} {University} {Press}. 2003. pp. xxii + 341. {ISBNs} 0 521 79179 0, 0 521 79629 6.},
	volume = {129},
	issn = {0035-9009},
	url = {https://doi.org/10.1256/00359000360683511},
	doi = {10.1256/00359000360683511},
	number = {592},
	urldate = {2021-05-06},
	journal = {Quarterly Journal of the Royal Meteorological Society},
	author = {Lorenc, Andrews},
	month = jul,
	year = {2003},
	note = {Publisher: John Wiley \& Sons, Ltd},
	pages = {2442--2442},
	annote = {https://doi.org/10.1256/00359000360683511}
}

@article{wikle_atmospheric_2005,
	title = {Atmospheric {Modeling}, {Data} {Assimilation}, and {Predictability}},
	volume = {47},
	issn = {0040-1706},
	url = {https://doi.org/10.1198/tech.2005.s326},
	doi = {10.1198/tech.2005.s326},
	number = {4},
	journal = {Technometrics},
	author = {Wikle, Christopher K},
	month = nov,
	year = {2005},
	note = {Publisher: Taylor \& Francis},
	pages = {521--521},
	annote = {doi: 10.1198/tech.2005.s326}
}

@article{glahn_use_1972-1,
	title = {The {Use} of {Model} {Output} {Statistics} ({MOS}) in {Objective} {Weather} {Forecasting}},
	volume = {11},
	issn = {00218952, 2163534X},
	url = {http://www.jstor.org/stable/26176961},
	abstract = {[Model Output Statistics (MOS) is an objective weather forecasting technique which consists of determining a statistical relationship between a predictand and variables forecast by a numerical model at some projection time(s). It is, in effect, the determination of the "weather related" statistics of a numerical model. This technique, together with screening regression, has been applied to the prediction of surface wind, probability of precipitation, maximum temperature, cloud amount, and conditional probability of frozen precipitation. Predictors used include surface observations at initial time and predictions from the Subsynoptic Advection Model (SAM) and the Primitive Equation model used operationally by the National Weather Service. Verification scores have been computed, and, where possible, compared to scores for forecasts from other objective techniques and for the official forecasts. MOS forecasts of surface wind, probability of precipitation, and conditional probability of frozen precipitation are being disseminated by the National Weather Service over teletype and facsimile. It is concluded that MOS is a useful technique in objective weather forecasting.]},
	number = {8},
	urldate = {2021-06-16},
	journal = {Journal of Applied Meteorology (1962-1982)},
	author = {Glahn, Harry R. and Lowry, Dale A.},
	year = {1972},
	note = {Publisher: American Meteorological Society},
	pages = {1203--1211}
}

@book{wilks_statistical_2011,
	title = {Statistical methods in the atmospheric sciences},
	volume = {100},
	publisher = {Academic press},
	author = {Wilks, Daniel S},
	year = {2011}
}

@article{cacuci_sensitivity_1981,
	title = {Sensitivity theory for nonlinear systems. {I}. {Nonlinear} functional analysis approach},
	volume = {22},
	issn = {0022-2488},
	url = {https://doi.org/10.1063/1.525186},
	doi = {10.1063/1.525186},
	number = {12},
	urldate = {2021-06-16},
	journal = {Journal of Mathematical Physics},
	author = {Cacuci, Dan G.},
	month = dec,
	year = {1981},
	note = {Publisher: American Institute of Physics},
	pages = {2794--2802},
	annote = {doi: 10.1063/1.525186}
}

@article{talagrand_use_1991,
	title = {The use of adjoint equations in numerical modelling of the atmospheric circulation},
	volume = {169},
	journal = {Automatic differentiation of algorithms: theory, implementation, and application},
	author = {Talagrand, Olivier},
	year = {1991},
	note = {Publisher: SIAM Philadelphia, PA},
	pages = {180}
}

@techreport{yang_documentation_1996,
	title = {Documentation of the {Tangent} {Linear} {Model} and {Its} {Adjoint} of the {Adiabatic} {Version} of the {NASA} {GEOS}-1 {C}-{Grid} {GCM}, {Version} 5.2},
	institution = {National Aeronautics and Space Administration, Goddard Space Flight Center},
	author = {Yang, Weiyu and Navon, Ionel Michael},
	year = {1996},
	pages = {66}
}

@article{giering_adjoint_1995,
	title = {Adjoint {Model} {Compiler}},
	journal = {MPI report},
	author = {Giering, Ralf},
	year = {1995}
}

@article{rostaing_automatic_1993,
	title = {Automatic differentiation in {Odyssée}},
	volume = {45},
	issn = {null},
	url = {https://doi.org/10.3402/tellusa.v45i5.15060},
	doi = {10.3402/tellusa.v45i5.15060},
	abstract = {This paper describes the design of Odyssée, a system for fortran programs manipulations and its application to automatic differentiation. The Odyssée system manipulates fortran programs as symbolic objects. It is an open system built as a toolkit, written in a high-level programming language adapted to this purpose. The use of a variational method to perform data assimilation requires the computation of the gradient of a cost function represented by a large-size fortran program. The usual drawback in the reverse automatic differentiation method is the storage requirement. The Odyssée system allows one to implement storage/recomputation strategies in order to fit the needed compromizes. We present the implementation of the strategy used in the weather forecasting arpege/ifs project to produce the adjoint code from the code representing the numerical model. Odyssée produces the same code as the hand-written adjoint code for thearpege/ifs project.},
	number = {5},
	journal = {Tellus A: Dynamic Meteorology and Oceanography},
	author = {Rostaing, Nicole and Dalmas, StéPhane and Galligo, André},
	month = jan,
	year = {1993},
	note = {Publisher: Taylor \& Francis},
	pages = {558--568},
	annote = {doi: 10.3402/tellusa.v45i5.15060}
}

@article{penny_hybrid_2015,
	title = {A {Hybrid} {Global} {Ocean} {Data} {Assimilation} {System} at {NCEP}},
	volume = {143},
	url = {https://journals.ametsoc.org/view/journals/mwre/143/11/mwr-d-14-00376.1.xml},
	doi = {10.1175/MWR-D-14-00376.1},
	language = {English},
	number = {11},
	journal = {Monthly Weather Review},
	author = {Penny, Stephen G. and Behringer, David W. and Carton, James A. and Kalnay, Eugenia},
	month = nov,
	year = {2015},
	note = {Place: Boston MA, USA
Publisher: American Meteorological Society},
	pages = {4660--4677}
}

@article{wikner_combining_2020,
	title = {Combining machine learning with knowledge-based modeling for scalable forecasting and subgrid-scale closure of large, complex, spatiotemporal systems},
	volume = {30},
	issn = {1054-1500},
	url = {https://doi.org/10.1063/5.0005541},
	doi = {10.1063/5.0005541},
	number = {5},
	urldate = {2021-06-21},
	journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
	author = {Wikner, Alexander and Pathak, Jaideep and Hunt, Brian and Girvan, Michelle and Arcomano, Troy and Szunyogh, Istvan and Pomerance, Andrew and Ott, Edward},
	month = may,
	year = {2020},
	note = {Publisher: American Institute of Physics},
	pages = {053111},
	annote = {doi: 10.1063/5.0005541}
}

@article{kochkov_machine_2021,
	title = {Machine learning–accelerated computational fluid dynamics},
	volume = {118},
	url = {http://www.pnas.org/content/118/21/e2101784118.abstract},
	doi = {10.1073/pnas.2101784118},
	abstract = {Accurate simulation of fluids is important for many science and engineering problems but is very computationally demanding. In contrast, machine-learning models can approximate physics very quickly but at the cost of accuracy. Here we show that using machine learning inside traditional fluid simulations can improve both accuracy and speed, even on examples very different from the training data. Our approach opens the door to applying machine learning to large-scale physical modeling tasks like airplane design and climate prediction.Numerical simulation of fluids plays an essential role in modeling many physical phenomena, such as weather, climate, aerodynamics, and plasma physics. Fluids are well described by the Navier–Stokes equations, but solving these equations at scale remains daunting, limited by the computational cost of resolving the smallest spatiotemporal features. This leads to unfavorable trade-offs between accuracy and tractability. Here we use end-to-end deep learning to improve approximations inside computational fluid dynamics for modeling two-dimensional turbulent flows. For both direct numerical simulation of turbulence and large-eddy simulation, our results are as accurate as baseline solvers with 8 to 10× finer resolution in each spatial dimension, resulting in 40- to 80-fold computational speedups. Our method remains stable during long simulations and generalizes to forcing functions and Reynolds numbers outside of the flows where it is trained, in contrast to black-box machine-learning approaches. Our approach exemplifies how scientific computing can leverage machine learning and hardware accelerators to improve simulations without sacrificing accuracy or generalization.Source code for our models, including learned components, and training and evaluation datasets are available at GitHub (https://github.com/google/jax-cfd).},
	number = {21},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Kochkov, Dmitrii and Smith, Jamie A. and Alieva, Ayya and Wang, Qing and Brenner, Michael P. and Hoyer, Stephan},
	month = may,
	year = {2021},
	pages = {e2101784118}
}

@article{arcomano_machine_2020,
	title = {A {Machine} {Learning}-{Based} {Global} {Atmospheric} {Forecast} {Model}},
	volume = {47},
	issn = {0094-8276},
	url = {https://doi.org/10.1029/2020GL087776},
	doi = {10.1029/2020GL087776},
	abstract = {Abstract The paper investigates the applicability of machine learning (ML) to weather prediction by building a reservoir computing-based, low-resolution, global prediction model. The model is designed to take advantage of the massively parallel architecture of a modern supercomputer. The forecast performance of the model is assessed by comparing it to that of daily climatology, persistence, and a numerical (physics-based) model of identical prognostic state variables and resolution. Hourly resolution 20-day forecasts with the model predict realistic values of the atmospheric state variables at all forecast times for the entire globe. The ML model outperforms both climatology and persistence for the first three forecast days in the midlatitudes, but not in the tropics. Compared to the numerical model, the ML model performs best for the state variables most affected by parameterized processes in the numerical model.},
	number = {9},
	urldate = {2021-06-21},
	journal = {Geophysical Research Letters},
	author = {Arcomano, Troy and Szunyogh, Istvan and Pathak, Jaideep and Wikner, Alexander and Hunt, Brian R. and Ott, Edward},
	month = may,
	year = {2020},
	note = {Publisher: John Wiley \& Sons, Ltd},
	pages = {e2020GL087776},
	annote = {https://doi.org/10.1029/2020GL087776}
}

@article{lu_attractor_2018,
	title = {Attractor reconstruction by machine learning},
	volume = {28},
	issn = {1054-1500},
	url = {https://doi.org/10.1063/1.5039508},
	doi = {10.1063/1.5039508},
	number = {6},
	urldate = {2021-06-21},
	journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
	author = {Lu, Zhixin and Hunt, Brian R. and Ott, Edward},
	month = jun,
	year = {2018},
	note = {Publisher: American Institute of Physics},
	pages = {061104},
	annote = {doi: 10.1063/1.5039508}
}

@article{boukabara_outlook_2021,
	title = {Outlook for exploiting artificial intelligence in the earth and environmental sciences},
	volume = {102},
	number = {5},
	journal = {Bulletin of the American Meteorological Society},
	author = {Boukabara, Sid-Ahmed and Krasnopolsky, Vladimir and Penny, Stephen G and Stewart, Jebb Q and McGovern, Amy and Hall, David and Ten Hoeve, John E and Hickey, Jason and Allen Huang, Hung-Lung and Williams, John K and {others}},
	year = {2021},
	pages = {E1016--E1032}
}

@article{bonavita_machine_2021,
	title = {Machine learning for earth system observation and prediction},
	volume = {102},
	number = {4},
	journal = {Bulletin of the American Meteorological Society},
	author = {Bonavita, Massimo and Arcucci, Rossella and Carrassi, Alberto and Dueben, Peter and Geer, Alan J and Le Saux, Bertrand and Longépé, Nicolas and Mathieu, Pierre-Philippe and Raynaud, Laure},
	year = {2021},
	pages = {E710--E716}
}

@book{krasnopolsky_application_2013,
	title = {The application of neural networks in the earth system sciences},
	volume = {46},
	isbn = {978-94-007-6073-8},
	url = {https://www.springer.com/gp/book/9789400760721},
	author = {Krasnopolsky, Vladimir M},
	year = {2013},
	note = {Publisher: Springer}
}

@article{norwood_lyapunov_2013,
	title = {Lyapunov, singular and bred vectors in a multi-scale system: an empirical exploration of vectors related to instabilities},
	volume = {46},
	issn = {1751-8113},
	url = {http://dx.doi.org/10.1088/1751-8113/46/25/254021},
	doi = {10.1088/1751-8113/46/25/254021},
	abstract = {We compute and compare the three types of vectors frequently used to explore the instability properties of dynamical models, namely Lyapunov vectors (LVs), singular vectors (SVs) and bred vectors (BVs) in two systems, using the Wolfe–Samelson (2007 Tellus A 59 355–66) algorithm to compute all of the Lyapunov vectors. The first system is the Lorenz (1963 J. Atmos. Sci. 20 130–41) three-variable model. Although the leading Lyapunov vector, LV1, grows fastest globally, the second Lyapunov vector, LV2, which has zero growth globally, often grows faster than LV1 locally. Whenever this happens, BVs grow closer to LV2, suggesting that in larger atmospheric or oceanic models where several instabilities can grow in different areas of the world, BVs will grow toward the fastest growing local unstable mode. A comparison of their growth rates at different times shows that all three types of dynamical vectors have the ability to predict regime changes and the duration of the new regime based on their growth rates in the last orbit of the old regime, as shown for BVs by Evans et al (2004 Bull. Am. Meteorol. Soc. 520–4). LV1 and BVs have similar predictive skill, LV2 has a tendency to produce false alarms, and even LV3 shows that maximum decay is also associated with regime change. Initial and final SVs grow much faster and are the most accurate predictors of regime change, although the characteristics of the initial SVs are strongly dependent on the length of the optimization window. The second system is the toy ‘ocean-atmosphere’ model developed by Peña and Kalnay (2004 Nonlinear Process. Geophys. 11 319–27) coupling three Lorenz (1963 J. Atmos. Sci. 20 130–41) systems with different time scales, in order to test the effects of fast and slow modes of growth on the dynamical vectors. A fast ‘extratropical atmosphere’ is weakly coupled to a fast ‘tropical atmosphere’ which is, in turn, strongly coupled to a slow ‘ocean’ system, the latter coupling imitating the tropical El Niño–Southern Oscillation. The bred vectors are able to separate the fast and slow modes of growth through appropriate selection of the breeding perturbation size and rescaling interval. The Lyapunov vectors are able to successfully separate the fast ‘extratropical atmosphere’, but are unable to completely decouple the ‘tropical atmosphere’ from the ‘ocean’. This leads to ‘coupled’ Lyapunov vectors that are mainly useful in the (slow) ‘ocean’ system, but are still affected by changes in the (fast) ‘tropical’ system. The singular vectors are excellent in capturing the fast modes, but are unable to capture the slow modes of growth. The dissimilar behavior of the three types of vectors leads to a degradation in the similarities of the subspaces they inhabit and affects their relative ability of representing the coupled modes.

This article is part of a special issue of Journal of Physics A: Mathematical and Theoretical devoted to ‘Lyapunov analysis: from dynamical systems theory to applications’.},
	number = {25},
	journal = {Journal of Physics A: Mathematical and Theoretical},
	author = {Norwood, Adrienne and Kalnay, Eugenia and Ide, Kayo and Yang, Shu-Chih and Wolfe, Christopher},
	month = jun,
	year = {2013},
	note = {Publisher: IOP Publishing},
	pages = {254021}
}
